<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    如何让单机下 Netty 支持百万长连接 - 大爷来玩儿啊~
    
    </title>
    <link rel="shortcut icon" href="media/15865826719099/icon.png" type="image/png" />

    
    
    <link href="atom.xml" rel="alternate" title="大爷来玩儿啊~" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="index.html">博客</a>
                
                <a target="_self" class="navbar-item " href="archives.html">归档</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            如何让单机下 Netty 支持百万长连接   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <figure class="media-left">
                              <p class="image is-48x48">
                                
                                  <img class="is-rounded" src="media/15865826719099/avatar.png">
                                
                              </p>
                            </figure>
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2020/10/04</span>
                                  <span class="tran-posted-in">posted in</span>&nbsp; 
                                  
                                      <span class="posted-in"><a href='%E9%9D%A2%E8%AF%95%E9%A2%98.html'>面试题</a></span>
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <p>单机下能不能让我们的网络应用支持百万连接?可以，但是有很多的工作要做。</p>
<h2><a id="%E9%A6%96%E5%85%88%E5%B0%B1%E6%98%AF%E8%A6%81%E7%AA%81%E7%A0%B4%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%99%90%E5%88%B6%E3%80%82" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>首先就是要突破操作系统的限制。</h2>
<p>在Linux平台上，无论编写客户端程序还是服务端程序，在进行高并发TCP连接处理时， 最高的并发数量都要受到系统对用户单一进程同时可打开文件数量的限制(这是因为系统为 每个 TCP 连接都要创建一个 socket 句柄，每个 socket 句柄同时也是一个文件句柄)。</p>
<p>可使用 ulimit 命令查看系统允许当前用户进程打开的文件数限制:</p>
<pre><code class="language-shell">&gt; ulimit -n
1024
</code></pre>
<p>这表示当前用户的每个进程最多允许同时打开 1024 个文件，这 1024 个文件中还得除去 每个进程必然打开的标准输入，标准输出，标准错误，服务器监听 socket,进程间通讯的 unix 域 socket 等文件，那么剩下的可用于客户端 socket 连接的文件数就只有大概 1024-10=1014 个左右。也就是说缺省情况下，基于 Linux 的通讯程序最多允许同时 1014 个 TCP 并发连接。</p>
<p>对于想支持更高数量的 TCP 并发连接的通讯处理程序，就必须修改 Linux 对当前用户 的进程同时打开的文件数量。</p>
<p>修改单个进程打开最大文件数限制的最简单的办法就是使用 ulimit 命令:</p>
<pre><code class="language-plain_text">&gt; ulimit –n 1000000
</code></pre>
<p>如果系统回显类似于&quot;Operation not permitted&quot;之类的话，说明上述限制修改失败，实际上是因为在中指定的数值超过了 Linux 系统对该用户打开文件数的软限制或硬限制。因此， 就需要修改 Linux 系统对用户的关于打开文件数的软限制和硬限制。</p>
<p>软限制(soft limit):是指 Linux 在当前系统能够承受的范围内进一步限制一个进程同时打开的文件数;</p>
<p>硬限制(hardlimit):是根据系统硬件资源状况(主要是系统内存)计算出来的系统最多 可同时打开的文件数量。</p>
<p>修改限制的具体操作步骤:</p>
<ul>
<li>第一步，修改/etc/security/limits.conf 文件，在文件中添加如下行:</li>
</ul>
<pre><code class="language-plain_text">* soft nofile 1000000
* hard nofile 1000000
</code></pre>
<p>'*' 号表示修改所有用户的限制;</p>
<p>soft 和 hard 为两种限制方式，其中 soft 表示警告的限制，hard 表示真正限制，nofile 表示打开的最大文件数。1000000 则指定了想要修改的新的限制值，即最大打开文件数(请 注意软限制值要小于或等于硬限制)。修改完后保存文件。</p>
<ul>
<li>
<p>第二步，修改/etc/pam.d/login 文件，在文件中添加如下行: session required /lib/security/pam_limits.so<br />
这是告诉 Linux 在用户完成系统登录后，应该调用 pam_limits.so 模块来设置系统对该用 户可使用的各种资源数量的最大限制(包括用户可打开的最大文件数限制)，而 pam_limits.so 模块就会从/etc/security/limits.conf 文件中读取配置来设置这些限制值。修改完后保存此文 件。</p>
</li>
<li>
<p>第三步，查看 Linux 系统级的最大打开文件数限制，使用如下命令:</p>
</li>
</ul>
<pre><code class="language-plain_text">&gt; cat /proc/sys/fs/file-max
12158
</code></pre>
<p>这表明这台Linux系统最多允许同时打开(即包含所有用户打开文件数总和)12158 个文件，是 Linux 系统级硬限制，所有用户级的打开文件数限制都不应超过这个数值。如果 没有特殊需要，不应该修改此限制，除非想为用户级打开文件数限制设置超过此限制的值。</p>
<p>如何修改这个系统最大文件描述符的限制呢? 修改 sysctl.conf 文件</p>
<pre><code class="language-plain_text">vi /etc/sysctl.conf

# 在末尾添加 
fs.file_max = 1000000
# 立即生效 
sysctl -p
</code></pre>
<h2><a id="netty%E8%B0%83%E4%BC%98" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Netty 调优</h2>
<h3><a id="%E8%AE%BE%E7%BD%AE%E5%90%88%E7%90%86%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%95%B0" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>设置合理的线程数</h3>
<p>对于线程池的调优,主要集中在用于接收海量设备 TCP 连接、TLS 握手的 Acceptor 线程 池( Netty 通常叫 boss NioEventLoop Group)上,以及用于处理网络数据读写、心跳发送的 1O 工作线程池(Nety 通常叫 work Nio EventLoop Group)上。</p>
<p>对于 Nety 服务端,通常只需要启动一个监听端口用于端侧设备接入即可,但是如果服务 端集群实例比较少,甚至是单机(或者双机冷备)部署,在端侧设备在短时间内大量接入时,需要 对服务端的监听方式和线程模型做优化,以满足短时间内(例如 30s)百万级的端侧设备接入的 需要。</p>
<p>服务端可以监听多个端口,利用主从 Reactor 线程模型做接入优化,前端通过 SLB 做 4层、7层负载均衡。</p>
<p>主从 Reactor 线程模型特点如下:服务端用于接收客户端连接的不再是一个单独的 NO 线程,而是一个独立的NIO线程池; Acceptor接收到客户端TCP连接请求并处理后(可能包含接 入认证等),将新创建的 Socketchanne 注册到 I/O 线程池(subReactor 线程池)的某个 IO 线程, 由它负责 Socketchannel 的读写和编解码工作; Acceptor 线程池仅用于客户端的登录、握手和 安全认证等,一旦链路建立成功,就将链路注册到后端 sub reactor 线程池的 IO 线程,由 IO 线程 负责后续的 IO 操作。</p>
<p>对于 IO 工作线程池的优化,可以先采用系统默认值(即 CPU 内核数×2)进行性能测试,在 性能测试过程中采集 IO 线程的 CPU 占用大小,看是否存在瓶颈， 具体可以观察线程堆栈， 如果连续采集几次进行对比,发现线程堆栈都停留在 Selectorlmpl. lockAndDoSelect，则说明 IO 线程比较空闲,无须对工作线程数做调整。</p>
<p>如果发现 IO 线程的热点停留在读或者写操作,或者停留在 Channelhandler 的执行处,则 可以通过适当调大 Nio EventLoop 线程的个数来提升网络的读写性能。</p>
<h3><a id="%E5%BF%83%E8%B7%B3%E4%BC%98%E5%8C%96" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>心跳优化</h3>
<p>针对海量设备接入的服务端,心跳优化策略如下。</p>
<ul>
<li>(1)要能够及时检测失效的连接,并将其剔除,防止无效的连接句柄积压,导致 OOM 等问题</li>
<li>(2)设置合理的心跳周期,防止心跳定时任务积压,造成频繁的老年代 GC(新生代和老年代 都有导致 STW 的 GC,不过耗时差异较大),导致应用暂停</li>
<li>(3)使用 Nety 提供的链路空闲检测机制,不要自己创建定时任务线程池,加重系统的负担, 以及增加潜在的并发安全问题。</li>
</ul>
<p>当设备突然掉电、连接被防火墙挡住、长时间 GC 或者通信线程发生非预期异常时,会导 致链路不可用且不易被及时发现。特别是如果异常发生在凌晨业务低谷期间,当早晨业务高 峰期到来时,由于链路不可用会导致瞬间大批量业务失败或者超时,这将对系统的可靠性产生 重大的威胁。</p>
<p>从技术层面看,要解决链路的可靠性问题,必须周期性地对链路进行有效性检测。目前最 流行和通用的做法就是心跳检测。</p>
<p>心跳检测机制分为三个层面:</p>
<ul>
<li>(1)TCP 层的心跳检测,即 TCP 的 Keep-Alive 机制,它的作用域是整个 TCP 协议栈。</li>
<li>(2)协议层的心跳检测,主要存在于长连接协议中,例如 MQTT。</li>
<li>(3)应用层的心跳检测,它主要由各业务产品通过约定方式定时给对方发送心跳消息实现。</li>
</ul>
<p>心跳检测的目的就是确认当前链路是否可用,对方是否活着并且能够正常接收和发送消 息。作为高可靠的 NIO 框架,Nety 也提供了心跳检测机制。</p>
<p>一般的心跳检测策略如下：</p>
<ul>
<li>(1)连续 N 次心跳检测都没有收到对方的 Pong 应答消息或者 Ping 请求消息,则认为链路已经发生逻辑失效,这被称为心跳超时。</li>
<li>(2)在读取和发送心跳消息的时候如果直接发生了 IO 异常,说明链路已经失效,这被称为 心跳失败。无论发生心跳超时还是心跳失败,都需要关闭链路,由客户端发起重连操作,保证链 路能够恢复正常。</li>
</ul>
<p>Nety 提供了三种链路空闲检测机制,利用该机制可以轻松地实现心跳检测</p>
<ul>
<li>(1)读空闲,链路持续时间 T 没有读取到任何消息。</li>
<li>(2)写空闲,链路持续时间 T 没有发送任何消息</li>
<li>(3)读写空闲,链路持续时间 T 没有接收或者发送任何消息</li>
</ul>
<p>对于百万级的服务器，一般不建议很长的心跳周期和超时时长。</p>
<h3><a id="%E6%8E%A5%E6%94%B6%E5%92%8C%E5%8F%91%E9%80%81%E7%BC%93%E5%86%B2%E5%8C%BA%E8%B0%83%E4%BC%98" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>接收和发送缓冲区调优</h3>
<p>在一些场景下,端侧设备会周期性地上报数据和发送心跳,单个链路的消息收发量并不大, 针对此类场景,可以通过调小 TCP 的接收和发送缓冲区来降低单个 TCP 连接的资源占用率</p>
<p>当然对于不同的应用场景,收发缓冲区的最优值可能不同,用户需要根据实际场景,结合 性能测试数据进行针对性的调优</p>
<h3><a id="%E5%90%88%E7%90%86%E4%BD%BF%E7%94%A8%E5%86%85%E5%AD%98%E6%B1%A0" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>合理使用内存池</h3>
<p>随着 JVM 虚拟机和 JT 即时编译技术的发展,对象的分配和回收是一个非常轻量级的工作。 但是对于缓冲区 Buffer,情况却稍有不同,特别是堆外直接内存的分配和回收,是一个耗时的 操作。</p>
<p>为了尽量重用缓冲区,Nety 提供了基于内存池的缓冲区重用机制。</p>
<p>在百万级的情况下,需要为每个接入的端侧设备至少分配一个接收和发送 ByteBuf 缓冲 区对象,采用传统的非池模式,每次消息读写都需要创建和释放 ByteBuf对象,如果有100万个 连接,每秒上报一次数据或者心跳,就会有 100 万次/秒的 ByteBuf 对象申请和释放,即便服务 端的内存可以满足要求,GC 的压力也会非常大。</p>
<p>以上问题最有效的解决方法就是使用内存池,每个 NioEventLoop 线程处理 N 个链路,在 线程内部,链路的处理是串行的。假如 A 链路首先被处理,它会创建接收缓冲区等对象,待解码 完成,构造的 POJO 对象被封装成任务后投递到后台的线程池中执行,然后接收缓冲区会被释 放,每条消息的接收和处理都会重复接收缓冲区的创建和释放。如果使用内存池,则当 A 链路 接收到新的数据报时,从 NioEventLoop 的内存池中申请空闲的 ByteBuf,解码后调用 release 将 ByteBuf 释放到内存池中,供后续的 B 链路使用。</p>
<p>Nety 内存池从实现上可以分为两类:堆外直接内存和堆内存。由于 Byte Buf 主要用于网 络 IO 读写,因此采用堆外直接内存会减少一次从用户堆内存到内核态的字节数组拷贝,所以 性能更高。由于 DirectByteBuf 的创建成本比较高,因此如果使用 DirectByteBuf,则需要配合内 存池使用,否则性价比可能还不如 Heap Byte。</p>
<p>Netty 默认的 IO 读写操作采用的都是内存池的堆外直接内存模式,如果用户需要额外使 用 ByteBuf,建议也采用内存池方式;如果不涉及网络 IO 操作(只是纯粹的内存操作),可以使用 堆内存池,这样内存的创建效率会更高一些。</p>
<h3><a id="io%E7%BA%BF%E7%A8%8B%E5%92%8C%E4%B8%9A%E5%8A%A1%E7%BA%BF%E7%A8%8B%E5%88%86%E7%A6%BB" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>IO 线程和业务线程分离</h3>
<p>如果服务端不做复杂的业务逻辑操作,仅是简单的内存操作和消息转发,则可以通过调大<br />
NioEventLoop工作线程池的方式,直接在IO线程中执行业务 Channelhandler,这样便减少了一 次线程上下文切换,性能反而更高。</p>
<p>如果有复杂的业务逻辑操作,则建议 IO 线程和业务线程分离,对于 IO 线程,由于互相之间 不存在锁竞争,可以创建一个大的 NioEvent Loop Group 线程组,所有 Channel 都共享同一个 线程池。</p>
<p>对于后端的业务线程池,则建议创建多个小的业务线程池,线程池可以与 IO 线程绑定,这 样既减少了锁竞争,又提升了后端的处理性能。</p>
<h3><a id="%E9%92%88%E5%AF%B9%E7%AB%AF%E4%BE%A7%E5%B9%B6%E5%8F%91%E8%BF%9E%E6%8E%A5%E6%95%B0%E7%9A%84%E6%B5%81%E6%8E%A7" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>针对端侧并发连接数的流控</h3>
<p>无论服务端的性能优化到多少,都需要考虑流控功能。当资源成为瓶颈,或者遇到端侧设 备的大量接入,需要通过流控对系统做保护。流控的策略有很多种，比如针对端侧连接数的 流控:</p>
<p>在 Nety 中,可以非常方便地实现流控功能:新增一个FlowControlchannelhandler，然后添 加到 ChannelPipeline 靠前的位置,覆盖 channelActive()方法,创建 TCP 链路后,执行流控逻辑, 如果达到流控阈值,则拒绝该连接,调用 ChannelHandler Context 的 close(方法关闭连接。</p>
<h2><a id="jvm%E5%B1%82%E9%9D%A2%E7%9B%B8%E5%85%B3%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>JVM 层面相关性能优化</h2>
<p>当客户端的并发连接数达到数十万或者数百万时,系统一个较小的抖动就会导致很严重 的后果,例如服务端的 GC,导致应用暂停(STW)的 GC 持续几秒,就会导致海量的客户端设备掉 线或者消息积压,一旦系统恢复,会有海量的设备接入或者海量的数据发送很可能瞬间就把服 务端冲垮。</p>
<p>JVM 层面的调优主要涉及 GC 参数优化,GC 参数设置不当会导致频繁 GC,甚至 OOM 异常, 对服务端的稳定运行产生重大影响。</p>
<h3><a id="%E7%A1%AE%E5%AE%9Agc%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87-gc%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E6%9C%89%E4%B8%89%E4%B8%AA%E4%B8%BB%E8%A6%81%E6%8C%87%E6%A0%87%E3%80%82" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>确定 GC 优化目标 GC(垃圾收集)有三个主要指标。</h3>
<ul>
<li>(1)吞吐量:是评价 GC 能力的重要指标,在不考虑 GC 引起的停顿时间或内存消耗时,吞吐 量是 GC 能支撑应用程序达到的最高性能指标。</li>
<li>(2)延迟:GC 能力的最重要指标之一,是由于 GC 引起的停顿时间,优化目标是缩短延迟时 间或完全消除停顿(STW),避免应用程序在运行过程中发生抖动。</li>
<li>(3)内存占用:GC 正常时占用的内存量。</li>
</ul>
<h3><a id="jvm-gc%E8%B0%83%E4%BC%98%E7%9A%84%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99%E5%A6%82%E4%B8%8B%E3%80%82" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>JVM GC 调优的三个基本原则如下。</h3>
<ul>
<li>
<p>(1) Minor go 回收原则:每次新生代 GC 回收尽可能多的内存,减少应用程序发生 Full gc 的 频率。</p>
</li>
<li>
<p>(2)GC 内存最大化原则:垃圾收集器能够使用的内存越大,垃圾收集效率越高,应用程序运 行也越流畅。但是过大的内存一次 Full go 耗时可能较长,如果能够有效避免 FullGC,就需要做 精细化调优。</p>
</li>
<li>
<p>(3) 3 选 2 原则:吞吐量、延迟和内存占用不能兼得,无法同时做到吞吐量和暂停时间都最 优,需要根据业务场景做选择。对于大多数应用,吞吐量优先,其次是延迟。当然对于时延敏感 型的业务,需要调整次序。</p>
</li>
</ul>
<h3><a id="%E7%A1%AE%E5%AE%9A%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>确定服务端内存占用</h3>
<p>在优化 GC 之前,需要确定应用程序的内存占用大小,以便为应用程序设置合适的内存,提升 GC 效率。内存占用与活跃数据有关,活跃数据指的是应用程序稳定运行时长时间存活的 Java 对象。活跃数据的计算方式:通过 GC 日志采集 GC 数据,获取应用程序稳定时老年代占用 的 Java 堆大小,以及永久代(元数据区)占用的 Java 堆大小,两者之和就是活跃数据的内存占用 大小。</p>
<h3><a id="gc%E4%BC%98%E5%8C%96%E8%BF%87%E7%A8%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>GC 优化过程</h3>
<ul>
<li>GC 数据的采集和研读</li>
<li>设置合适的 JVM 堆大小</li>
<li>选择合适的垃圾回收器和回收策略</li>
</ul>
<p>当然具体如何做，请参考 JVM 相关课程。而且 GC 调优会是一个需要多次调整的过程， 期间不仅有参数的变化，更重要的是需要调整业务代码</p>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
              Copyright &copy; 2019
              Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
              Theme used <a target="_blank" href="https://bulma.io/">Bulma CSS</a>.
          </p>
        </div>
      </footer>



  













<script src="asset/prism.js"></script>



  
    




  </body>
</html>
