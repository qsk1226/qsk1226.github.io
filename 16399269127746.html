<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    ElasticSearch 文本分析 - 大爷来玩儿啊~
    
    </title>
    <link rel="shortcut icon" href="media/15865826719099/icon.png" type="image/png" />

    
    
    <link href="atom.xml" rel="alternate" title="大爷来玩儿啊~" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="index.html">博客</a>
                
                <a target="_self" class="navbar-item " href="archives.html">归档</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            ElasticSearch 文本分析   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <figure class="media-left">
                              <p class="image is-48x48">
                                
                                  <img class="is-rounded" src="media/15865826719099/avatar.png">
                                
                              </p>
                            </figure>
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2021/12/19</span>
                                  <span class="tran-posted-in">posted in</span>&nbsp; 
                                  
                                      <span class="posted-in"><a href='ELK.html'>ELK</a></span>
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <ul>
<li><a href="#1%E3%80%81%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90">1、文本分析</a>
<ul>
<li><a href="#1-1%E3%80%81%E5%AD%97%E7%AC%A6%E8%BF%87%E6%BB%A4">1.1、字符过滤</a></li>
<li><a href="#1-2%E3%80%81%E5%88%87%E5%88%86%E4%B8%BA%E5%88%86%E8%AF%8D">1.2、切分为分词</a></li>
<li><a href="#1-3%E3%80%81%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8">1.3、分词过滤器</a></li>
<li><a href="#1-4%E3%80%81%E5%88%86%E8%AF%8D%E7%B4%A2%E5%BC%95">1.4、分词索引</a></li>
<li><a href="#1-5%E3%80%81%E5%88%86%E6%9E%90%E5%99%A8">1.5、分析器</a></li>
</ul>
</li>
<li><a href="#2%E3%80%81%E9%85%8D%E7%BD%AE%E5%88%86%E6%9E%90%E5%99%A8">2、配置分析器</a>
<ul>
<li><a href="#2-1%E3%80%81%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E6%97%B6">2.1、创建索引时</a>
<ul>
<li><a href="#2-1-1%E3%80%81%E8%AE%BE%E7%BD%AE%E7%B4%A2%E5%BC%95%E9%BB%98%E8%AE%A4%E5%88%86%E8%AF%8D%E5%99%A8">2.1.1、设置索引默认分词器</a></li>
<li><a href="#2-1-2%E3%80%81%E4%B8%BA%E5%AD%97%E6%AE%B5%E6%8C%87%E5%AE%9A%E5%86%85%E7%BD%AE%E5%88%86%E8%AF%8D%E5%99%A8">2.1.2、为字段指定内置分词器</a></li>
</ul>
</li>
<li><a href="#2-2%E3%80%81%E6%96%87%E6%A1%A3%E6%90%9C%E7%B4%A2%E6%97%B6">2.2、文档搜索时</a>
<ul>
<li><a href="#2-2-1%E3%80%81%E6%90%9C%E7%B4%A2%E6%97%B6%E6%8C%87%E5%AE%9A-analyzer%E6%9F%A5%E8%AF%A2%E5%8F%82%E6%95%B0">2.2.1、搜索时指定 analyzer 查询参数</a></li>
<li><a href="#2-2-2%E3%80%81%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E6%97%B6%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E7%9A%84-analyzer%E5%92%8C-seach-analyzer">2.2.2、创建索引时指定字段的 analyzer 和 seach_analyzer</a></li>
<li><a href="#2-2-3%E3%80%81%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E6%97%B6%E6%8C%87%E5%AE%9A%E7%B4%A2%E5%BC%95%E7%9A%84%E9%BB%98%E8%AE%A4%E6%90%9C%E7%B4%A2%E5%88%86%E8%AF%8D%E5%99%A8">2.2.3、创建索引时指定索引的默认搜索分词器</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3%E3%80%81%E5%86%85%E7%BD%AE%E5%88%86%E6%9E%90%E5%99%A8">3、内置分析器</a>
<ul>
<li><a href="#3-1%E3%80%81%E5%AD%97%E7%AC%A6%E8%BF%87%E6%BB%A4%E5%99%A8-character-filters">3.1、字符过滤器(Character filters)</a>
<ul>
<li><a href="#3-1-1%E3%80%81html%E5%AD%97%E7%AC%A6%E8%BF%87%E6%BB%A4%E5%99%A8-html-strip-char-filter">3.1.1、HTML 字符过滤器(HTML Strip Char Filter)</a></li>
<li><a href="#3-1-2%E3%80%81%E6%98%A0%E5%B0%84%E5%AD%97%E7%AC%A6%E8%BF%87%E6%BB%A4%E5%99%A8-mapping-char-filter">3.1.2、映射字符过滤器(Mapping Char Filter)</a></li>
<li><a href="#3-1-3%E3%80%81%E6%A8%A1%E5%BC%8F%E6%9B%BF%E6%8D%A2%E8%BF%87%E6%BB%A4%E5%99%A8-pattern-replace-char-filter">3.1.3、模式替换过滤器(Pattern Replace Char Filter)</a></li>
</ul>
</li>
<li><a href="#3-2%E3%80%81%E5%88%86%E8%AF%8D%E5%99%A8%EF%BC%88tokenizer%EF%BC%89">3.2、分词器（Tokenizer）</a>
<ul>
<li><a href="#3-2-1%E3%80%81%E6%A0%87%E5%87%86%E5%88%86%E8%AF%8D%E5%99%A8-standard">3.2.1、标准分词器(standard)</a></li>
<li><a href="#3-2-2%E3%80%81%E5%85%B3%E9%94%AE%E8%AF%8D%E5%88%86%E8%AF%8D%E5%99%A8-keyword">3.2.2、关键词分词器(keyword)</a></li>
<li><a href="#3-2-3%E3%80%81%E5%AD%97%E6%AF%8D%E5%88%86%E8%AF%8D%E5%99%A8-letter">3.2.3、字母分词器(letter)</a></li>
<li><a href="#3-2-4%E3%80%81%E5%B0%8F%E5%86%99%E5%88%86%E8%AF%8D%E5%99%A8-lowercase">3.2.4、小写分词器(lowercase)</a></li>
<li><a href="#3-2-5%E3%80%81%E7%A9%BA%E7%99%BD%E5%88%86%E8%AF%8D%E5%99%A8-whitespace">3.2.5、空白分词器(whitespace)</a></li>
<li><a href="#3-2-6%E3%80%81%E6%A8%A1%E5%BC%8F%E5%88%86%E8%AF%8D%E5%99%A8-pattern">3.2.6、模式分词器(pattern)</a></li>
<li><a href="#3-2-7%E3%80%81uax-url%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6%E5%88%86%E8%AF%8D%E5%99%A8-uax-url-email">3.2.7、UAX URL 电子邮件分词器(uax_url_email)</a></li>
<li><a href="#3-2-8%E3%80%81%E8%B7%AF%E5%BE%84%E5%B1%82%E6%AC%A1%E5%88%86%E8%AF%8D%E5%99%A8-path-hierarchy">3.2.8、路径层次分词器(path_hierarchy)</a></li>
</ul>
</li>
<li><a href="#3-3%E3%80%81%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-token-filters">3.3、分词过滤器(Token filters)</a>
<ul>
<li><a href="#3-3-1%E3%80%81%E6%A0%87%E5%87%86%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-standard">3.3.1、标准分词过滤器(standard)</a></li>
<li><a href="#3-3-2%E3%80%81%E5%B0%8F%E5%86%99%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-lowercase">3.3.2、小写分词过滤器(lowercase)</a></li>
<li><a href="#3-3-3%E3%80%81%E9%95%BF%E5%BA%A6%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-length">3.3.3、长度分词过滤器(length)</a></li>
<li><a href="#3-3-4%E3%80%81%E5%81%9C%E7%94%A8%E8%AF%8D%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-stop">3.3.4、停用词分词过滤器(stop)</a></li>
<li><a href="#3-3-5%E3%80%81%E6%88%AA%E6%96%AD%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8%E3%80%81%E4%BF%AE%E5%89%AA%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8%E5%92%8C%E9%99%90%E5%88%B6%E5%88%86%E8%AF%8D%E6%95%B0%E9%87%8F%E8%BF%87%E6%BB%A4%E5%99%A8">3.3.5、截断分词过滤器、修剪分词过滤器和限制分词数量过滤器</a></li>
</ul>
</li>
<li><a href="#3-4%E3%80%81%E5%B8%B8%E7%94%A8%E5%86%85%E7%BD%AE%E5%88%86%E6%9E%90%E5%99%A8">3.4、常用内置分析器</a>
<ul>
<li><a href="#3-4-1%E3%80%81%E6%A0%87%E5%87%86%E5%88%86%E6%9E%90%E5%99%A8">3.4.1、标准分析器</a></li>
<li><a href="#3-4-2%E3%80%81%E7%AE%80%E5%8D%95%E5%88%86%E6%9E%90%E5%99%A8">3.4.2、简单分析器</a></li>
<li><a href="#3-4-3%E3%80%81%E7%A9%BA%E7%99%BD%E5%88%86%E6%9E%90%E5%99%A8">3.4.3、空白分析器</a></li>
<li><a href="#3-4-4%E3%80%81%E5%81%9C%E7%94%A8%E8%AF%8D%E5%88%86%E6%9E%90%E5%99%A8">3.4.4、停用词分析器</a></li>
<li><a href="#3-4-5%E3%80%81%E5%85%B3%E9%94%AE%E8%AF%8D%E5%88%86%E6%9E%90%E5%99%A8">3.4.5、关键词分析器</a></li>
<li><a href="#3-4-6%E3%80%81%E6%A8%A1%E5%BC%8F%E5%88%86%E6%9E%90%E5%99%A8">3.4.6、模式分析器</a></li>
<li><a href="#3-4-7%E3%80%81%E9%9B%AA%E7%90%83%E5%88%86%E6%9E%90%E5%99%A8">3.4.7、雪球分析器</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#4%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E6%9E%90%E5%99%A8">4、自定义分析器</a></li>
<li><a href="#5%E3%80%81%E4%B8%AD%E6%96%87%E5%88%86%E6%9E%90%E5%99%A8">5、中文分析器</a></li>
</ul>

<p>词条(term)查询和全文(fulltext)查询最大的不同之处是:全文查询首先 分析(Analyze)查询字符串，使用默认的分析器分解成一系列的分词，term1， term2，termN，然后从索引中搜索是否有文档包含这些分词中的一个或多个。</p>
<p>所以，在基于全文的检索里，ElasticSearch 引擎会先分析(analyze)查询字 符串，将其拆分成小写的分词，只要已分析的字段中包含词条的任意一个，或全 部包含，就匹配查询条件，返回该文档;如果不包含任意一个分词，表示没有任何文档匹配查询条件。</p>
<p>这里就牵涉到了 ES 里很重要的概念，文本分析，当然对应非 text 类型字段来说，本身不存在文本数据词项提取的问题，所以没有文本分析的问题。</p>
<hr />
<h2><a id="1%E3%80%81%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1、文本分析</h2>
<p>分析( analysis )是在文档被发送并加入倒排索引之前，Elasticsearch 在其主体 上进行的操作。在文档被加入索引之前，Elasticsearch 让每个被分析字段经过一 系列的处理步骤。</p>
<ul>
<li>字符过滤: 使用字符过滤器转变字符。</li>
<li>文本切分为分词: 将文本切分为单个或多个分词。</li>
<li>分词过滤: 使用分词过滤器转变每个分词。</li>
<li>分词索引: 将这些分词存储到索引中。</li>
</ul>
<p>例如下面一段话：&quot;I want to play games,it include WOW&amp;Diablo&amp;Starcraft&quot;，经过分析后的分词为： i want to play games it include WOW Diablo Starcraft</p>
<h3><a id="1-1%E3%80%81%E5%AD%97%E7%AC%A6%E8%BF%87%E6%BB%A4" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.1、字符过滤</h3>
<p>Elasticsearch 首先运行字符过滤器(char_filter)，这些过滤器将特定的字符 序列转变为其他的字符序列。这个可以用于将 HTML 从文本中剥离，或者是将任 意数量的字符转化为其他字符，例如可将上面的 &quot;I want to.....&quot; 中的 &amp; 转换为 AND</p>
<h3><a id="1-2%E3%80%81%E5%88%87%E5%88%86%E4%B8%BA%E5%88%86%E8%AF%8D" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2、切分为分词</h3>
<p>在应用了字符过滤器之后，文本需要被分割为可以操作的片段。底层的 Lucene 是不会对大块的字符串数据进行操作。相反，它处理的是被称为分词 (token) 的数据。</p>
<p>分词是从文本片段生成的，可能会产生任意数量(甚至是 0)的分词。例如， 在英文中一个通用的分词是标准分词器，它根据空格、换行和破折号等其他字符, 将文本分割为分词。</p>
<h3><a id="1-3%E3%80%81%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3、分词过滤器</h3>
<p>一旦文本块被转换为分词，ES 将会对每个分词运用分词过滤器<br />
(token_filter)，这些分词过滤器可以将一个分词作为输入， 然后根据需要进行 修改，添加或者是删除。最为有用的和常用的分词过滤器是小写分词过滤器,它 将输人的分词变为小写，确保在搜索词条 &quot;mysql&quot; 的时候，可以发现关于 &quot;MySql&quot; 的数据。</p>
<p>分词可以经过多于 1 个的分词过滤器，每个过滤器对分词进行不同的操 作，将数据塑造为最佳的形式，便于之后的索引。</p>
<h3><a id="1-4%E3%80%81%E5%88%86%E8%AF%8D%E7%B4%A2%E5%BC%95" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.4、分词索引</h3>
<p>当分词经历了零个或者多个分词过滤器，它们将被发送到 Lucene 进行文档 的索引。这些分词存入倒排索引。</p>
<h3><a id="1-5%E3%80%81%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.5、分析器</h3>
<p>所有这些不同的部分，组成了一个分析器( analyzer ), 它可以定义为零个或多 个字符过滤器、1 个分词器、零个或多个分词过滤器。</p>
<p>Elasticsearch 中提供了很多预定义的分析器。我们可以直接使用它们而无须构建自己的分析器。</p>
<hr />
<h2><a id="2%E3%80%81%E9%85%8D%E7%BD%AE%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2、配置分析器</h2>
<p>文本分词会发生在两个地方:</p>
<ul>
<li>创建索引<br />
当索引文档字符类型为 text 时，在建立索引时将会对该字段进行分词;</li>
<li>搜索<br />
当对一个 text 类型的字段进行全文检索时，会对用户输入的文本进行分词。</li>
</ul>
<p>这两个地方都可以对分词进行配置。</p>
<h3><a id="2-1%E3%80%81%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E6%97%B6" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1、创建索引时</h3>
<p>ES 将按照下面顺序来确定使用哪个分词器:</p>
<ul>
<li>先判断字段是否有设置分词器，如果有，则使用字段属性上的分词器设置;</li>
<li>如果设置了 analysis.analyzer.default，则使用该设置的分词器;</li>
<li>如果上面两个都未设置，则使用默认的 standard 分词器</li>
</ul>
<h4><a id="2-1-1%E3%80%81%E8%AE%BE%E7%BD%AE%E7%B4%A2%E5%BC%95%E9%BB%98%E8%AE%A4%E5%88%86%E8%AF%8D%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1.1、设置索引默认分词器</h4>
<pre><code class="language-bash">PUT /my_index
{
  &quot;settings&quot;: {
    &quot;analysis&quot;: {
      &quot;analyzer&quot;: {
        &quot;default&quot;: {
          &quot;type&quot;: &quot;simple&quot;
        }
      }
    }
  }
}
</code></pre>
<p>response :</p>
<pre><code class="language-json">{
  &quot;acknowledged&quot; : true,
  &quot;shards_acknowledged&quot; : true,
  &quot;index&quot; : &quot;test&quot;
}
</code></pre>
<p>还可以为索引配置内置分词器，并修改内置的部分选项修改它的行为</p>
<pre><code class="language-bash">DELETE /my_index
PUT /my_index
{
  &quot;settings&quot;: {
    &quot;analysis&quot;: {
      &quot;analyzer&quot;: {
        &quot;my_analyzer&quot;: {
          &quot;type&quot;: &quot;standard&quot;,
          &quot;stopwords&quot;: [&quot;the&quot;, &quot;a&quot;, &quot;an&quot;, &quot;this&quot;, &quot;is&quot;]
        }
      }
    }
  }
}
</code></pre>
<h4><a id="2-1-2%E3%80%81%E4%B8%BA%E5%AD%97%E6%AE%B5%E6%8C%87%E5%AE%9A%E5%86%85%E7%BD%AE%E5%88%86%E8%AF%8D%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1.2、为字段指定内置分词器</h4>
<pre><code class="language-bash">DELETE /my_index
PUT /my_index
{
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;title&quot;: {
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;standard&quot;,
        &quot;search_analyzer&quot;: &quot;simple&quot;
      }
    }
  }
}
</code></pre>
<p>还可以自定义分词器</p>
<pre><code class="language-bash">DELETE /my_index
PUT /my_index
{
  &quot;settings&quot;: {
    &quot;analysis&quot;: {
      &quot;analyzer&quot;: {
        &quot;std_english&quot;: {
          &quot;type&quot;: &quot;standard&quot;,
          &quot;stopwords&quot;: &quot;_english_&quot;
        }
      }
    }
  },
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;my_text&quot;: {
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;standard&quot;,
        &quot;fields&quot;: {
          &quot;english&quot;: {
            &quot;type&quot;: &quot;text&quot;,
            &quot;analyzer&quot;: &quot;std_english&quot;
          }
        }
      }
    }
  }
}
</code></pre>
<p>我们首先，在索引 my_index 中配置了一个分析器 std_english，std_english 中使用了内置分析器 standard，并将 standard 的停止词模式改为英语模式 <code>_english_</code> (缺省是没有的)，对字段 my_text 配置为多数据类型，分别使用了两 种分析器，standard 和 std_english。</p>
<pre><code class="language-bash">POST /my_index/_analyze
{
  &quot;field&quot;: &quot;my_text&quot;,
  &quot;text&quot;: &quot;There is an old man&quot;
}
</code></pre>
<p>response:</p>
<pre><code class="language-json">{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;there&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 5,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 0
    },
    {
      &quot;token&quot; : &quot;is&quot;,
      &quot;start_offset&quot; : 6,
      &quot;end_offset&quot; : 8,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 1
    },
    {
      &quot;token&quot; : &quot;an&quot;,
      &quot;start_offset&quot; : 9,
      &quot;end_offset&quot; : 11,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 2
    },
    {
      &quot;token&quot; : &quot;old&quot;,
      &quot;start_offset&quot; : 12,
      &quot;end_offset&quot; : 15,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 3
    },
    {
      &quot;token&quot; : &quot;man&quot;,
      &quot;start_offset&quot; : 16,
      &quot;end_offset&quot; : 19,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 4
    }
  ]
}
</code></pre>
<pre><code class="language-bash">POST /my_index/_analyze
{
  &quot;field&quot;: &quot;my_text.english&quot;,
  &quot;text&quot;: &quot;There is an old man&quot;
}
</code></pre>
<p>response:</p>
<pre><code class="language-json">{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;old&quot;,
      &quot;start_offset&quot; : 12,
      &quot;end_offset&quot; : 15,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 3
    },
    {
      &quot;token&quot; : &quot;man&quot;,
      &quot;start_offset&quot; : 16,
      &quot;end_offset&quot; : 19,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 4
    }
  ]
}
</code></pre>
<p>通过上面两个例子看出来 There is an 经过分析之后，被删除了，而standard没有被删除，这是因为 my_text.english 单独配置单独的停止词。</p>
<h3><a id="2-2%E3%80%81%E6%96%87%E6%A1%A3%E6%90%9C%E7%B4%A2%E6%97%B6" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2、文档搜索时</h3>
<p>文档搜索时使用的分析器有一点复杂，它依次从如下参数中如果查找文档分析器，如果都没有设置则使用 standard 分析器:</p>
<ul>
<li>1、搜索时指定 analyzer 参数</li>
<li>2、创建索引时字段指定的 search_analyzer 属性</li>
<li>3、创建索引时字段指定的 analyzer 属性</li>
<li>4、创建索引时 setting 里指定的 analysis.analyzer.default_search</li>
<li>5、如果都没有设置则使用 standard 分析器</li>
</ul>
<h4><a id="2-2-1%E3%80%81%E6%90%9C%E7%B4%A2%E6%97%B6%E6%8C%87%E5%AE%9A-analyzer%E6%9F%A5%E8%AF%A2%E5%8F%82%E6%95%B0" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.1、搜索时指定 analyzer 查询参数</h4>
<pre><code class="language-bash">GET /my_index/_search
{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;message&quot;: {
        &quot;query&quot;: &quot;Quick foxes&quot;,
        &quot;analyzer&quot;: &quot;stop&quot;
      }
    }
  }
}
</code></pre>
<h4><a id="2-2-2%E3%80%81%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E6%97%B6%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E7%9A%84-analyzer%E5%92%8C-seach-analyzer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.2、创建索引时指定字段的 analyzer 和 seach_analyzer</h4>
<pre><code class="language-bash">PUT /my_index
{
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;title&quot;: {
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;whitespace&quot;,
        &quot;search_analyzer&quot;: &quot;simple&quot;
      }
    }
  }
}
</code></pre>
<h4><a id="2-2-3%E3%80%81%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E6%97%B6%E6%8C%87%E5%AE%9A%E7%B4%A2%E5%BC%95%E7%9A%84%E9%BB%98%E8%AE%A4%E6%90%9C%E7%B4%A2%E5%88%86%E8%AF%8D%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.3、创建索引时指定索引的默认搜索分词器</h4>
<p>analysis.analyzer.default_search</p>
<pre><code class="language-bash">PUT /my_index
{
  &quot;settings&quot;: {
    &quot;analysis&quot;: {
      &quot;analyzer&quot;: {
        &quot;default&quot;: {
          &quot;type&quot;: &quot;simple&quot;
        },
        &quot;default_seach&quot;: {
          &quot;type&quot;: &quot;whitespace&quot;
        }
      }
    }
  }
}
</code></pre>
<hr />
<h2><a id="3%E3%80%81%E5%86%85%E7%BD%AE%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3、内置分析器</h2>
<p>前面说过，每个被分析字段经过一系列的处理步骤:<br />
1、字符过滤---使用字符过滤器转变字符。<br />
2、文本切分为分词---将文本切分为单个或多个分词。<br />
3、分词过滤---使用分词过滤器转变每个分词。</p>
<p>每个分析器基本上都要包含上面三个步骤至少一个。其中字符过滤器可以为 0 个，也可以为多个，分词器则必须，但是也只能有一个，分词过滤器可以为 0 个，也可以为多个。</p>
<p>Elasticsearch 已经为我们内置了很多的字符过滤器、分词器和分词过滤器， 以及分析器。不过常用的就是那么几个。</p>
<h3><a id="3-1%E3%80%81%E5%AD%97%E7%AC%A6%E8%BF%87%E6%BB%A4%E5%99%A8-character-filters" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1、字符过滤器(Character filters)</h3>
<p>字符过滤器种类不多, elasticearch 只提供了三种字符过滤器</p>
<h4><a id="3-1-1%E3%80%81html%E5%AD%97%E7%AC%A6%E8%BF%87%E6%BB%A4%E5%99%A8-html-strip-char-filter" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1.1、HTML 字符过滤器(HTML Strip Char Filter)</h4>
<p>从文本中去除 HTML 元素。<br />
html_strip</p>
<pre><code class="language-bash">POST _analyze
{
  &quot;tokenizer&quot;: &quot;keyword&quot;,
  &quot;char_filter&quot;: [&quot;html_strip&quot;],
  &quot;text&quot;: &quot;&lt;p&gt;I&amp;apos;m your &lt;b&gt;brother&lt;/b&gt;!&lt;/p&gt;&quot;
}
</code></pre>
<p>response:</p>
<pre><code class="language-json">{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;&quot;&quot;
I'm your brother!
&quot;&quot;&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 36,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 0
    }
  ]
}
</code></pre>
<h4><a id="3-1-2%E3%80%81%E6%98%A0%E5%B0%84%E5%AD%97%E7%AC%A6%E8%BF%87%E6%BB%A4%E5%99%A8-mapping-char-filter" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1.2、映射字符过滤器(Mapping Char Filter)</h4>
<p>接收键值的映射，每当遇到与键相同的字符串时，它就用该键关联的值替换它们。</p>
<p>我们自定义一个分析器，其内的分词器使用关键字分词器，字符 过滤器则是自定制的，将字符中的 &quot;土豆哪里去挖&quot; 替换为 666，&quot;一挖一麻袋&quot; 替换为 888。</p>
<pre><code class="language-bash">PUT /my_index
{
  &quot;settings&quot;: {
    &quot;analysis&quot;: {
      &quot;analyzer&quot;: {
        &quot;my_analyzer&quot;: {
          &quot;tokenizer&quot;: &quot;keyword&quot;,
          &quot;char_filter&quot;: [
            &quot;my_char_filter&quot;
          ]
        }
      },
      &quot;char_filter&quot;: {
        &quot;my_char_filter&quot;: {
          &quot;type&quot;: &quot;mapping&quot;,
          &quot;mappings&quot;: [
            &quot;土豆哪里去挖 =&gt; 666&quot;,
            &quot;一挖一麻袋 =&gt; 888&quot;
          ]
        }
      }
    }
  }
}
</code></pre>
<pre><code class="language-bash">POST /my_index/_analyze
{
  &quot;analyzer&quot;: &quot;my_analyzer&quot;,
  &quot;text&quot;: &quot; 土豆哪里去挖，土豆山里去挖，一挖一麻袋&quot;
}
</code></pre>
<p>response:</p>
<pre><code class="language-json">{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot; 666，土豆山里去挖，888&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 20,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 0
    }
  ]
}

</code></pre>
<h4><a id="3-1-3%E3%80%81%E6%A8%A1%E5%BC%8F%E6%9B%BF%E6%8D%A2%E8%BF%87%E6%BB%A4%E5%99%A8-pattern-replace-char-filter" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1.3、模式替换过滤器(Pattern Replace Char Filter)</h4>
<pre><code class="language-bash">POST _analyze
{
  &quot;analyzer&quot;: &quot;standard&quot;,
  &quot;text&quot;: &quot;My phone number is 123-456-789&quot;
}
</code></pre>
<p>这样分词，会导致 123-456-789 被分为 123 456 789，但是我们希望 123-456-789 是一个整体，可以使用模式替换过滤器，替换掉“-”</p>
<pre><code class="language-plain_text">PUT /my_index
{
  &quot;settings&quot;: {
    &quot;analysis&quot;: {
      &quot;analyzer&quot;: {
        &quot;my_analyzer&quot;: {
          &quot;tokenizer&quot;: &quot;standard&quot;,
          &quot;char_filter&quot;: [
            &quot;my_char_filter&quot;
          ]
        }
      },
      &quot;char_filter&quot;: {
        &quot;my_char_filter&quot;: {
          &quot;type&quot;: &quot;pattern_replace&quot;,
          &quot;pattern&quot;: &quot;&quot;&quot;(\d+)-(?=\d)&quot;&quot;&quot;,
          &quot;replacement&quot;: &quot;$1_&quot;
        }
      }
    }
  }
}
</code></pre>
<pre><code class="language-bash">POST /my_index/_analyze
{
  &quot;analyzer&quot;: &quot;my_analyzer&quot;,
  &quot;text&quot;: &quot;My phone number is 123-456-789&quot;
}
</code></pre>
<p>response</p>
<pre><code class="language-json">{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;My&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 2,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 0
    },
    {
      &quot;token&quot; : &quot;credit&quot;,
      &quot;start_offset&quot; : 3,
      &quot;end_offset&quot; : 9,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 1
    },
    {
      &quot;token&quot; : &quot;card&quot;,
      &quot;start_offset&quot; : 10,
      &quot;end_offset&quot; : 14,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 2
    },
    {
      &quot;token&quot; : &quot;is&quot;,
      &quot;start_offset&quot; : 15,
      &quot;end_offset&quot; : 17,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 3
    },
    {
      &quot;token&quot; : &quot;123_456_789&quot;,
      &quot;start_offset&quot; : 18,
      &quot;end_offset&quot; : 29,
      &quot;type&quot; : &quot;&lt;NUM&gt;&quot;,
      &quot;position&quot; : 4
    }
  ]
}
</code></pre>
<hr />
<h3><a id="3-2%E3%80%81%E5%88%86%E8%AF%8D%E5%99%A8%EF%BC%88tokenizer%EF%BC%89" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2、分词器（Tokenizer）</h3>
<h4><a id="3-2-1%E3%80%81%E6%A0%87%E5%87%86%E5%88%86%E8%AF%8D%E5%99%A8-standard" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.1、标准分词器(standard)</h4>
<p>标准分词器( standard tokenizer) 是一个基于语法的分词器，对于大多数欧洲<br />
语言来说是不错的。它还处理了 Unicode 文本的切分。它也移除了逗号和句号这样的标点符号</p>
<h4><a id="3-2-2%E3%80%81%E5%85%B3%E9%94%AE%E8%AF%8D%E5%88%86%E8%AF%8D%E5%99%A8-keyword" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.2、关键词分词器(keyword)</h4>
<p>关键词分词器( keyword tokenizer )是-种简单的分词器，将整个文本作为单个的分词，提供给分词过滤器。只想应用分词过滤器，而不做任何分词操作时，它可能非常有用。</p>
<pre><code class="language-bash">POST _analyze
{
  &quot;analyzer&quot;: &quot;keyword&quot;,
  &quot;text&quot;: &quot;My credit-- card is 123-456-789&quot;
}
</code></pre>
<p>response</p>
<pre><code class="language-json">{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;My credit-- card is 123-456-789&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 31,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 0
    }
  ]
}

</code></pre>
<h4><a id="3-2-3%E3%80%81%E5%AD%97%E6%AF%8D%E5%88%86%E8%AF%8D%E5%99%A8-letter" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.3、字母分词器(letter)</h4>
<p>字母分词器根据非字母的符号,将文本切分成分词。例如，对于句子<br />
“Hi,there.&quot;分词是 Hi 和 there,</p>
<p>因为逗号、空格和句号都不是字母: 'Hi, there. '分词是 Hi 和 there。</p>
<h4><a id="3-2-4%E3%80%81%E5%B0%8F%E5%86%99%E5%88%86%E8%AF%8D%E5%99%A8-lowercase" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.4、小写分词器(lowercase)</h4>
<p>小写分词器( lowercase tokenizer)结合了常规的字母分词器和小写分词过滤<br />
器(如你所想，它将整个分词转化为小写)的行为。通过 1 个单独的分词器来实现 的主要原因是，2 次进行两项操作会获得更好的性能。<br />
'Hi, there.'分词是 hi 和 there。</p>
<h4><a id="3-2-5%E3%80%81%E7%A9%BA%E7%99%BD%E5%88%86%E8%AF%8D%E5%99%A8-whitespace" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.5、空白分词器(whitespace)</h4>
<p>空白分词器( whitespace tokenizer )通过空白来分隔不同的分词，空白包括空<br />
格、制表符、换行等。请注意，这种分词器不会删除任何标点符号。<br />
'Hi， there. '分词是 Hi,和 there.</p>
<h4><a id="3-2-6%E3%80%81%E6%A8%A1%E5%BC%8F%E5%88%86%E8%AF%8D%E5%99%A8-pattern" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.6、模式分词器(pattern)</h4>
<p>模式分词器( patterm tokenizer)允许指定一个任 意的模式，将文本切分为分<br />
词。被指定的模式应该匹配间隔符号。例如，可以创建一个定制分析器，它在出 现文本“. -.”的地方将分词断开。</p>
<h4><a id="3-2-7%E3%80%81uax-url%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6%E5%88%86%E8%AF%8D%E5%99%A8-uax-url-email" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.7、UAX URL 电子邮件分词器(uax_url_email)</h4>
<h4><a id="3-2-8%E3%80%81%E8%B7%AF%E5%BE%84%E5%B1%82%E6%AC%A1%E5%88%86%E8%AF%8D%E5%99%A8-path-hierarchy" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.8、路径层次分词器(path_hierarchy)</h4>
<p>路径层次分词器( path hierarchy tokenizer )允许以特定的方式索引文件系统<br />
的路径，这样在搜索时，共享同样路径的文件将被作为结果返回。</p>
<hr />
<h3><a id="3-3%E3%80%81%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-token-filters" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3、分词过滤器(Token filters)</h3>
<h4><a id="3-3-1%E3%80%81%E6%A0%87%E5%87%86%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-standard" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3.1、标准分词过滤器(standard)</h4>
<p>不要认为标准分词过滤器(standard token filter)进行了什么复杂的计算，实际上它什么事情也没做。</p>
<h4><a id="3-3-2%E3%80%81%E5%B0%8F%E5%86%99%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-lowercase" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3.2、小写分词过滤器(lowercase)</h4>
<p>小写分词过滤器( lowercase token filter)只是做了这件事:将任何经过的分词<br />
转换为小写。这应该非常简单也易于理解。</p>
<h4><a id="3-3-3%E3%80%81%E9%95%BF%E5%BA%A6%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-length" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3.3、长度分词过滤器(length)</h4>
<p>长度分词过滤器(length token filter)将长度超出最短和最长限制范围的单词<br />
过滤掉。举个例子，如果将 min 设置为 2，并将 max 设置为 8，任何小于 2 个字符和任何大于 8 个字符的分词将会被移除。</p>
<h4><a id="3-3-4%E3%80%81%E5%81%9C%E7%94%A8%E8%AF%8D%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8-stop" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3.4、停用词分词过滤器(stop)</h4>
<p>停用词分词过滤器(stop token fite)将停用词从分词流中移除。对于英文而言，<br />
这意味着停用词列表中的所有分词都将会被完全移除。用户也可以为这个过滤器指定一个待移除单词的列表。</p>
<p>什么是停用词?<br />
停用词是指在信息检索中，为节省存储空间和提高搜索效率，在处理自然语 言数据(或文本)之前或之后会自动过滤掉某些字或词，这些字或词即被称为 Stop Words(停用词)</p>
<p>停用词(Stop Words)大致可分为如下两类：</p>
<ul>
<li>使用十分广泛，甚至是过于频繁的一些单词。比如英文的“i”、“is”、 “what”，中文的“我”、“就”之类词几乎在每个文档上均会出现</li>
<li>文本中出现频率很高，但实际意义又不大的词。这一类主要包括了语气 助词、副词、介词、连词等，通常自身并无明确意义，只有将其放入一个完整的 句子中才有一定作用的词语。如常见的“的”、“在”、“和”、“接着”之类</li>
</ul>
<h4><a id="3-3-5%E3%80%81%E6%88%AA%E6%96%AD%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8%E3%80%81%E4%BF%AE%E5%89%AA%E5%88%86%E8%AF%8D%E8%BF%87%E6%BB%A4%E5%99%A8%E5%92%8C%E9%99%90%E5%88%B6%E5%88%86%E8%AF%8D%E6%95%B0%E9%87%8F%E8%BF%87%E6%BB%A4%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3.5、截断分词过滤器、修剪分词过滤器和限制分词数量过滤器</h4>
<p>下面 3 个分词过滤器，通过某种方式限制分词流</p>
<ul>
<li>截断分词过滤器(truncate token filter)允许你通过定制配置中的 length 参数，截断超过一定长度的分词。默认截断多于 10 个字符的部分。</li>
<li>修剪分词过滤器(trim token filter) 删除 1 个分词中的所有空白部分。例如， 分词&quot; foo &quot;将被转变为分词 foo。</li>
<li>限制分词数量分词过滤器(limit token count token filter)限制了某个字段可包含分词的最大数量。例如，如果创建了一个定制的分词数量过滤器，限制是 8, 那么分词流中只有前 8 个分词会被索引。这个设置使用 max_token_count 参数， 默认是 1 (只有 1 个分词会被索引)。</li>
</ul>
<hr />
<h3><a id="3-4%E3%80%81%E5%B8%B8%E7%94%A8%E5%86%85%E7%BD%AE%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.4、常用内置分析器</h3>
<h4><a id="3-4-1%E3%80%81%E6%A0%87%E5%87%86%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.4.1、标准分析器</h4>
<p>当没有指定分析器的时候，标准分析器( standardanalyzer)是文本的默认分析<br />
器。它综合了对大多欧洲语言来说合理的默认模块，它没有字符过滤器，包括标 准分词器、小写转换分词过滤器和停用词分词过滤器(默认为_none_，也就是不去除停止词)。这里只需要记住，如果不为某个字段指定分析器，那么该字段就 会使用标准分析器。可配置的参数如下:</p>
<ul>
<li>max_token_length，默认值 255，表示词项最大长度，超过这个长度将按该 长度分为多个词项</li>
<li>stopwords，默认值_none_，表示分析器使用的停止词数组，可使用内置停 止词列表，比如_english_等</li>
<li>stopwords_path 停止词文件路径</li>
</ul>
<h4><a id="3-4-2%E3%80%81%E7%AE%80%E5%8D%95%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.4.2、简单分析器</h4>
<p>简单分析器(simple analyzer)就是那么简单!它只使用了小写转换分词器，这<br />
意味着在非字母处进行分词，并将分词自动转变为小写。这个分析器对于亚洲语言来说效果不佳，因为亚洲语言不是根据空白来分词，所以请仅仅针对欧洲语言使用它。</p>
<h4><a id="3-4-3%E3%80%81%E7%A9%BA%E7%99%BD%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.4.3、空白分析器</h4>
<p>空白分析器(whitespace analyzer)什么事情都不做,只是根据空白将文本切分<br />
为若干分词。</p>
<h4><a id="3-4-4%E3%80%81%E5%81%9C%E7%94%A8%E8%AF%8D%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.4.4、停用词分析器</h4>
<p>停用词分析器(stop analyzer) 和建单分析器的行为很像，只是在分词流中额外的过滤了停用词</p>
<h4><a id="3-4-5%E3%80%81%E5%85%B3%E9%94%AE%E8%AF%8D%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.4.5、关键词分析器</h4>
<p>关键词分析器（keyword analyzer）将整个字段当做一个单独的分词</p>
<h4><a id="3-4-6%E3%80%81%E6%A8%A1%E5%BC%8F%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.4.6、模式分析器</h4>
<p>模板分析器(pattern analyzer)允许你指定一个分词切分的模式。 但是，由<br />
于可能无论如何都要指定模式，通常更有意义的做法是使用定制分析器，组合现 有的模式分词器和所需的分词过滤器</p>
<h4><a id="3-4-7%E3%80%81%E9%9B%AA%E7%90%83%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.4.7、雪球分析器</h4>
<p>雪球分析器(snowball analyzer)除了使用标准的分词器和分词过滤器(和标<br />
准分析器一样),也使用了小写分词过滤器和停用词过滤器。它还使用了雪球词干 器对文本进行词干提取。</p>
<hr />
<h2><a id="4%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4、自定义分析器</h2>
<p>业务需求如下:<br />
去除所有的 HTML 标签<br />
将 &amp; 替换成 and ，使用一个自定义的 mapping 字符过滤器</p>
<p>1）自定义 mapping 类型的字符过滤器<br />
2）自定义一个停止词 分词过滤器<br />
3）组装分析器</p>
<pre><code class="language-bash">DELETE /my_index
PUT /my_index
{
  &quot;settings&quot;: {
    &quot;analysis&quot;: {
      &quot;analyzer&quot;: {
        &quot;my_analyzer&quot;:{
          &quot;type&quot;:&quot;custom&quot;,
          &quot;char_filter&quot;:[&quot;&amp;_to_and&quot;,&quot;html_strip&quot;],
          &quot;filter&quot;:[&quot;my_stopwords&quot;,&quot;lowercase&quot;],
          &quot;tokenizer&quot;:&quot;standard&quot;
          
        }
      },
      &quot;char_filter&quot;: {
        &quot;&amp;_to_and&quot;:{
          &quot;type&quot;:&quot;mapping&quot;,
          &quot;mappings&quot;:[
            &quot;&amp;=&gt;and&quot;
          ]
        }
      },
      &quot;filter&quot;: {
        &quot;my_stopwords&quot;:{
          &quot;type&quot;:&quot;stop&quot;,
          &quot;stopwords&quot;:[
            &quot;play&quot;,&quot;giao&quot;
          ]
        }
      }
    }
  }
}
</code></pre>
<pre><code class="language-bash">POST /my_index/_analyze
{
  &quot;analyzer&quot;: &quot;my_analyzer&quot;,
  &quot;text&quot;: [&quot;I giao do not want to giao work,play&quot;]
}
</code></pre>
<p>response:</p>
<pre><code class="language-json">{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;i&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 1,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 0
    },
    {
      &quot;token&quot; : &quot;do&quot;,
      &quot;start_offset&quot; : 7,
      &quot;end_offset&quot; : 9,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 2
    },
    {
      &quot;token&quot; : &quot;not&quot;,
      &quot;start_offset&quot; : 10,
      &quot;end_offset&quot; : 13,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 3
    },
    {
      &quot;token&quot; : &quot;want&quot;,
      &quot;start_offset&quot; : 14,
      &quot;end_offset&quot; : 18,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 4
    },
    {
      &quot;token&quot; : &quot;to&quot;,
      &quot;start_offset&quot; : 19,
      &quot;end_offset&quot; : 21,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 5
    },
    {
      &quot;token&quot; : &quot;work&quot;,
      &quot;start_offset&quot; : 27,
      &quot;end_offset&quot; : 31,
      &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;,
      &quot;position&quot; : 7
    }
  ]
}
</code></pre>
<h2><a id="5%E3%80%81%E4%B8%AD%E6%96%87%E5%88%86%E6%9E%90%E5%99%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>5、中文分析器</h2>
<p>上面的分析器对中文的支持不行，这里使用比较有名的 ik 作为这次的中文分析器。</p>
<p>IK 分词器有两种分词效果，一种是 ik_max_word(最大分词)和 ik_smart(最 小分词)</p>
<ul>
<li>ik_max_word: 会将文本做最细粒度的拆分，比如会将“马克思主义思想”拆分为“马克思主义,马克思,马克,思想,主义等等，会穷尽各种可能的组合;</li>
<li>ik_smart: 会做最粗粒度的拆分，比如会将“马克思主义思想”拆分为 “马克思主义,思想”。</li>
</ul>
<p>使用方式和一般的分析器没有什么差别</p>
<pre><code class="language-bash">POST _analyze
{
  &quot;analyzer&quot;: &quot;ik_max_word&quot;,
  &quot;text&quot;: [&quot;马克思主义思想&quot;]
}

</code></pre>
<p>response:</p>
<pre><code class="language-json">{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;马克思主义&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 5,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 0
    },
    {
      &quot;token&quot; : &quot;马克思&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 3,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 1
    },
    {
      &quot;token&quot; : &quot;马克&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 2,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 2
    },
    {
      &quot;token&quot; : &quot;思&quot;,
      &quot;start_offset&quot; : 2,
      &quot;end_offset&quot; : 3,
      &quot;type&quot; : &quot;CN_CHAR&quot;,
      &quot;position&quot; : 3
    },
    {
      &quot;token&quot; : &quot;主义&quot;,
      &quot;start_offset&quot; : 3,
      &quot;end_offset&quot; : 5,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 4
    },
    {
      &quot;token&quot; : &quot;思想&quot;,
      &quot;start_offset&quot; : 5,
      &quot;end_offset&quot; : 7,
      &quot;type&quot; : &quot;CN_WORD&quot;,
      &quot;position&quot; : 5
    }
  ]
}

</code></pre>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
              Copyright &copy; 2019
              Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
              Theme used <a target="_blank" href="https://bulma.io/">Bulma CSS</a>.
          </p>
        </div>
      </footer>



  













<script src="asset/prism.js"></script>



  
    




  </body>
</html>
