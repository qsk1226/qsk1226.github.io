<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大爷来玩儿啊~]]></title>
  <link href="http://www.throne4j.com/atom.xml" rel="self"/>
  <link href="http://www.throne4j.com/"/>
  <updated>2020-10-10T01:21:00+08:00</updated>
  <id>http://www.throne4j.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[解答 Kafka]]></title>
    <link href="http://www.throne4j.com/16022540100685.html"/>
    <updated>2020-10-09T22:33:30+08:00</updated>
    <id>http://www.throne4j.com/16022540100685.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">kafka 中的 zookeeper 起到什么作用，可以不用zookeeper 么?(初级)</h2>

<p>zookeeper 是一个分布式的协调组件，早期版本的 kafka 用 zk 做 meta 信息存储， consumer 的消费状态，group 的管理以及 offset 的值。考虑到 zk 本身的一些因素以及整个 架构较大概率存在单点问题，新版本中逐渐弱化了 zookeeper 的作用。新的 consumer 使用 了 kafka 内部的 group coordination 协议，也减少了对 zookeeper 的依赖，但是 broker 依然依 赖于 ZK，zookeeper 在 kafka 中还用来选举和检测 broker 是否存活等等。</p>

<h2 id="toc_1">kafka 中 consumer group 是什么概念(初级)</h2>

<p>同样是逻辑上的概念，是 Kafka 实现单播和广播两种消息模型的手段。同一个 topic 的 数据，会广播给不同的 group;同一个 group 中的 worker，只有一个 worker 能拿到这个数 据。换句话说，对于同一个 topic，每个 group 都可以拿到同样的所有数据，但是数据进入 group 后只能被其中的一个 worker 消费。group 内的 worker 可以使用多线程或多进程来实 现，也可以将进程分散在多台机器上，worker 的数量通常不超过 partition 的数量，且二者 最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费(同 一 group 内)。</p>

<h2 id="toc_2">kafka 为什么那么快?(中级)</h2>

<p>系统缓存，页面缓存技术。<br/>
顺序写:由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机 写内存还要快。<br/>
Zero-copy 零拷技术减少拷贝次数。 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。 Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。</p>

<h2 id="toc_3">Kafka 中是怎么体现消息顺序性的?(中级) kafka 每个 partition 中的消息在写入时都是有序的，消费时，每个 partition 只能被每一</h2>

<p>个 group 中的一个消费者消费，保证了消费时也是有序的。<br/>
整个 topic 不保证有序。如果为了保证 topic 整个有序，那么将 partition 调整为 1.</p>

<h2 id="toc_4">kafka follower 如何与 leader 同步数据(高级)</h2>

<p>Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求 All Alive Follower 都复制完，这条消息才会被认为 commit，这种复制方式极大的影响了吞吐 率。而异步复制方式下，Follower 异步的从 Leader 复制数据，数据只要被 Leader 写入 log 就被认为已经 commit，这种情况下，如果 leader 挂掉，会丢失数据，kafka 使用 ISR 的方式 很好的均衡了确保数据不丢失以及吞吐率。</p>

<p>kafka producer 如何优化生产速度 增加线程<br/>
提高 batch.size<br/>
增加更多 producer 实例<br/>
增加 partition 数<br/>
设置 acks=-1 时，如果延迟增大:可以增大 num.replica.fetchers(follower 同步数据的<br/>
线程数)来调解;<br/>
跨数据中心的传输:增加 socket 缓冲区设置以及 OS tcp 缓冲区设置。</p>

<h2 id="toc_5">为什么 Kafka 不支持读写分离?(高级)</h2>

<p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，<br/>
从而实现的是一种主写主读的生产消费模型。<br/>
Kafka 并不支持主写从读，因为主写从读有 2 个很明显的缺点:<br/>
(1)数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时 间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值 都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读 取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。<br/>
(2)延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要 经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而 在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘 →网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能 并不太适用。</p>

<h2 id="toc_6">有几百万消息持续积压几小时怎么解决?(高级)</h2>

<p>发生了线上故障，几千万条数据在 MQ 里积压很久。是修复 consumer 的问题，让他恢 复消费速度，然后等待几个小时消费完毕?这是个解决方案。不过有时候我们还会进行临时 紧急扩容。</p>

<p>一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟是 18 万条。1000 多万 条，所以如果积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间 才能恢复过来。</p>

<p>一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下:</p>

<p>先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。<br/>
新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍或者 20 倍的 queue 数 量。然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消 费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。</p>

<p>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的 数据。</p>

<p>这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度 来消费数据。</p>

<p>等快速消费完积压数据之后，再恢复原先部署架构，重新用原先的 consumer 机器来消费消息。</p>

<h2 id="toc_7">Kafka 是如何实现高性能的?(高级)</h2>

<p>宏观架构层面利用 Partition 实现并行处理</p>

<p>Kafka 中每个 Topic 都包含一个或多个 Partition，不同 Partition 可位于不同节点。同时 Partition 在物理上对应一个本地文件夹，每个 Partition 包含一个或多个 Segment，每个 Segment 包含一个数据文件和一个与之对应的索引文件。在逻辑上，可以把一个 Partition 当 作一个非常长的数组，可通过这个“数组”的索引(offset)去访问其数据。</p>

<p>一方面，由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间 的并行处理。另一方面，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同 一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的 disk drive 上，从而实现 磁盘间的并行处理，充分发挥多磁盘的优势。</p>

<p>利用多磁盘的具体方法是，将不同磁盘mount到不同目录，然后server.properties中， 将 log.dirs 设置为多目录(用逗号分隔)。Kafka 会自动将所有Partition 尽可能均匀分配到不 同目录也即不同目录(也即不同 disk)上。</p>

<p>Partition 是最小并发粒度，Partition 个数决定了可能的最大并行度。。 </p>

<h3 id="toc_8">ISR 实现可用性与数据一致性的动态平衡</h3>

<p>常用数据复制及一致性方案</p>

<ul>
<li><p>Master-Slave</p>
<ul>
<li>RDBMS 的读写分离即为典型的 Master-Slave 方案</li>
<li>同步复制可保证强一致性但会影响可用性</li>
<li>异步复制可提供高可用性但会降低一致性</li>
</ul></li>
<li><p>WNR</p>
<ul>
<li>主要用于去中心化的分布式系统中。</li>
<li>N 代表总副本数，W 代表每次写操作要保证的最少写成功的副本数，R 代表每次读至少要读取的副本数</li>
<li>当 W+R&gt;N 时，可保证每次读取的数据至少有一个副本拥有最新的数据</li>
<li>多个写操作的顺序难以保证，可能导致多副本间的写操作顺序不一致。Dynamo 通过 向量时钟保证最终一致性</li>
</ul></li>
<li><p>Paxos 及其变种</p>
<ul>
<li>Google 的 Chubby，Zookeeper 的原子广播协议(Zab)，RAFT 等</li>
</ul></li>
</ul>

<h3 id="toc_9">基于 ISR 的数据复制方案</h3>

<p>Kafka 的数据复制是以 Partition 为单位的。而多个备份间的数据复制，通过 Follower 向 Leader 拉取数据完成。从一这点来讲，Kafka 的数据复制方案接近于上文所讲的 Master-Slave 方案。不同的是，Kafka 既不是完全的同步复制，也不是完全的异步复制，而是基于 ISR 的 动态复制方案。</p>

<p>ISR，也即 In-sync Replica。每个 Partition 的 Leader 都会维护这样一个列表，该列表中， 包含了所有与之同步的 Replica(包含 Leader 自己)。每次数据写入时，只有 ISR 中的所有 Replica 都复制完，Leader 才会将其置为 Commit，它才能被 Consumer 所消费。</p>

<p>这种方案，与同步复制非常接近。但不同的是，这个 ISR 是由 Leader 动态维护的。如果 Follower 不能紧“跟上”Leader，它将被 Leader 从 ISR 中移除，待它又重新“跟上”Leader 后，会被 Leader 再次加加 ISR 中。每次改变 ISR 后，Leader 都会将最新的 ISR 持久化到 Zookeeper 中。</p>

<p>由于 Leader 可移除不能及时与之同步的 Follower，故与同步复制相比可避免最慢的 Follower 拖慢整体速度，也即 ISR 提高了系统可用性。</p>

<p>ISR 中的所有 Follower 都包含了所有 Commit 过的消息，而只有 Commit 过的消息才会被 Consumer 消费，故从 Consumer 的角度而言，ISR 中的所有Replica 都始终处于同步状态，从 而与异步复制方案相比提高了数据一致性。</p>

<p>ISR 可动态调整，极限情况下，可以只包含 Leader，极大提高了可容忍的宕机的 Follower 的数量。与 Majority Quorum 方案相比，容忍相同个数的节点失败，所要求的总节点数少了 近一半。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySql 事务]]></title>
    <link href="http://www.throne4j.com/16022490047332.html"/>
    <updated>2020-10-09T21:10:04+08:00</updated>
    <id>http://www.throne4j.com/16022490047332.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">数据库事务具备ACID特性</h2>

<ul>
<li>原子性(A)：要执行的事务是一个独立的操作单元，要么全部执行，要么全部不执行</li>
<li>一致性(C)：事务的一致性是指事务的执行不能破坏数据库的一致性，一致性也称为完整性。一个事务在执行后，数据库必须从一个一致性状态转变为另一个一致性状态</li>
<li>隔离性(I)：多个事务并发执行时，一个事务的执行不应影响其他事务的执行</li>
<li>持久性(D)：是事务的保证，事务终结的标志(内存的数据持久到硬盘文件中)</li>
</ul>

<h2 id="toc_1">无隔离性会出现的问题：</h2>

<ul>
<li><p>丢失更新<br/>
A 事务撤销时，把已经提交的 B 事务的更新数据覆盖了。这种错误可能造成很严重的问 题，通过下面的账户取款转账就可以看出来，MySQL 通过三级封锁协议的第一级解决了丢 失更新，事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。</p></li>
<li><p>脏读<br/>
脏读主要是读取到了其他事务的数据，而其他事务随后发生回滚。MySQL 通过三级封锁 协议的第二级解决了脏读，在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上 释放 S 锁。</p></li>
<li><p>不可重复度<br/>
不可重复读是读取到数据后，随后其他事务对数据发生了修改，无法再次读取。MySQL 通过三级封锁协议的第三级解决了不可重复读。在二级的基础上，要求读取数据 A 时必须 加 S 锁，直到事务结束了才能释放 S 锁。</p></li>
<li><p>幻读 <br/>
幻读是读取到数据后，随后其他事务对数据发生了新增，无法再次读取。在 InnoDB 引擎 Repeatable Read 的隔离级别下，MySQL 通过 Next-Key Lock 以及 MVCC 解决了幻读，事务中 分为当前读以及快照读。</p></li>
</ul>

<h2 id="toc_2">事务隔离性</h2>

<p>SQL92规范中对隔离性定义了 4 种隔离级别（隔离性从上向下依次增强，但是导致的问题是并发能力的减弱）：</p>

<ul>
<li>读未提交(READ UNCOMMITED)
<ul>
<li>事物A和事物B，事物A未提交的数据，事物B可以读取到</li>
<li>这种隔离级别最低，这种级别一般是在理论上存在，数据库隔离级别一般都高于该级别</li>
<li>这里读取到的数据叫做“脏数据”</li>
</ul></li>
<li>读已提交(READ COMMITTED)
<ul>
<li>事物A和事物B，事物A提交的数据，事物B才能读取到</li>
<li>这种隔离级别高于读未提交</li>
<li>换句话说，对方事物提交之后的数据，我当前事物才能读取到</li>
<li>这种级别可以避免“脏数据”</li>
<li>这种隔离级别会导致“不可重复读取”</li>
</ul></li>
<li>可重复读(REPEATABLE READ)
<ul>
<li>事务A和事务B，事务A提交之后的数据，事务B读取不到</li>
<li>事务B是可重复读取数据</li>
<li>这种隔离级别高于读已提交</li>
<li>换句话说，对方提交之后的数据，我还是读取不到</li>
<li>这种隔离级别可以避免“不可重复读取”，达到可重复读取</li>
<li>比如1点和2点读到数据是同一个</li>
<li>MySQL默认级别</li>
<li>虽然可以达到可重复读取，但是会导致“幻读”</li>
</ul></li>
<li>序列化(SERIALIZABLE)。
<ul>
<li>事务A和事务B，事务A在操作数据库时，事务B只能排队等待</li>
<li>这种隔离级别很少使用，吞吐量太低，用户体验差</li>
<li>这种级别可以避免“幻像读”，每一次读取的都是数据库中真实存在数据，事务A与事务B串行，而不并发</li>
</ul></li>
</ul>

<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
<th>概念</th>
</tr>
</thead>

<tbody>
<tr>
<td>READ UNCOMMITED</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>事务能够看到其他事务没有提交的修改，当另一个事务又回滚了修改后的情况，又被称为脏读dirty read</td>
</tr>
<tr>
<td>READ COMMITTED</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>事务能够看到其他事务提交后的修改，这时会出现一个事务内两次读取数据可能因为其他事务提交的修改导致不一致的情况，称为不可重复读</td>
</tr>
<tr>
<td>REPEATABLE READ</td>
<td>×</td>
<td>×</td>
<td>√</td>
<td>事务在两次读取时读取到的数据的状态是一致的</td>
</tr>
<tr>
<td>SERIALIZABLE</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>可重复读中可能出现第二次读读到第一次没有读到的数据，也就是被其他事务插入的数据，这种情况称为幻读phantom read, 该级别中不能出现幻读</td>
</tr>
</tbody>
</table>

<p>大多数数据库系统的默认隔离级别都是READ COMMITTED（但MySQL不是)，InnoDB存储引擎默认隔离级别REPEATABLE READ，通过多版本并发控制（MVCC，Multiversion Concurrency Control）解决了幻读的问题。</p>

<h3 id="toc_3">隔离级别的实现原理</h3>

<p>为了解决更新丢失、脏读、不可重复读、幻读的问题，MySQL事务提出了4个不同的隔离级别，而这些隔离级别的实现本质上就是通过加锁，解锁来实现的。</p>

<p>那么我们该何时加锁，占锁多长时间，何时解锁呢？这就是我们今天的主题三级封锁协议。三级封锁协议顾名思义是3个不同级别的封锁协议，它们是以何时加锁，何时解锁来区分的。下面我们看一下具体的定义：</p>

<ul>
<li><p>一级封锁协议<br/>
事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。 一级封锁协议可以防止丢失修改，并保证事务T是可恢复的。使用一级封锁协议可以解决丢失修改问题。在一级封锁协议中，如果仅仅是读数据不对其进行修改，是不需要加锁的，它不能保证可重复读和不读“脏”数据。</p></li>
<li><p>二级封锁协议<br/>
在一级封锁协议之上，事务T在读取数据R之前必须先对其加S锁，读完后方可释放S锁。 二级封锁协议除防止了丢失修改，还可以进一步防止读“脏”数据。但在二级封锁协议中，由于读完数据后即可释放S锁，所以它不能保证可重复读。</p></li>
<li><p>三级封锁协议<br/>
在一级封锁协议之上，事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放。 三级封锁协议除防止了丢失修改和不读“脏”数据外，还进一步防止了不可重复读。</p></li>
</ul>

<p>在继续往下之前，我们需要先搞清楚什么是X锁，S锁。如果我们直接在网上搜索，我们能得到这样的一个关系：</p>

<p>排它锁 == 写锁 == X锁 ， 共享锁 == 读锁 == S锁</p>

<p>简单理解就是如果我对资源A加上了排它锁，那么我既可以读取资源A，也可以插入或更新资源A，而其他人都无法对资源A再加排它锁或共享锁。 如果我对资源A加上了共享锁，那么所有人都不能再对资源A加上排它锁 （包括我自己），而其他人也都可以对资源A再加共享锁。</p>

<p>关于X锁和S锁，我们需要了解，普通的select语句是不需要加锁的，而insert，update，delete，select ... for update 需要加X锁，select ... lock in share mode 这样的语句会加S锁。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解答RabbitMQ]]></title>
    <link href="http://www.throne4j.com/16022464930141.html"/>
    <updated>2020-10-09T20:28:13+08:00</updated>
    <id>http://www.throne4j.com/16022464930141.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">为什么使用消息队列</h2>

<p>首先 消息队列关注于数据的发送和接收，利用高效可靠的异步消息传递机制对分布式系统中的其余各个子系统进行集成。但是它拥有以下优点：</p>

<ul>
<li>高效:对于消息的处理处理速度快。 </li>
<li>可靠:一般消息中间件都会有消息持久化机制和其他的机制确保消息不丢失。 </li>
<li>异步:指发送完一个请求，不需要等待返回，随时可以再发送下一个请求，既不需要等待。</li>
</ul>

<p>使用消息队列可以实现应用之间的解耦、异步调用和削峰填谷。</p>

<p>但是引入消息队列也有如下一些问题：</p>

<ul>
<li>系统的可用性降低</li>
<li>系统的复杂度变高</li>
<li>一致性问题</li>
</ul>

<h2 id="toc_1">使用了消息中间件之后消息可能重复的原因，如何解决？</h2>

<h3 id="toc_2">重复的原因：</h3>

<ul>
<li><p>消息发送端应用重复发送</p>
<ul>
<li>消息发送端发送消息给消息中间件,消息中间件收到消息并成功存储,而这时消息中 间件出现了问题,导致应用端没有收到消息发送成功的返回因而进行重试产生了重 复。</li>
<li>消息中间件因为负载高响应变慢,成功把消息存储到消息存储中后,返回“成功”这 个结果时超时。</li>
<li>消息中间件将消息成功写入消息存储,在返回结果时网络出现问题,导致应用发送端 重试,而重试时网络恢复,由此导致重复。</li>
</ul></li>
<li><p>消息到达了消息存储，由消息中间件进行向外的投递时产生重复</p>
<ul>
<li>消息被投递到消息接收者进行处理，处理完毕后应用出现问题，消息中间件不知道消息的处理结果，会再次投递消息</li>
<li>消息被投递到消息接收者进行处理，处理完毕后网络出现问题，消息中间件不知道消息的处理结果，会再次投递消息</li>
<li>消息被投递到消息接收者进行处理，处理时间比较长，消息中间件因为消息超时会再次投递</li>
<li>消息被投递到消息接收者进行处理，处理完毕后消息中间件出现问题没能收到消息结果并处理，会再次投递消息</li>
<li>消息被投递到消息接收者进行处理，处理完毕消息中间件收到结果，但是遇到消息存储故障，没能更新投递状态，会再次投递消息</li>
</ul></li>
</ul>

<h3 id="toc_3">如何解决消息重复的问题？</h3>

<p>主要是要求消息接收者来处理这种重复的情况,也就是要 求消息接收者的消息处理是幂等操作。</p>

<h4 id="toc_4">什么是幂等性</h4>

<p>对于消息接收端的情况,幂等的含义是采用同样的输入多次调用处理函数,得到同样的结 果。</p>

<h4 id="toc_5">常见幂等的方法</h4>

<p>因此应对消息重复的办法是,使消息接收端的处理是一个幂等操作。这样的做法降低了 消息中间件的整体复杂性,不过也给使用消息中间件的消息接收端应用带来了一定的限制和门槛。</p>

<h5 id="toc_6">MVCC</h5>

<p>多版本并发控制，乐观锁的一种实现，在生产者发送消息时进行数据更新时需要带上数据的版本号，消费者去更新时需要去比较持有的数据版本号，版本号不一致的操作无法成功。</p>

<h5 id="toc_7">去重表</h5>

<p>利用数据库表单的特性来实现幂等，常用的一个思路是在表上构建唯一性索引，保证某<br/>
一类数据一旦执行完毕，后续同样的请求不再重复处理了</p>

<h2 id="toc_8">RabbitMQ中 channel、exchange、queue概念及作用</h2>

<p>Queue 就是消息队列，用于存储消息，具有自己的 erlang 进程。</p>

<p>exchange 内部实现为 保存 binding 关系的查找表;</p>

<p>channel 是实际进行路由工作的实体，即负责按照 routing_key 将 message 投递给 queue 。</p>

<p>在 RabbitMQ 中所有客户端与 RabbitMQ 之间的通讯都是在 channel 上，channel 是真实 TCP 连接之上的虚拟连接，所有 AMQP 命令都是通过 channel 发送的。</p>

<h2 id="toc_9">RabbitMQ 中的元数据有哪些？</h2>

<p>元数据主要分为 </p>

<ul>
<li>Queue 元数据(queue 名字和属性等)</li>
<li>Exchange 元数据(exchange 名字、类型和属性等)</li>
<li>Binding 元数据(存放路由关系的查找表)</li>
<li>Vhost 元数据(vhost 范围内针对前三者的名字空间约束和安全属性设置)，另外在集群中，元数据都是在一个 broker 中都是全局复制的。</li>
</ul>

<h2 id="toc_10">RabbitMQ中的vhost 是什么?起什么作用?</h2>

<p>vhost 可以理解为虚拟 broker ，即一个迷你版的 RabbitMQ server。其内部均含有独立 的 queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段。</p>

<h2 id="toc_11">RabbitMQ 上的一个 queue 中存放的 message 是 否有数量限制?</h2>

<p>默认情况下一般是无限制，因为限制取决于机器的内存，但是消息过多会导致处理效率 的下降。同时可以通过参数来限制， x-max-length :对队列中消息的条数进行限制 ， x-max-length-bytes :对队列中消息的总量进行限制。</p>

<h2 id="toc_12">为什么对所有的 message 都使用持久化机制?</h2>

<p>首先，必然导致性能的下降，因为写磁盘比写内存慢的多，Rabbit 的吞吐量有 10 倍的差距。</p>

<p>其次，message 的持久化机制用在 RabbitMQ 的集群时会出现“坑爹”问题。矛盾点 在于，要实现持久化的话，必须消息、消息队列、交换器三者持久化，如果集群中不同机器 中三者属性有差异，会发生不可预料的问题。</p>

<p>所以一般处理原则是:仅对关键消息作持久化 处理(根据业务重要程度)，且应该保证关键消息的量不会导致性能瓶颈。 </p>

<h2 id="toc_13">RAM node 和 Disk node 的区别？</h2>

<p>RAM node 就是内存节点，Rabbit 中的 queue、exchange 和 binding 等 RabbitMQ 基础 构件中相关元数据保存到内存中，</p>

<p>Disk node 是磁盘节点，上述数据会在内存和磁盘中均进 行存储。</p>

<p>一般在 RabbitMQ 集群中至少存在一个 Disk node.</p>

<h2 id="toc_14">RabbitMQ 如何确保消息的可靠性传输</h2>

<p>因为 MQ 中涉及到了 MQ 本身，生产者和消费，所以需要从三个角度来看</p>

<h3 id="toc_15">生产者</h3>

<p>生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络充斥着不稳定性，有以下几种方案：</p>

<h4 id="toc_16">选择RabbitMQ 提供的事务功能</h4>

<p>选择RabbitMQ的事务功能 就是生产者发送数据之前开启 RabbitMQ 事务(channel.txSelect)，然后发送消息，如果消息没有成功被 RabbitMQ 接收到， 那么生产者会收到异常报错，此时就可以回滚事务(channel.txRollback)，然后重试发送消 息;如果收到了消息，那么可以提交事务(channel.txCommit)。但是问题是，RabbitMQ 事 务机制一搞，基本上吞吐量会下来，因为太耗性能。</p>

<h4 id="toc_17">开启confirm 模式</h4>

<p>在生产者 那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。</p>

<p>如果 RabbitMQ 没能处理这个消息，会回调你一个 nack 接口，告诉你这个消息接收失败，你可以重试。而 且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收 到这个消息的回调，那么你可以重发。</p>

<p>事务机制和 cnofirm 机制最大的不同在于，事务机制是同步的，你提交一个事务之后会 阻塞在那儿，但是 confirm 机制是异步的，你发送个消息之后就可以发送下一个消息，然后 那个消息 RabbitMQ 接收了之后会异步回调你一个接口通知你这个消息接收到了。</p>

<p>所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。</p>

<h3 id="toc_18">RabbitMQ 自身</h3>

<p>RabbitMQ 自己丢数据，这个时候我们就必须开启 RabbitMQ 的持久化，结合confirm模式，等到消息持久化到磁盘之后才会通知生产者，就算这时RabbitMQ挂掉了，我们也可以自己重发。</p>

<h3 id="toc_19">消费端</h3>

<p>RabbitMQ 如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。</p>

<p>这个时候得用 RabbitMQ 提供的 ack 机制，简单来说，就是你关闭 RabbitMQ 自动 ack，进行手动确认，只有程序手动确认消息已消费才会在RabbitMQ中删除消息，这样消息就不会丢啦。</p>

<h2 id="toc_20">RabbitMQ 如何保证消息的顺序性</h2>

<p>从根本上说，异步消息是不应该有顺序依赖的。在 MQ 上估计是没法解决。要实现严格 的顺序消息，简单且可行的办法就是:保证生产者 - MQServer - 消费者是一对一对一的关系。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--队列]]></title>
    <link href="http://www.throne4j.com/16022443352683.html"/>
    <updated>2020-10-09T19:52:15+08:00</updated>
    <id>http://www.throne4j.com/16022443352683.html</id>
    <content type="html"><![CDATA[
<p>RabbitMQ 中消费行为主要跟队列有直接关系，那么我们接下来深入的分析队列。</p>

<h2 id="toc_0">临时队列</h2>

<p>临时队列对应的是没有持久化的队列，也就是如果 RabbitMQ 服务器重启，那么这些队列就不会存在，所以我们称之为临时队列。</p>

<h2 id="toc_1">自动删除队列</h2>

<p>自动删除队列和普通队列在使用上没有什么区别，唯一的区别是，当消费者断开连接时，队列将会被删除。</p>

<p>自动删除队列允许的消费者没有限制， 也就是说当这个队列上最后一个消费者断开连接才会执行删除。</p>

<p>自动删除队列只需要在声明队列时，设置属性 auto-delete 标识为 true 即可</p>

<h2 id="toc_2">单消费者队列</h2>

<p>普通队列允许的消费者没有限制，多个消费者绑定到多个队列时，RabbitMQ 会采用轮询进行投递。如果需要消费者独占队列，在队列创建的时候， 设定属性参数exclusive 为 true。</p>

<h2 id="toc_3">自动过期队列</h2>

<p>指队列在超过一定时间没使用，队列会从 RabbitMQ 中被删除。</p>

<p>什么是没使用?</p>

<ul>
<li>一定时间内没有 Get 操作发生。</li>
<li>没有 Consumer 连接在队列上</li>
</ul>

<p>就算一直有消息进入队列，也不算队列在被使用。 通过声明队列时，设定x-expires 参数即可，单位毫秒。</p>

<h2 id="toc_4">队列的持久性</h2>

<p>持久化队列和非持久化队列的区别是，持久化队列会被保存在磁盘中，固定并持久的存储，当 RabbitMQ 服务重启后，该队列会保持原来的状态在 RabbitMQ 中被管理，而非持久化队列不会被保存在磁盘中，RabbitMQ 服务重启后队列就会消失。</p>

<h2 id="toc_5">队列级别消息过期</h2>

<p>就是为每个队列设置消息的超时时间。只要给队列设置 x-message-ttl 参数，就设定了该队列所有消息的存活时间，时间单位是毫秒。如果声明队列时指定了死信交换器，则过期消息会成为死信消息。</p>

<h2 id="toc_6">队列参数列表</h2>

<table>
<thead>
<tr>
<th>参数</th>
<th>目的</th>
</tr>
</thead>

<tbody>
<tr>
<td>x-dead-letter-exchange</td>
<td>死信交换机</td>
</tr>
<tr>
<td>x-dead-letter-routing-key</td>
<td>死信消息的可选路由键</td>
</tr>
<tr>
<td>x-expires</td>
<td>队列在指定毫秒数后被删除</td>
</tr>
<tr>
<td>x-ha-policy</td>
<td>创建 HA 队列</td>
</tr>
<tr>
<td>x-ha-nodes</td>
<td>HA 队列的分布节点</td>
</tr>
<tr>
<td>x-max-length</td>
<td>队列的最大消息条数</td>
</tr>
<tr>
<td>x-max-length-bytes</td>
<td>消息的最大总量</td>
</tr>
<tr>
<td>x-message-ttl</td>
<td>毫秒为单位的消息过期时间，队列级别</td>
</tr>
<tr>
<td>x-max-prority</td>
<td>最大优先值为255的队列优先排序功能</td>
</tr>
</tbody>
</table>

<h2 id="toc_7">消息的属性</h2>

<p>按照 AMQP 的协议单个最大的消息大小为 16EB(2 的 64 次方)，但是 RabbitMQ 将消息大小限定为 2GB(2的31次方)。<br/>
<figure><img src="media/16022443352683/16022456945696.jpg" alt="" style="width:882px;"/></figure></p>

<p><figure><img src="media/16022443352683/16022457151235.jpg" alt=""/></figure></p>

<h3 id="toc_8">消息存活时间</h3>

<p>当队列消息的 TTL 和消息 TTL 都被设置，时间短的 TTL 设置生效。<br/>
如果将一个过期消息发送给 RabbitMQ，该消息不会路由到任何队列，而是直接丢弃。</p>

<p>为消息设置 TTL 有一个问题:RabbitMQ 只对处于队头的消息判断是否过期(即不会扫描队列)，所以，很可能队列中已存在死消息，但是队列并不 知情。这会影响队列统计数据的正确性，妨碍队列及时释放资源。</p>

<h3 id="toc_9">消息的持久化</h3>

<p>默认情况下，队列和交换器在服务器重启后都会消失，消息当然也是。将队列和交换器的 durable 属性设为 true，缺省为 false，但是消息要持久化还 不够，还需要将消息在发布前，将投递模式设置为 2。消息要持久化，必须要有持久化的队列、交换器和投递模式都为 2 。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--死信交换器 DLX]]></title>
    <link href="http://www.throne4j.com/16022411349774.html"/>
    <updated>2020-10-09T18:58:54+08:00</updated>
    <id>http://www.throne4j.com/16022411349774.html</id>
    <content type="html"><![CDATA[
<p><figure><img src="media/16022411349774/16022427035514.jpg" alt="" style="width:851px;"/></figure></p>

<p>如果使用消息拒绝机制，同时 requeue 参数设置为 false 时，消息丢失了，这点作为程序员我们不能忍。</p>

<p>所以 RabbitMQ 作为一个高级消息中间件，提出了死信交换器的概念，死信，意思就是死了的信息。这种交换器专门处理死了的信息(被拒绝可以重新投递的信息不能算死的)。</p>

<p>死信交换器是 RabbitMQ 对 AMQP 规范的一个扩展，往往用在对问题消息的诊断上(主要针对消费者)，还有延时队列的功能。</p>

<p>消息变成死信一般是以下三种情况:</p>

<ul>
<li>消息被拒绝，并且设置 requeue 参数为 false</li>
<li>消息过期(默认情况下 Rabbit 中的消息不过期，但是可以设置队列的过期时间和消息的过期时间以达到消息过期的效果) </li>
<li>队列达到最大长度(一般当设置了最大队列长度或大小并达到最大值时)</li>
</ul>

<p>死信交换器仍然只是一个普通的交换器，创建时并没有特别要求和操作。在创建队列的时候，声明该交换器将用作保存被拒绝的消息即可，即设置参数 x-dead-letter-exchange 指定哪个交换机为死信交换机。参数 x-dead-letter-routing-key 指定 死信routing-key。</p>

<p><figure><img src="media/16022411349774/16022418380839.jpg" alt=""/></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--消息的消费]]></title>
    <link href="http://www.throne4j.com/16022373268306.html"/>
    <updated>2020-10-09T17:55:26+08:00</updated>
    <id>http://www.throne4j.com/16022373268306.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">消息的获取方式</h2>

<h3 id="toc_1">拉取 Get</h3>

<p>属于一种轮询模型，发送一次 get 请求，获得一个消息。如果此时 RabbitMQ 中没有消息，会获得一个表示空的回复。总的来说，这种方式性能比较 差，很明显，每获得一条消息，都要和 RabbitMQ 进行网络通信发出请求。而且对 RabbitMQ 来说，RabbitMQ 无法进行任何优化，因为它永远不知道应用 程序何时会发出请求。对我们实现者来说，要在一个循环里，不断去服务器 get 消息。</p>

<h3 id="toc_2">推送 Consume</h3>

<p>属于一种推送模型。注册一个消费者后，RabbitMQ 会在消息可用时，自动将消息进行推送给消费者，这种模式我们已经使用过很多次。</p>

<h3 id="toc_3">消息的应答</h3>

<p>消费者收到的每一条消息都必须进行确认。消息确认后，RabbitMQ 才会从队列删除这条消息，RabbitMQ 不会为未确认的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么设计的原因是 RabbitMQ 允许消费者消费一条消 息的时间可以很久很久。</p>

<h3 id="toc_4">自动确认</h3>

<p>消费者在声明队列时，可以指定 autoAck 参数，当 autoAck=true 时，一旦消费者接收到了消息，就视为自动确认了消息。如果消费者在处理消息的过 程中，出了错，就没有什么办法重新处理这条消息，所以我们很多时候，需要在消息处理成功后，再确认消息，这就需要手动确认。</p>

<h3 id="toc_5">手动确认</h3>

<p>当 autoAck=false 时，RabbitMQ 会等待消费者显式发回 ack 信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息。否则，RabbitMQ 会在队列 中消息被消费后立即删除它。</p>

<p>采用消息确认机制后，只要令 autoAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题， 因为 RabbitMQ 会一直持有消息直到消费者显式调用 basicAck 为止。</p>

<p>当 autoAck=false 时，对于 RabbitMQ 服务器端而言，队列中的消息分成了两部分:一部分是等待投递给消费者的消息;一部分是已经投递给消费者， 但是还没有收到消费者 ack 信号的消息。如果服务器端一直没有收到消费者的 ack 信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消 息重新进入队列，等待投递给下一个消费者(也可能还是原来的那个消费者)</p>

<h3 id="toc_6">QoS 预取模式</h3>

<p>在确认消息被接收之前，消费者可以预先要求接收一定数量的消息，在处理完一定数量的消息后，批量进行确认。如果消费者应用程序在确认消息之前崩溃，则所有未确认的消息将被重新发送给其他消费者。所以这里存在着一定程度上的可靠性风险。</p>

<p>这种机制一方面可以实现限速(将消息暂存到 RabbitMQ 内存中)的作用，一方面可以保证消息确认质量(比如确认了但是处理有异常的情况)。</p>

<p><strong>注意</strong>: 消费确认模式必须是非自动 ACK 机制(这个是使用 baseQos 的前提条件，否则会 Qos 不生效)，然后设置 basicQos 的值;另外，还可以基于 consume 和 channel 的粒度进行设置(global)。</p>

<p>basicQos 方法参数详细解释:</p>

<ul>
<li>prefetchSize:最多传输的内容的大小的限制，0 为不限制，但据说 prefetchSize 参数，rabbitmq 没有实现。</li>
<li>prefetchCount:会告诉 RabbitMQ 不要同时给一个消费者推送多于 N 个消息，即一旦有 N 个消息还没有 ack，则该 consumer 将 block 掉，直到有消息 ack</li>
<li>global:true\false 是否将上面设置应用于 channel，简单点说，就是上面限制是 channel 级别的还是 consumer 级别。</li>
</ul>

<p>如果同时设置 channel 和消费者，会怎么样?AMQP 规范没有解释如果使用不同的全局值多次调用 basic.qos 会发生什么。 RabbitMQ 将此解释为意味着两个预取限制应该彼此独立地强制执行; 消费者只有在未达到未确认消息限制时才会收到新消息。 </p>

<h2 id="toc_7">消费者中的事务</h2>

<p>使用方法和生产者一致 假设消费者模式中使用了事务，并且在消息确认之后进行了事务回滚，会是什么样的结果? 结果分为两种情况:</p>

<ul>
<li>autoAck=false 手动应对的时候是支持事务的，也就是说即使你已经手动确认了消息已经收到了，但 RabbitMQ 对消息的确认会等事务的 返回结果，再做最终决定是确认消息还是重新放回队列，如果你手动确认之后，又回滚了事务，那么以事务回滚为准，此条消息会重新放回队列;</li>
<li>autoAck=true 如果自动确认为 true 的情况是不支持事务的，也就是说你即使在收到消息之后在回滚事务也是于事无补的，队列已经把 消息移除了。</li>
</ul>

<h2 id="toc_8">消息的拒绝</h2>

<h3 id="toc_9">Reject 和 Nack</h3>

<p>消息确认可以让 RabbitMQ 知道消费者已经接受并处理完消息。但是如果消息本身或者消息的处理过程出现问题怎么办?需要一种机制通知 RabbitMQ 这个消息我无法处理，请让别的消费者处理。</p>

<p>这里就有两种机制，Reject 和 Nack。</p>

<ul>
<li>Reject 在拒绝消息时，可以使用 requeue 标识，告诉 RabbitMQ 是否需要重新发送给别的消费者。如果是 false 则不重新发送，一般这个消息就会被RabbitMQ 丢弃。Reject 一次只能拒绝一条消息。如果是 true 则消息发生了重新投递。</li>
<li>Nack 跟 Reject 类似，只是它可以一次性拒绝多个消息。也可以使用 requeue 标识，这是 RabbitMQ 对 AMQP 规范的一个扩展。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--消息发布时的权衡]]></title>
    <link href="http://www.throne4j.com/16022331778802.html"/>
    <updated>2020-10-09T16:46:17+08:00</updated>
    <id>http://www.throne4j.com/16022331778802.html</id>
    <content type="html"><![CDATA[
<p>在 RabbitMQ 中，有不同的投递机制(生产者)，但是每一种机制都对性能有一定的影响。一般来讲速度快的可靠性低，可靠性好的性能差，具体怎 么使用需要根据你的应用程序来定，所以说没有最好的方式，只有最合适的方式。只有把你的项目和技术相结合，才能找到适合你的平衡。</p>

<p><figure><img src="media/16022331778802/16022332641946.jpg" alt=""/></figure></p>

<p>在 RabbitMQ 中实际项目中，生产者和消费者都是客户端，它们都可以完成申明交换器、申明队列和绑定关系，但是在我们的实战过程中，我们在生产者代码中申明交换器，在消费者代码中申明队列和绑定关系。</p>

<p>另外还要申明的就是，生产者发布消息时不一定非得需要消费者，对于 RabbitMQ 来说，如果是单纯的生产者你只需要生产者客户端、申明交换器、 申明队列、确定绑定关系，数据就能从生产者发送至 RabbitMQ。</p>

<h2 id="toc_0">无保障</h2>

<p>通过 basicPublish 发布你的消息并使用正确的交换器和路由信息，你的消息会被接收并发送到合适的队列中, 但是如果有网络问题，或者消息不可路由，或者RabbitMQ 自身有问题的话，这种方式就有风险。所以无保证的消息发送一般情况下不推荐。</p>

<h2 id="toc_1">失败确认</h2>

<p>在发送消息时设置 mandatory = true 标志，告诉 RabbitMQ，如果消息不可路由，应该将消息返回给发送者，并通知失败。可以这样认为，开启 mandatory 是开启故障检测模式。</p>

<p>注意:它只会让 RabbitMQ 向你通知失败，而不会通知成功。如果消息正确路由到队列，则发布者不会受到任何通知。带来的问题是无法确保发布消 息一定是成功的，因为通知失败的消息可能会丢失。</p>

<p>channel.addConfirmListener 则用来监听 RabbitMQ 发回的信息。</p>

<h2 id="toc_2">事务</h2>

<p>事务的实现主要是对信道(Channel)的设置，主要的方法有三个:</p>

<ul>
<li>channel.txSelect()声明启动事务模式;</li>
<li>channel.txComment()提交事务;</li>
<li>channel.txRollback()回滚事务;</li>
</ul>

<p>在发送消息之前，需要声明 channel 为事务模式，提交或者回滚事务即可。 开启事务后，客户端和 RabbitMQ 之间的通讯交互流程:</p>

<ul>
<li>客户端发送给服务器 Tx.Select(开启事务模式)</li>
<li>服务器端返回 Tx.Select-Ok(开启事务模式 ok)  推送消息</li>
<li>客户端发送给事务提交 Tx.Commit</li>
<li>服务器端返回 Tx.Commit-Ok</li>
</ul>

<p>以上就完成了事务的交互流程，如果其中任意一个环节出现问题，就会抛出 IoException，这样用户就可以拦截异常进行事务回滚，或决定要不要重<br/>
复消息。</p>

<p>既然已经有事务了，为何还要使用发送方确认模式呢，原因是因为事务的性能是非常差的。根据相关资料，事务会降低 2~10 倍的性能。</p>

<h2 id="toc_3">发送方确认模式</h2>

<p>基于事务的性能问题，RabbitMQ 团队为我们拿出了更好的方案，即采用发送方确认模式，该模式比事务更轻量，性能影响几乎可以忽略不计。</p>

<p>原理:生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式，所有在该信道上面发布的消息都将会被指派一个唯一的 ID(从 1 开始)，由这个 id 在生产者和 RabbitMQ 之间进行消息的确认。 </p>

<p>不可路由的消息，当交换器发现，消息不能路由到任何队列，会进行确认操作，表示收到了消息。如果发送方设置了 mandatory 模式,则会先调用 addReturnListener 监听器。</p>

<p>可路由的消息，要等到消息被投递到所有匹配的队列之后，broker 会发送一个确认给生产者(包含消息的唯一 ID)，这就使得生产者知道消息已经正确 到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker 回传给生产者的确认消息中 delivery-tag 域包含了 确认消息的序列号。</p>

<p>confirm 模式最大的好处在于它可以是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消息，生产者应用程序同样可以在回调方法中处理该 nack 消息决定下一步的处理。</p>

<p>Confirm 的三种实现方式:</p>

<ul>
<li>channel.waitForConfirms() 普通发送方确认模式，消息到达交换机，机会返回 true</li>
<li>channel.waitForConfirmsOrDie() 批量确认模式，使用同步方式等所有的消息发送之后才会执行后面代码，只要有一个小心未到达交换器就会抛出 IOException 异常</li>
<li>channel.addConfirmListener()一步监听发送方确认模式</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--AMQP 概论]]></title>
    <link href="http://www.throne4j.com/16022252063226.html"/>
    <updated>2020-10-09T14:33:26+08:00</updated>
    <id>http://www.throne4j.com/16022252063226.html</id>
    <content type="html"><![CDATA[
<p>AMQP 是应用层协议的一个开放标准, 为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。目标是实现一种在全行业广泛使用的标准消息中间件技术，以便降低企业和系统集成的开销，并且向大众提供工业级的集成服务。 主要实现有 RabbitMQ。</p>

<h2 id="toc_0">客户端与 RabbitMQ 的通讯</h2>

<h3 id="toc_1">连接</h3>

<p>首先作为客户端(无论是生产者还是消费者)，如果要与 RabbitMQ 通讯的话，客户端与服务端之间必须创建一条 TCP 连接，当然同时建立连接后，客户端还必须发送一条“问候语”让彼此知道我们都是符合 AMQP 的语言的，比如你跟别人打招呼一般会说“你好!”，你跟国外的美女一般会说“hello!”一样。 你们确认好“语言”之后，就相当于客户端和 RabbitMQ 通过“认证”了。你们之间可以创建一条 AMQP 的信道。</p>

<p>连接在 RabbitMQ 原生客户端(5.0.0)版本中默认使用 java 的原生 socket，但是也支持 NIO，需要手动设置修改。</p>

<h3 id="toc_2">信道</h3>

<p>信道是生产者/消费者与 RabbitMQ 通信的渠道。信道是建立在 TCP 连接上的虚拟连接，什么意思呢? 就是说 rabbitmq 在一条 TCP 上建立成百上千个信道来达到多个线程处理，这个 TCP 被多个线程共享，每个线程对应一个信道，信道在RabbitMQ 都有唯一的 ID ,保证了信道私有性，对应上唯一的线程使用。</p>

<p>疑问: 为什么不建立多个 TCP 连接呢? </p>

<p>原因是 rabbit 保证性能，系统为每个线程开辟一个 TCP 是非常消耗性能，每秒成百上千的建立销毁 TCP 会严重消耗系统。</p>

<p>所以 rabbitmq 选择建立多个信道(建立在 tcp 的虚拟连接)连接到 rabbit 上。<br/>
从技术上讲，这被称之为“多路复用”，对于执行多个任务的多线程或者异步应用程序来说，好使的很。</p>

<h2 id="toc_3">RabbitMQ 中使用 AMQP</h2>

<h3 id="toc_4">包括的要素</h3>

<ul>
<li>生产者<br/>
消息的创建者，发送到RabbitMQ</li>
<li>消费者<br/>
连接到 RabbitMQ 订阅到队列上，消费消息，持续订阅(basicConsumer)和单条订阅(basicGet)</li>
<li>包含有效载荷和标签，有效载荷指要传输的数据，标签描述了有效载荷，并且 RabbitMQ用它来决定谁获得消息，消费者只能拿到有效载荷，病不知道生产者是谁。</li>
</ul>

<h3 id="toc_5">交换器、队列、绑定、路由键</h3>

<p>队列通过路由键(routing key，某种确定的规则)绑定到交换器，生产者将消息发布到交换器，交换器根据绑定的路由键将消息路由到特定队列， 然后由订阅这个队列的消费者进行接收。（routing_key和 丙丁见 binding_key 的最大长度是 255 个字节）</p>

<p><figure><img src="media/16022252063226/16022280502106.jpg" alt="" style="width:882px;"/></figure></p>

<h3 id="toc_6">消息的确认</h3>

<p>消费者收到的每一条消息都必须进行确认(自动确认和自行确认)。</p>

<p>消费者在声明队列时，可以指定 autoAck 参数，当 autoAck=false 时，RabbitMQ 会等待消费者显式发回 ack 信号后才从内存(和磁盘，如果是持久化消<br/>
息的话)中移去消息。否则，RabbitMQ 会在队列中消息被消费后立即删除它。</p>

<p>采用消息确认机制后，只要令 autoAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题， 因为 RabbitMQ 会一直持有消息直到消费者显式调用 basicAck 为止。</p>

<p>当 autoAck=false 时，对于 RabbitMQ 服务器端而言，队列中的消息分成了两部分:一部分是等待投递给消费者的消息;一部分是已经投递给消费者， 但是还没有收到消费者 ack 信号的消息。如果服务器端一直没有收到消费者的 ack 信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消 息重新进入队列，等待投递给下一个消费者(也可能还是原来的那个消费者)。</p>

<p>RabbitMQ 不会为未 ack 的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么 设计的原因是 RabbitMQ 允许消费者消费一条消息的时间可以很久很久</p>

<h2 id="toc_7">虚拟主机</h2>

<p>虚拟消息服务器，vhost，本质上就是一个 mini 版的 mq 服务器，有自己的队列、交换器和绑定，最重要的，自己的权限机制。Vhost 提供了逻辑上的 分离，可以将众多客户端进行区分，又可以避免队列和交换器的命名冲突。Vhost 必须在连接时指定，rabbitmq 包含缺省 vhost:“/”，通过缺省用户和 口令 guest 进行访问。</p>

<p>rabbitmq 里创建用户，必须要被指派给至少一个 vhost，并且只能访问被指派内的队列、交换器和绑定。Vhost 必须通过 rabbitmq 的管理控制工具创建。</p>

<h2 id="toc_8">交换器类型</h2>

<p>共有四种 direct、fanout、topic、headers，其中headers和 direct 可以忽略。</p>

<h3 id="toc_9">fanout</h3>

<p>消息广播到绑定的队列，不管队列绑定了什么路由键，消息经过交换器，每个队列都有一份</p>

<h3 id="toc_10">Topic</h3>

<p><code>通过使用 “*”和“#”通配符进行处理，使来自不同源头的消息到达同一个队列，”.”将路由键分为了几个标识符，“*” 匹配 1 个，“#”匹配一个或多个。</code></p>

<p><figure><img src="media/16022252063226/16022297347390.jpg" alt="" style="width:799px;"/></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[什么是消息中间件]]></title>
    <link href="http://www.throne4j.com/16021705401610.html"/>
    <updated>2020-10-08T23:22:20+08:00</updated>
    <id>http://www.throne4j.com/16021705401610.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">消息中间件(MQ)的定义</h2>

<p>其实并没有标准定义。一般认为，消息中间件属于分布式系统中一个子系统，关注于数据的发送和接收，利用高效可靠的异步消息传递机制对分布式系统中的其余各个子系统进行集成。</p>

<ul>
<li>高效:对于消息的处理处理速度快。 </li>
<li>可靠:一般消息中间件都会有消息持久化机制和其他的机制确保消息不丢失。 </li>
<li>异步:指发送完一个请求，不需要等待返回，随时可以再发送下一个请求，既不需要等待。 </li>
</ul>

<p>一句话总结，我们消息中间件不生产消息，只是消息的搬运工。</p>

<h2 id="toc_1">为什么要用消息中间件?</h2>

<p>所以消息中间件主要解决分布式系统之间消息的传递，同时为分布式系统中其他子系统提供了松耦合的架构，同时还有以下好处。</p>

<ul>
<li><p>低耦合<br/>
低耦合，不管是程序还是模块之间，使用消息中间件进行间接通信。</p></li>
<li><p>异步通信能力<br/>
异步通信能力，使得子系统之间得以充分执行自己的逻辑而无需等待。</p></li>
<li><p>缓冲能力<br/>
缓冲能力，消息中间件像是一个巨大的蓄水池，将高峰期大量的请求存储下来慢慢交给后台进行处理，对于秒杀业务来说尤为重要。</p></li>
<li><p>伸缩性<br/>
伸缩性，是指通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。就像弹簧一样挂东西一样，用 户多，伸一点，用户少，浅一点，啊，不对，缩一点。是伸缩，不是深浅。衡量架构是否高伸缩性的主要标准就是是否可用多台服务器构建集群，是否 容易向集群中添加新的服务器。加入新的服务器后是否可以提供和原来服务器无差别的服务。集群中可容纳的总的服务器数量是否有限制。</p></li>
<li><p>扩展性<br/>
扩展性，主要标准就是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。比如用户购买电影票的应用，现在我们要增加一个功能，用户买了铁血战士的票后，随机抽取用户送异形的限量周边。怎么做到不改动用户购票功能的基础上增加这个功能。熟悉设计模式的同学，应该很眼熟，这是设计模式中的开闭原则(对扩展开放，对修改关闭)在架构层面的一个原则。</p></li>
</ul>

<h2 id="toc_2">和 RPC 有何区别?</h2>

<p>RPC 和消息中间件的场景的差异很大程度上在于就是“依赖性”和“同步性”。</p>

<ul>
<li>依赖性:<br/>
比如短信通知服务并不是事交易环节必须的，并不影响下单流程，不是强依赖，所以交易系统不应该依赖短信服务。如果是 RPC 调用，短信通知服 务挂了，整个业务就挂了，这个就是依赖性导致的，而消息中间件则没有这个依赖性。</li>
</ul>

<p>消息中间件出现以后对于交易场景可能是调用库存中心等强依赖系统执行业务，之后发布一条消息(这条消息存储于消息中间件中)。像是短信通 知服务、数据统计服务等等都是依赖于消息中间件去消费这条消息来完成自己的业务逻辑。</p>

<ul>
<li>同步性:<br/>
RPC 方式是典型的同步方式，让远程调用像本地调用。消息中间件方式属于异步方式。</li>
</ul>

<h2 id="toc_3">消息中间件有些什么使用场景?</h2>

<h3 id="toc_4">异步处理</h3>

<p>场景说明: 用户注册后，需要发注册邮件和注册短信。</p>

<p>传统的做法有两种 </p>

<ul>
<li>串行的方式<br/>
将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。</li>
<li>并行方式<br/>
将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并 行的方式可以提高处理的时间。
<figure><img src="media/16021705401610/16021728568093.jpg" alt="串行"/><figcaption>串行</figcaption></figure></li>
</ul>

<p><figure><img src="media/16021705401610/16021728464187.jpg" alt="并行"/><figcaption>并行</figcaption></figure></p>

<p>上案例描述，传统的方式系统的性能(并发量，吞吐量，响应时间)会有瓶颈。如何解决这个问题呢? </p>

<p>引入消息队列，将不是必须的业务逻辑，异步处理。</p>

<p><figure><img src="media/16021705401610/16021712978489.jpg" alt="" style="width:560px;"/></figure></p>

<p>按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是 50 毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入 消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是 50 毫秒。因此架构改变后，系统的吞吐量提高到每秒 20 QPS。比串行提高了 3 倍，比 并行提高了两倍。</p>

<h3 id="toc_5">应用解耦</h3>

<p>场景说明:用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。</p>

<p>传统模式的缺点:</p>

<ul>
<li>1) 假如库存系统无法访问，则订单减库存将失败，从而导致订单失败;</li>
<li>2) 订单系统与库存系统耦合;</li>
</ul>

<p>如何解决以上问题呢?引入应用消息队列后的方案</p>

<p>订单系统:用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。 </p>

<p>库存系统:订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。</p>

<p>假如:在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与 库存系统的应用解耦。</p>

<h3 id="toc_6">流量削峰</h3>

<p>流量削峰也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。</p>

<p>应用场景:秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列:可以控制活动的人数;可以缓解短时间内高流量压垮应用。</p>

<h3 id="toc_7">日志处理</h3>

<p>日志处理是指将消息队列用在日志处理中，比如 Kafka 的应用，解决大量日志传输的问题。架构简化如下:<br/>
<figure><img src="media/16021705401610/16022199054947.jpg" alt="" style="width:623px;"/></figure></p>

<p>日志采集客户端，负责日志数据采集，定时写入 Kafka 队列:Kafka 消息队列，负责日志数据的接收，存储和转发;日志处理应用:订阅并消费 kafka 队列中的日志数据;</p>

<h3 id="toc_8">消息通讯</h3>

<p>消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。 点对点通讯:客户端 A 和客户端 B 使用同一队列，进行消息通讯。<br/>
聊天室通讯:客户端 A，客户端 B，客户端 N 订阅同一主题，进行消息发布和接收。实现类似聊天室效果。</p>

<h2 id="toc_9">常见的消息中间件比较</h2>

<p><figure><img src="media/16021705401610/16022199788204.jpg" alt="" style="width:1025px;"/></figure></p>

<p>如果一般的业务系统要引入 MQ，怎么选型:</p>

<p>用户访问量在 ActiveMQ 的可承受范围内，而且确实主要是基于解耦和异步来用的，可以考虑 ActiveMQ，也比较贴近 Java 工程师的使用习惯，但是<br/>
ActiveMQ 现在停止维护了，同时 ActiveMQ 并发不高，所以业务量一定的情况下可以考虑使用。</p>

<p>RabbitMQ 作为一个纯正血统的消息中间件，有着高级消息协议 AMQP 的完美结合，在消息中间件中地位无可取代，但是 erlang 语言阻止了我们去深入研究和掌控，对公司而言，底层技术无法控制，但是确实是开源的，有比较稳定的支持，活跃度也高。</p>

<p>对自己公司技术实力有绝对自信的，可以用 RocketMQ，但是 RocketMQ 诞生比较晚，并且更新迭代很快，这个意味着在使用过程中有可能会遇到很多坑，所以如果你们公司 Java 技术不是很强，不推荐使用。</p>

<p>如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，几乎是全世界这个领域的事实性规范。 </p>

<p>从性能上来看，使用文件系统的消息中间件(kafka、rokcetMq)性能是最好的，所以基于文件系统存储的消息中间件是发展趋势。(从存储方式和效率来看 文件系统&gt;KV存储&gt;关系型数据库)</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[B+ 树]]></title>
    <link href="http://www.throne4j.com/16020916538677.html"/>
    <updated>2020-10-08T01:27:33+08:00</updated>
    <id>http://www.throne4j.com/16020916538677.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在 java 中守护线程和用户线程的区别?]]></title>
    <link href="http://www.throne4j.com/16020533928895.html"/>
    <updated>2020-10-07T14:49:52+08:00</updated>
    <id>http://www.throne4j.com/16020533928895.html</id>
    <content type="html"><![CDATA[
<p>java 中的线程分为两种:守护线程(Daemon)和用户线程(User)。</p>

<p>任何线程都可以设置为守护线程和用户线程，通过方法 Thread.setDaemon(bool on); true 则把该线程设置为守护线程，反之则为用户线程 。Thread.setDaemon()必须在 Thread.start()之前调用，否则运行时会抛出异常。<br/>
两者的区别:<br/>
唯一的区别是判断虚拟机(JVM)何时离开，Daemon 是为其他线程提供服务，<br/>
如果全部的 User Thread 已经结束，Daemon 没有可服务的线程，JVM 关闭。 扩展:Thread Dump 打印出来的线程信息，含有 daemon 字样的线程即为守<br/>
护进程</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[伪共享]]></title>
    <link href="http://www.throne4j.com/16020519457966.html"/>
    <updated>2020-10-07T14:25:45+08:00</updated>
    <id>http://www.throne4j.com/16020519457966.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">缓存行</h2>

<p>对计算机组成原理相对熟悉的小伙伴都知道，CPU 的速度比内存的速度高了几个数量级，为了 CPU 更快从内存中读取数据，设置了多级缓存机制，如下图所示：<br/>
<figure><img src="media/16020519457966/16020586138762.jpg" alt=""/></figure></p>

<p>当 CPU 运算时，首先会从 L1 缓存查找所需要的数据，如果没有找到，再去 L2 缓存中去找，以此类推，直到从内存中获取数据，这也就意味着，越长的调用链，所耗费的执行时间也越长。</p>

<p>那是不是可以从主内存拿数据的时候，顺便多拿一些呢？这样就可以避免频繁从主内存中获取数据了。聪明的计算机科学家已经想到了这个法子，这就是缓存行的由来。</p>

<p>缓存是由多个缓存行组成的，而每个缓存行大小通常来说，大小为 64 字节，并且每个缓存行有效地引用主内存中的一块儿地址，CPU 每次从主内存中获取数据时，会将相邻的数据也一同拉取到缓存行中，这样当 CPU 执行运算时，就大大减少了与主内存的交互。</p>

<pre><code class="language-java">public class CacheLineDemo {

    //考虑一般缓存行大小是64字节，一个 long 类型占8字节
    static long[][] arr;

    public static void main(String[] args) {

        int size = 1024 * 1024;

        arr = new long[size][];
        for (int i = 0; i &lt; size; i++) {
            arr[i] = new long[8];
            for (int j = 0; j &lt; 8; j++) {
                arr[i][j] = 0L;
            }
        }
        long sum = 0L;
        long marked = System.currentTimeMillis();
        for (int i = 0; i &lt; size; i++) {
            for (int j = 0; j &lt; 8; j++) {
                sum = arr[i][j];
            }
        }
        System.out.println(&quot;[cache line]Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;);

        marked = System.currentTimeMillis();
        for (int i = 0; i &lt; 8; i += 1) {
            for (int j = 0; j &lt; size; j++) {
                sum = arr[j][i];
            }
        }
        System.out.println(&quot;[no cache line]Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;);
    }

}
</code></pre>

<h2 id="toc_1">伪共享问题</h2>

<p>当 CPU 执行完后，还需要将数据回写到内存上，以便于别的线程可以从主内存中获取最新的数据。假设两个线程都加载了相同的 Cache line 数据，会产生什么样的影响呢？下面我用一张图解释：</p>

<p><figure><img src="media/16020519457966/16020585354167.jpg" alt=""/></figure></p>

<p>数据 A、B、C 被加载到同一个 Cache line，假设线程 1 在 core1 中修改 A，线程 2 在 core2 中修改 B。</p>

<p>线程 1 首先对 A 进行修改，这时 core1 会告知其它 CPU 核，当前引用同一地址的 Cache line 已经无效，随后 core2 发起修改 B，会导致 core1 将数据回写到主内存中，core2 这时会重新从主内存中读取该 Cache line 数据。</p>

<p>可见，如果同一个 Cache line 的内容被多个线程读取，就会产生相互竞争，频繁回写主内存，降低了性能。</p>

<h2 id="toc_2">如何解决伪共享问题</h2>

<p>要解决伪共享这个问题最简单的做法就是将线程间共享元素分开到不同的 Cache line 中，这种做法叫用空间换取时间，具体做法如下：</p>

<pre><code class="language-java">public final static class ValuePadding {
  // 前置填充对象
  protected long p1, p2, p3, p4, p5, p6, p7;
  // value 值
  protected volatile long value = 0L;
  // 后置填充对象
  protected long p9, p10, p11, p12, p13, p14, p15;
}
</code></pre>

<p>JDK1.8 有专门的注解 @Contended 来避免伪共享，为了更加直观，我使用了对象填充的方法，其中 protected long p1, p2, p3, p4, p5, p6, p7 作为前置填充对象，protected long p9, p10, p11, p12, p13, p14, p15作为后置填充对象，这样任意线程访问 ValuePadding 时，value 都处于不同的 Cache line 中，不会产生伪共享问题。</p>

<p>下面的例子用来演示伪共享与解决伪共享后的性能差异：</p>

<pre><code class="language-java">public class FakeShareDemo {

    public static void main(String[] args) throws InterruptedException {
        for (int i = 1; i &lt; 10; i++) {
            System.gc();
            final long start = System.currentTimeMillis();
            runTest(Type.PADDING, i);
            System.out.println(&quot;[PADDING]Thread num &quot; + i + &quot; duration = &quot; + (System.currentTimeMillis() - start));
        }

        for (int i = 1; i &lt; 10; i++) {
            System.gc();
            final long start = System.currentTimeMillis();
            runTest(Type.NO_PADDING, i);
            System.out.println(&quot;[NO_PADDING] Thread num &quot; + i + &quot; duration = &quot; + (System.currentTimeMillis() - start));
        }
    }

    private static void runTest(Type type, int NUM_THREADS) throws InterruptedException {
        Thread[] threads = new Thread[NUM_THREADS];

        switch (type) {
            case PADDING:
                DataPadding.longs = new ValuePadding[NUM_THREADS];
                for (int i = 0; i &lt; DataPadding.longs.length; i++) {
                    DataPadding.longs[i] = new ValuePadding();
                }
                break;
            case NO_PADDING:
                Data.longs = new ValueNoPadding[NUM_THREADS];
                for (int i = 0; i &lt; Data.longs.length; i++) {
                    Data.longs[i] = new ValueNoPadding();
                }
                break;
        }


        for (int i = 0; i &lt; threads.length; i++) {
            threads[i] = new Thread(new FakeSharing(type, i));
        }
        for (Thread t : threads) {
            t.start();
        }
        for (Thread t : threads) {
            t.join();
        }
    }

    // 线程执行单元
    static class FakeSharing implements Runnable {
        public final static long ITERATIONS = 500L * 1000L * 100L;
        private int arrayIndex;
        private Type type;

        public FakeSharing(Type type, final int arrayIndex) {
            this.arrayIndex = arrayIndex;
            this.type = type;
        }

        public void run() {
            long i = ITERATIONS + 1;
            // 读取共享变量中指定的下标对象，并对其value变量不断修改
            // 由于每次读取数据都会写入缓存行，如果线程间有共享的缓存行数据，就会导致伪共享问题发生
            // 如果对象已填充，那么线程每次读取到缓存行中的对象就不会产生伪共享问题
            switch (type) {
                case NO_PADDING:
                    while (0 != --i) {
                        Data.longs[arrayIndex].value = 0L;
                    }
                    break;
                case PADDING:
                    while (0 != --i) {
                        DataPadding.longs[arrayIndex].value = 0L;
                    }
                    break;
            }
        }
    }

    // 线程间贡献的数据
    public final static class Data {
        public static ValueNoPadding[] longs;
    }

    public final static class DataPadding {
        public static ValuePadding[] longs;
    }

    // 使用填充对象
    public final static class ValuePadding {
        // 前置填充对象
        protected long p1, p2, p3, p4, p5, p6;
        // value 值
        protected volatile long value = 0L;
        // 后置填充对象
        protected long p9, p10, p11, p12, p13, p14, p15;
    }

    // 不填充对象
    //    @sun.misc.Contended
    public final static class ValueNoPadding {
        protected volatile long value = 0L;
    }

    enum Type {
        NO_PADDING,
        PADDING
    }
}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Disruptor]]></title>
    <link href="http://www.throne4j.com/16020511412975.html"/>
    <updated>2020-10-07T14:12:21+08:00</updated>
    <id>http://www.throne4j.com/16020511412975.html</id>
    <content type="html"><![CDATA[
<p>Disruptor 是英国外汇交易公司 LMAX 开发的一个高性能队列，研发的初衷是 解决内部的内存队列的延迟问题，而不是分布式队列。基于 Disruptor 开发的系 统单线程能支撑每秒 600 万订单，2010 年在 QCon 演讲后，获得了业界关注。</p>

<p>Disruptor 是一个高性能的线程间异步通信的框架，即在同一个 JVM 进程中 的多线程间消息传递。</p>

<h2 id="toc_0">传统队列问题</h2>

<p>在 JDK 中，Java 内部的队列 BlockQueue 的各种实现，仔细分析可以得知， 队列的底层数据结构一般分成三种:数组、链表和堆，堆这里是为了实现带有优先级特性的队列暂且不考虑。</p>

<p>在稳定性和性能要求特别高的系统中，为了防止生产者速度过快，导致内存 溢出，只能选择有界队列;同时，为了减少 Java 的垃圾回收对系统性能的影响， 会尽量选择 Array 格式的数据结构。这样筛选下来，符合条件的队列就只有 ArrayBlockingQueue。但是 ArrayBlockingQueue 是通过加锁的方式保证线程安全， 而且 ArrayBlockingQueue 还存在伪共享问题，这两个问题严重影响了性能。</p>

<p>ArrayBlockingQueue 的这个伪共享问题存在于哪里呢，分析下核心的部分源 码，其中最核心的三个成员变量为：takeIndex、putIndex、count，在 ArrayBlockingQueue 的核心 enqueue 和 dequeue 方法中经常会用到的，这三 个变量很容易放到同一个缓存行中，进而产生伪共享问题。</p>

<h2 id="toc_1">高性能的原理</h2>

<p>引入环形的数组结构:数组元素不会被回收，避免频繁的 GC， </p>

<p>无锁的设计:采用 CAS 无锁方式，保证线程的安全性 </p>

<p>属性填充:通过添加额外的无用信息，避免伪共享问题</p>

<p>环形数组结构是整个 Disruptor 的核心所在。</p>

<p><figure><img src="media/16020511412975/16020523609287.jpg" alt="" style="width:738px;"/></figure></p>

<p>首先，因为是数组，所以要比链表快，而且根据我们对上面缓存行的解释知道， 数组中的一个元素加载，相邻的数组元素也是会被预加载的，因此在这样的结构中，cpu 无需时不时去主存加载数组中的下一个元素。而且，你可以为数组预先分配内存，使得数组对象一直存在(除非程序终止)。</p>

<p>这就意味着不需要花大量的时间用于垃圾回收。此外，不像链表那样，需要为每一个添加到其上面的对象创造节点对象，对应的，当删除节点时，需要执行相应的内存清理操作。环形数组中的元素采用覆盖方式，避免了 jvm 的 GC。</p>

<p>其次，结构作为环形，数组的大小为 2 的 n 次方，这样元素定位可以通过位运算效率会更高，这个跟一致性哈希中的环形策略有点像。在 disruptor 中，这个牛逼的环形结构就是 RingBuffer，既然是数组，那么就有大小，而且这个大小必须是2的n次方。</p>

<p>其实质只是一个普通的数组，只是当放置数据填充满队列(即到达 2<sup>n-1</sup> 位 置)之后，再填充数据，就会从 0 开始，覆盖之前的数据，于是就相当于一个环。</p>

<p>每个生产者首先通过 CAS 竞争获取可以写的空间，然后再进行慢慢往里放数据，如果正好这个时候消费者要消费数据，那么每个消费者都需要获取最大可消费的下标。</p>

<p>同时，Disruptor 不像传统的队列，分为一个队头指针和一个队尾指针，而是只有一个角标(上图的 seq)，它属于一个 volatile 变量，同时也是我们能够不用锁操作就能实现 Disruptor 的原因之一，而且通过缓存行补充，避免伪共享 问题。该指针是通过一直自增的方式来获取下一个可写或者可读数据。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[jdk8 新增的并发]]></title>
    <link href="http://www.throne4j.com/16020424526444.html"/>
    <updated>2020-10-07T11:47:32+08:00</updated>
    <id>http://www.throne4j.com/16020424526444.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">原子操作 CAS</h2>

<p>JDK1.8 时，java.util.concurrent.atomic 包中提供了一个新的原子类:LongAdder。</p>

<p>LongAdder 在高并发的场景下会比它的前辈 --- AtomicLong 具有更好的性能，代价是消耗更多的内存空间。</p>

<p>AtomicLong 是利用了底层的 CAS 操作来提供并发性的，调用了 Unsafe 类的 getAndAddLong 方法，该方法是个 native 方法，它的逻辑是采用自旋的方式不断 更新目标值，直到更新成功。</p>

<p>在并发量较低的环境下，线程冲突的概率比较小，自旋的次数不会很多。但 是，高并发环境下，N 个线程同时进行自旋操作，会出现大量失败并不断自旋的 情况，此时 AtomicLong 的自旋会成为瓶颈。</p>

<p>AtomicLong 中有个内部变量 value 保存着实际的 long 值，所有的操作都是 针对该变量进行。也就是说，高并发环境下，value 变量其实是一个热点，也就 是 N 个线程竞争一个热点。</p>

<p>LongAdder 的基本思路就是分散热点，将 value 值分散到一个数组中，不同 线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行 CAS 操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的 long 值，只有将各个槽中的变量值累加返回，这个值也仅仅是个近似值，这也是他不能完全代替LongAtomic 的原因之一。</p>

<p>除了引入 LongAdder外，还有引入了其它三个类：LongAccumulator、DoubleAdder、DoubleAccumulator。</p>

<p>通过 LongBinaryOperator，可以自定义对入参的任意操作，并返回结果 (LongBinaryOperator 接收 2 个 long 作为参数，并返回 1 个 long)。<br/>
LongAccumulator 内部原理和 LongAdder 几乎完全一样。 DoubleAdder 和 DoubleAccumulator 用于操作 double 原始类型。</p>

<h2 id="toc_1">StampLock</h2>

<p>StampedLock 是 Java8 引入的一种新的锁机制,简单的理解,可以认为它是读写 锁的一个改进版本。</p>

<p>读写锁虽然分离了读和写的功能,使得读与读之间可以完全并发,但是读和写之间依然是冲突的,读锁会完全阻塞写锁,它使用的依然是悲观的锁策略.如果有大量的读线程,他也有可能引起写线程的饥饿。</p>

<p>而 StampedLock 则提供了一种乐观的读策略,这种乐观策略的锁非常类似于 无锁的操作,使得乐观锁完全不会阻塞写线程。它的思想是读写锁中读不仅不阻塞读，同时也不应该阻塞写。</p>

<p>读不阻塞写的实现思路:<br/>
在读的时候如果发生了写，则应当重读而不是在读的时候直接阻塞写!即读 写之间不会阻塞对方，但是写和写之间还是阻塞的! StampedLock 的内部实现是基于 CLH 的。</p>

<h2 id="toc_2">CompleteableFuture</h2>

<p>JDK1.8 才新加入的一个实现类 CompletableFuture，实现了 Future<T>，CompletionStage<T>两个接口。详情见 ： <a href="15882235745444.html">CompletableFuture</a></p>

<h2 id="toc_3">lambada 表达式</h2>

<p>在语法上，Lambda 表达式包含三个部分，参数列表，箭头，主体，比如:</p>

<pre><code class="language-text">(parameters) -&gt; expression 

(parameters) -&gt; {statements;}
</code></pre>

<p>Lambda 表达式用在函数式接口上，所谓函数式接口，是只定义了一个抽象方法的接口(Interface)，接口中是否有默认方法，不影响。</p>

<p>注解@FunctionalInterface 可以帮助我们在设计函数式接口时防止出错。</p>

<p>我们常用的 Runnable,Callable 都是函数式接口，JDK8 中新增了几个函数式接 口:</p>

<ul>
<li><p>Predicate<T> :<br/>
包含 test 方法，接受泛型的 T，返回 boolean，可以视为断言(检查)接口 </p></li>
<li><p>Consumer<T> :<br/>
包含 accept 方法，接受泛型的 T，无返回，可以视为数据消费接口 </p></li>
<li><p>Function<T，R> :<br/>
包含 apply 方法，接受泛型的 T，返回 R，可以视为映射转换接口 Supplier<T><br/>
包含 get 方法，无输入，返回 T，可以视为创建一个新对象接口 </p></li>
<li><p>UnaryOperator<T></p></li>
</ul>

<p>扩展至 Function<T，T>，所以这个本质上也是一个映射转换接口，只不过映 射转换后的类型保持不变</p>

<ul>
<li><p>BiFunction<T, U, R><br/>
包含 apply 方法，接受泛型的 T、U，返回 R，可以视为复合型映射转换接口</p></li>
<li><p>BinaryOperator<T><br/>
扩展至Function BiFunction<T,T,T>，所以这个本质上也是一个复合型映射转 换接口，只不过映射转换后的类型保持不变</p></li>
<li><p>BiPredicate <T, U><br/>
包含 test 方法，接受泛型的 T，U，返回 boolean，可以视为复合型断言(检 查)接口</p></li>
<li><p>BiConsumer<T，U>:<br/>
包含 accept 方法，接受泛型的 T，U，无返回，可以视为复合型数据消费接<br/>
口</p></li>
</ul>

<h3 id="toc_4">函数描述符</h3>

<p>函数式接口的抽象方法的签名基本上就是 Lambda 表达式的签名。我们将这 种抽象方法叫作函数描述符</p>

<p>Runnable 接口可以看作一个什么也不接受什么也不返回(void)的函数的签 名，因为它只有一个叫作 run 的抽象方法，这个方法什么也不接受，什么也不返 回(void)。</p>

<p>我们可以用 () -&gt; void 代表参数列表为空，且返回 void 的函数。这正是 Runnable 接口所代表的。我们于是可以称() -&gt; void 是 Runnable 接口的函数描述符。</p>

<h2 id="toc_5">新增类库的新特性</h2>

<h3 id="toc_6">Optional</h3>

<p>Optional实际上是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。</p>

<pre><code class="language-java">Optional&lt; String &gt; fullName = Optional.ofNullable( null );
System.out.println( &quot;Full Name is set? &quot; + fullName.isPresent() );        
System.out.println( &quot;Full Name: &quot; + fullName.orElseGet( () -&gt; &quot;[none]&quot; ) ); 
System.out.println( fullName.map( s -&gt; &quot;Hey &quot; + s + &quot;!&quot; ).orElse( &quot;Hey Stranger!&quot; ) );
</code></pre>

<h3 id="toc_7">Stream</h3>

<p>最新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中,Stream API极大简化了集合框架的处理</p>

<h3 id="toc_8">Date/Time API (JSR 310)</h3>

<p>当前北京时间：  2020-10-07 23:41:45</p>

<ul>
<li>第一个是Clock类<br/>
它通过指定一个时区，然后就可以获取到当前的时刻，日期与时间。Clock可以替换System.currentTimeMillis()与TimeZone.getDefault()。</li>
</ul>

<pre><code class="language-java">// Get the system clock as UTC offset 
final Clock clock = Clock.systemUTC();
System.out.println( clock.instant() );
System.out.println( clock.millis() );

2020-10-07T15:46:53.818Z
1602085613878
</code></pre>

<ul>
<li>LocaleDateTime、LocalDate、LocalTime</li>
</ul>

<p>LocaleDate只持有ISO-8601格式且无时区信息的日期部分。相应的，LocaleTime只持有ISO-8601格式且无时区信息的时间部分。LocaleDate与LocalTime都可以从Clock中得到</p>

<pre><code class="language-java">// Get the local date and local time
final LocalDate date = LocalDate.now();
final LocalDate dateFromClock = LocalDate.now( clock );
         
System.out.println( date );
System.out.println( dateFromClock );
         
// Get the local date and local time
final LocalTime time = LocalTime.now();
final LocalTime timeFromClock = LocalTime.now( clock );
         
System.out.println( time );
System.out.println( timeFromClock );

2020-10-07
2020-10-07
23:47:33.925
15:47:33.925
</code></pre>

<p>LocalDateTime</p>

<pre><code class="language-java">// Get the local date/time
final LocalDateTime datetime = LocalDateTime.now();
final LocalDateTime datetimeFromClock = LocalDateTime.now( clock );
         
System.out.println( datetime );
System.out.println( datetimeFromClock );

2020-10-07T23:50:34.974
2020-10-07T15:50:34.974
</code></pre>

<p>如果你需要特定时区的日期/时间，那么ZonedDateTime是你的选择。它持有ISO-8601格式具具有时区信息的日期与时间</p>

<pre><code class="language-java">// Get the zoned date/time
final ZonedDateTime zonedDatetime = ZonedDateTime.now();
final ZonedDateTime zonedDatetimeFromClock = ZonedDateTime.now( clock );
final ZonedDateTime zonedDatetimeFromZone = ZonedDateTime.now( ZoneId.of( &quot;Asia/Shanghai&quot; ) );
         
System.out.println( zonedDatetime );
System.out.println( zonedDatetimeFromClock );
System.out.println( zonedDatetimeFromZone );

2020-10-07T23:56:49.792+08:00[Asia/Shanghai]
2020-10-07T15:56:49.792Z
2020-10-07T23:56:49.792+08:00[Asia/Shanghai]
</code></pre>

<h2 id="toc_9">JavaScript 引擎 Nashorn</h2>

<p>Nashorn，一个新的JavaScript引擎随着Java 8一起公诸于世，它允许在JVM上开发运行某些JavaScript应用。Nashorn就是javax.script.ScriptEngine的另一种实现，并且它们俩遵循相同的规则，允许Java与JavaScript相互调用。下面看一个例子：</p>

<pre><code class="language-java">ScriptEngineManager manager = new ScriptEngineManager();
ScriptEngine engine = manager.getEngineByName( &quot;JavaScript&quot; );
         
System.out.println( engine.getClass().getName() );
System.out.println( &quot;Result:&quot; + engine.eval( &quot;function f() { return 1; }; f() + 1;&quot; ) );
</code></pre>

<h2 id="toc_10">Base64</h2>

<p>在Java 8中，Base64编码已经成为Java类库的标准。</p>

<pre><code class="language-java">import java.nio.charset.StandardCharsets;
import java.util.Base64;
 
public class Base64s {
    public static void main(String[] args) {
        final String text = &quot;Base64 finally in Java 8!&quot;;
         
        final String encoded = Base64
            .getEncoder()
            .encodeToString( text.getBytes( StandardCharsets.UTF_8 ) );
        System.out.println( encoded );
         
        final String decoded = new String( 
            Base64.getDecoder().decode( encoded ),
            StandardCharsets.UTF_8 );
        System.out.println( decoded );
    }
}
</code></pre>

<p>Base64类同时还提供了对URL、MIME友好的编码器与解码器（Base64.getUrlEncoder() / Base64.getUrlDecoder(), Base64.getMimeEncoder() / Base64.getMimeDecoder()）。</p>

<h2 id="toc_11">并行（parallel）数组</h2>

<p>Java 8增加了大量的新方法来对数组进行并行处理。可以说，最重要的是parallelSort()方法，因为它可以在多核机器上极大提高数组排序的速度。</p>

<pre><code class="language-java">import java.util.Arrays;
import java.util.concurrent.ThreadLocalRandom;
 
public class ParallelArrays {
    public static void main( String[] args ) {
        long[] arrayOfLong = new long [ 20000 ];        
         
        Arrays.parallelSetAll( arrayOfLong, 
            index -&gt; ThreadLocalRandom.current().nextInt( 1000000 ) );
        Arrays.stream( arrayOfLong ).limit( 10 ).forEach( 
            i -&gt; System.out.print( i + &quot; &quot; ) );
        System.out.println();
         
        Arrays.parallelSort( arrayOfLong );     
        Arrays.stream( arrayOfLong ).limit( 10 ).forEach( 
            i -&gt; System.out.print( i + &quot; &quot; ) );
        System.out.println();
    }
}
</code></pre>

<h2 id="toc_12">Java虚拟机（JVM）的新特性</h2>

<p>PermGen空间被移除了，取而代之的是Metaspace（JEP 122）。JVM选项-XX:PermSize与-XX:MaxPermSize分别被-XX:MetaSpaceSize与-XX:MaxMetaspaceSize所代替</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[java 内存模型]]></title>
    <link href="http://www.throne4j.com/16019058386155.html"/>
    <updated>2020-10-05T21:50:38+08:00</updated>
    <id>http://www.throne4j.com/16019058386155.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">概念</h2>

<p>在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。</p>

<p>在命令式编程中，线程之间的通信机制有两种</p>

<ul>
<li><p>共享内存<br/>
在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写 - 读内存中的公共状态来隐式进行通信。</p></li>
<li><p>消息传递。<br/>
在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。</p></li>
</ul>

<p>同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。</p>

<p>Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的 Java 程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。</p>

<p>Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这三个特征来建立的</p>

<h2 id="toc_1">java 内存模型产生的原因</h2>

<p>由于计算机的存储设备与处理器的运算速度有着几个数量级的差距，所以现代计算机系统都不得不加入一层或多 层读写速度尽可能接近处理器运算速度的高速缓存(Cache)来作为内存与处理器之间的缓冲:将运算 需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处 理器就无须等待缓慢的内存读写了。下图说明了处理器、高速缓存、主内存之间的交互关系：</p>

<p><figure><img src="media/16019058386155/16019095209346.jpg" alt=""/></figure></p>

<p>基于高速缓存的存储交互很好地解决了处理器与内存速度之间的矛盾，但是也为计算机系统带来 更高的复杂度，它引入了一个新的问题:<strong><em>缓存一致性(Cache Coherence)</em></strong>。</p>

<p><strong>在多路处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存(Main Memory)，这种系统称为共享内存多核系统</strong></p>

<p>Java虚拟机规范中曾试图定义一种 ”java 内存模型“来 屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。</p>

<p>Java内存模型的主要目的是定义程序中各种变量的访问规则，即关注在虚拟机中把变量值存储到 内存和从内存中取出变量值这样的底层细节。</p>

<p>Java内存模型规定了所有的变量都存储在主内存(Main Memory)中，每条线程还有自己的工作内存，线程的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的数据。</p>

<p>线程、主内存、工作内存的交互关系如下图所示：<br/>
<figure><img src="media/16019058386155/16019096316120.jpg" alt=""/></figure></p>

<h2 id="toc_2">java内存模型带来的问题</h2>

<h3 id="toc_3">可见性问题</h3>

<p><figure><img src="media/16019058386155/16019103811364.jpg" alt=""/></figure></p>

<p>左边 CPU 中运行的线程从主存中拷贝共享对象 obj 到它的 CPU 缓存，把对 象 obj 的 count 变量改为 2。但这个变更对运行在右边 CPU 中的线程不可见，因 为这个更改还没有 flush 到主存中。</p>

<p>要解决共享对象可见性这个问题，我们可以使用 volatile 关键字或者是加锁</p>

<h3 id="toc_4">竞争问题</h3>

<p><figure><img src="media/16019058386155/16019105072940.jpg" alt=""/></figure></p>

<p>图中两个加 1 操作是并行的，不管 是线程 A 还是线程 B 先 flush 计算结果到主存，最终主存中的 Obj.count 只会增 加 1 次变成 2，尽管一共有两次加 1 操作。 </p>

<p>要解决上面的问题我们可以使用 java synchronized 代码块</p>

<h2 id="toc_5">重排序</h2>

<p>在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：</p>

<ul>
<li>编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</li>
<li>指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</li>
<li>内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</li>
</ul>

<p>从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序：<br/>
<figure><img src="media/16019058386155/16019073878819.jpg" alt=""/></figure></p>

<p>JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。</p>

<h2 id="toc_6">数据依赖性</h2>

<p>数据依赖性:如果两个操作访问同一个变量，且这两个操作中有一个为写操 作，此时这两个操作之间就存在数据依赖性。数据依赖分为下列 3 种类型，上面 3 种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。<br/>
<figure><img src="media/16019058386155/16019107599119.jpg" alt=""/></figure></p>

<p>依赖关系：<br/>
<figure><img src="media/16019058386155/16019108342482.jpg" alt=""/></figure></p>

<p>很明显，A 和 C 存在数据依赖，B 和 C 也存在数据依赖，而 A 和 B 之间不存 在数据依赖，如果重排序了 A 和 C 或者 B 和 C 的执行顺序，程序的执行结果就 会被改变。</p>

<p>不管如何重排序，都必须保证代码在单线程下的运行正确，连单线 程下都无法正确，更不用讨论多线程并发的情况，所以就提出了一个 as-if-serial 的概念。</p>

<h2 id="toc_7">as-if-serial</h2>

<p>as-if-serial 语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime 和处理器都必须遵守 as-if-serial 语义。</p>

<p>为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。</p>

<h2 id="toc_8">happens-before</h2>

<p>在 Java 规范提案中为让大家理解内存可见性的这个概念，JSR-133 提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 </p>

<p>happens-before 关系保证正确同步的多线程程序的执行结果不被改变。与程序员密切相关的 happens-before 规则如下：</p>

<ul>
<li>程序顺序规则：一个线程中的每个操作，happens-before 于该线程中的任意后续操作。</li>
<li>监视器锁规则：对一个监视器锁的解锁，happens-before 于随后对这个监视器锁的加锁。</li>
<li>volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。</li>
<li>传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。</li>
<li>start() 规则：如果线程A执行操作 ThreadB.start()（启动线程B)，那么 A 线程 的ThreadB.start() 操作 happens-before 与线程 B 中的任意操作</li>
<li>join()规则：如果线程 A 执行曹邹 ThreadB.join()并成功返回，那么线程 B 中的任意操作 happens-before 与线程A从 ThreadB.join() 操作成功返回。</li>
<li>线程中断规则： 对线程 interrupt 方法的调用 happens-before 与被中断线程的代码检测到中断事件的发生。</li>
</ul>

<p>注意： 两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。</p>

<h2 id="toc_9">内存屏障</h2>

<p>Java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，从而让程序按我们预想的流程去执行。</p>

<ul>
<li>保证特定操作的执行顺序。</li>
<li>影响某些数据(或则是某条指令的执行结果)的内存可见性</li>
</ul>

<p>编译器和 CPU 能够重排序指令，保证最终相同的结果，尝试优化性能。插入一条 Memory Barrier 会告诉编译器和 CPU:不管什么指令都不能和这条 Memory Barrier 指令重排序。</p>

<p>Memory Barrier 所做的另外一件事是强制刷出各种 CPU cache，如一个 Write-Barrier(写入屏障)将刷出所有在 Barrier 之前写入 cache 的数据，因此， 任何 CPU 上的线程都能读取到这些数据的最新版本。</p>

<p>JMM 把内存屏障指令分为 4 类</p>

<ul>
<li>LoadLoad barrier<br/>
Load1: LoadLoad: Load2  确保load1 数据的装载，之前与Load2及所有后续装载指令的装载 </li>
<li>StoreStore barrier<br/>
Store1: StoreStore : Store2 确保 Sttore1 数据对其他处理器可见（刷新到内存)之前与Store2以及所有后续存储指令的存储</li>
<li>LoadStore barrier<br/>
Load1：LoadStore：Store2 确保 Load1数据装载之前与Store2以及所有后续的存储指令刷新到内存 </li>
<li>StoreLoad barrier<br/>
Store1: StoreLoad: Load2  确保Store1数据对其他处理器变得可见（指刷新到内存）之前与 Load2 以及所有后续装载指令的装载，StoreLoad barrier 会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令</li>
</ul>

<p>StoreLoad Barrier 是一个“全能型”的屏障，它同时具有其他 3 个屏障的 效果。现代的多处理器大多支持该屏障(其他类型的屏障不一定被所有处理器支持)。</p>

<h2 id="toc_10">volatile 详解</h2>

<h3 id="toc_11">volatile特性</h3>

<p>volatile 变量自身具有下列特性：</p>

<ul>
<li>可见性： 对于一个volatile 变量的读 总是能看到对这个volatile变量最后的写入</li>
<li>原子性： 对任意单个 volatile 变量的 读/写 具有原子性，但类似于 volatile++ 这种复合操作不具有原子性</li>
</ul>

<h3 id="toc_12">volatile 的内存语义</h3>

<p>内存语义： 可以简单理解为 volatile， synchronize，atomic，lock 之类的在 JVM 中的内存方面实现原则。</p>

<p>volatile 写的内存语义： 当写一个 volatile 变量时，JMM 会把该线程对应的本地内存中的共享变量值刷新到主内存。</p>

<p>volatile读的内存语义： 当读一个 volatile 变量时，JMM 会把该线程对应的本地内存中的共享变量值刷新到主内存。</p>

<pre><code class="language-java">public class VolatileDemo {
    private volatile static boolean ready;
    private static int number = 1;

    private static class PrintThread extends Thread {
        public PrintThread(String name) {
            super(name);
        }
        @Override
        public void run() {
            while (!ready) {
                System.out.println(&quot;number: &quot; + number++);
            }
        }
    }

    public static void main(String[] args) throws InterruptedException {
        new PrintThread(&quot;volatile apply&quot;).start();
        Thread.sleep(2000);
        ready = true;
    }
}
</code></pre>

<h3 id="toc_13">volatile 的内存屏障</h3>

<p>在java中 对volatile 修饰的变量，编译器在生成字节码的时候，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序问题。</p>

<p><figure><img src="media/16019058386155/16020040859402.jpg" alt=""/></figure></p>

<p><figure><img src="media/16019058386155/16020041276962.jpg" alt=""/></figure></p>

<h3 id="toc_14">volatile 的实现原理</h3>

<p>通过对 OpenJDK 中的 unsafe.cpp 源码的分析，会发现被 volatile 关键字修饰的变量会存在一个“lock:”的前缀。</p>

<p>Lock 前缀，Lock 不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock<br/>
会对 CPU 总线和高速缓存加锁，可以理解为 CPU 指令级的一种锁。</p>

<p>同时该指令会将当前处理器缓存行的数据直接写会到系统内存中，且这个写 回内存的操作会使在其他 CPU 里缓存了该地址的数据无效。</p>

<p>在具体的执行上，它先对总线和缓存加锁，然后执行后面的指令，最后释放 锁后会把高速缓存中的脏数据全部刷新回主内存。在 Lock 锁住总线的时候， 其他 CPU 的读写请求都会被阻塞，直到锁释放。</p>

<h2 id="toc_15">final 关键字</h2>

<p>final 引用不能从构造函数内逃逸</p>

<h3 id="toc_16">final 的两个重排序规则</h3>

<p>对应 final 域，编译器和处理器需要遵守两个重排序规则。</p>

<ul>
<li>写 final 域的重排序规则可以确保在对象引用为任意线程可见之前， 对象的 final 域已经被正常的初始化了，而普通域不具有这样的保证。</li>
<li>读 final 域的重排序规则可以确保在读一个对象的 final 域之前，一定会先读包含这个 final 域的对象的引用。</li>
</ul>

<h3 id="toc_17">final 语义的实现</h3>

<p>会要求编译器在final域的写之后，构造函数return之前插入一个StoreStore<br/>
障屏。<br/>
读 final 域的重排序规则要求编译器在读 final 域的操作前面插入一个<br/>
LoadLoad 屏障</p>

<h2 id="toc_18">synchronized 的实现原理</h2>

<p><a href="16005248987908.html">Synchronized关键字解析</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[并发下的性能]]></title>
    <link href="http://www.throne4j.com/16019052240877.html"/>
    <updated>2020-10-05T21:40:24+08:00</updated>
    <id>http://www.throne4j.com/16019052240877.html</id>
    <content type="html"><![CDATA[
<p>使用并发的目标是为了提高性能，引入多线程后，其实会引入额外的开销， 如线程之间的协调、增加的上下文切换，线程的创建和销毁，线程的调度等等。 过度的使用和不恰当的使用，会导致多线程程序甚至比单线程还要低。</p>

<p>衡量应用的程序的性能:服务时间，延迟时间，吞吐量，可伸缩性等等，其中服务时间，延迟时间(多快)，吞吐量(处理能力的指标，完成工作的多少)。 多快和多少，完全独立，甚至是相互矛盾的。<br/>
对服务器应用来说:多少(可伸缩性，吞吐量)这个方面比多快更受重视。 我们做应用的时候: </p>

<ul>
<li>先保证程序正确，确实达不到要求的时候，再提高速度。(黄金原则) </li>
<li>一定要以测试为基准。</li>
</ul>

<h2 id="toc_0">线程引入的开销</h2>

<ul>
<li>上下文切换<br/>
上下文切换对系统来说意味着消耗大量的 CPU 时间</li>
</ul>

<p>如果主线程是唯一的线程,那么它基本上不会被调度出去。另一方面,如果可 运行的线程数大于 CPU 的数量,那么操作系统最终会将某个正在运行的线程调度 出来,从而使其他线程能够使用 CPU。这将导致一次上下文切换,在这个过程中将 保存当前运行线程的执行上下文,并将新调度进来的线程的执行上下文设置为当 前上下文。</p>

<ul>
<li>内存同步<br/>
同步操作的性能开销包括多个方面。在 synchronized 和 volatile 提供的可见 性保证中可能会使用一些特殊指令,即内存屏障( Memory Barrier)。</li>
</ul>

<p>内存屏障可以刷新缓存,使缓存无效刷新硬件的写缓冲,以及停止执行管道。可能同样会对性能带来间接的影响，因为他们会由于禁止指令重排序进而抑制一些编译器优化操作</p>

<ul>
<li>阻塞<br/>
引起阻塞的原因： 包括阻塞 IO,等待获取发生竞争的锁, 或者在条件变量上等待等等。</li>
</ul>

<h2 id="toc_1">如何减少锁的竞争</h2>

<ul>
<li><p>减少锁的粒度<br/>
使用锁的时候，锁所保护的对象是多个，当这些多个对象其实是独立变化的 时候，不如用多个锁来一一保护这些对象。但是如果有同时要持有多个锁的业务 方法，要注意避免发生死锁</p></li>
<li><p>缩小锁的范围<br/>
对锁的持有实现快进快出，尽量缩短持由锁的的时间。将一些与锁无关的代 码移出锁的范围，特别是一些耗时，可能阻塞的操作</p></li>
<li><p>避免多余的锁<br/>
两次加锁之间的语句非常简单，导致加锁的时间比执行这些语句还长，这个时候应该进行锁粗化—扩大锁的范围。</p></li>
<li><p>锁分段： jdk7 中的 ConcurrrentHashMap就是典型的锁分段</p></li>
<li><p>替换独占锁<br/>
使用读写锁、自旋CAS 或 使用并发容器</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[阻塞队列]]></title>
    <link href="http://www.throne4j.com/16018869228940.html"/>
    <updated>2020-10-05T16:35:22+08:00</updated>
    <id>http://www.throne4j.com/16018869228940.html</id>
    <content type="html"><![CDATA[
<p>队列是一种特殊的线性表，特殊之处在于它只允许在表的前端(front)进行删除操作，而在表的后端(rear)进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。</p>

<p>在队列中插入一个队列元素称为入队，从队列中删除一个队列元素称为出队。 因为队列只允许在一端插入，在另一端删除，所以只有最早进入队列的元素才能 最先从队列中删除，故队列又称为先进先出(FIFO—first in first out)线性表。</p>

<h2 id="toc_0">什么是阻塞队列</h2>

<p>1)支持阻塞的插入方法: 意思是当队列满时，队列会阻塞插入元素的线程， 直到队列不满。<br/>
2)支持阻塞的移除方法: 意思是在队列为空时，获取元素的线程会等待队 列变为非空。</p>

<p>BlockingQueue不接受null元素, 其实现被设计为主要用于生产者 - 消费者队列。消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用 来获取元素的容器。</p>

<p>在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。</p>

<p>如下生产者消费模式：</p>

<pre><code class="language-java">class Producer implements Runnable {
    private final BlockingQueue queue;

    Producer(BlockingQueue q) {
        queue = q;
    }

    public void run() {
        try {
            while (true) {
                queue.put(produce());
            }
        } catch (InterruptedException ex) { 
            //...handle ...
        }
    }

    Object produce() { 
        // 生产...
    }
}

class Consumer implements Runnable {
    private final BlockingQueue queue;

    Consumer(BlockingQueue q) {
        queue = q;
    }

    public void run() {
        try {
            while (true) {
                consume(queue.take());
            }
        } catch (InterruptedException ex) { ...handle ...}
    }

    void consume(Object x) { 
        // do something...
    }
}
</code></pre>

<hr/>

<h2 id="toc_1">阻塞队列的操作</h2>

<p>BlockingQueue 方法有四种形式，具有不同的操作方式，不能立即满足，但可能在将来的某个时间点满足的方法:</p>

<table>
<thead>
<tr>
<th>方法</th>
<th>抛出异常</th>
<th>返回特殊值</th>
<th>一直阻塞</th>
<th>超时退出</th>
</tr>
</thead>

<tbody>
<tr>
<td>插入方法</td>
<td>add(e)</td>
<td>offer(e)</td>
<td>put(e)</td>
<td>offer(e,time,unit)</td>
</tr>
<tr>
<td>移除方法</td>
<td>remove()</td>
<td>poll()</td>
<td>take()</td>
<td>pull(time,unit)</td>
</tr>
<tr>
<td>检索方法</td>
<td>element()</td>
<td>peek()</td>
<td>无</td>
<td>无</td>
</tr>
</tbody>
</table>

<ul>
<li><p>抛出异常<br/>
IllegalStateException - 如果由于容量限制，此时无法添加该元素<br/>
ClassCastException - 由于类型转换异常，无法添加元素<br/>
NullPointerException - 如果指定的元素为null<br/>
IllegalArgumentException - 如果指定元素的某些属性阻止将其添加到此队列中</p></li>
<li><p>返回特殊值:当往队列插入元素时，会返回元素是否插入成功，成功返回 true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回 null。</p></li>
<li><p>一直阻塞:当阻塞队列满时，如果生产者线程往队列里 put 元素，队列会 一直阻塞生产者线程，直到队列可用或者响应中断退出。当队列空时，如果消费 者线程从队列里 take 元素，队列会阻塞住消费者线程，直到队列不为空。</p></li>
<li><p>超时退出:当阻塞队列满时，如果生产者线程往队列里插入元素，队列会 阻塞生产者线程一段时间，如果超过了指定的时间，生产者线程就会退出。</p></li>
</ul>

<hr/>

<p>BlockingQueue实现是线程安全的。 所有排队方法使用内部锁或其他形式的并发控制在原子上实现其效果.</p>

<h2 id="toc_2">常用的阻塞队列</h2>

<ul>
<li>ArrayBlockingQueue:一个由数组结构组成的有界阻塞队列。<br/>
是一个用数组实现的有界阻塞队列。此队列按照先进先出(FIFO)的原则对 元素进行排序。默认情况下不保证线程公平的访问队列，所谓公平访问队列是指 阻塞的线程，可以按照阻塞的先后顺序访问队列，即先阻塞线程先访问队列。非 公平性是对先等待的线程是非公平的，当队列可用时，阻塞的线程都可以争夺访 问队列的资格，有可能先阻塞的线程最后才访问队列。</li>
<li>LinkedBlockingQueue:一个由链表结构组成的有界阻塞队列。 </li>
<li>PriorityBlockingQueue:一个支持优先级排序的无界阻塞队列。 </li>
<li>DelayQueue:一个使用优先级队列实现的无界阻塞队列。<br/>
是一个支持延时获取元素的无界阻塞队列。队列使用 PriorityQueue 来实现。 队列中的元素必须实现 Delayed 接口，在创建元素时可以指定多久才能从队列中 获取当前元素。只有在延迟期满时才能从队列中提取元素。<br/>
DelayQueue 非常有用，可以将 DelayQueue 运用在以下应用场景。<br/>
缓存系统的设计:可以用 DelayQueue 保存缓存元素的有效期，使用一个线 程循环查询 DelayQueue，一旦能从 DelayQueue 中获取元素时，表示缓存有效期 到了。还有订单到期，限时支付等等</li>
<li>SynchronousQueue:一个不存储元素的阻塞队列。 <br/>
是一个不存储元素的阻塞队列。每一个 put 操作必须等待一个 take 操作， 否则不能继续添加元素。SynchronousQueue 可以看成是一个传球手，负责把生 产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常 适合传递性场景。SynchronousQueue 的吞吐量高于 LinkedBlockingQueue 和 ArrayBlockingQueue。</li>
<li>LinkedTransferQueue:一个由链表结构组成的无界阻塞队列。 </li>
<li>LinkedBlockingDeque:一个由链表结构组成的双向阻塞队列。</li>
</ul>

<h3 id="toc_3">Array 实现和 Linked 实现的区别</h3>

<ul>
<li>队列中锁的实现不同<br/>
ArrayBlockingQueue 实现的队列中的锁是没有分离的，即生产和消费用的是 同一个锁;<br/>
LinkedBlockingQueue 实现的队列中的锁是分离的，即生产用的是 putLock， 消费是 takeLock</li>
<li>在生产或消费时操作不同<br/>
ArrayBlockingQueue 实现的队列中在生产和消费的时候，是直接将枚举对象插入或移除的;<br/>
LinkedBlockingQueue 实现的队列中在生产和消费的时候，需要把枚举对象转换为 Node<E>进行插入或移除，会影响性能 </li>
<li>队列大小初始化方式不同<br/>
ArrayBlockingQueue 实现的队列中必须指定队列的大小; LinkedBlockingQueue 实现的队列中可以不指定队列的大小，但是默认是Integer.MAX_VALUE<br/>
### DelayQueue<br/>
是一个支持延时获取元素的无界阻塞队列。队列使用 PriorityQueue 来实现。 队列中的元素必须实现 Delayed 接口，在创建元素时可以指定多久才能从队列中 获取当前元素。只有在延迟期满时才能从队列中提取元素。</li>
</ul>

<p>可以将 DelayQueue 运用在以下应用场景:<br/>
缓存系统的设计:可以用 DelayQueue 保存缓存元素的有效期，使用一个线程循环查询 DelayQueue，一旦能从 DelayQueue 中获取元素时，表示缓存有效期到了。还有订单到期，限时支付等等</p>

<h3 id="toc_4">SynchronousQueue</h3>

<p>本身不存储任何元素，每一个put操作必须等待一个take操作，将消息从生产者直接传递到消费者。</p>

<h3 id="toc_5">LinkedBlockingDeque</h3>

<p>LinkedBlockingDeque 是一个由链表结构组成的双向阻塞队列。所谓双向队列 指的是可以从队列的两端插入和移出元素。双向队列因为多了一个操作队列的入 口，在多线程同时入队时，也就减少了一半的竞争。多了 addFirst、addLast、offerFirst、offerLast、peekFirst 和 peekLast 等方法。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[并发容器]]></title>
    <link href="http://www.throne4j.com/16018795144440.html"/>
    <updated>2020-10-05T14:31:54+08:00</updated>
    <id>http://www.throne4j.com/16018795144440.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">跳跃表</h2>

<p>传统意义的单链表是一个线性结构，向有序的链表中插入一个节点需要 O(n) 的时间，查找操作需要 O(n)的时间。</p>

<p>跳跃表其实也是一种通过“空间来换取时间”的一个算法，令链表的每个结 点不仅记录 next 结点位置，还可以按照 level 层级分别记录后继第 level 个结点。 此法使用的就是“先大步查找确定范围，再逐渐缩小迫近”的思想进行的查找。跳 跃表在算法效率上很接近红黑树。</p>

<p>跳跃表又被称为概率，或者说是随机化的数据结构，目前开源软件 Redis 和 lucence 都有用到它。</p>

<p>都是线程安全的 Map 实现，ConcurrentHashMap 的性能和存储空间要优于 ConcurrentSkipListMap，但是 ConcurrentSkipListMap 有一个功能: 它会按照键的 顺序进行排序。</p>

<h2 id="toc_1">ConcurrentLinkedQueue</h2>

<p>界非阻塞队列，它是一个基于链表的无界线程安全队列。该队列的元素 遵循先进先出的原则。头是最先加入的，尾是最近加入的。插入元素是追加到 尾上。提取一个元素是从头提取。</p>

<p>大家可以看成是 LinkedList 的并发版本，常用方法: concurrentLinkedQueue.add(&quot;c&quot;);<br/>
concurrentLinkedQueue.offer(&quot;d&quot;); // 将指定元素插入到此队列的尾部。 concurrentLinkedQueue.peek(); // 检索并不移除此队列的头，如果此队列为<br/>
空，则返回 null。<br/>
concurrentLinkedQueue.poll(); // 检索并移除此队列的头，如果此队列为空， 则返回 null。</p>

<h2 id="toc_2">写时复制容器 CopyOnWriteArrayList 和 CopyOnWriteArraySet</h2>

<p>CopyOnWrite 容器即写时复制的容器。通俗的理解是当我们往一个容器添加 元素的时候，不直接往当前容器添加，而是先将当前容器进行 Copy，复制出一 个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指 向新的容器。</p>

<p>这样做的好处是我们可以对 CopyOnWrite 容器进行并发的读，而不需要加锁， 因为当前容器不会添加任何元素。所以 CopyOnWrite 容器也是一种读写分离的思 想，读和写不同的容器。如果读的时候有多个线程正在向 CopyOnWriteArrayList 添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList。</p>

<p>使用 CopyOnWriteMap 需要注意两件事情:</p>

<ul>
<li>减少扩容开销。根据实际需要，初始化 CopyOnWriteMap 的大小，<br/>
避免写时 CopyOnWriteMap 扩容的开销。</li>
<li>使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加<br/>
次数，可以减少容器的复制次数。</li>
</ul>

<h3 id="toc_3">写时复制容器的问题</h3>

<ul>
<li><p>性能问题<br/>
每次修改都创建一个新数组，然后复制所有内容，如果数组比较大，修改操作又比较频繁，可以想象，性能是很低的，而且内存开销会很大。</p></li>
<li><p>数据一致性问题。<br/>
CopyOnWrite 容器只能保证数据的最终一致性，不能保证数据的实时一致性。 所以如果你希望写入的的数据，马上能读到，不要使用 CopyOnWrite 容器</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Map相关面试题]]></title>
    <link href="http://www.throne4j.com/16018300195259.html"/>
    <updated>2020-10-05T00:46:59+08:00</updated>
    <id>http://www.throne4j.com/16018300195259.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">HashMap、LinkedHashMap、treeMap的区别以及使用场景</h2>

<ul>
<li>HashMap：允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。</li>
<li>LinkedHashMap：保存了记录的插入顺序，在用iterator遍历时，险渠道的记录肯定是先插入的，但是遍历比 HashMap 慢，在需要输出顺序和输入顺序相同的情况下使用。</li>
<li>TreeMap：实现了SortMap接口，能够吧它保存的记录根据键排序（默认是按键值升序排序，也可以指定排序的比较器）。在需要按自然顺序或自定义顺序便来键的情况下使用。</li>
</ul>

<h2 id="toc_1">HashMap和HashTable有什么区别</h2>

<ul>
<li>HashMap是线程不安全的，HashTable是线程安全的</li>
<li>HashTabe 效率比 HashMap 效率低</li>
<li>HashMap最多只允许一条记录的键为null，允许多条记录的值为 null， HashTable 不允许 null</li>
<li>HashMap的默认初始化数组大小为 16，而 HashTable 为 11，HashMap 扩容时是扩大两倍，HashTable扩容时扩大两倍+1</li>
<li>HashMap需要重新计算 hash值，HashTable直接使用对象的 hashCode</li>
</ul>

<h2 id="toc_2">Java 中的另一个线程安全的与 HashMap 极其类似的类是什么?同样是 线程安全，它与 HashTable 在线程同步上有什么不同?</h2>

<p>ConcurrentHashMap 类(是 Java 并发包 java.util.concurrent 中提供的一 个线程安全且高效的 HashMap 实现)</p>

<p>HashTable 是使用 synchronize 关键字加锁的原理(就是对对象加锁);<br/>
而针对 ConcurrentHashMap，在 JDK 1.7 中采用分段锁的方式;JDK 1.8 中 直接采用了 CAS(无锁算法)+ synchronized，也采用分段锁的方式并大大缩小了 锁的粒度。</p>

<h2 id="toc_3">HashMap &amp; ConcurrentHashMap 的区别?</h2>

<p>除了加锁，原理上无太大区别。<br/>
另外，HashMap 的键值对允许有 null，但是 ConCurrentHashMap 都不允许。 在数据结构上，红黑树相关的节点类</p>

<h2 id="toc_4">为什么 ConcurrentHashMap 比 HashTable 效率要高?</h2>

<p>HashTable 使用一把锁(锁住整个链表结构)处理并发问题，多个线程竞争一把锁，容易阻塞;</p>

<p>ConcurrentHashMap</p>

<p>JDK 1.7 中使用分段锁(ReentrantLock + Segment + HashEntry)，相当于把一 个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度:基 于 Segment，包含多个 HashEntry。</p>

<p>JDK 1.8 中使用 CAS + synchronized + Node + 红黑树。锁粒度:Node(首结 点)(实现 Map.Entry<K,V>)。锁粒度降低了。</p>

<h2 id="toc_5">针对 ConcurrentHashMap 锁机制具体分析(JDK 1.7 VS JDK 1.8)?</h2>

<p>JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组+链表<br/>
的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。 </p>

<ul>
<li>1、Segment 继承 ReentrantLock(重入锁) 用来充当锁的角色，每个Segment 对象守护每个散列映射表的若干个桶; </li>
<li>2、HashEntry 用来封装映射表的键-值对;</li>
<li>3、每个桶是由若干个 HashEntry 对象链接起来的链表。</li>
</ul>

<p>JDK 1.8 中，采用 Node + CAS + Synchronized 来保证并发安全。取消类 Segment，直接用 table 数组存储键值对;当 HashEntry 对象组成的链表长度超 过 TREEIFY_THRESHOLD 时，链表转换为红黑树，提升性能。底层变更为数组 + 链表 + 红黑树。</p>

<h2 id="toc_6">ConcurrentHashMap 在 JDK 1.8 中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock?</h2>

<ul>
<li>JVM 开发团队在 1.8 中对 synchronized 做了大量性能上的优化，而且基 于 JVM 的 synchronized 优化空间更大，更加自然</li>
<li>在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。</li>
</ul>

<h2 id="toc_7">ConcurrentHashMap 简单介绍?</h2>

<ul>
<li><p>1、重要的常量:<br/>
private transient volatile int sizeCtl;<br/>
当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容; 当为 0 时，表示 table 还没有初始化; 当为其他正数时，表示初始化或者下一次进行扩容的大小。 </p></li>
<li><p>2、数据结构:<br/>
Node 是存储结构的基本单元，继承 HashMap 中的 Entry，用于存储数据; TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储<br/>
结构，用于红黑树中存储数据;<br/>
TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。</p></li>
<li><p>3、存储对象时(put() 方法):</p>
<ul>
<li>1.如果没有初始化，就调用 initTable() 方法来进行初始化;</li>
<li>2.如果没有 hash 冲突就直接 CAS 无锁插入;</li>
<li>3.如果需要扩容，就先进行扩容;</li>
<li>4.如果存在 hash 冲突，就加锁来保证线程安全，两种情况:一种是链表形 式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入;</li>
<li>5.如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一 次进入循环</li>
<li>6.如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。 </li>
</ul></li>
<li><p>4、扩容方法 transfer():默认容量为 16，扩容时，容量变为原来的两倍。 helpTransfer():调用多个工作线程一起帮助进行扩容，这样的效率就会更高。</p></li>
<li><p>5、获取对象时(get()方法):</p>
<ul>
<li>1.计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回;</li>
<li>2.如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find()方法，查找该结点，匹配就返回; </li>
<li>3.以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null</li>
</ul></li>
</ul>

<h2 id="toc_8">ConcurrentHashMap 的并发度是什么?</h2>

<p>1.7 中程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的最大线程数。默认为 16，且可以在构造函数中设置。当用户设置并发度时， ConcurrentHashMap 会使用大于等于该值的最小 2 幂指数作为实际并发度(假如 用户设置并发度为 17，实际并发度则为 32)。</p>

<p>1.8 中并发度则无太大的实际意义了，主要用处就是当设置的初始容量小于并发度，将初始容量提升至并发度大小。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ConcurrentHashMap]]></title>
    <link href="http://www.throne4j.com/16017909054092.html"/>
    <updated>2020-10-04T13:55:05+08:00</updated>
    <id>http://www.throne4j.com/16017909054092.html</id>
    <content type="html"><![CDATA[
<p><figure><img src="media/16017909054092/16018069992959.jpg" alt=""/></figure></p>

<h2 id="toc_0">jdk7 ConcurrentHashMap</h2>

<p><figure><img src="media/16017909054092/16018260090249.jpg" alt=""/></figure></p>

<p>ConcurrentHashMap是由 HashEntry数组结构 和 Segment数组结构组成，</p>

<ul>
<li>HashEntry 用于存储键值对数据；</li>
<li>Segment 是一种可重入锁，一个 Segment 里包含一个 HashEntry 数组，其中每个 HashEntry 一个链表结构的元素。<br/>
每个 Segment 守护着一个 HashEntry 数组里的元素，当对 HashEntry 数组的数据 进行修改时，必须首先获得与它对应的 Segment 锁。</li>
</ul>

<p>ConcurrentHashMap 使用了分段锁的思想提高了并发的的访问量,就是使用很多把锁,每一个segment代表了一把锁,每一段只能有一个线程获取锁;但是segment的数量初始化了,就不能修改,所以这也代表了并发的不能修改,这也是1.7的一个局限性.</p>

<p>从get方法可以看出使用了UNSAFE的一些方法和volatile关键字来代替锁,提高了并发性.在size和containsValue这些方法提供一种尝试思想,先不加锁尝试统计,如果其中没有变化就返回,有变化接着尝试,达到尝试次数再加锁,这样也避免了立即加锁对并发的影响。</p>

<p>查询是对链表遍历判断是否存在 key 相同的节点以及获得该节点的 value。但<br/>
由于遍历过程中其他线程可能对链表结构做了调整，因此 get 和 containsKey 返 回的可能是过时的数据，这一点是 ConcurrentHashMap 在弱一致性上的体现。如 果要求强一致性，那么必须使用 Collections.synchronizedMap()方法。</p>

<h3 id="toc_1">构造方法</h3>

<pre><code class="language-text">public ConcurrentHashMap(int initialCapacity,
                         float loadFactor, int concurrencyLevel) {
    if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0)
        throw new IllegalArgumentException();
    // 大于最大segments容量,取最大容量
    if (concurrencyLevel &gt; MAX_SEGMENTS)
        concurrencyLevel = MAX_SEGMENTS;
    // Find power-of-two sizes best matching arguments
    // 2^sshift = ssize 例如:sshift = 4,ssize = 16
    // 根据concurrencyLevel计算出ssize为segments数组的长度
    int sshift = 0;
    int ssize = 1;
    while (ssize &lt; concurrencyLevel) { // 第一次 满足
        ++sshift;  // 第一次 1
        ssize &lt;&lt;= 1; // 第一次 ssize = ssize &lt;&lt; 1 (1 * 2^1)
    }
    // segmentShift和segmentMask的定义
    this.segmentShift = 32 - sshift; // 用于计算hash参与运算位数
    this.segmentMask = ssize - 1; // segments位置范围
    if (initialCapacity &gt; MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    // 计算每个segment中table的容量
    int c = initialCapacity / ssize;
    if (c * ssize &lt; initialCapacity)
        ++c;
    // HashEntry[]默认 容量
    int cap = MIN_SEGMENT_TABLE_CAPACITY;
    // 确保cap是2^n
    while (cap &lt; c)
        cap &lt;&lt;= 1;
    // create segments and segments[0]
    // 创建segments并初始化第一个segment数组,其余的segment延迟初始化
    Segment&lt;K,V&gt; s0 =
            new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor),
                    (HashEntry&lt;K,V&gt;[])new HashEntry[cap]);
    Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize];
    UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
    this.segments = ss;
}
</code></pre>

<h3 id="toc_2">成员变量定义</h3>

<p>与HashMap相比，ConcurrentHashMap 增加了两个属性用于定位段，分别是 segmentMask 和 segmentShift。此外，不同于HashMap的是，ConcurrentHashMap底层结构是一个Segment数组，具体源码如下：</p>

<pre><code class="language-java">/**
 * 默认的初始容量 16
 */
static final int DEFAULT_INITIAL_CAPACITY = 16;
/**
 * 默认的负载因子
 */
static final float DEFAULT_LOAD_FACTOR = 0.75f;
/**
 * 默认的并发数量,会影响segments数组的长度(初始化后不能修改)
 */
static final int DEFAULT_CONCURRENCY_LEVEL = 16;

/**
 * 最大容量,构造ConcurrentHashMap时指定的值超过,就用该值替换
 * ConcurrentHashMap大小必须是2^n,且小于等于2^30
 */
static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;
/**
 * 每个segment中table数组的长度,必须是2^n,至少为2
 */
static final int MIN_SEGMENT_TABLE_CAPACITY = 2;
/**
 * 允许最大segment数量,用于限定concurrencyLevel的边界,必须是2^n
 */
static final int MAX_SEGMENTS = 1 &lt;&lt; 16;
/**
 * 非锁定情况下调用size和contains方法的重试次数,避免由于table连续被修改导致无限重试
 */
static final int RETRIES_BEFORE_LOCK = 2;
/**
 * 用于segment的掩码值,用于与hash的高位进行取&amp;
 */
final int segmentMask;
/**
 * 用于算segment位置时,hash参与运算的位数
 */
final int segmentShift;
/**
 * segments数组
 */
final Segment&lt;K,V&gt;[] segments;  
</code></pre>

<h3 id="toc_3">HashEntry存储数据的链式结构</h3>

<pre><code class="language-java">static final class HashEntry&lt;K,V&gt; {
    // hash值
    final int hash;
    // key
    final K key;
    // 保证内存可见性,每次从内存中获取
    volatile V value;
    volatile HashEntry&lt;K,V&gt; next;

    HashEntry(int hash, K key, V value, HashEntry&lt;K,V&gt; next) {
        this.hash = hash;
        this.key = key;
        this.value = value;
        this.next = next;
    }

    /**
     * 使用volatile语义写入next,保证可见性
     */
    final void setNext(HashEntry&lt;K,V&gt; n) {
        UNSAFE.putOrderedObject(this, nextOffset, n);
    }
    ....
}
</code></pre>

<h3 id="toc_4">Segment</h3>

<p>Segment 类继承于 ReentrantLock 类，从而使得 Segment 对象能充当锁的角色。每个 Segment 对象用来守护它的成员对象 table 中包含的若干个桶。</p>

<pre><code class="language-java">static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable {
    private static final long serialVersionUID = 2249069246763182397L;

    /**
     * 对segment加锁时,在阻塞之前自旋的次数
     *
     */
    static final int MAX_SCAN_RETRIES =
            Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1;

    /**
     * 每个segment的HashEntry table数组,访问数组元素可以通过entryAt/setEntryAt提供的volatile语义来完成
     * volatile保证可见性
     */
    transient volatile HashEntry&lt;K,V&gt;[] table;

    /**
     * 元素的数量,只能在锁中或者其他保证volatile可见性之间进行访问
     */
    transient int count;

    /**
     * 当前segment中可变操作发生的次数,put,remove等,可能会溢出32位
     * 它为chm isEmpty() 和size()方法中的稳定性检查提供了足够的准确性.
     * 只能在锁中或其他volatile读保证可见性之间进行访问
     */
    transient int modCount;

    /**
     * 当table大小超过阈值时,对table进行扩容,值为(int)(capacity *loadFactor)
     */
    transient int threshold;

    /**
     * 负载因子
     */
    final float loadFactor;

    /**
     * 构造方法
     */
    Segment(float lf, int threshold, HashEntry&lt;K,V&gt;[] tab) {
        this.loadFactor = lf;
        this.threshold = threshold;
        this.table = tab;
    }
    
    ...
}
</code></pre>

<h3 id="toc_5">put方法</h3>

<pre><code class="language-java">/**
 * map的put方法,定位segment
 */
public V put(K key, V value) {
    Segment&lt;K,V&gt; s;
    // value不能为空
    if (value == null)
        throw new NullPointerException();
    // 获取hash
    int hash = hash(key);
    // 定位segments 数组的位置
    int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask;
    // 获取这个segment
    if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject(segments, (j &lt;&lt; SSHIFT) + SBASE)) == null)
        // 为null 初始化当前位置的segment
        s = ensureSegment(j);
    return s.put(key, hash, value, false);
}
    /**
     * put到table方法
     */
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    // 是否获取锁,失败自旋获取锁(直到成功)
    HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value);
    V oldValue;
    try {
        HashEntry&lt;K,V&gt;[] tab = table;
        // 定义位置
        int index = (tab.length - 1) &amp; hash;
        // 获取第一个桶的第一个元素
        // entryAt 底层调用getObjectVolatile 具有volatile读语义
        HashEntry&lt;K,V&gt; first = entryAt(tab, index);
        for (HashEntry&lt;K,V&gt; e = first;;) {
            if (e != null) { // 证明链式结构有数据 遍历节点数据替换,直到e=null
                K k;
                if ((k = e.key) == key ||
                        (e.hash == hash &amp;&amp; key.equals(k))) { //  找到了相同的key
                    oldValue = e.value;
                    if (!onlyIfAbsent) { // 默认值false
                        e.value = value; // 替换value
                        ++modCount;
                    }
                    break; // 结束循环
                }
                e = e.next;
            }
            else { // e=null (1) 之前没有数据 (2) 没有找到替换的元素
                // node是否为空,这个获取锁的是有关系的
                // (1) node不为null,设置node的next为first
                // (2) node为null,创建头节点,指定next为first
                if (node != null)
                    // 底层使用 putOrderedObject 方法 具有volatile写语义
                    node.setNext(first);
                else
                    node = new HashEntry&lt;K,V&gt;(hash, key, value, first);
                int c = count + 1;
                // 扩容条件 (1)entry数量大于阈值 (2) 当前table的数量小于最大容量  满足以上条件就扩容
                if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY)
                    // 扩容方法,方法里面具体讲
                    rehash(node);
                else
                    // 给table的index位置设置为node,
                    // node为头结点,原来的头结点first为node的next节点
                    // 底层也是调用的 putOrderedObject 方法 具有volatile写语义
                    setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
        unlock();
    }
    return oldValue;
}
</code></pre>

<p>执行流程：</p>

<ul>
<li>map的put方法就做了三件事情,找出segments的位置;判断当前位置有没有初始化,没有就调用ensureSegment()方法初始化;然后调用segment的put方法.</li>
<li>segment的put方法,获取当前segment的锁,成功接着执行,失败调用scanAndLockForPut方法自旋获取锁,成功后也是接着往下执行，失败的话调用lock申请锁.</li>
<li>通过hash计算出位置,获取节点,找出相同的key和hash替换value,返回.没有找到相同的,设置找出的节点为当前创建节点的next节点,设置创建节点前,判断是否需要扩容,需要调用扩容方法rehash();不需要,设置节点,返回,释放锁.</li>
</ul>

<h3 id="toc_6">ensureSegment(int k) 初始化 segment</h3>

<pre><code class="language-text">private Segment&lt;K,V&gt; ensureSegment(int k) {
    final Segment&lt;K,V&gt;[] ss = this.segments;  // 当前的segments数组
    long u = (k &lt;&lt; SSHIFT) + SBASE;  // 计算原始偏移量,在segments数组的位置
    Segment&lt;K,V&gt; seg;
    if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) { // 判断没有被初始化
        Segment&lt;K,V&gt; proto = ss[0]; // 获取第一个segment ss[0]
        // 这就是为什么要在初始化化map时要初始化一个segment,需要用cap和loadFactoe 为模板
        int cap = proto.table.length; // 容量
        float lf = proto.loadFactor; // 负载因子
        int threshold = (int)(cap * lf); // 阈值
        // 初始化ss[k] 内部的tab数组 // recheck
        HashEntry&lt;K,V&gt;[] tab = (HashEntry&lt;K,V&gt;[])new HashEntry[cap];
        // 再次检查这个ss[k]  有没有被初始化
        if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u))
                == null) { // recheck
            // 创建一个Segment
            Segment&lt;K,V&gt; s = new Segment&lt;K,V&gt;(lf, threshold, tab);
            // 这里用自旋CAS来保证把segments数组的u位置设置为s
            // 万一有多线程执行到这一步,只有一个成功,break
            // getObjectVolatile 保证了读的可见性,所以一旦有一个线程初始化了,那么就结束自旋
            while ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u))
                    == null) {
                if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))
                    break;
            }
        }
    }
    return seg;
}
</code></pre>

<p>计算 Segment 位置,使用 UNSAFE 的方法判断当前位置有没有初始化,然后使用segmets[0]的模板创建一个新的HashEntry[],再次判断当前位置有没有初始化,可能存在多线程同时初始化,然后创建一个新的segment,最后使用自旋cas设置新的segment的位置,保证只有一个线程初始化成功.</p>

<h3 id="toc_7">scanAndLockForPut(K key, int hash, V value)</h3>

<pre><code class="language-java">private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) {
    HashEntry&lt;K,V&gt; first = entryForHash(this, hash); // 根据hash获取头结点
    HashEntry&lt;K,V&gt; e = first;
    HashEntry&lt;K,V&gt; node = null;
    int retries = -1; // 是为了找到对应hash桶,遍历链表时找到就停止
    while (!tryLock()) { // 尝试获取锁,成功就返回,失败就开始自旋
        HashEntry&lt;K,V&gt; f; // to recheck first below
        if (retries &lt; 0) {
            if (e == null) {  // 结束遍历节点
                if (node == null) // 创造新的节点
                    node = new HashEntry&lt;K,V&gt;(hash, key, value, null);
                retries = 0; // 结束遍历
            }
            else if (key.equals(e.key)) // 找到节点 停止遍历
                retries = 0;
            else
                e = e.next; // 下一个节点 直到为null
        }
        else if (++retries &gt; MAX_SCAN_RETRIES) { // 达到自旋的最大次数
            lock(); // 进入加锁方法,失败进入队列,阻塞当前线程
            break;
        }
        else if ((retries &amp; 1) == 0 &amp;&amp;
                (f = entryForHash(this, hash)) != first) {
            e = first = f; // 头结点变化,需要重新遍历,说明有新的节点加入或者移除
            retries = -1;
        }
    }
    return node;
}
</code></pre>

<p>我们在put方法获取锁失败,才会进入这个方法,这个方法采用自旋获取锁,直到成功才返回,但是使用了自旋次数的限制,这么做的好处是什么了,就是竞争太激烈的话,这个线程可能一直获取不到锁,自旋也是消耗cpu性能的,所以当达到自旋次数时,就阻塞当前线程,直到有线程释放了锁,通知这些线程.在等待过程中是不消耗cpu的.</p>

<p>当我们进入这个方法时,说明获取锁失败,那么可别是别的线程在对这个segment进行修改操作,所以说如果别的线程在操作之后,我们自己的工作内存中的数据可能已经不是最新的了,这个时候我们使用具有volatile语义的方法重新读了数据,在自旋过程中遍历这些数据,把最新的数据缓存在工作内存中,当前线程再次获取锁时,我们的数据是最新的,就不用重新去住内存中获取,这样在自旋获取的锁的过程中就预热了这些数据,在获取锁之后的执行中就提升了效率.</p>

<h3 id="toc_8">rehash()</h3>

<pre><code class="language-java">private void rehash(HashEntry&lt;K,V&gt; node) {

    // 旧的table
    HashEntry&lt;K,V&gt;[] oldTable = table;
    // 旧的table的长度
    int oldCapacity = oldTable.length;
    // 扩容原来capacity的一倍
    int newCapacity = oldCapacity &lt;&lt; 1;
    // 新的阈值
    threshold = (int)(newCapacity * loadFactor);
    // 新的table
    HashEntry&lt;K,V&gt;[] newTable =
            (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity];
    // 新的掩码
    int sizeMask = newCapacity - 1;
    // 遍历旧的table
    for (int i = 0; i &lt; oldCapacity ; i++) {
        // table中的每一个链表元素
        HashEntry&lt;K,V&gt; e = oldTable[i];
        if (e != null) { // e不等于null
            HashEntry&lt;K,V&gt; next = e.next; // 下一个元素
            int idx = e.hash &amp; sizeMask;  // 重新计算位置,计算在新的table的位置
            if (next == null)   //  Single node on list 证明只有一个元素
                newTable[idx] = e; // 把当前的e设置给新的table
            else { // Reuse consecutive sequence at same slot
                HashEntry&lt;K,V&gt; lastRun = e; // 当前e
                int lastIdx = idx;          // 在新table的位置
                for (HashEntry&lt;K,V&gt; last = next;
                     last != null;
                     last = last.next) { // 遍历链表
                    int k = last.hash &amp; sizeMask; // 确定在新table的位置
                    if (k != lastIdx) { // 头结点和头结点的next元素的节点发生了变化
                        lastIdx = k;    // 记录变化位置
                        lastRun = last; // 记录变化节点
                    }
                }
                // 以下把链表设置到新table分为两种情况
                // (1) lastRun 和 lastIdx 没有发生变化,也就是整个链表的每个元素位置和一样,都没有发生变化
                // (2) lastRun 和 lastIdx 发生了变化,记录变化位置和变化节点,然后把变化的这个节点设置到新table
                //     ,但是整个链表的位置只有变化节点和它后面关联的节点是对的
                //      下面的这个遍历就是处理这个问题,遍历当前头节点e,找出不等于变化节点(lastRun)的节点重新处理
                newTable[lastIdx] = lastRun;
                // Clone remaining nodes
                for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) {
                    V v = p.value;
                    int h = p.hash;
                    int k = h &amp; sizeMask;
                    HashEntry&lt;K,V&gt; n = newTable[k];
                    newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n);
                }
            }
        }
    }
    // 处理扩容时那个添加的节点

    // 计算位置
    int nodeIndex = node.hash &amp; sizeMask; // add the new node
    // 设置next节点,此时已经扩容完成,要从新table里面去当前位置的头结点为next节点
    node.setNext(newTable[nodeIndex]);
    // 设置位置
    newTable[nodeIndex] = node;
    // 新table替换旧的table
    table = newTable;
}
</code></pre>

<h3 id="toc_9">get(Object key)</h3>

<pre><code class="language-java">public V get(Object key) {
    Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead
    HashEntry&lt;K,V&gt;[] tab;
    // 准备定位的hash值
    int h = hash(key);
    long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; // 获取segment的位置
    // getObjectVolatile getObjectVolatile语义读取最新的segment,获取table
    if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp;
            (tab = s.table) != null) {
        // getObjectVolatile getObjectVolatile语义读取最新的hashEntry,并遍历
        for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile
                (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE);
             e != null; e = e.next) {
            K k;
            // 找到相同的key 返回
            if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k)))
                return e.value;
        }
    }
    return null;
}
</code></pre>

<p>get 操作先经过一次再散列，然后使用这个散列值通过散列运算定位到 Segment(使用了散列值的高位部分)，再通过散列算法定位到 table(使用了散列值 的全部)。整个 get 过程，没有加锁，而是通过 volatile 保证 get 总是可以拿到最新值。</p>

<p>注意:get方法使用了getObjectVolatile方法读取segment和hashentry,保证是最新的,具有锁的语义,可见性</p>

<p>分析:为什么get不加锁可以保证线程安全<br/>
(1) 首先获取value,我们要先定位到segment,使用了UNSAFE的getObjectVolatile具有读的volatile语义,也就表示在多线程情况下,我们依旧能获取最新的segment.<br/>
(2) 获取hashentry[],由于table是每个segment内部的成员变量,使用volatile修饰的,所以我们也能获取最新的table.<br/>
(3) 然后我们获取具体的hashentry,也时使用了UNSAFE的getObjectVolatile具有读的volatile语义,然后遍历查找返回.<br/>
(4) 总结我们发现怎个get过程中使用了大量的volatile关键字,其实就是保证了可见性(加锁也可以,但是降低了性能),get只是读取操作,所以我们只需要保证读取的是最新的数据即可.</p>

<h3 id="toc_10">size()</h3>

<pre><code class="language-java">public int size() {
    // Try a few times to get accurate count. On failure due to
    // continuous async changes in table, resort to locking.
    final Segment&lt;K,V&gt;[] segments = this.segments;
    int size;
    boolean overflow; // 为true表示size溢出32位
    long sum;         // modCounts的总和
    long last = 0L;   // previous sum
    int retries = -1; // 第一次不计算次数,所以会重试三次
    try {
        for (;;) {
            if (retries++ == RETRIES_BEFORE_LOCK) { // 重试次数达到3次 对所有segment加锁
                for (int j = 0; j &lt; segments.length; ++j)
                    ensureSegment(j).lock(); // force creation
            }
            sum = 0L;
            size = 0;
            overflow = false;
            for (int j = 0; j &lt; segments.length; ++j) {
                Segment&lt;K,V&gt; seg = segmentAt(segments, j);
                if (seg != null) { // seg不等于空
                    sum += seg.modCount; // 不变化和size一样
                    int c = seg.count; // seg 的size
                    if (c &lt; 0 || (size += c) &lt; 0)
                        overflow = true;
                }
            }
            if (sum == last) // 没有变化
                break;
            last = sum; // 变化,记录这一次的变化值,下次循环时对比.
        }
    } finally {
        if (retries &gt; RETRIES_BEFORE_LOCK) {
            for (int j = 0; j &lt; segments.length; ++j)
                segmentAt(segments, j).unlock();
        }
    }
    return overflow ? Integer.MAX_VALUE : size;
}
</code></pre>

<p>尝试3次不加锁获取sum,如果发生变化就全部加锁,size和containsValue方法的思想也是基本类似.<br/>
执行流程<br/>
(1) 第一次,retries++=0,不满足全部加锁条件,遍历所有的segment,sum就是所有segment的容量,last等于0,第一次不相等,last=sum.<br/>
(2) 第二次,retries++=1,不满足加锁条件,计算所有的segment,sum就是所有的segment的容量,last是上一次的sum,相等结束循环,不相等下次循环.<br/>
(3) 第三次,retries++=2,先运算后赋值,所以此时还是不满足加锁条件和上面一样统计sum,判断这一次的sum和last(上一次的sum)是否相等,相等结束,不相等,下一次循环.<br/>
(4) 第四次,retries++=2,满足加锁条件,给segment全部加锁,这样所有线程就没有办法进行修改操作,统计每个segment的数量求和,然后返回size.(ps:全部加锁提高了size的准确率,但是降低了吞吐量,统计size的过程中如果其它线程进行修改操作这些线程全部自旋或者阻塞).</p>

<h3 id="toc_11">isEmpty()</h3>

<pre><code class="language-java">public boolean isEmpty() {
    long sum = 0L;
    final Segment&lt;K,V&gt;[] segments = this.segments;
    for (int j = 0; j &lt; segments.length; ++j) {
        Segment&lt;K,V&gt; seg = segmentAt(segments, j);
        if (seg != null) {
            if (seg.count != 0)
                return false; // 某一个不为null,立即返回
            sum += seg.modCount;
        }
    }
    // 上面执行完 说明不为空,并且过程可能发生了变化
    // 发生变化
    if (sum != 0L) { // recheck unless no modifications
        for (int j = 0; j &lt; segments.length; ++j) {
            Segment&lt;K,V&gt; seg = segmentAt(segments, j);
            if (seg != null) {
                if (seg.count != 0)
                    return false;
                sum -= seg.modCount;
            }
        }
        if (sum != 0L) // 变化值没有为0,说明不为空
            return false;
    }
    // 没有发生变化
    return true;
}
</code></pre>

<h3 id="toc_12">并发级别</h3>

<p>并发级别可以理解为程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的最大线程数，实际上就是 ConcurrentHashMap 中的分段锁个数，即 Segment[]的数组长度。ConcurrentHashMap 默认的并发度为 16，但用户也可以 在构造函数中设置并发度。当用户设置并发度时，ConcurrentHashMap 会使用大 于等于该值的最小 2 幂指数作为实际并发度(假如用户设置并发度为 17，实际 并发度则为 32)。</p>

<p>如果并发度设置的过小，会带来严重的锁竞争问题;如果并发度设置的过大， 原本位于同一个 Segment 内的访问会扩散到不同的 Segment 中，CPU cache 命中 率会下降，从而引起程序性能下降。(文档的说法是根据你并发的线程数量决定， 太多会导性能降低)</p>

<p>segments 数组的长度 ssize 是通过 concurrencyLevel 计算得出的。为了能通 过按位与的散列算法来定位 segments 数组的索引，必须保证 segments 数组的长 度是 2 的 N 次方(power-of-two size)，所以必须计算出一个大于或等于 concurrencyLevel 的最小的 2 的 N 次方值来作为 segments 数组的长度。假如 concurrencyLevel 等于 14、15 或 16，ssize 都会等于 16，即容器里锁的个数也是 16。 </p>

<h2 id="toc_13">jdk8 版本的 ConcurrentHashMap</h2>

<p>取消 segments 字段，直接采用 transient volatile HashEntry<K,V>[] table 保存数据，采用 table 数组元素作为锁，从而实现了对缩小锁的粒度，进一 步减少并发冲突的概率，并大量使用了采用了 CAS + synchronized 来保证并发安 全性。</p>

<p>将原先 table 数组+单向链表的数据结构，变更为 table 数组+单 向链表+红黑树的结构。对于 hash 表来说，最核心的能力在于将 key hash 之后 能均匀的分布在数组中。如果 hash 之后散列的很均匀，那么 table 数组中的每个 队列长度主要为 0 或者 1，人品不好的话，还是会存在一些队列长度过长的情况，如果还是采用单向链表方式，那么查询某个节点的时间复杂度为 O(n)，因此链表个数超过 8 的时候，将有链表转换为 红黑树，那么查询的时间复杂度可以降低到 O(logN)</p>

<p>使用 Node(1.7 为 Entry) 作为链表的数据结点，仍然包含 key，value， hash 和 next 四个属性。 红黑树的情况使用的是 TreeNode(extends Node)。</p>

<h3 id="toc_14">成员变量</h3>

<pre><code class="language-java">//最大容量
private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;

//默认容量
private static final int DEFAULT_CAPACITY = 16;
//扩容因子
private static final float LOAD_FACTOR = 0.75f;
//数组槽的链表个数，转红黑树条件
static final int TREEIFY_THRESHOLD = 8;
//数组槽的红黑树反转链表条件
static final int UNTREEIFY_THRESHOLD = 6;
//转红黑树，数组最小容量
static final int MIN_TREEIFY_CAPACITY = 64;
//每个cpu强制处理的最小Map容量数
private static final int MIN_TRANSFER_STRIDE = 16;

//生成sizeCtl所使用的bit位数（还不大明白）
private static int RESIZE_STAMP_BITS = 16;

//参与扩容的最大线程数
private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;

//移位量，把生成戳移位后保存在sizeCtl中当做扩容线程计数的基数，相反方//向移位后能够反解出生成戳（抄的）
private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;


static final int MOVED     = -1; // hash for forwarding nodes
static final int TREEBIN   = -2; // hash for roots of trees
static final int RESERVED  = -3; // hash for transient reservations
static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash

// hash数组
transient volatile Node&lt;K,V&gt;[] table;

//扩容时新的hash数组，容量是以前的两倍 
private transient volatile Node&lt;K,V&gt;[] nextTable;

//用于节点计数
private transient volatile long baseCount;

//sizeCtl = -1，表示有线程正在进行初始化操作，防止多线程同时初始化Map  
//sizeCtl = -(1 + nThreads)，表示有nThreads个线程正在进行扩容操作  
//sizeCtl &gt; 0，表示接下来的初始化操作中的Map容量，或者表示初始化/扩容完成后的阈值
//sizeCtl = 0，默认值
private transient volatile int sizeCtl;

//用以维护多线程扩容时候的线程安全
private transient volatile int transferIndex;
</code></pre>

<p>sizeCtl 非常非常非常重要的一个参数，统御全局, 控制标识符，用来控制table初始化和扩容操作的，在不同的地方有不同的用途，其值也不同，所代表的含义也不同</p>

<ul>
<li>负数代表正在进行初始化或扩容操作</li>
<li>-1代表正在初始化</li>
<li>-N 表示有N-1个线程正在进行扩容操作</li>
<li>正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小</li>
</ul>

<h3 id="toc_15">链表的Node对象</h3>

<p>Node 是最核心的内部类，它包装了key-value键值对</p>

<pre><code class="language-java">static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
    final int hash;
    final K key;
    volatile V val;
    volatile Node&lt;K,V&gt; next;
  …

}

/** 插入的时候，才初始化，大小必须是2的次幂*/
transient volatile Node&lt;K,V&gt;[] table;
</code></pre>

<h3 id="toc_16">红黑树节点TreeNode</h3>

<p>树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为 TreeNode。</p>

<pre><code class="language-java">static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; {
    TreeNode&lt;K,V&gt; parent;  // red-black tree links
    TreeNode&lt;K,V&gt; left;
    TreeNode&lt;K,V&gt; right;
    TreeNode&lt;K,V&gt; prev;    // 删除节点的时候，会用到这个指向
    boolean red;

…

}
</code></pre>

<p>与 jdk8 中的 HashMap 不同点：</p>

<ul>
<li>他并不是直接转换为红黑树的，而是把这些节点放在 TreeBin 对象中，由 TreeBin 完成对红黑树的包装</li>
<li>TreeNode 在ConcurrentHashMap 扩展自 Node 类，而并非 HashMap 中的扩展自 LinkedHashMap.Entry<K,V> ，也就是说 TreeNode 带有 next 指针</li>
</ul>

<h3 id="toc_17">装TreeNode节点的TreeBin对象</h3>

<p>TreeBin 继承自 Node ，负责 TreeNode 节点。它代替了 TreeNode 的根节点，也就是说在实际的 ConcurrentHashMap“数组”中，存放的是 TreeBin 对象，而不是 TreeNode 对象。 另外这个类还带有了读写锁机制。</p>

<pre><code class="language-java">//红黑树的根节点
TreeNode&lt;K,V&gt; root;

//链表头结点，TreeBin仍然保存了链表结构
volatile TreeNode&lt;K,V&gt; first;
//标记设置 WAITER 标识位的线程

volatile Thread waiter;

//锁状态标志位
volatile int lockState;
// values for lockState

//写锁标志位
static final int WRITER = 1; 

//等待写锁标志位
static final int WAITER = 2;

//读锁标志位
static final int READER = 4; 
</code></pre>

<h3 id="toc_18">ForwardingNode</h3>

<p>一个特殊的 Node 结点，hash 值为 -1，其中存储 nextTable 的引用。有<br/>
table 发生扩容的时候，ForwardingNode 发挥作用，作为一个占位符放在 table 中表示当前结点为 null 或者已经被移动。</p>

<h3 id="toc_19">方法：tabAt、casTabAt、setTabAt</h3>

<pre><code class="language-java">/**
 * 利用硬件级别的原子操作，获得在i位置上的Node节点
 * Unsafe.getObjectVolatile可以直接获取指定内存的数据
 * 保证每次拿到的数据都是最新的
 */
@SuppressWarnings(&quot;unchecked&quot;)
static final &lt;K, V&gt; Node&lt;K, V&gt; tabAt(Node&lt;K, V&gt;[] tab, int i) {
    return (Node&lt;K, V&gt;) U.getObjectVolatile(tab, ((long) i &lt;&lt; ASHIFT) + ABASE);
}

/**
 * 利用CAS操作设置 i位置上的 Node 节点
 */
static final &lt;K, V&gt; boolean casTabAt(Node&lt;K, V&gt;[] tab, int i,
                                     Node&lt;K, V&gt; c, Node&lt;K, V&gt; v) {
    return U.compareAndSwapObject(tab, ((long) i &lt;&lt; ASHIFT) + ABASE, c, v);
}

/**
 * 利用硬件级别的原子操作，设置在 i 位置上的Node节点
 * Unsafe.getObjectVolatile可以直接设置指定内存的数据
 * 保证了其它线程访问这个节点时一定可以看到最新的数据
 */
static final &lt;K, V&gt; void setTabAt(Node&lt;K, V&gt;[] tab, int i, Node&lt;K, V&gt; v) {
    U.putObjectVolatile(tab, ((long) i &lt;&lt; ASHIFT) + ABASE, v);
}
</code></pre>

<h3 id="toc_20">构造函数</h3>

<pre><code class="language-java">public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) {

    if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0)
        throw new IllegalArgumentException();
    if (initialCapacity &lt; concurrencyLevel)   // Use at least as many bins
        initialCapacity = concurrencyLevel;   // as estimated threads
    long size = (long) (1.0 + (long) initialCapacity / loadFactor);
    int cap = (size &gt;= (long) MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int) size);
    this.sizeCtl = cap;
}
</code></pre>

<p>在构造方法中并不会创建其中的数组等相关部件，只是进行简单的属性设置，同样的，table的大小也被规定为 必须是 2的 幂次方</p>

<p>真正的初始化是放在了 向 ConcurrentHashMap 中插入元素的时候发生的，比如：put、computeIfAbsent、compute、merge 等方法，调用实际是检查 table == null</p>

<h3 id="toc_21">get 操作</h3>

<p>get 方法比较简单，给定一个 key 来确定 value 的时候，必须满足两个条件<br/>
key 相同 hash 值相同，对于节点可能在链表或树上的情况，需要分别去查找。</p>

<pre><code class="language-java">public V get(Object key) {
    Node&lt;K, V&gt;[] tab;
    Node&lt;K, V&gt; e, p;
    int n, eh;
    K ek;
    // 计算 hash 值
    int h = spread(key.hashCode());
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) {
        // node数组中的节点就是要找的节点
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))
                return e.val;
        } else if (eh &lt; 0) // eh &lt; 0 说明这个节点在 树上，调用树的 find 方法寻找
            return (p = e.find(h, key)) != null ? p.val : null;
        // key 在 链表上，遍历脸比爱哦你查找到对应的值并返回
        while ((e = e.next) != null) {
            if (e.hash == h &amp;&amp;
                    ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
</code></pre>

<h3 id="toc_22">put 操作</h3>

<pre><code class="language-java">public V put(K key, V value) {
    return putVal(key, value, false);
}

/**
 * Implementation for put and putIfAbsent
 */
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 计算key的hash值
    int hash = spread(key.hashCode());
    int binCount = 0;
    /*死循环 何时插入成功 何时跳出*/
    for (Node&lt;K, V&gt;[] tab = table; ; ) {
        Node&lt;K, V&gt; f;
        int n, i, fh;
        if (tab == null || (n = tab.length) == 0) {
            /*如果table为空的话，初始化table*/
            tab = initTable();
        } else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {
            /*Node数组中的元素，这个位置没有值 ，使用CAS操作放进去*/
            if (casTabAt(tab, i, null, new Node&lt;K, V&gt;(hash, key, value, null)))
                break;// no lock when adding to empty bin
        } else if ((fh = f.hash) == MOVED) {
            /*正在进行扩容，当前线程帮忙扩容*/
            tab = helpTransfer(tab, f);
        } else {
            V oldVal = null;
            /*锁Node数组中的元素，这个位置是Hash冲突组成链表的头结点或者是红黑树的根节点*/
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    // fh &gt;= 0 说明 这个节点是一个链表的节点，而不是树的节点
                    if (fh &gt;= 0) {
                        binCount = 1;
                        for (Node&lt;K, V&gt; e = f; ; ++binCount) {
                            K ek;
                            // put操作和 putIfAbsent 操作业务实现
                            if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node&lt;K, V&gt; pred = e;
                            // 如果遍历到了最后一个节点，使用尾插法，吧它插入到链表尾部
                            if ((e = e.next) == null) {
                                pred.next = new Node&lt;K, V&gt;(hash, key,
                                        value, null);
                                break;
                            }
                        }
                    } else if (f instanceof TreeBin) { // 按照树的方式插入值
                        Node&lt;K, V&gt; p;
                        binCount = 2;
                        if ((p = ((TreeBin&lt;K, V&gt;) f).putTreeVal(hash, key,
                                value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }

            if (binCount != 0) {
                // 达到临界值 8 需要把链表转换为 树形结构
                if (binCount &gt;= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    // map的元素数量+1 并检查是否需要扩容
    addCount(1L, binCount);
    return null;
}
</code></pre>

<h3 id="toc_23">initTable()初始化</h3>

<pre><code class="language-java">private final Node&lt;K, V&gt;[] initTable() {
    Node&lt;K, V&gt;[] tab;
    int sc;
    while ((tab = table) == null || tab.length == 0) {
        // 小于 0 表示有其他线程正在进行初始化操作，把当前线程CPU时间让出来。因为对于table的初始化工作，只能有一个线程在运行。
        if ((sc = sizeCtl) &lt; 0)
            Thread.yield(); // lost initialization race; just spin
        // 利用 CAS 操作吧 sizectl 的值置为  -1  表示本线程正在进行初始化操作
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings(&quot;unchecked&quot;)
                    Node&lt;K, V&gt;[] nt = (Node&lt;K, V&gt;[]) new Node&lt;?, ?&gt;[n];
                    table = tab = nt;
                    //n 右移 2 位，本质上是 n变为 原来的 1/4，所以sc = 0.75*n
                    sc = n - (n &gt;&gt;&gt; 2);
                }
            } finally {
                // 设置成扩容的阈值
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
</code></pre>

<h2 id="toc_24">transfer</h2>

<p>当 ConcurrentHashMap 容量不足的时候，需要对 table 进行扩容。为何要并发扩容?因为在扩容的时候，总是会涉及到从一个“数组”到另一 个“数组”拷贝的操作，如果这个操作能够并发进行，就能利用并发处理去减少扩容带来的时间影响。</p>

<p>并发扩容其实就是将数据迁移任务拆分成多个小迁移任务，在实现上使用了 一个变量 stride 作为步长控制，每个线程每次负责迁移其中的一部分。</p>

<h3 id="toc_25">remove</h3>

<p>移除方法的基本流程和put方法很类似，只不过操作由插入数据变为移除数 据而已，而且如果存在红黑树的情况下，会检查是否需要将红黑树转为链表的步 骤。不再重复讲述。</p>

<h3 id="toc_26">treeifyBin</h3>

<p>用于将过长的链表转换为 TreeBin 对象。但是他并不是直接转换，而是进行 一次容量判断，如果容量没有达到转换的要求，直接进行扩容操作并返回;如果 满足条件才将链表的结构转换为 TreeBin ，这与 HashMap 不同的是，它并没有 把 TreeNode 直接放入红黑树，而是利用了 TreeBin 这个小容器来封装所有的 TreeNode。</p>

]]></content>
  </entry>
  
</feed>
