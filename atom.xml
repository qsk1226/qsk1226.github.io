<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大爷来玩儿啊~]]></title>
  <link href="http://www.throne4j.com/atom.xml" rel="self"/>
  <link href="http://www.throne4j.com/"/>
  <updated>2020-09-24T00:43:17+08:00</updated>
  <id>http://www.throne4j.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[redis 面试问题]]></title>
    <link href="http://www.throne4j.com/16007650152263.html"/>
    <updated>2020-09-22T16:56:55+08:00</updated>
    <id>http://www.throne4j.com/16007650152263.html</id>
    <content type="html"><![CDATA[
<p>1、什么是Redis？</p>

<p>Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。 Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。 Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</p>

<p>2、Redis相比memcached有哪些优势？<br/>
(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型<br/>
(2) redis的速度比memcached快很多<br/>
(3) redis可以持久化其数据</p>

<p>3、Redis支持哪几种数据类型？<br/>
String、List、Set、Sorted Set、hashes</p>

<p>4、Redis主要消耗什么物理资源？<br/>
redis是一种基于内存高性能的数据库--- 主要依赖于内存<br/>
内存。</p>

<p>5、Redis的全称是什么？<br/>
Remote Dictionary Server。</p>

<p>6、Redis有哪几种数据淘汰策略？</p>

<p>noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）<br/>
allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。<br/>
volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。<br/>
allkeys-random: 回收随机的键使得新添加的数据有空间存放。<br/>
volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。<br/>
volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。</p>

<p>7、Redis官方为什么不提供Windows版本？<br/>
因为目前Linux版本已经相当稳定，而且用户量很大，无需开发windows版本，反而会带来兼容性等问题。</p>

<p>8、一个字符串类型的值能存储最大容量是多少？</p>

<p>512M</p>

<p>9、为什么Redis需要把所有数据放到内存中？</p>

<p>Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。</p>

<p>10、Redis集群方案应该怎么做？都有哪些方案？</p>

<p>1.twemproxy，大概概念是，它类似于一个代理方式，使用方法和普通redis无任何区别，设置好它下属的多个redis实例后，使用时在本需要连接redis的地方改为连接twemproxy，它会以一个代理的身份接收请求并使用一致性hash算法，将请求转接到具体redis，将结果再返回twemproxy。使用方式简便(相对redis只需修改连接端口)，对旧项目扩展的首选。 问题：twemproxy自身单端口实例的压力，使用一致性hash后，对redis节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。</p>

<p>2.codis，目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。</p>

<p>3.redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。</p>

<p>4.在业务代码层实现，起几个毫无关联的redis实例，在代码层，对key 进行hash计算，然后去对应的redis实例操作数据。 这种方式对hash层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。</p>

<p>11、Redis集群方案什么情况下会导致整个集群不可用？</p>

<p>有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用。</p>

<p>12、MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？</p>

<p>redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</p>

<p>13、Redis有哪些适合的场景？</p>

<p>（1）、会话缓存（Session Cache）</p>

<p>最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？</p>

<p>幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。</p>

<p>（2）、全页缓存（FPC）</p>

<p>除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。</p>

<p>再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。</p>

<p>此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。</p>

<p>（3）、队列</p>

<p>Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。</p>

<p>如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。</p>

<p>（4），排行榜/计数器</p>

<p>Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：</p>

<p>当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：</p>

<p>ZRANGE user_scores 0 10 WITHSCORES</p>

<p>Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。</p>

<p>（5）、发布/订阅</p>

<p>最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。</p>

<p>14、Redis支持的Java客户端都有哪些？官方推荐用哪个？</p>

<p>Redisson、Jedis、lettuce等等，官方推荐使用Redisson。</p>

<p>15、Redis和Redisson有什么关系？</p>

<p>Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。</p>

<p>16、Jedis与Redisson对比有什么优缺点？</p>

<p>Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。</p>

<p>17、Redis如何设置密码及验证密码？</p>

<p>设置密码：config set requirepass 123456</p>

<p>授权密码：auth 123456</p>

<p>18、说说Redis哈希槽的概念？</p>

<p>Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。</p>

<p>19、Redis集群的主从复制模型是怎样的？</p>

<p>为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品.</p>

<p>20、Redis集群会有写操作丢失吗？为什么？</p>

<p>Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。</p>

<p>21、Redis集群之间是如何复制的？</p>

<p>异步复制</p>

<p>22、Redis集群最大节点个数是多少？</p>

<p>16384个。</p>

<p>23、Redis集群如何选择数据库？</p>

<p>Redis集群目前无法做数据库选择，默认在0数据库。</p>

<p>24、怎么测试Redis的连通性？</p>

<p>ping</p>

<p>25、Redis中的管道有什么用？</p>

<p>一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。</p>

<p>这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多POP3协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。</p>

<p>26、怎么理解Redis事务？</p>

<p>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p>

<p>事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。</p>

<p>27、Redis事务相关的命令有哪几个？</p>

<p>MULTI、EXEC、DISCARD、WATCH</p>

<p>28、Redis key的过期时间和永久有效分别怎么设置？</p>

<p>EXPIRE和PERSIST命令。</p>

<p>29、Redis如何做内存优化？</p>

<p>尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面.</p>

<p>30、Redis回收进程如何工作的？</p>

<p>一个客户端运行了新的命令，添加了新的数据。</p>

<p>Redi检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。</p>

<p>一个新的命令被执行，等等。</p>

<p>所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。</p>

<p>如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。</p>

<p>**31、Redis回收使用的是什么算法？ **</p>

<p>LRU算法</p>

<p>32、Redis如何做大量数据插入？</p>

<p>Redis2.6开始redis-cli支持一种新的被称之为pipe mode的新模式用于执行大量数据插入工作。</p>

<p>33、为什么要做Redis分区？</p>

<p>分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升,Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。</p>

<p>34、你知道有哪些Redis分区实现方案？</p>

<p>客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。</p>

<p>代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy</p>

<p>查询路由(Query routing) 的意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。</p>

<p>35、Redis分区有什么缺点？</p>

<p>涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。</p>

<p>同时操作多个key,则不能使用Redis事务.</p>

<p>分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set）.</p>

<p>当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB / AOF文件。</p>

<p>分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。</p>

<p>36、Redis持久化数据和缓存怎么做扩容？</p>

<p>如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。</p>

<p>如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。</p>

<p>37、分布式Redis是前期做还是后期规模上来了再做好？为什么？</p>

<p>既然Redis是如此的轻量（单实例只使用1M内存）,为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。</p>

<p>一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。</p>

<p>这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。</p>

<p>38、Twemproxy是什么？</p>

<p>Twemproxy是Twitter维护的（缓存）代理系统，代理Memcached的ASCII协议和Redis协议。它是单线程程序，使用c语言编写，运行起来非常快。它是采用Apache 2.0 license的开源软件。 Twemproxy支持自动分区，如果其代理的其中一个Redis节点不可用时，会自动将该节点排除（这将改变原来的keys-instances的映射关系，所以你应该仅在把Redis当缓存时使用Twemproxy)。 Twemproxy本身不存在单点问题，因为你可以启动多个Twemproxy实例，然后让你的客户端去连接任意一个Twemproxy实例。 Twemproxy是Redis客户端和服务器端的一个中间层，由它来处理分区功能应该不算复杂，并且应该算比较可靠的。</p>

<p>39、支持一致性哈希的客户端有哪些？</p>

<p>Redis-rb、Predis等。</p>

<p>40、Redis与其他key-value存储有什么不同？</p>

<p>Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。</p>

<p>Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，应为数据量不能大于硬件内存。在内存数据库方面的另一个优点是， 相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。 同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。</p>

<p>41、Redis的内存占用情况怎么样？</p>

<p>给你举个例子： 100万个键值对（键是0到999999值是字符串“hello world”）在我的32位的Mac笔记本上 用了100MB。同样的数据放到一个key里只需要16MB， 这是因为键值有一个很大的开销。 在Memcached上执行也是类似的结果，但是相对Redis的开销要小一点点，因为Redis会记录类型信息引用计数等等。</p>

<p>当然，大键值对时两者的比例要好很多。</p>

<p>64位的系统比32位的需要更多的内存开销，尤其是键值对都较小时，这是因为64位的系统里指针占用了8个字节。 但是，当然，64位系统支持更大的内存，所以为了运行大型的Redis服务器或多或少的需要使用64位的系统。</p>

<p>42、都有哪些办法可以降低Redis的内存使用情况呢？</p>

<p>如果你使用的是32位的Redis实例，可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。</p>

<p>43、查看Redis使用情况及状态信息用什么命令？</p>

<p>info</p>

<p>44、Redis的内存用完了会发生什么？</p>

<p>如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以将Redis当缓存来使用配置淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。</p>

<p>45、Redis是单线程的，如何提高多核CPU的利用率？</p>

<p>可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。</p>

<p>46、一个Redis实例最多能存放多少的keys？List、Set、Sorted Set他们最多能存放多少元素？</p>

<p>理论上Redis可以处理多达232的keys，并且在实际中进行了测试，每个实例至少存放了2亿5千万的keys。我们正在测试一些较大的值。</p>

<p>任何list、set、和sorted set都可以放232个元素。</p>

<p>换句话说，Redis的存储极限是系统中的可用内存值。</p>

<p>47、Redis常见性能问题和解决方案？</p>

<p>(1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件</p>

<p>(2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次</p>

<p>(3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内</p>

<p>(4) 尽量避免在压力很大的主库上增加从库</p>

<p>(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3...</p>

<p>这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。</p>

<p>48、Redis提供了哪几种持久化方式？</p>

<p>RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储.</p>

<p>AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.</p>

<p>如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.</p>

<p>你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.</p>

<p>最重要的事情是了解RDB和AOF持久化方式的不同,让我们以RDB持久化方式开始。</p>

<p>49、如何选择合适的持久化方式？</p>

<p>一般来说， 如果想达到足以媲美PostgreSQL的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。</p>

<p>有很多用户都只使用AOF持久化，但并不推荐这种方式：因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外， 使用RDB还可以避免之前提到的AOF程序的bug。</p>

<p>50、修改配置不重启Redis会实时生效吗？</p>

<p>针对运行实例，有许多配置选项可以通过 CONFIG SET 命令进行修改，而无需执行任何形式的重启。 从 Redis 2.2 开始，可以从 AOF 切换到 RDB 的快照持久性或其他方式而不需要重启 Redis。检索 ‘CONFIG GET *’ 命令获取更多信息。</p>

<p>但偶尔重新启动是必须的，如为升级 Redis 程序到新的版本，或者当你需要修改某些目前 CONFIG 命令还不支持的配置参数的时候。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql query语句是怎么执行的]]></title>
    <link href="http://www.throne4j.com/16006573741586.html"/>
    <updated>2020-09-21T11:02:54+08:00</updated>
    <id>http://www.throne4j.com/16006573741586.html</id>
    <content type="html"><![CDATA[
<p>下面给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。</p>

<p><figure><img src="media/16006573741586/16006774614968.jpg" alt=""/></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Synchronized关键字解析]]></title>
    <link href="http://www.throne4j.com/16005248987908.html"/>
    <updated>2020-09-19T22:14:58+08:00</updated>
    <id>http://www.throne4j.com/16005248987908.html</id>
    <content type="html"><![CDATA[
<p>线程安全是并发编程中的重要关注点，应该注意到的是，造成线程安全问题的主要诱因有两点：</p>

<ul>
<li>存在共享数据(也称临界资源)</li>
<li>存在多条线程共同操作共享数据。</li>
</ul>

<p>为了解决并发安全的问题，大神们琢磨出被称为 互斥锁 的东西，它的作用如下：<br/>
当存在多个线程操作共享数据时，需要保证同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再进行</p>

<p>在 Java 中，关键字 synchronized可以保证在同一个时刻，只有一个线程可以执行某个方法或者某个代码块(主要是对方法或者代码块中存在共享数据的操作)，同时我们还应该注意到synchronized另外一个重要的作用，synchronized可保证一个线程的变化(主要是共享数据的变化)被其他线程所看到</p>

<h2 id="toc_0">1、synchronized的作用</h2>

<p>Synchronized是Java中解决并发问题的一种最常用的方法，也是最简单的一种方法。Synchronized的作用主要有三个：</p>

<ul>
<li>原子性：确保线程互斥的访问同步代码；</li>
<li>可见性：保证共享变量的修改能够及时可见</li>
<li>有序性：有效解决重排序问题，即 “一个unlock操作先行发生(happen-before)于后面对同一个锁的lock操作”；</li>
</ul>

<h2 id="toc_1">2、synchronized的三种应用方式</h2>

<p>synchronized关键字最主要有以下3种应用方式：</p>

<ul>
<li>作用在实例方法时，锁对象便是对象实例（this）；</li>
<li>作用在静态方法时，锁对象便是对象的Class实例，因为Class数据存在于永久代，因此静态方法锁相当于该类的一个全局锁；</li>
<li>作用在某一个对象实例时，锁对象便是括号括起来的对象实例；</li>
</ul>

<h2 id="toc_2">3、synchronized反编译</h2>

<pre><code class="language-text">public class SyncDemo {
    
    public void method() {
        synchronized (SyncDemo.class) {
            System.out.println(&quot;互斥&quot;);
        }
    }
}


&gt; javap -v SyncDemo.class

...

public void method();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=2, locals=3, args_size=1
         0: ldc           #2                  // class com/goddess/base/SyncDemo
         2: dup
         3: astore_1
         4: monitorenter
         5: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;
         8: ldc           #4                  // String 互斥
        10: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
        13: aload_1
        14: monitorexit
        15: goto          23
        18: astore_2
        19: aload_1
        20: monitorexit
        21: aload_2
        22: athrow
        23: return
        
    ...
</code></pre>

<p>重点看到第4行 ‘monitorenter’ 与第14行 ‘monitorexit’，分别是进入同步代码块与退出同步代码块。</p>

<p>眼尖的同学会看到第20行也有一个 ‘monitorexit’，那么与第14行的 ‘monitorexit’ 有什么区别呢？</p>

<p>第14行 为同步正常退出释放锁；第20行为发生异步退出释放锁</p>

<p>进入monitorenter时，被监视的对象就被成为 监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权。</p>

<p>monitorenter过程如下：</p>

<ul>
<li>如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者；</li>
<li>如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1；</li>
<li>如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权；</li>
</ul>

<p>monitorexit过程如下：<br/>
执行monitorexit的线程必须是objectref所对应的monitor的所有者。指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。</p>

<p>注意： Synchronized的语义底层是通过一个monitor的对象来完成，其实Object的 wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。</p>

<p>我们再看一种 synchronized 的同步方式</p>

<pre><code class="language-text">public class SyncDemo {

    public synchronized void method() {
        System.out.println(&quot;互斥&quot;);
    }

}

&gt;javap -v SyncDemo.class
 public synchronized void method();
    descriptor: ()V
    flags: ACC_PUBLIC, ACC_SYNCHRONIZED
    Code:
      stack=2, locals=1, args_size=1
         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
         3: ldc           #3                  // String 互斥
         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
         8: return

</code></pre>

<p>从编译的结果来看，方法的同步并没有通过指令 monitorenter 和 monitorexit 来完成（理论上其实也可以通过这两条指令来实现），不过相对于未被synchronized修饰的普通方法，其常量池中多了 ACC_SYNCHRONIZED 标示符。</p>

<p>jvm 在执行method方法的时候当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。</p>

<p>被synchronized修饰的静态方法，反编译的结果中 既带有 ACC_SYNCHRONIZED标识符在方法中又存在 &#39;monitorenter&#39; 和 &#39;monitorexit&#39;</p>

<h2 id="toc_3">4、synchronized 原理预备知识</h2>

<p>查看java 对象头 ，图例如下，详情请查看<a href="15865981620428.html">二、JVM自动内存管理--java内存区域与内存溢出异常</a> 中的 java 对象头部分<br/>
<figure><img src="media/16005248987908/16007887135696.jpg" alt=""/></figure></p>

<h3 id="toc_4">4.1、jvm 关于synchronized的参数配置</h3>

<p>jvm 默认情况下 偏向锁的延迟是开启的，好像是4秒，可以通过如下命令查找到</p>

<p>UseBiasedLocking: jvm 默认开启偏向锁<br/>
UseHeavyMonitors：jvm 模式关闭重量级锁标记，如果指定了-XX:+UseHeavyMonitors，代表禁用偏向锁和轻量级锁</p>

<pre><code class="language-text">&gt; java -XX:+PrintFlagsFinal -version
</code></pre>

<p>关闭延迟开启偏向锁    -XX:BiasedLockingStartupDelay=0<br/>
禁止偏向锁 -XX:-UseBiasedLocking<br/>
启用偏向锁 -XX:+UseBiasedLocking</p>

<h3 id="toc_5">4.2、对象头中Mark Word与线程中Lock Record</h3>

<p>在线程进入同步代码块的时候，如果此同步对象没有被锁定，即它的锁标志位是01，则虚拟机首先在当前线程的栈中创建我们称之为“锁记录（Lock Record）”的空间，用于存储锁对象的Mark Word的拷贝，官方把这个拷贝称为Displaced Mark Word。整个Mark Word及其拷贝至关重要。</p>

<p>Lock Record是线程私有的数据结构，每一个线程都有一个可用Lock Record列表，同时还有一个全局的可用列表。每一个被锁住的对象Mark Word都会和一个Lock Record关联（对象头的MarkWord中的Lock Word指向Lock Record的起始地址），同时Lock Record中有一个Owner字段存放拥有该锁的线程的唯一标识（或者object mark word），表示该锁被这个线程占用。</p>

<h3 id="toc_6">4.3、监视器（Monitor）</h3>

<p>那什么是Monitor？可以把它理解为 一个同步工具，也可以描述为 一种同步机制，它通常被描述为一个对象。</p>

<p>每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做 内部锁 或者 Monitor 锁。</p>

<p>也就是通常说Synchronized的对象锁，MarkWord锁标识位为10，其中指针指向的是Monitor对象的起始地址。在Java虚拟机（HotSpot）中，Monitor是由ObjectMonitor实现的，其主要数据结构如下：</p>

<pre><code class="language-text">ObjectMonitor() {
    _header       = NULL;
    _count        = 0; // 记录个数
    _waiters      = 0,
    _recursions   = 0;
    _object       = NULL;
    _owner        = NULL;
    _WaitSet      = NULL; // 处于wait状态的线程，会被加入到_WaitSet
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ; // 处于等待锁block状态的线程，会被加入到该列表
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
  }
</code></pre>

<p>ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表（ 每个等待锁的线程都会被封装成ObjectWaiter对象 ），_owner指向持有ObjectMonitor对象的线程，</p>

<p>当锁膨胀为重量级锁的时候，会有以下操作：</p>

<ul>
<li>首先会进入 _EntryList 集合，当线程获取到对象的monitor后，进入 _Owner区域并把monitor中的owner变量设置为当前线程，同时monitor中的计数器count加1；</li>
<li>若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSet集合中等待被唤醒；</li>
<li>若当前线程执行完毕，也将释放monitor（锁）并复位count的值，以便其他线程进入获取monitor(锁)；</li>
</ul>

<p>由于wait/notify 会使用到Monitor锁，所以在同步代码块中使用 wait/notify后，互斥锁就会膨胀为重量级锁。</p>

<h2 id="toc_7">5、synchronized 加锁以及锁膨胀流程</h2>

<p>这里给出来 synchronized 加锁的流程图如下，此处纯属个人理解，不保证全部正确：<br/>
<figure><img src="media/16005248987908/Synchronized%20%E5%85%B3%E9%94%AE%E5%AD%97%E6%B5%81%E7%A8%8B%20-1-.jpg" alt="Synchronized 关键字流程 -1-"/><figcaption>Synchronized 关键字流程 -1-</figcaption></figure></p>

<h2 id="toc_8">6、锁的优化</h2>

<p>从JDK6开始，就对synchronized的实现机制进行了较大调整，包括使用JDK5引进的CAS自旋之外，还增加了自适应的CAS自旋、锁消除、锁粗化、偏向锁、轻量级锁这些优化策略。由于此关键字的优化使得性能极大提高，同时语义清晰、操作简单、无需手动关闭，所以推荐在允许的情况下尽量使用此关键字，同时在性能上此关键字还有优化的空间。</p>

<h3 id="toc_9">6.1、偏向锁</h3>

<p>偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。</p>

<p>偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。</p>

<p>当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程进入和退出同步块时不需要花费CAS操作来争夺锁资源，只需要检查是否为偏向锁、锁标识为ThreadID即可，处理流程如下：</p>

<ul>
<li>1、检测Mark Word是否为可偏向状态，即是否为偏向锁1，锁标识位为01；</li>
<li>2、若为可偏向状态，则测试线程ID是否为当前线程ID，如果是，则执行步骤（5），否则执行步骤（3）；</li>
<li>3、如果测试线程ID不为当前线程ID，则通过CAS操作竞争锁，竞争成功，则将Mark Word的线程ID替换为当前线程ID，否则执行线程（4）；</li>
<li>4、通过CAS竞争锁失败，证明当前存在多线程竞争情况，当到达全局安全点，获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码块；</li>
<li>5、执行同步代码块；</li>
</ul>

<p>所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。</p>

<p>但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。下面我们接着了解轻量级锁。</p>

<h4 id="toc_10">6.2、偏向锁的释放</h4>

<p>偏向锁的释放采用了 一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。偏向锁的撤销需要 等待全局安全点（这个时间点是上没有正在执行的代码）。其步骤如下：</p>

<ul>
<li>1、暂停拥有偏向锁的线程；</li>
<li>2、判断锁对象是否还处于被锁定状态，否，则恢复到无锁状态（01），以允许其余线程竞争。是，则挂起持有锁的当前线程，并将指向当前线程的锁记录地址的指针放入对象头Mark Word，升级为轻量级锁状态（00），然后恢复持有锁的当前线程，进入轻量级锁的竞争模式；<br/>
### 6.3、轻量级锁<br/>
倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。</li>
</ul>

<p>引入轻量级锁的主要目的是 在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗</p>

<p>对于轻量级锁，其性能提升的依据是 “对于绝大部分的锁，在整个生命周期内都是不会存在竞争的”，如果打破这个依据则除了互斥的开销外，还有额外的CAS操作，因此在有多线程竞争的情况下，轻量级锁比重量级锁更慢。</p>

<p>当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁过程如下：</p>

<p>1、在线程进入同步块时，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。<br/>
2、拷贝对象头中的Mark Word复制到锁记录（Lock Record）中；<br/>
3、拷贝成功后，虚拟机将使用CAS操作尝试将对象Mark Word中的Lock Word更新为指向当前线程Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤（4），否则执行步骤（5）；</p>

<p>4、如果这个更新动作成功了，那么当前线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态</p>

<p>5、如果这个更新操作失败了，虚拟机首先会检查对象Mark Word中的Lock Word是否指向当前线程的栈帧，如果是，就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，进入自旋执行（3），若自旋结束时仍未获得锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，当前线程以及后面等待锁的线程也要进入阻塞状态。</p>

<h4 id="toc_11">6.3.1、轻量级锁的释放</h4>

<p>轻量级锁的释放也是通过CAS操作来进行的，主要步骤如下：</p>

<ul>
<li>1、通过CAS操作尝试把线程中复制的Displaced Mark Word对象替换当前的Mark Word；</li>
<li>2、如果替换成功，整个同步过程就完成了，恢复到无锁状态（01）；</li>
<li>3、如果替换失败，说明有其他线程尝试过获取该锁（此时锁已膨胀），那就要在释放锁的同时，唤醒被挂起的线程；</li>
</ul>

<h4 id="toc_12">6.3.2、为什么升级为轻量锁时要把对象头里的Mark Word复制到线程栈的锁记录中呢？</h4>

<p>因为在申请对象锁时需要以该值作为CAS的比较条件，同时在升级到重量级锁的时候，能通过这个比较判定是否在持有锁的过程中此锁被其他线程申请过，如果被其他线程申请了，则在释放锁的时候要唤醒被挂起的线程。</p>

<h4 id="toc_13">6.3.3、为什么会尝试CAS不成功以及什么情况下会不成功？</h4>

<p>CAS本身是不带锁机制的，其是通过比较而来。</p>

<p>假设如下场景：线程A和线程B都在对象头里的锁标识为无锁状态进入，那么如线程A先更新对象头为其锁记录指针成功之后，线程B再用CAS去更新，就会发现此时的对象头已经不是其操作前的对象HashCode了，所以CAS会失败。也就是说，只有两个线程并发申请锁的时候会发生CAS失败。</p>

<p>然后线程B进行CAS自旋，等待对象头的锁标识重新变回无锁状态或对象头内容等于对象HashCode（因为这是线程B做CAS操作前的值），这也就意味着线程A执行结束（参见后面轻量级锁的撤销，只有线程A执行完毕撤销锁了才会重置对象头），此时线程B的CAS操作终于成功了，于是线程B获得了锁以及执行同步代码的权限。</p>

<p>如果线程A的执行时间较长，线程B经过若干次CAS时钟没有成功，则锁膨胀为重量级锁，即线程B被挂起阻塞、等待重新调度。</p>

<h3 id="toc_14">6.4、自旋锁</h3>

<p>线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。</p>

<p>所以引入自旋锁，何谓自旋锁？</p>

<p>所谓自旋锁，就是指当一个线程尝试获取某个锁时，如果该锁已被其他线程占用，就一直循环检测锁是否被释放，而不是进入线程挂起或睡眠状态。</p>

<p>自旋锁适用于锁保护的临界区很小的情况，临界区很小的话，锁占用的时间就很短。自旋等待不能替代阻塞，虽然它可以避免线程切换带来的开销，但是它占用了CPU处理器的时间。如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好，反之，自旋的线程就会白白消耗掉处理的资源，它不会做任何有意义的工作，典型的占着茅坑不拉屎，这样反而会带来性能上的浪费。所以说，自旋等待的时间（自旋的次数）必须要有一个限度，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起。</p>

<p>自旋锁在JDK 1.4.2中引入，默认关闭，但是可以使用-XX:+UseSpinning开开启，在JDK1.6中默认开启。同时自旋的默认次数为10次，可以通过参数-XX:PreBlockSpin来调整</p>

<h3 id="toc_15">6.5、自适应自旋锁</h3>

<p>JDK 1.6引入了更加聪明的自旋锁，即自适应自旋锁。所谓自适应就意味着自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。那它如何进行适应性自旋呢？ </p>

<p>线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。</p>

<h3 id="toc_16">6.6、锁消除</h3>

<p>消除锁是虚拟机另外一种锁的优化，<strong><em>它的依据是逃逸分析的数据支持</em></strong>，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。</p>

<h3 id="toc_17">6.7、锁粗化</h3>

<p>在使用同步锁的时候，需要让同步块的作用范围尽可能小—仅在共享数据的实际作用域中才进行同步，这样做的目的是为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。</p>

<p>在大多数的情况下，上述观点是正确的。但是如果一系列的连续加锁解锁操作，可能会导致不必要的性能损耗，所以引入锁粗话的概念。</p>

<p>锁粗话概念比较好理解，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁</p>

<p>举个例子来说： vector每次add的时候都需要加锁操作，JVM检测到对同一个对象（vector）连续加锁、解锁操作，会合并一个更大范围的加锁、解锁操作，即加锁解锁操作会移到for循环之外。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[]]></title>
    <link href="http://www.throne4j.com/16001854729591.html"/>
    <updated>2020-09-15T23:57:52+08:00</updated>
    <id>http://www.throne4j.com/16001854729591.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TCP 粘包/拆包]]></title>
    <link href="http://www.throne4j.com/16001815961184.html"/>
    <updated>2020-09-15T22:53:16+08:00</updated>
    <id>http://www.throne4j.com/16001815961184.html</id>
    <content type="html"><![CDATA[
<p>TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行包的划分，即滑动窗口的概念。所以一个完整的业务包可能会被TCP拆分成多个包进行发送，也有可能吧多个晓得包封装成一个大的数据包发送，这就是所谓的TCP粘包与拆包问题。</p>

<h2 id="toc_0">TCP粘包与拆包问题说明</h2>

<p><figure><img src="media/16001815961184/16001825107010.jpg" alt="" style="width:622px;"/></figure></p>

<p>假设客户端分别发送了两个数据包D1 和D2给服务端，由于服务端一次读取到的字节数是不确定的，故可能存在以下4种情况：</p>

<ul>
<li>服务端分两次读取到了两个独立的数据包 D1 和 D2 ，没有 粘包与拆包</li>
<li>服务端一次接收到了两个数据包，D1和D2粘合在一起，被称为TCP粘包</li>
<li>服务端分两次读取到了两个数据包，第一次读取到了完整的D1 包和D2包的部分内容，第二次读取到了 D2 包的剩余内容，这被称为 TCP拆包</li>
<li>服务端分两次读取到了两个数据包，第一次读取到了D1包的部分内容 D1_1 ，第二次读取到了D1包的剩余内容 D1_2 和 D2 包的整包。</li>
</ul>

<p>如果此时服务端 tcp 接收 滑窗 非常小，而数据包 D1 和 D2 比较大，很有可能会发生第5种情况，即服务端分多次才能将D1和D2包 接受完全，期间发生多次拆包。</p>

<h2 id="toc_1">TCP 粘包/拆包发生的原因</h2>

<p>问题产生的原因有 三个：</p>

<ul>
<li>应用程序write 写入的字节大小大于套接口发送缓冲区大小</li>
<li>进行MSS大小的TCP分段</li>
<li>以太网帧的payload 大于 MTU 进行 IP 分片。</li>
</ul>

<p><figure><img src="media/16001815961184/16001830988462.jpg" alt=""/></figure></p>

<h2 id="toc_2">粘包问题的解决策略</h2>

<p>由于底层的 TCP 无法理解上层的业务数据，所以在底层是无法保证数据包不被拆分和重组的，这个问题只能通过上层的应用协议栈设计来解决，根据业界的主流协议的解决方案，可以归纳如下：</p>

<ul>
<li>消息定长，例如每个报文的大小为固定长度200字节，如果不够，空位补空格</li>
<li>在包尾增加回车换行符作为消息结束符，例如 FTP协议，在文本协议中应用比较广泛</li>
<li>将特殊的分隔符作为消息的结束标志，回车换行符就是一种特殊的结束分隔符</li>
<li>将消息分为消息头和消息体，消息头中包含消息总长度（或者消息体长度）的字段，通常设计思路为消息头的第一个字段使用 int32 来表示消息的总长度</li>
<li>更复杂的应用层协议</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql 查询语句优化]]></title>
    <link href="http://www.throne4j.com/16000606506318.html"/>
    <updated>2020-09-14T13:17:30+08:00</updated>
    <id>http://www.throne4j.com/16000606506318.html</id>
    <content type="html"><![CDATA[
<p>在分析如何优化 MySQL 查询语句之前，我们需要先了解一下查询语句优化的基本思路和原则。一般来说，查询语句的优化思路和原则主要提现在以下几个方面：</p>

<ul>
<li><p>优化更需要优化的查询；<br/>
一般来说，高并发低消耗的语句回避地并发高消耗的语句对系统的影响要大的多，因为优化高并发下的查询语句一旦有问题，可能使整个系统崩溃掉，而低并发的查询有问题的话，一般只会影响当前查询</p></li>
<li><p>定位优化对象的性能瓶颈；<br/>
在拿到一条需要优化的 Query 之后，我们首先要判断出这个 Query 的瓶颈到底是 IO 还是CPU。在MySQL中，我们可以通过系统自带的 PROFILING 功能很清楚的找出一个Query 的瓶颈所在</p>
<ul>
<li>通过慢查询日志定位那些执行效率较低的SL语向,用-SSL语句的日志文件--log-slow-queries[=file name] 选项启动时, mysqld写一个包含所有执行时间超过 long query time秒t 具体可以查看本书第26章中日志管理的相关部分。</li>
<li>慢查询日志在查询结東以后才记录,所以在应用反映执行效率出现问题的时候查询慢查询日志并不能定位问题,可以使用 show processlist f命今查看当前 MYSQL在进行的线程,包括线程的状态、是否锁表等,可以实时地查看SQL的执行情况,同时对一些锁表操作进行优化。</li>
</ul></li>
<li><p>明确的优化目标；<br/>
一般来说，我们首先需要清楚的了解数据库目前的整体状态，同时也要清楚的知道数据库中与该 Query 相关的数据库对象的各种信息，而且还要了解该 Query 在整个应用系统中所实现的功能。了解了数据库整体状态，我们就能知道数据库所能承受的最大压力，也就清楚了我们能够接受的最悲观情况。根据功能的重要性，确定 query 的优化目标。</p></li>
<li><p>从 Explain 入手；</p></li>
<li><p>多使用 profile；</p></li>
<li><p>永远用小结果集驱动大的结果集；</p></li>
<li><p>尽可能在索引中完成排序；</p></li>
<li><p>只取出自己需要的 Columns；</p></li>
<li><p>仅仅使用最有效的过滤条件；</p></li>
<li><p>尽可能避免复杂的 Join 和子查询；</p></li>
</ul>

<h2 id="toc_0">explain 的使用</h2>

<ul>
<li>ID：Query Optimizer 所选定的执行计划中查询的序列号；</li>
<li>Select_type：所使用的查询类型，主要有以下这几种查询类型
<ul>
<li>DEPENDENT SUBQUERY：子查询中内层的第一个 SELECT，依赖于外部查询的结果集；</li>
<li>DEPENDENT UNION：子查询中的 UNION，且为 UNION 中从第二个 SELECT 开始的后面所有SELECT，同样依赖于外部查询的结果集</li>
<li>PRIMARY：子查询中的最外层查询，注意并不是主键查询；</li>
<li>SIMPLE：除子查询或者 UNION 之外的其他查询；</li>
<li>SUBQUERY：子查询内层查询的第一个 SELECT，结果不依赖于外部查询结果集；</li>
<li>UNCACHEABLE SUBQUERY：结果集无法缓存的子查询；</li>
<li>UNION：UNION 语句中第二个 SELECT 开始的后面所有 SELECT，第一个 SELECT 为 PRIMARY</li>
<li>UNION RESULT：UNION 中的合并结果；</li>
</ul></li>
<li>Table：显示这一步所访问的数据库中的表的名称；</li>
<li><p>Type：告诉我们对表所使用的访问方式，主要包含如下集中类型：</p>
<ul>
<li>a11:全表扫描</li>
<li>index:全索引扫描; </li>
<li>index merge:查询中同时使用两个(或更多)索引,然后对索引结果进行 merge之后再读取表数据; </li>
<li>index subquery:子查询中的返回结果字段组合是一个索引(或索引组合),但不是一个主键或者唯一索引rang:索引范围扫描; </li>
<li>range: 索引范围扫描，常见于&lt;、&lt;=、&gt;、&gt;=、 between等操作符</li>
<li>ref:使用非唯一索引扫描或唯一索引的前缀扫描，最多只会有一条匹配结果,一般是通过主键或者唯一键索引来访问; </li>
<li>eq_ref: 使用唯一索引，每个索引键值，只有一条结果记录匹配</li>
<li>const:读常量,且最多只会有一条记录匹配,由于是常量,所以实际上只需要读一次eq </li>
<li>system:系统表,表中只有一行数据;</li>
<li></li>
<li><p>unique_ subquery:子查询中的返回结果字段组合是主键或者唯一约束;</p></li>
</ul></li>
<li><p>Possible_keys：该查询可以利用的索引. 如果没有任何索引可以使用，就会显示成 null，这一项内容对于优化时候索引的调整非常重要；</p></li>
<li><p>Key：MySQL Query Optimizer 从 possible_keys 中所选择使用的索引；</p></li>
<li><p>Key_len：被选中使用索引的索引键长度；</p></li>
<li><p>Ref：列出是通过常量（const），还是某个表的某个字段（如果是 join）来过滤（通过 key）的；</p></li>
<li><p>Rows：MySQL Query Optimizer 通过系统收集到的统计信息估算出来的结果集记录条数；</p></li>
<li><p>Extra：查询中每一步实现的额外细节信息，主要可能会是以下内容：</p>
<ul>
<li>Distinct：查找 distinct 值，所以当 mysql 找到了第一条匹配的结果后，将停止该值的查询而转为后面其他值的查询；</li>
<li>Full scan on NULL key：子查询中的一种优化方式，主要在遇到无法通过索引访问 null 值的使用使用；</li>
<li>Impossible WHERE noticed after reading const tables：MySQL Query Optimizer 通过收集到的统计信息判断出不可能存在结果；</li>
<li>No tables：Query语句中使用 FROM DUAL 或者不包含任何 FROM子句；</li>
<li>Not exists：在某些左连接中 MySQL Query Optimizer 所通过改变原有 Query 的组成而使用的优化方法，可以部分减少数据访问次数；</li>
<li>Range checked for each record (index map: N)：通过 MySQL 官方手册的描述，当MySQL Query Optimizer 没有发现好的可以使用的索引的时候，如果发现如果来自前面的表的列值已知，可能部分索引可以使用。对前面的表的每个行组合，MySQL 检查是否可以使用 range 或 index_merge 访问方法来索取行。</li>
<li>Select tables optimized away：当我们使用某些聚合函数来访问存在索引的某个字段的时候，MySQL Query Optimizer 会通过索引而直接一次定位到所需的数据行完成整个查询。当然，前提是在 Query 中不能有 GROUP BY 操作。如使用 MIN()或者 MAX（）的时候；</li>
<li>Using filesort：当我们的 Query 中包含 ORDER BY 操作，而且无法利用索引完成排序操作的时候，MySQL Query Optimizer 不得不选择相应的排序算法来实现。</li>
<li>Using index：所需要的数据只需要在 Index 即可全部获得而不需要再到表中取数据；</li>
<li>Using index for group-by：数据访问和 Using index 一样，所需数据只需要读取索引即可，而当 Query 中使用了 GROUP BY 或者 DISTINCT 子句的时候，如果分组字段也在索引中，Extra 中的信息就会是 Using index for group-by；</li>
<li>Using temporary：当 MySQL 在某些操作中必须使用临时表的时候，在 Extra 信息中就会出现 Using temporary 。主要常见于 GROUP BY 和 ORDER BY 等操作中。</li>
<li>Using where：如果我们不是读取表的所有数据，或者不是仅仅通过索引就可以获取所有需要的数据，则会出现 Using where 信息；</li>
<li>Using where with pushed condition：这是一个仅仅在 NDBCluster 存储引擎中才会出现的信息，而且还需要通过打开 Condition Pushdown 优化功能才可能会被使用。控制参数为 engine_condition_pushdown。</li>
</ul></li>
</ul>

<h2 id="toc_1">合理设计并利用索引</h2>

<h3 id="toc_2">索引设计原则</h3>

<ul>
<li>搜索的索引列,不一定是所要选择的列。换句话说,最适合索引的列是出现在 WHERE 子句中的列,或连接子向中指定的列,而不是出现在 SELECT关键字后的选择列表中的列。</li>
<li>使用唯一索引。考虑某列中值的分布。索引的列的基数越大,索引的效果越好。例如, 存放出生日期的列具有不同值,很容易区分各行。而用来记录性别的列,只含有“M”和“F”, 则对此列进行索引没有多大用处,因为不管搜索哪个值,都会得出大约一半的行。</li>
<li>使用短索引。如果对字符串列进行索引,应该指定一个前缀长度,只要有可能就应该这样做。例如,有一个CHAR(200列,如果在前10个或20个字符内,多数值是唯一的,那么就不要对整个列进行索引。对前10个或20个字符进行索引能够节省大量索引空间,也可能会使查询更快。较小的索引涉及的磁盘10较少,较短的值比较起来更快。更为重要的是,对于较短的健值,索引高速缓存中的块能容纳更多的键值,因此, MYSQL也可以在内存中容纳更多的值。这样就増加了找到行而不用读取索引中较多块的可能性</li>
<li><p>利用最左前级。在创建一个n列的索引时,实际是创建了 MYSQL可利用的n个索引多列索引可起几个索引的作用,因为可利用索引中最左边的列集来匹配行。这样的列集称为最左前缀。</p></li>
<li><p>不要过度索引。不要以为索引“越多越好”,什么东西都用索引是错误的。每个额外的索引都要占用额外的磁盘空间,并降低写操作的性能。在修改表的内容时,索引必须进行更新,有时可能需要重构,因此,索引越多,所花的时间越长。如果有一个索引很少利用或从不使用,那么会不必要地减缓表的修改速度。此外, MYSQL在生成一个执行计划时,要考虑各个索引,这也要花费时间。创建多余的索引给查询优化带来了更多的工作。索引太多,也可能会使 MYSQL选择不到所要使用的最好索引。只保持所需的索引有利于查询优化</p></li>
<li><p>对于 INNODB存储引擎的表,记录默认会按照一定的顺序保存,如果有明确定义的主键,则按照主键顺序保存。如果没有主键,但是有唯一索引,那么就是按照唯一索引的顺序保存。如果既没有主键又没有唯一索引,那么表中会自动生成一个内部列,按照这个列的顺序保存。按照主键或者内部列进行的访问是最快的,所以 INNODB表尽量自己指定主键,当表中同时有几个列都是唯一的,都可以作为主键的时候,要选择最常作为访问条件的列作为主键,提高查询的效率。另外,还需要注意, INNODB表的普通索引都会保存主键的键值,所以主键要尽可能选择较短的数据类型,可以有效地减少索引的磁盘占用,提高索引的缓存效果。</p></li>
</ul>

<h3 id="toc_3">BTREE索引与HASH索引</h3>

<p>HASH索引有一些重要的特征需要在使用的时候特别注意：</p>

<ul>
<li>只用于使用 = 操作符的等式比较</li>
<li>优化器不能使用 HASH 索引来加速 ORDER BY操作。</li>
<li>MYSQL不能确定在两个值之间大约有多少行。如果将一个 MYISAM 表改为 HASH 索引的 MEMORY表,会影响一些查询的执行效率</li>
<li>只能使用整个关键字来搜索一行</li>
</ul>

<p>而对于 BTREE索引,当使用&gt;、&lt;、&gt;=、&lt;=、 BETWEEN、!=或者,或者 LIKE &#39; pattern (其中&#39;pattern&#39;不以通配符开始)操作符时,都可以使用相关列上的索引。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[传统的 BIO 通信模型与NIO发展历程]]></title>
    <link href="http://www.throne4j.com/15998898223293.html"/>
    <updated>2020-09-12T13:50:22+08:00</updated>
    <id>http://www.throne4j.com/15998898223293.html</id>
    <content type="html"><![CDATA[
<p>首先看一下BIO通信模型示意图，如下图所示：</p>

<p><figure><img src="media/15998898223293/15998918203285.jpg" alt="" style="width:843px;"/></figure></p>

<p><figure><img src="media/15998898223293/15998920886309.jpg" alt="" style="width:844px;"/></figure></p>

<p>网络编程的基本模型是 Client/ Server模型,也就是两个进程之间进行相互通信,其中服务端提供位置信息(绑定的IP地址和监听端口),客户端通过连接操作向服务端监听的地址发起连接请求,通过三次握手建立连接,如果连接建立成功,双方就可以通过网络套接字(Socket)进行通信。</p>

<p>在基于传统同步阻塞模型开发中, Serversocket负责绑定IP地址,启动监听端口Socket负责发起连接操作。连接成功之后,双方通过输入和输出流进行同步阻塞式通信。</p>

<p>采用 BIO 通信模型的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接，它接收到客户端连接请求之后为每个客户端创建一 个新的线程进行链路处理没处理完成后，通过输出流返回应答给客户端，线程销毁。即典型的一请求一应答模型。</p>

<p>该模型最大的问题就是缺乏弹性伸缩能力，当客户端并发访问量增加后，服 务端的线程个数和客户端并发访问数呈 1:1 的正比关系，Java 中的线程也是比较 宝贵的系统资源，线程数量快速膨胀后，系统的性能将急剧下降，随着访问量的 继续增大，系统最终就不堪重负挂掉了。</p>

<p>为了改进这种一连接一线程的模型，我们可以使用线程池来管理这些线程， 实现 1 个或多个线程处理 N 个客户端的模型(但是底层还是使用的同步阻塞 I/O)， 通常被称为“伪异步 I/O 模型“。</p>

<p>我们看一下 返回应答时间过长会引起的级联故障：</p>

<p>(1)服务端处理缓慢,返回应答消息耗费60s,平时只需要10ms </p>

<p>(2)米用伪异步1/O的线程正在读取故障服务节点的响应,由于读取输入流是阻塞的,它将别阻塞 60s。</p>

<p>(3)假如所有的可用线程都被故障服务器阻塞,那后续所有的1/O消息都将在队列中排队。</p>

<p>(4)由于线程池采用阻塞队列实现,当队列积满之后,后续入队列的操作将被阻塞</p>

<p>(5)由于前端只有一个 Accptor线程接收客户端接入,它被阻塞在线程池的同步阻塞队列之后,新的客户端请求消息将被拒绝,客户端会发生大量的连接超时。</p>

<p>(6)由于几乎所有的连接都超时,调用者会认为系统已经崩溃,无法接收新的请求消息。</p>

<p>代码如下：</p>

<pre><code class="language-java">import java.io.*;
import java.net.InetSocketAddress;
import java.net.ServerSocket;
import java.net.Socket;

/**
 * BIO 服务端
 **/
public class Server {

    public static void main(String[] args) throws IOException {
        ServerSocket serverSocket = new ServerSocket();
        serverSocket.bind(new InetSocketAddress(8081));
        System.out.println(&quot;server 启动了&quot;);
        while (true) {
            // 在这里会阻塞接受连接请求
            Socket accept = serverSocket.accept();
            // 这里可以换成线程池实现用户与线程 N:M 的伪异步IO模型
            // 但是如果发生读取数据较慢时，大量并发的情况下，其它接入的消息只能一直等待，这是此模型的最大弊端
            new Thread(new ServerTask(accept)).start();
        }
    }


    private static class ServerTask implements Runnable {
        private Socket socket = null;

        public ServerTask(Socket socket) {
            this.socket = socket;
        }

        @Override
        public void run() {
            try {
                InputStream inputStream = socket.getInputStream();
                OutputStream outputStream = socket.getOutputStream();

                ObjectInputStream objectInputStream = new ObjectInputStream(inputStream);
                ObjectOutputStream objectOutputStream = new ObjectOutputStream(outputStream);

                String s = objectInputStream.readUTF();
                System.out.println(&quot;server accept &quot; + s);

                objectOutputStream.writeUTF(&quot;有胆你就来&quot;);
                objectOutputStream.flush();
            } catch (IOException e) {
                e.printStackTrace();
            }

        }
    }
}

</code></pre>

<pre><code class="language-java">
import java.io.IOException;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;
import java.net.InetSocketAddress;
import java.net.Socket;

/**
 * 请求客户端
 **/
public class Client {

    public static void main(String[] args) throws IOException {
        Socket socket = new Socket();
        socket.connect(new InetSocketAddress(&quot;127.0.0.1&quot;,8081));

        ObjectOutputStream outputStream = new ObjectOutputStream(socket.getOutputStream());
        ObjectInputStream inputStream = new ObjectInputStream(socket.getInputStream());

        outputStream.writeUTF(&quot;老子来逛逛&quot;);
        outputStream.flush();
        System.out.println(inputStream.readUTF());

    }
}

</code></pre>

<h2 id="toc_0">JDK对NIO的支持与演进</h2>

<p>由于上面几点阻塞IO引起的问题，java 在JDK1.4的时候，随着JSR-51的发布，引入了NIO，它新增了一个java.nio包。提供了很多进行一步IO开发的API和类库。主要的类和接口如下：</p>

<ul>
<li>进行异步I/O操作的缓冲区 Bytebuffer等;</li>
<li>进行异步1O操作的管道Pipe </li>
<li>进行各种1/O操作(异步或者同步)的 Channel,包括 ServerSocketChannel和SocketChannel </li>
<li>多种字符集的编码能力和解码能力</li>
<li>实现非阻塞1/O操作的多路复用器 selector </li>
<li>基于流行的Perl实现的正则表达式类库; </li>
<li>文件通道 FileChannel</li>
</ul>

<p>虽然NIO类库促进了基于java 的一步非阻塞编程的发展和应用，但是，它仍然有不完善的地方，主要问题如下：</p>

<ul>
<li>没有统一的文件属性</li>
<li>API能力比较弱，例如目录的级联创建和递归遍历，需要自己实现</li>
<li>底层存储系统的一些高级API无法使用</li>
<li>所有的文件操作都是同步阻塞调用，不支持异步文件读写操作</li>
</ul>

<p>之后随着 JDK1.7 正式发布，NIO升级为成我们口中的额 NIO2.0 ,它是有JSR-203演进而来，主要提供了如下三个方面的改进：</p>

<ul>
<li>提供能够批量获取文件属性的API，这些API具有平台无关性，不予特性的文件系统相耦合</li>
<li>提供AIO功能，支持基于文件的异步IO操作和针对网络套接字的异步操作</li>
<li>完成JSR-51定义的通道功能，包括对配置和多播数据报的支持等。</li>
</ul>

<h2 id="toc_1">BIO和NIO的区别</h2>

<p>Java NIO 和 IO 之间第一个最大的区别是，IO 是面向流的，NIO 是面向缓冲 区的。 </p>

<p>Java IO 的各种流是阻塞的，Java NIO 的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它 仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不 是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事 情。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql的锁定机制]]></title>
    <link href="http://www.throne4j.com/15998158611428.html"/>
    <updated>2020-09-11T17:17:41+08:00</updated>
    <id>http://www.throne4j.com/15998158611428.html</id>
    <content type="html"><![CDATA[
<p>为了保证数据的一致完整性，任何一个数据库都存在锁定机制，在mysql中使用最为频繁的当属 innoDB 和 MyISAM，我们就来具体探讨一下这两种存储引擎是如何实现锁机制的。</p>

<p>数据库锁定机制简单来说就是数据库为了保证数据的一致性而使各种共享资源在被并发访问访问变得有序所设计的一种规则。</p>

<p>MySQL 各存储引擎使用了三种类型（级别）的锁定机制：行级锁定，页级锁定和表级锁定。</p>

<table>
<thead>
<tr>
<th>锁机制</th>
<th>描述</th>
<th>优点</th>
<th>缺点</th>
<th>存储引擎</th>
</tr>
</thead>

<tbody>
<tr>
<td>行级锁</td>
<td>锁定对象的颗粒度很小</td>
<td>由于锁定颗粒度很小，所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。</td>
<td>由于锁定颗粒度很小，每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大。另外可能会引发死锁的情况</td>
<td>Innodb 存储引擎和 NDB Cluster 存储引擎</td>
</tr>
<tr>
<td>表级锁</td>
<td>各存储引擎中最大颗粒度的锁定机制。</td>
<td>实现逻辑非常简单，带来的系统负面影响最小</td>
<td>出现锁定资源争用的概率也会最高，致使并大度大打折扣</td>
<td>MyISAM，Memory，CSV 等一些非事务性存储引擎</td>
</tr>
<tr>
<td>页级锁</td>
<td>锁定颗粒度介于行级锁定与表级锁之间</td>
<td>并发处理能力介于行级锁和表级锁之间</td>
<td>页级锁定和行级锁定一样，会发生死锁</td>
<td>BerkeleyDB</td>
</tr>
</tbody>
</table>

<h2 id="toc_0">表级锁定</h2>

<p>mysql的表级锁定主要分为两种类型：读锁定、写锁定。主要通过4个队列来维护这两种锁定。</p>

<p>两个存放当前正在锁定中的读和写锁定信息，另外两个存放等待中的读写锁定信息，</p>

<p>如下：<br/>
• Current read-lock queue (lock-&gt;read) <br/>
• Pending read-lock queue (lock-&gt;read_wait) <br/>
• Current write-lock queue (lock-&gt;write) <br/>
• Pending write-lock queue (lock-&gt;write_wait)</p>

<h3 id="toc_1">读锁定</h3>

<p>一个新的客户端请求在申请获取读锁定资源的时候，需要满足两个条件：</p>

<ul>
<li>请求锁定的资源当前没有被写锁定；</li>
<li>写锁定等待队列（Pending write-lock queue）中没有更高优先级的写锁定等待；</li>
</ul>

<p>如果满足了上面两个条件之后，该请求会被立即通过，并将相关的信息存入 Current read-lock queue 中，而如果上面两个条件中任何一个没有满足，都会被迫进入等待队列 Pending read-lock queue 中等待资源的释放。</p>

<h3 id="toc_2">写锁定</h3>

<p>当客户端请求写锁定的时候，MySQL 首先检查在 Current write-lock queue 是否已经有锁定相同资源的信息存在。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mysql]]></title>
    <link href="http://www.throne4j.com/15998153885959.html"/>
    <updated>2020-09-11T17:09:48+08:00</updated>
    <id>http://www.throne4j.com/15998153885959.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">隔离级别</h2>

<p><figure><img src="media/15998153885959/16003980475787.jpg" alt="" style="width:808px;"/></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux 网络 I/O 模型]]></title>
    <link href="http://www.throne4j.com/15996615430684.html"/>
    <updated>2020-09-09T22:25:43+08:00</updated>
    <id>http://www.throne4j.com/15996615430684.html</id>
    <content type="html"><![CDATA[
<p>首先需要搞清楚什么是同步和异步、阻塞与非阻塞</p>

<p>同步和异步：关注的是结果消息的通信机制</p>

<p>同步：调用方需要主动等待结果的返回。<br/>
异步： 不需要主动等待结果返回，而是通过其他手段获取结果，比如状态通知、回调函数等。</p>

<p>阻塞和非阻塞： 主要关注的是等待结果返回调用方的状态</p>

<p>阻塞：结果返回之前，当前线程被挂起，不做任何事。<br/>
非阻塞：结果在返回之前，线程可以做一些其它事情，不会被挂起。</p>

<h2 id="toc_0">linux 五种I/O 模型</h2>

<ul>
<li>阻塞 I/O，同步的</li>
<li>非阻塞 I/O，同步的</li>
<li>I/O 复用，同步的</li>
<li>信号驱动 I/O ，同步的</li>
<li>异步 I/O ，异步的</li>
</ul>

<h3 id="toc_1">阻塞 I/O</h3>

<p><figure><img src="media/15996615430684/15998806724839.jpg" alt="" style="width:998px;"/></figure></p>

<p>应用程序调用一个 IO 函数，导致应用程序阻塞，等待数据准备好。 如果数 据没有准备好，一直等待，数据准备好之后，从内核拷贝到用户空间,IO 函数返回 成功指示。</p>

<h3 id="toc_2">非阻塞 I/O 模型(不推荐使用，占用大量CPU时间)</h3>

<p><figure><img src="media/15996615430684/15998806939008.jpg" alt="" style="width:965px;"/></figure></p>

<p>一个 SOCKET 接口设置为非阻塞就是告诉内核，当所请求的 I/O 操作 无法完成时，不要将进程睡眠，而是返回一个错误。这样我们的 I/O 操作函数将 不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用 CPU 的时间。上述模型绝不被推荐。</p>

<h3 id="toc_3">IO 多路复用模型</h3>

<p><figure><img src="media/15996615430684/15998807171142.jpg" alt="" style="width:967px;"/></figure></p>

<p>Linux提供 select/poll,进程通过件事一个或多个fd(描述符) ，并将 fd 传递给 select 或poll 系统调用, 阻塞在 select 操作上,这样 select/poll 可以帮我们监视多个 fd 是否处于就绪状态。 </p>

<p>select/poll 是顺序扫描 fd 是否就绪, 而且支持的 fd 数量有限,因此它的使用受到了一些制约。 </p>

<p>Linux还提供了一个 epoll 系统调用, epoll 使用基于事件驱动方式代替顺序扫描,因此性能更高。当有 fd 就绪时,立即回调函数 rollback。</p>

<h3 id="toc_4">信号启动 I/O</h3>

<p><figure><img src="media/15996615430684/15998810595890.jpg" alt="" style="width:1292px;"/></figure></p>

<p>首先开启套接口信号驱动I/O功能,并通过系统调用 sigaction 执行一个信号处理函数(此系统调用立即返回,进程继续工作,它是非阻塞的)。当数据准备就绪时,就为该进程生成一个 SIGIO信号,通过信号回调通知应用程序调用 recvfrom 来读取数据,并通知主循环函数处理数据,如图1-4所示。</p>

<h3 id="toc_5">异步I/O</h3>

<p><figure><img src="media/15996615430684/15998897558637.jpg" alt="" style="width:665px;"/></figure></p>

<p>告知内核启动某个操作,并让内核在整个操作完成后(包括将数据从内核复制到用户自己的缓冲区)通知我们。这种模型与信号驱动模型的主要区别是:信号驱动1O由内核通知我们何时可以开始一个1/O操作;异步1O模型由内核通知我们1(O 操作何时已经完成</p>

<h3 id="toc_6">五种 IO 模型的比较</h3>

<p><figure><img src="media/15996615430684/15998878764474.jpg" alt="" style="width:879px;"/></figure></p>

<h2 id="toc_7">多路复用 IO</h2>

<p>select、poll、epoll 的区别</p>

<table>
<thead>
<tr>
<th>操作</th>
<th>描述符限制</th>
<th>IO效率</th>
<th>消息传递方式</th>
</tr>
</thead>

<tbody>
<tr>
<td>select</td>
<td>单个进程所能打开的 fd 最大连接数有限制，由 FD_SETSIZE 宏定义，默认是1024，其大小事32个整数的大小，也可以手动修改，然后重新编译内核，但是性能可能受到影响</td>
<td>当拥有一个很大的socket集合时，由于select/poll 线性地扫描全部集合，会导致效率程直线下降的问题。</td>
<td>内核需要将消息传递到用户控件，都需要内核考别动作</td>
</tr>
<tr>
<td>poll</td>
<td>poll在本质上和select没有区别，但是它没有最大连接的限制</td>
<td>同上</td>
<td>同上</td>
</tr>
<tr>
<td>epoll</td>
<td>它所支持的FD上限是操作系统的最大文件句柄数，远远大于1024，可通过 cat/proc/sys/fs/file -max 查看，这个数可系统内存关系比较大</td>
<td>epoll 只会对活跃的socket进行操作，epoll会根据每个fd上的回调函数实现。如果所有的socket处于活跃状态，则epoll的效率并不比select/poll效率高多少，在活跃socket比较少的情况下，epoll效率不成为题</td>
<td>epoll 通过内核和用户空间共享一块内存mmap来实现</td>
</tr>
</tbody>
</table>

<p>无论是 select、poll还是epol都需要内核把FD消息通知给用户空间,如何避免不必要的内存复制就显得非常重要，epoll 通过内核和用户空间共享一块内存mmap来避免不必要的内存复制。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[redis.conf 详解]]></title>
    <link href="http://www.throne4j.com/15991189115875.html"/>
    <updated>2020-09-03T15:41:51+08:00</updated>
    <id>http://www.throne4j.com/15991189115875.html</id>
    <content type="html"><![CDATA[
<pre><code class="language-text"># Redis configuration file example.
#
# Note that in order to read the configuration file, Redis must be
# started with the file path as first argument:
#
# ./redis-server /path/to/redis.conf
#以上--redis启动说明：redis启动指令的第一个参数必须是配置文件路径

# Note on units: when memory size is needed, it is possible to specify
# it in the usual form of 1k 5GB 4M and so forth:
#
# 1k =&gt; 1000 bytes
# 1kb =&gt; 1024 bytes
# 1m =&gt; 1000000 bytes
# 1mb =&gt; 1024*1024 bytes
# 1g =&gt; 1000000000 bytes
# 1gb =&gt; 1024*1024*1024 bytes
#
# units are case insensitive so 1GB 1Gb 1gB are all the same.
# 以上--units单位说明：定义了基本度量单位，并且说明不区分单位大小写

################################## INCLUDES ###################################

# Include one or more other config files here.  This is useful if you
# have a standard template that goes to all Redis servers but also need
# to customize a few per-server settings.  Include files can include
# other files, so use this wisely.
#
# Notice option &quot;include&quot; won&#39;t be rewritten by command &quot;CONFIG REWRITE&quot;
# from admin or Redis Sentinel. Since Redis always uses the last processed
# line as value of a configuration directive, you&#39;d better put includes
# at the beginning of this file to avoid overwriting config change at runtime.
#
# If instead you are interested in using includes to override configuration
# options, it is better to use include as the last line.
#
# include /path/to/local.conf
# include /path/to/other.conf
#以上--INCLUDES：redis.conf作为配置总闸，可以在此处关联其它配置文件

################################## NETWORK #####################################

# By default, if no &quot;bind&quot; configuration directive is specified, Redis listens
# for connections from all the network interfaces available on the server.
# It is possible to listen to just one or multiple selected interfaces using
# the &quot;bind&quot; configuration directive, followed by one or more IP addresses.
#
# Examples:
#
# bind 192.168.1.100 10.0.0.1
# bind 127.0.0.1 ::1
#
# ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the
# internet, binding to all the interfaces is dangerous and will expose the
# instance to everybody on the internet. So by default we uncomment the
# following bind directive, that will force Redis to listen only into
# the IPv4 lookback interface address (this means Redis will be able to
# accept connections only from clients running into the same computer it
# is running).
#
# IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES
# JUST COMMENT THE FOLLOWING LINE.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
bind 127.0.0.1
#以上--IP绑定说明，默认绑定本次127.0.0.1，可以设置绑定单个或多个IP，如果不设置，则redis表示对全部IP开放

# Protected mode is a layer of security protection, in order to avoid that
# Redis instances left open on the internet are accessed and exploited.
#
# When protected mode is on and if:
#
# 1) The server is not binding explicitly to a set of addresses using the
#    &quot;bind&quot; directive.
# 2) No password is configured.
#
# The server only accepts connections from clients connecting from the
# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain
# sockets.
#
# By default protected mode is enabled. You should disable it only if
# you are sure you want clients from other hosts to connect to Redis
# even if no authentication is configured, nor a specific set of interfaces
# are explicitly listed using the &quot;bind&quot; directive.
protected-mode yes
#以上--redis3.2版本后新增protected-mode配置，默认是yes，即开启。设置外部网络连接redis服务，设置方式如下：1、关闭protected-mode模式，此时外部网络可以直接访问；2、开启protected-mode保护模式，需配置bind ip或者设置访问密码

# Accept connections on the specified port, default is 6379 (IANA #815344).
# If port 0 is specified Redis will not listen on a TCP socket.
port 6379
#以上--redis默认端口号

# TCP listen() backlog.
#
# In high requests-per-second environments you need an high backlog in order
# to avoid slow clients connections issues. Note that the Linux kernel
# will silently truncate it to the value of /proc/sys/net/core/somaxconn so
# make sure to raise both the value of somaxconn and tcp_max_syn_backlog
# in order to get the desired effect.
tcp-backlog 511
#以上--tcp-backlog，设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog两个值来达到想要的效果

# Unix socket.
#
# Specify the path for the Unix socket that will be used to listen for
# incoming connections. There is no default, so Redis will not listen
# on a unix socket when not specified.
#
# unixsocket /tmp/redis.sock
# unixsocketperm 700
#以上--Unix socket，没有默认值，即默认不监听Unix socket

# Close the connection after a client is idle for N seconds (0 to disable)
timeout 0
#以上-timeout：指一个连接闲置多久后会被关闭，默认0，表示不关闭

# TCP keepalive.
#
# If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence
# of communication. This is useful for two reasons:
#
# 1) Detect dead peers.
# 2) Take the connection alive from the point of view of network
#    equipment in the middle.
#
# On Linux, the specified value (in seconds) is the period used to send ACKs.
# Note that to close the connection the double of the time is needed.
# On other kernels the period depends on the kernel configuration.
#
# A reasonable value for this option is 300 seconds, which is the new
# Redis default starting with Redis 3.2.1.
tcp-keepalive 300
#以上--TCP keepalive： 单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60 

################################# GENERAL #####################################

# By default Redis does not run as a daemon. Use &#39;yes&#39; if you need it.
# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.
daemonize no
#以上--daemonize：redis是否已后台进程的方式运行，默认NO

# If you run Redis from upstart or systemd, Redis can interact with your
# supervision tree. Options:
#   supervised no      - no supervision interaction
#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode
#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET
#   supervised auto    - detect upstart or systemd method based on
#                        UPSTART_JOB or NOTIFY_SOCKET environment variables
# Note: these supervision methods only signal &quot;process is ready.&quot;
#       They do not enable continuous liveness pings back to your supervisor.
supervised no
#以上--supervised：可以通过upstart和systemd管理Redis守护进程。
   #supervised no - 没有监督互动
   #supervised upstart - 通过将Redis置于SIGSTOP模式来启动信号
   #supervised systemd - signal systemd将READY = 1写入$ NOTIFY_SOCKET
   #supervised auto - 检测upstart或systemd方法基于 UPSTART_JOB或NOTIFY_SOCKET环境变量

# If a pid file is specified, Redis writes it where specified at startup
# and removes it at exit.
#
# When the server runs non daemonized, no pid file is created if none is
# specified in the configuration. When the server is daemonized, the pid file
# is used even if not specified, defaulting to &quot;/var/run/redis.pid&quot;.
#
# Creating a pid file is best effort: if Redis is not able to create it
# nothing bad happens, the server will start and run normally.
pidfile /var/run/redis_6379.pid
#以上-pidfile：配置PID文件路径，当redis作为守护进程运行的时候，它会把 pid 默认写到 /var/redis/run/redis_6379.pid 文件里面

# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
loglevel notice
#以上-loglevel：redis日志级别。  debug（记录大量日志信息，适用于开发、测试阶段）；verbose（较多日志信息）；notice（适量日志信息，使用于生产环境）；warning（仅有部分重要、关键信息才会被记录）

# Specify the log file name. Also the empty string can be used to force
# Redis to log on the standard output. Note that if you use standard
# output for logging but daemonize, logs will be sent to /dev/null
logfile &quot;&quot;
#以上--logfile:日志文件的位置，当指定为空字符串时，为标准输出，如果redis已守护进程模式运行，那么日志将会输出到/dev/null

# To enable logging to the system logger, just set &#39;syslog-enabled&#39; to yes,
# and optionally update the other syslog parameters to suit your needs.
# syslog-enabled no
#以上--syslog-enabled：要想把日志记录到系统日志，就把它改成 yes，也可以可选择性的更新其他的syslog 参数以达到你的要求

# Specify the syslog identity.
# syslog-ident redis
#以上--syslog-ident：设置系统日志的ID

# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.
# syslog-facility local0
#以上--syslog-facility：指定系统日志设置，必须是 USER 或者是 LOCAL0-LOCAL7 之间的值

# Set the number of databases. The default database is DB 0, you can select
# a different one on a per-connection basis using SELECT &lt;dbid&gt; where
# dbid is a number between 0 and &#39;databases&#39;-1
databases 16
#以上--databases：设置数据库的数目。默认的数据库是DB 0 ，可以在每个连接上使用select  &lt;dbid&gt; 命令选择一个不同的数据库，dbid是一个介于0到databases - 1 之间的数值。

################################ SNAPSHOTTING  ################################
#
# Save the DB on disk:
#
#   save &lt;seconds&gt; &lt;changes&gt;
#
#   Will save the DB if both the given number of seconds and the given
#   number of write operations against the DB occurred.
#
#   In the example below the behaviour will be to save:
#   after 900 sec (15 min) if at least 1 key changed
#   after 300 sec (5 min) if at least 10 keys changed
#   after 60 sec if at least 10000 keys changed
#
#   Note: you can disable saving completely by commenting out all &quot;save&quot; lines.
#
#   It is also possible to remove all the previously configured save
#   points by adding a save directive with a single empty string argument
#   like in the following example:
#
#   save &quot;&quot;

save 900 1
save 300 10
save 60 10000
#以上--Save the DB on disk：
    #格式：save &lt;间隔时间（秒）&gt; &lt;写入次数&gt;
    #根据给定的时间间隔和写入次数将数据保存到磁盘
    #下面的例子的意思是：
    #900 秒内如果至少有 1 个 key 的值变化，则保存
    #300 秒内如果至少有 10 个 key 的值变化，则保存
    #60 秒内如果至少有 10000 个 key 的值变化，则保存
    #注意：你可以注释掉所有的 save 行来停用保存功能。
    #也可以直接一个空字符串来实现停用：

# By default Redis will stop accepting writes if RDB snapshots are enabled
# (at least one save point) and the latest background save failed.
# This will make the user aware (in a hard way) that data is not persisting
# on disk properly, otherwise chances are that no one will notice and some
# disaster will happen.
#
# If the background saving process will start working again Redis will
# automatically allow writes again.
#
# However if you have setup your proper monitoring of the Redis server
# and persistence, you may want to disable this feature so that Redis will
# continue to work as usual even if there are problems with disk,
# permissions, and so forth.
stop-writes-on-bgsave-error yes
#以上--stop-writes-on-bgsave-error：
  #如果用户开启了RDB快照功能，那么在redis持久化数据到磁盘时如果出现失败，默认情况下，redis会停止接受所有的写请求。
  #这样做的好处在于可以让用户很明确的知道内存中的数据和磁盘上的数据已经存在不一致了。
  #如果redis不顾这种不一致，一意孤行的继续接收写请求，就可能会引起一些灾难性的后果。
  #如果下一次RDB持久化成功，redis会自动恢复接受写请求。
  #如果不在乎这种数据不一致或者有其他的手段发现和控制这种不一致的话，可以关闭这个功能，
  #以便在快照写入失败时，也能确保redis继续接受新的写请求。

# Compress string objects using LZF when dump .rdb databases?
# For default that&#39;s set to &#39;yes&#39; as it&#39;s almost always a win.
# If you want to save some CPU in the saving child set it to &#39;no&#39; but
# the dataset will likely be bigger if you have compressible values or keys.
rdbcompression yes
#以上--rdbcompression： 对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。

# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.
# This makes the format more resistant to corruption but there is a performance
# hit to pay (around 10%) when saving and loading RDB files, so you can disable it
# for maximum performances.
#
# RDB files created with checksum disabled have a checksum of zero that will
# tell the loading code to skip the check.
rdbchecksum yes
#以上--rdbchecksum：在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。

# The filename where to dump the DB
dbfilename dump.rdb
#以上--dbfilename：设置快照的文件名

# The working directory.
#
# The DB will be written inside this directory, with the filename specified
# above using the &#39;dbfilename&#39; configuration directive.
#
# The Append Only File will also be created inside this directory.
#
# Note that you must specify a directory here, not a file name.
dir ./
#以上--dir：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名

################################# REPLICATION #################################

# Master-Slave replication. Use slaveof to make a Redis instance a copy of
# another Redis server. A few things to understand ASAP about Redis replication.
#
# 1) Redis replication is asynchronous, but you can configure a master to
#    stop accepting writes if it appears to be not connected with at least
#    a given number of slaves.
# 2) Redis slaves are able to perform a partial resynchronization with the
#    master if the replication link is lost for a relatively small amount of
#    time. You may want to configure the replication backlog size (see the next
#    sections of this file) with a sensible value depending on your needs.
# 3) Replication is automatic and does not need user intervention. After a
#    network partition slaves automatically try to reconnect to masters
#    and resynchronize with them.
#
# slaveof &lt;masterip&gt; &lt;masterport&gt;
#以上--slaveof：  主从复制，使用 slaveof 来让一个 redis 实例成为另一个reids 实例的副本，默认关闭。注意这个只需要在 slave 上配置

# If the master is password protected (using the &quot;requirepass&quot; configuration
# directive below) it is possible to tell the slave to authenticate before
# starting the replication synchronization process, otherwise the master will
# refuse the slave request.
#
# masterauth &lt;master-password&gt;
#以上--masterauth：如果 master 需要密码认证，就在这里设置，默认不设置

# When a slave loses its connection with the master, or when the replication
# is still in progress, the slave can act in two different ways:
#
# 1) if slave-serve-stale-data is set to &#39;yes&#39; (the default) the slave will
#    still reply to client requests, possibly with out of date data, or the
#    data set may just be empty if this is the first synchronization.
#
# 2) if slave-serve-stale-data is set to &#39;no&#39; the slave will reply with
#    an error &quot;SYNC with master in progress&quot; to all the kind of commands
#    but to INFO and SLAVEOF.
#
slave-serve-stale-data yes
#以上--slave-serve-stale-data：
  #当一个 slave 与 master 失去联系，或者复制正在进行的时候，
  #slave 可能会有两种表现：
  #1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，
  #   或者数据可能是空的在第一次同步的时候
  #2) 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，
  #   slave 都将返回一个 &quot;SYNC with master in progress&quot; 的错误

# You can configure a slave instance to accept writes or not. Writing against
# a slave instance may be useful to store some ephemeral data (because data
# written on a slave will be easily deleted after resync with the master) but
# may also cause problems if clients are writing to it because of a
# misconfiguration.
#
# Since Redis 2.6 by default slaves are read-only.
#
# Note: read only slaves are not designed to be exposed to untrusted clients
# on the internet. It&#39;s just a protection layer against misuse of the instance.
# Still a read only slave exports by default all the administrative commands
# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve
# security of read only slaves using &#39;rename-command&#39; to shadow all the
# administrative / dangerous commands.
slave-read-only yes
#以上--slave-read-only:   
  #你可以配置一个 slave 实体是否接受写入操作。
  #通过写入操作来存储一些短暂的数据对于一个 slave 实例来说可能是有用的，
  #因为相对从 master 重新同步数而言，据数据写入到 slave 会更容易被删除。
  #但是如果客户端因为一个错误的配置写入，也可能会导致一些问题。
  #从 redis 2.6 版起，默认 slaves 都是只读的。

# Replication SYNC strategy: disk or socket.
#
# -------------------------------------------------------
# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY
# -------------------------------------------------------
#
# New slaves and reconnecting slaves that are not able to continue the replication
# process just receiving differences, need to do what is called a &quot;full
# synchronization&quot;. An RDB file is transmitted from the master to the slaves.
# The transmission can happen in two different ways:
#
# 1) Disk-backed: The Redis master creates a new process that writes the RDB
#                 file on disk. Later the file is transferred by the parent
#                 process to the slaves incrementally.
# 2) Diskless: The Redis master creates a new process that directly writes the
#              RDB file to slave sockets, without touching the disk at all.
#
# With disk-backed replication, while the RDB file is generated, more slaves
# can be queued and served with the RDB file as soon as the current child producing
# the RDB file finishes its work. With diskless replication instead once
# the transfer starts, new slaves arriving will be queued and a new transfer
# will start when the current one terminates.
#
# When diskless replication is used, the master waits a configurable amount of
# time (in seconds) before starting the transfer in the hope that multiple slaves
# will arrive and the transfer can be parallelized.
#
# With slow disks and fast (large bandwidth) networks, diskless replication
# works better.
repl-diskless-sync no
#以上--repl-diskless-sync
  #主从数据复制是否使用无硬盘复制功能。
  #新的从站和重连后不能继续备份的从站，需要做所谓的“完全备份”，即将一个RDB文件从主站传送到从站。
  #这个传送有以下两种方式：
  #1）硬盘备份：redis主站创建一个新的进程，用于把RDB文件写到硬盘上。过一会儿，其父进程递增地将文件传送给从站。
  #2）无硬盘备份：redis主站创建一个新的进程，子进程直接把RDB文件写到从站的套接字，不需要用到硬盘。
  #在硬盘备份的情况下，主站的子进程生成RDB文件。一旦生成，多个从站可以立即排成队列使用主站的RDB文件。
  #在无硬盘备份的情况下，一次RDB传送开始，新的从站到达后，需要等待现在的传送结束，才能开启新的传送。
  #如果使用无硬盘备份，主站会在开始传送之间等待一段时间（可配置，以秒为单位），希望等待多个子站到达后并行传送。
  #在硬盘低速而网络高速（高带宽）情况下，无硬盘备份更好。

# When diskless replication is enabled, it is possible to configure the delay
# the server waits in order to spawn the child that transfers the RDB via socket
# to the slaves.
#
# This is important since once the transfer starts, it is not possible to serve
# new slaves arriving, that will be queued for the next RDB transfer, so the server
# waits a delay in order to let more slaves arrive.
#
# The delay is specified in seconds, and by default is 5 seconds. To disable
# it entirely just set it to 0 seconds and the transfer will start ASAP.
repl-diskless-sync-delay 5
#以上--repl-diskless-sync-delay：
  #当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。
  #这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段
  #时间以期更多的从站到达。
  #延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动。

# Slaves send PINGs to server in a predefined interval. It&#39;s possible to change
# this interval with the repl_ping_slave_period option. The default value is 10
# seconds.
#
# repl-ping-slave-period 10
#以上--repl-ping-slave-period： 从redis会周期性的向主redis发出PING包，你可以通过repl_ping_slave_period指令来控制其周期，默认是10秒。

# The following option sets the replication timeout for:
#
# 1) Bulk transfer I/O during SYNC, from the point of view of slave.
# 2) Master timeout from the point of view of slaves (data, pings).
# 3) Slave timeout from the point of view of masters (REPLCONF ACK pings).
#
# It is important to make sure that this value is greater than the value
# specified for repl-ping-slave-period otherwise a timeout will be detected
# every time there is low traffic between the master and the slave.
#
# repl-timeout 60
#以上--repl-timeout：
  #接下来的选项为以下内容设置备份的超时时间：
  #1）从从站的角度，同步期间的批量传输的I/O
  #2）从站角度认为的主站超时（数据，ping）
  #3）主站角度认为的从站超时（REPLCONF ACK pings)
  #确认这些值比定义的repl-ping-slave-period要大，否则每次主站和从站之间通信低速时都会被检测为超时。

# Disable TCP_NODELAY on the slave socket after SYNC?
#
# If you select &quot;yes&quot; Redis will use a smaller number of TCP packets and
# less bandwidth to send data to slaves. But this can add a delay for
# the data to appear on the slave side, up to 40 milliseconds with
# Linux kernels using a default configuration.
#
# If you select &quot;no&quot; the delay for data to appear on the slave side will
# be reduced but more bandwidth will be used for replication.
#
# By default we optimize for low latency, but in very high traffic conditions
# or when the master and slaves are many hops away, turning this to &quot;yes&quot; may
# be a good idea.
repl-disable-tcp-nodelay no
#以上--repl-disable-tcp-nodelay：
  #同步之后是否禁用从站上的TCP_NODELAY
  #如果你选择yes，redis会使用较少量的TCP包和带宽向从站发送数据。但这会导致在从站增加一点数据的延时。
  #Linux内核默认配置情况下最多40毫秒的延时。
  #如果选择no，从站的数据延时不会那么多，但备份需要的带宽相对较多。
  #默认情况下我们将潜在因素优化，但在高负载情况下或者在主从站都跳的情况下，把它切换为yes是个好主意。

# Set the replication backlog size. The backlog is a buffer that accumulates
# slave data when slaves are disconnected for some time, so that when a slave
# wants to reconnect again, often a full resync is not needed, but a partial
# resync is enough, just passing the portion of data the slave missed while
# disconnected.
#
# The bigger the replication backlog, the longer the time the slave can be
# disconnected and later be able to perform a partial resynchronization.
#
# The backlog is only allocated once there is at least a slave connected.
#
# repl-backlog-size 1mb
#以上--repl-backlog-size：
  #设置备份的工作储备大小。工作储备是一个缓冲区，当从站断开一段时间的情况时，它替从站接收存储数据，
  #因此当从站重连时，通常不需要完全备份，只需要一个部分同步就可以，即把从站断开时错过的一部分数据接收。
  #工作储备越大，从站可以断开并稍后执行部分同步的断开时间就越长。
  #只要有一个从站连接，就会立刻分配一个工作储备。


# After a master has no longer connected slaves for some time, the backlog
# will be freed. The following option configures the amount of seconds that
# need to elapse, starting from the time the last slave disconnected, for
# the backlog buffer to be freed.
#
# A value of 0 means to never release the backlog.
#
# repl-backlog-ttl 3600
#以上--repl-backlog-ttl：
  #主站有一段时间没有与从站连接，对应的工作储备就会自动释放。
  #这个选项用于配置释放前等待的秒数，秒数从断开的那一刻开始计算，值为0表示不释放。

# The slave priority is an integer number published by Redis in the INFO output.
# It is used by Redis Sentinel in order to select a slave to promote into a
# master if the master is no longer working correctly.
#
# A slave with a low priority number is considered better for promotion, so
# for instance if there are three slaves with priority 10, 100, 25 Sentinel will
# pick the one with priority 10, that is the lowest.
#
# However a special priority of 0 marks the slave as not able to perform the
# role of master, so a slave with priority of 0 will never be selected by
# Redis Sentinel for promotion.
#
# By default the priority is 100.
slave-priority 100
#以上--slave-priority：
  #从站优先级是可以从redis的INFO命令输出中查到的一个整数。当主站不能正常工作时
  #redis sentinel使用它来选择一个从站并将它提升为主站。
  #优先级的从站被认为更适合于提升，因此如果有三个从站优先级分别是10，
  #100，25，sentinel会选择优先级为10的从站，因为它的优先级最低。
  #然而优先级值为0的从站不能执行主站的角色，因此优先级为0的从站永远不会被redis sentinel提升。
  #默认优先级是100

# It is possible for a master to stop accepting writes if there are less than
# N slaves connected, having a lag less or equal than M seconds.
#
# The N slaves need to be in &quot;online&quot; state.
#
# The lag in seconds, that must be &lt;= the specified value, is calculated from
# the last ping received from the slave, that is usually sent every second.
#
# This option does not GUARANTEE that N replicas will accept the write, but
# will limit the window of exposure for lost writes in case not enough slaves
# are available, to the specified number of seconds.
#
# For example to require at least 3 slaves with a lag &lt;= 10 seconds use:
#
# min-slaves-to-write 3
# min-slaves-max-lag 10
#
# Setting one or the other to 0 disables the feature.
#
# By default min-slaves-to-write is set to 0 (feature disabled) and
# min-slaves-max-lag is set to 10.
#以上
  #主站可以停止接受写请求，当与它连接的从站少于N个，滞后少于M秒，N个从站必须是在线状态。
  #延迟的秒数必须&lt;=所定义的值，延迟秒数是从最后一次收到的来自从站的ping开始计算。ping通常是每秒一次。
  #这一选项并不保证N个备份都会接受写请求，但是会限制在指定秒数内由于从站数量不够导致的写操作丢失的情况。
  #如果想要至少3个从站且延迟少于10秒，如上配置即可

# A Redis master is able to list the address and port of the attached
# slaves in different ways. For example the &quot;INFO replication&quot; section
# offers this information, which is used, among other tools, by
# Redis Sentinel in order to discover slave instances.
# Another place where this info is available is in the output of the
# &quot;ROLE&quot; command of a masteer.
#
# The listed IP and address normally reported by a slave is obtained
# in the following way:
#
#   IP: The address is auto detected by checking the peer address
#   of the socket used by the slave to connect with the master.
#
#   Port: The port is communicated by the slave during the replication
#   handshake, and is normally the port that the slave is using to
#   list for connections.
#
# However when port forwarding or Network Address Translation (NAT) is
# used, the slave may be actually reachable via different IP and port
# pairs. The following two options can be used by a slave in order to
# report to its master a specific set of IP and port, so that both INFO
# and ROLE will report those values.
#
# There is no need to use both the options if you need to override just
# the port or the IP address.
#
# slave-announce-ip 5.5.5.5
# slave-announce-port 1234
#以上--
 #Redis master能够以不同的方式列出所连接slave的地址和端口。
 #例如，“INFO replication”部分提供此信息，除了其他工具之外，Redis Sentinel还使用该信息来发现slave实例。
 #此信息可用的另一个地方在masterser的“ROLE”命令的输出中。
 #通常由slave报告的列出的IP和地址,通过以下方式获得：
 #IP：通过检查slave与master连接使用的套接字的对等体地址自动检测地址。
 #端口：端口在复制握手期间由slavet通信，并且通常是slave正在使用列出连接的端口。
 #然而，当使用端口转发或网络地址转换（NAT）时，slave实际上可以通过(不同的IP和端口对)来到达。 slave可以使用以下两个选项，以便向master报告一组特定的IP和端口，
 #以便INFO和ROLE将报告这些值。
 #如果你需要仅覆盖端口或IP地址，则没必要使用这两个选项。


################################## SECURITY ###################################

# Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other
# commands.  This might be useful in environments in which you do not trust
# others with access to the host running redis-server.
#
# This should stay commented out for backward compatibility and because most
# people do not need auth (e.g. they run their own servers).
#
# Warning: since Redis is pretty fast an outside user can try up to
# 150k passwords per second against a good box. This means that you should
# use a very strong password otherwise it will be very easy to break.
#
# requirepass foobared
#以上--requirepass：设置redis连接密码

# Command renaming.
#
# It is possible to change the name of dangerous commands in a shared
# environment. For instance the CONFIG command may be renamed into something
# hard to guess so that it will still be available for internal-use tools
# but not available for general clients.
#
# Example:
#
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#
# It is also possible to completely kill a command by renaming it into
# an empty string:
#
# rename-command CONFIG &quot;&quot;
#
# Please note that changing the name of commands that are logged into the
# AOF file or transmitted to slaves may cause problems.
#以上--rename-command CONFIG： 将命令重命名，为了安全考虑，可以将某些重要的、危险的命令重命名。当你把某个命令重命名成空字符串的时候就等于取消了这个命令。

################################### LIMITS ####################################

# Set the max number of connected clients at the same time. By default
# this limit is set to 10000 clients, however if the Redis server is not
# able to configure the process file limit to allow for the specified limit
# the max number of allowed clients is set to the current file limit
# minus 32 (as Redis reserves a few file descriptors for internal uses).
#
# Once the limit is reached Redis will close all the new connections sending
# an error &#39;max number of clients reached&#39;.
#
# maxclients 10000
#以上--maxclients：
  #设置客户端最大并发连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件
  #描述符数-32（redis server自身会使用一些），如果设置 maxclients为0
  #表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息

# Don&#39;t use more memory than the specified amount of bytes.
# When the memory limit is reached Redis will try to remove keys
# according to the eviction policy selected (see maxmemory-policy).
#
# If Redis can&#39;t remove keys according to the policy, or if the policy is
# set to &#39;noeviction&#39;, Redis will start to reply with errors to commands
# that would use more memory, like SET, LPUSH, and so on, and will continue
# to reply to read-only commands like GET.
#
# This option is usually useful when using Redis as an LRU cache, or to set
# a hard memory limit for an instance (using the &#39;noeviction&#39; policy).
#
# WARNING: If you have slaves attached to an instance with maxmemory on,
# the size of the output buffers needed to feed the slaves are subtracted
# from the used memory count, so that network problems / resyncs will
# not trigger a loop where keys are evicted, and in turn the output
# buffer of slaves is full with DELs of keys evicted triggering the deletion
# of more keys, and so forth until the database is completely emptied.
#
# In short... if you have slaves attached it is suggested that you set a lower
# limit for maxmemory so that there is some free RAM on the system for slave
# output buffers (but this is not needed if the policy is &#39;noeviction&#39;).
#
# maxmemory &lt;bytes&gt;
#以上--maxmemory：
  #指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key
  #当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，
  #会把Key存放内存，Value会存放在swap区，格式：maxmemory &lt;bytes&gt;

# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory
# is reached. You can select among five behaviors:
#
# volatile-lru -&gt; remove the key with an expire set using an LRU algorithm
# allkeys-lru -&gt; remove any key according to the LRU algorithm
# volatile-random -&gt; remove a random key with an expire set
# allkeys-random -&gt; remove a random key, any key
# volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)
# noeviction -&gt; don&#39;t expire at all, just return an error on write operations
#
# Note: with any of the above policies, Redis will return an error on write
#       operations, when there are no suitable keys for eviction.
#
#       At the date of writing these commands are: set setnx setex append
#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
#       getset mset msetnx exec sort
#
# The default is:
#
# maxmemory-policy noeviction
#以上--maxmemory-policy：
  #当内存使用达到最大值时，redis使用的清楚策略。有以下几种可以选择：
  #1）volatile-lru   利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used )
  #2）allkeys-lru   利用LRU算法移除任何key
  #3）volatile-random 移除设置过过期时间的随机key
  #4）allkeys-random  移除随机ke
  #5）volatile-ttl   移除即将过期的key(minor TTL)
  #6）noeviction  noeviction   不移除任何key，只是返回一个写错误 ，默认选项


# LRU and minimal TTL algorithms are not precise algorithms but approximated
# algorithms (in order to save memory), so you can tune it for speed or
# accuracy. For default Redis will check five keys and pick the one that was
# used less recently, you can change the sample size using the following
# configuration directive.
#
# The default of 5 produces good enough results. 10 Approximates very closely
# true LRU but costs a bit more CPU. 3 is very fast but not very accurate.
#
# maxmemory-samples 5
#以上--maxmemory-samples：LRU 和 minimal TTL 算法都不是精准的算法，但是相对精确的算法(为了节省内存)；随意你可以选择样本大小进行检，redis默认选择3个样本进行检测，你可以通过maxmemory-samples进行设置样本数


############################## APPEND ONLY MODE ###############################

# By default Redis asynchronously dumps the dataset on disk. This mode is
# good enough in many applications, but an issue with the Redis process or
# a power outage may result into a few minutes of writes lost (depending on
# the configured save points).
#
# The Append Only File is an alternative persistence mode that provides
# much better durability. For instance using the default data fsync policy
# (see later in the config file) Redis can lose just one second of writes in a
# dramatic event like a server power outage, or a single write if something
# wrong with the Redis process itself happens, but the operating system is
# still running correctly.
#
# AOF and RDB persistence can be enabled at the same time without problems.
# If the AOF is enabled on startup Redis will load the AOF, that is the file
# with the better durability guarantees.
#
# Please check http://redis.io/topics/persistence for more information.

appendonly no
#以上--appendonly：
  #默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，
  #会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，
  #可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入appendonly.aof文件，
  #每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。

# The name of the append only file (default: &quot;appendonly.aof&quot;)

appendfilename &quot;appendonly.aof&quot;
#以上--appendfilename：aof文件名

# The fsync() call tells the Operating System to actually write data on disk
# instead of waiting for more data in the output buffer. Some OS will really flush
# data on disk, some other OS will just try to do it ASAP.
#
# Redis supports three different modes:
#
# no: don&#39;t fsync, just let the OS flush the data when it wants. Faster.
# always: fsync after every write to the append only log. Slow, Safest.
# everysec: fsync only one time every second. Compromise.
#
# The default is &quot;everysec&quot;, as that&#39;s usually the right compromise between
# speed and data safety. It&#39;s up to you to understand if you can relax this to
# &quot;no&quot; that will let the operating system flush the output buffer when
# it wants, for better performances (but if you can live with the idea of
# some data loss consider the default persistence mode that&#39;s snapshotting),
# or on the contrary, use &quot;always&quot; that&#39;s very slow but a bit safer than
# everysec.
#
# More details please check the following article:
# http://antirez.com/post/redis-persistence-demystified.html
#
# If unsure, use &quot;everysec&quot;.

# appendfsync always
appendfsync everysec
# appendfsync no
#以上--
  #aof持久化策略的配置
  #no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。
  #always表示每次写入都执行fsync，以保证数据同步到磁盘。
  #everysec表示每秒执行一次fsync，可能会导致丢失这1s数据

# When the AOF fsync policy is set to always or everysec, and a background
# saving process (a background save or AOF log background rewriting) is
# performing a lot of I/O against the disk, in some Linux configurations
# Redis may block too long on the fsync() call. Note that there is no fix for
# this currently, as even performing fsync in a different thread will block
# our synchronous write(2) call.
#
# In order to mitigate this problem it&#39;s possible to use the following option
# that will prevent fsync() from being called in the main process while a
# BGSAVE or BGREWRITEAOF is in progress.
#
# This means that while another child is saving, the durability of Redis is
# the same as &quot;appendfsync none&quot;. In practical terms, this means that it is
# possible to lose up to 30 seconds of log in the worst scenario (with the
# default Linux settings).
#
# If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as
# &quot;no&quot; that is the safest pick from the point of view of durability.

no-appendfsync-on-rewrite no
#以上--no-appendfsync-on-rewrite：
   #在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，
   #执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。
   #如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。
   #设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。
   #Linux的默认fsync策略是30秒。可能丢失30秒数据。

# Automatic rewrite of the append only file.
# Redis is able to automatically rewrite the log file implicitly calling
# BGREWRITEAOF when the AOF log size grows by the specified percentage.
#
# This is how it works: Redis remembers the size of the AOF file after the
# latest rewrite (if no rewrite has happened since the restart, the size of
# the AOF at startup is used).
#
# This base size is compared to the current size. If the current size is
# bigger than the specified percentage, the rewrite is triggered. Also
# you need to specify a minimal size for the AOF file to be rewritten, this
# is useful to avoid rewriting the AOF file even if the percentage increase
# is reached but it is still pretty small.
#
# Specify a percentage of zero in order to disable the automatic AOF
# rewrite feature.

auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
#以上--
  #aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，
  #即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。
  #当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。
  #设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写

# An AOF file may be found to be truncated at the end during the Redis
# startup process, when the AOF data gets loaded back into memory.
# This may happen when the system where Redis is running
# crashes, especially when an ext4 filesystem is mounted without the
# data=ordered option (however this can&#39;t happen when Redis itself
# crashes or aborts but the operating system still works correctly).
#
# Redis can either exit with an error when this happens, or load as much
# data as possible (the default now) and start if the AOF file is found
# to be truncated at the end. The following option controls this behavior.
#
# If aof-load-truncated is set to yes, a truncated AOF file is loaded and
# the Redis server starts emitting a log to inform the user of the event.
# Otherwise if the option is set to no, the server aborts with an error
# and refuses to start. When the option is set to no, the user requires
# to fix the AOF file using the &quot;redis-check-aof&quot; utility before to restart
# the server.
#
# Note that if the AOF file will be found to be corrupted in the middle
# the server will still exit with an error. This option only applies when
# Redis will try to read more data from the AOF file but not enough bytes
# will be found.
aof-load-truncated yes
#以上--aof-load-truncated：
  #aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。
  #重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项，出现这种现象
  #redis宕机或者异常终止不会造成尾部不完整现象，可以选择让redis退出，或者导入尽可能多的数据。
  #如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。
  #如果是no，用户必须手动redis-check-aof修复AOF文件才可以。

################################ LUA SCRIPTING  ###############################

# Max execution time of a Lua script in milliseconds.
#
# If the maximum execution time is reached Redis will log that a script is
# still in execution after the maximum allowed time and will start to
# reply to queries with an error.
#
# When a long running script exceeds the maximum execution time only the
# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be
# used to stop a script that did not yet called write commands. The second
# is the only way to shut down the server in the case a write command was
# already issued by the script but the user doesn&#39;t want to wait for the natural
# termination of the script.
#
# Set it to 0 or a negative value for unlimited execution without warnings.
lua-time-limit 5000
#以上--lua-time-limit：
  #如果达到最大时间限制（毫秒），redis会记个log，然后返回error。当一个脚本超过了最大时限。
  #只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write命令的东西。
  #要是已经调用了write，只能用第二个命令杀
  
################################ REDIS CLUSTER  ###############################
#
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however
# in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage
# of users to deploy it in production.
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#
# Normal Redis instances can&#39;t be part of a Redis Cluster; only nodes that are
# started as cluster nodes can. In order to start a Redis instance as a
# cluster node enable the cluster support uncommenting the following:
#
# cluster-enabled yes
#以上--cluster-enabled：集群开关，默认是不开启集群模式


# Every cluster node has a cluster configuration file. This file is not
# intended to be edited by hand. It is created and updated by Redis nodes.
# Every Redis Cluster node requires a different cluster configuration file.
# Make sure that instances running in the same system do not have
# overlapping cluster configuration file names.
#
# cluster-config-file nodes-6379.conf
#以上--cluster-config-file
 #集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。
 #这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件
 #请确保与实例运行的系统中配置文件名称不冲突


# Cluster node timeout is the amount of milliseconds a node must be unreachable
# for it to be considered in failure state.
# Most other internal time limits are multiple of the node timeout.
#
# cluster-node-timeout 15000
#以上--cluster-node-timeou： 节点互连超时的阀值，集群节点超时毫秒数



# A slave of a failing master will avoid to start a failover if its data
# looks too old.
#
# There is no simple way for a slave to actually have a exact measure of
# its &quot;data age&quot;, so the following two checks are performed:
#
# 1) If there are multiple slaves able to failover, they exchange messages
#    in order to try to give an advantage to the slave with the best
#    replication offset (more data from the master processed).
#    Slaves will try to get their rank by offset, and apply to the start
#    of the failover a delay proportional to their rank.
#
# 2) Every single slave computes the time of the last interaction with
#    its master. This can be the last ping or command received (if the master
#    is still in the &quot;connected&quot; state), or the time that elapsed since the
#    disconnection with the master (if the replication link is currently down).
#    If the last interaction is too old, the slave will not try to failover
#    at all.
#
# The point &quot;2&quot; can be tuned by user. Specifically a slave will not perform
# the failover if, since the last interaction with the master, the time
# elapsed is greater than:
#
#   (node-timeout * slave-validity-factor) + repl-ping-slave-period
#
# So for example if node-timeout is 30 seconds, and the slave-validity-factor
# is 10, and assuming a default repl-ping-slave-period of 10 seconds, the
# slave will not try to failover if it was not able to talk with the master
# for longer than 310 seconds.
#
# A large slave-validity-factor may allow slaves with too old data to failover
# a master, while a too small value may prevent the cluster from being able to
# elect a slave at all.
#
# For maximum availability, it is possible to set the slave-validity-factor
# to a value of 0, which means, that slaves will always try to failover the
# master regardless of the last time they interacted with the master.
# (However they&#39;ll always try to apply a delay proportional to their
# offset rank).
#
# Zero is the only value able to guarantee that when all the partitions heal
# the cluster will always be able to continue.
#
# cluster-slave-validity-factor 10
#以上--cluster-slave-validity-factor：
  #在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，
  #导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。
  #判断方法是：
  #   比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period
  #   如果节点超时时间为三十秒, 并且slave-validity-factor为10,
  #   假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移

# Cluster slaves are able to migrate to orphaned masters, that are masters
# that are left without working slaves. This improves the cluster ability
# to resist to failures as otherwise an orphaned master can&#39;t be failed over
# in case of failure if it has no working slaves.
#
# Slaves migrate to orphaned masters only if there are still at least a
# given number of other working slaves for their old master. This number
# is the &quot;migration barrier&quot;. A migration barrier of 1 means that a slave
# will migrate only if there is at least 1 other working slave for its master
# and so forth. It usually reflects the number of slaves you want for every
# master in your cluster.
#
# Default is 1 (slaves migrate only if their masters remain with at least
# one slave). To disable migration just set it to a very large value.
# A value of 0 can be set but is useful only for debugging and dangerous
# in production.
#
# cluster-migration-barrier 1
#以上--cluster-migration-barrier：
  #master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，
  #那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。

# By default Redis Cluster nodes stop accepting queries if they detect there
# is at least an hash slot uncovered (no available node is serving it).
# This way if the cluster is partially down (for example a range of hash slots
# are no longer covered) all the cluster becomes, eventually, unavailable.
# It automatically returns available as soon as all the slots are covered again.
#
# However sometimes you want the subset of the cluster which is working,
# to continue to accept queries for the part of the key space that is still
# covered. In order to do so, just set the cluster-require-full-coverage
# option to no.
#
# cluster-require-full-coverage yes
#以上--cluster-require-full-coverage：
  #默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。
  #设置为no，可以在slot没有全部分配的时候提供服务。
  #不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致

# In order to setup your cluster make sure to read the documentation
# available at http://redis.io web site. 

################################## SLOW LOG ###################################

# The Redis Slow Log is a system to log queries that exceeded a specified
# execution time. The execution time does not include the I/O operations
# like talking with the client, sending the reply and so forth,
# but just the time needed to actually execute the command (this is the only
# stage of command execution where the thread is blocked and can not serve
# other requests in the meantime).
#
# You can configure the slow log with two parameters: one tells Redis
# what is the execution time, in microseconds, to exceed in order for the
# command to get logged, and the other parameter is the length of the
# slow log. When a new command is logged the oldest one is removed from the
# queue of logged commands.

# The following time is expressed in microseconds, so 1000000 is equivalent
# to one second. Note that a negative number disables the slow log, while
# a value of zero forces the logging of every command.
slowlog-log-slower-than 10000

# There is no limit to this length. Just be aware that it will consume memory.
# You can reclaim memory used by the slow log with SLOWLOG RESET.
slowlog-max-len 128
#以上--slowlog-log-slower-than： 慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉，这个长度没有限制。只要有足够的内存就行，你可以通过 SLOWLOG RESET 来释放内存

################################ LATENCY MONITOR ##############################

# The Redis latency monitoring subsystem samples different operations
# at runtime in order to collect data related to possible sources of
# latency of a Redis instance.
#
# Via the LATENCY command this information is available to the user that can
# print graphs and obtain reports.
#
# The system only logs operations that were performed in a time equal or
# greater than the amount of milliseconds specified via the
# latency-monitor-threshold configuration directive. When its value is set
# to zero, the latency monitor is turned off.
#
# By default latency monitoring is disabled since it is mostly not needed
# if you don&#39;t have latency issues, and collecting data has a performance
# impact, that while very small, can be measured under big load. Latency
# monitoring can easily be enabled at runtime using the command
# &quot;CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;&quot; if needed.
latency-monitor-threshold 0
#以上-latency-monitor-threshold:
  #延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。
  #只记录大于等于下边设置的值的操作，0的话，就是关闭监视。
  #默认延迟监控功能是关闭的，如果你需要打开，也可以通过CONFIG SET命令动态设置。

############################# EVENT NOTIFICATION ##############################

# Redis can notify Pub/Sub clients about events happening in the key space.
# This feature is documented at http://redis.io/topics/notifications
#
# For instance if keyspace events notification is enabled, and a client
# performs a DEL operation on key &quot;foo&quot; stored in the Database 0, two
# messages will be published via Pub/Sub:
#
# PUBLISH __keyspace@0__:foo del
# PUBLISH __keyevent@0__:del foo
#
# It is possible to select the events that Redis will notify among a set
# of classes. Every class is identified by a single character:
#
#  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.
#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.
#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...
#  $     String commands
#  l     List commands
#  s     Set commands
#  h     Hash commands
#  z     Sorted set commands
#  x     Expired events (events generated every time a key expires)
#  e     Evicted events (events generated when a key is evicted for maxmemory)
#  A     Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.
#
#  The &quot;notify-keyspace-events&quot; takes as argument a string that is composed
#  of zero or multiple characters. The empty string means that notifications
#  are disabled.
#
#  Example: to enable list and generic events, from the point of view of the
#           event name, use:
#
#  notify-keyspace-events Elg
#
#  Example 2: to get the stream of the expired keys subscribing to channel
#             name __keyevent@0__:expired use:
#
#  notify-keyspace-events Ex
#
#  By default all notifications are disabled because most users don&#39;t need
#  this feature and the feature has some overhead. Note that if you don&#39;t
#  specify at least one of K or E, no events will be delivered.
notify-keyspace-events &quot;&quot;
#以上--notify-keyspace-events &quot;&quot;：
键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。
 #notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：
 # K 键空间通知，所有通知以 __keyspace@__ 为前缀
 # E 键事件通知，所有通知以 __keyevent@__ 为前缀
 # g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知
 # $ 字符串命令的通知
 # l 列表命令的通知
 # s 集合命令的通知
 # h 哈希命令的通知
 # z 有序集合命令的通知
 # x 过期事件：每当有过期键被删除时发送
 # e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送
 # A 参数 g$lshzxe 的别名
 #输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。

############################### ADVANCED CONFIG ###############################

# Hashes are encoded using a memory efficient data structure when they have a
# small number of entries, and the biggest entry does not exceed a given
# threshold. These thresholds can be configured using the following directives.
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
#以上--hash-max-ziplist-entries：
 #hash类型的数据结构在编码上可以使用ziplist和hashtable。
 #ziplist的特点就是文件存储(以及内存存储)所需的空间较小,在内容较小时,性能和hashtable几乎一样。
 #因此redis对hash类型默认采取ziplist。如果hash中条目的条目个数或者value长度达到阀值,将会被重构为hashtable。
 #这个参数指的是ziplist中允许存储的最大条目个数，，默认为512，建议为128
#以上--hash-max-ziplist-value：ziplist中允许条目value值最大字节数，默认为64，建议为1024

# Lists are also encoded in a special way to save a lot of space.
# The number of entries allowed per internal list node can be specified
# as a fixed maximum size or a maximum number of elements.
# For a fixed maximum size, use -5 through -1, meaning:
# -5: max size: 64 Kb  &lt;-- not recommended for normal workloads
# -4: max size: 32 Kb  &lt;-- not recommended
# -3: max size: 16 Kb  &lt;-- probably not recommended
# -2: max size: 8 Kb   &lt;-- good
# -1: max size: 4 Kb   &lt;-- good
# Positive numbers mean store up to _exactly_ that number of elements
# per list node.
# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),
# but if your use case is unique, adjust the settings as necessary.
list-max-ziplist-size -2
#以上--list-max-ziplist-size:
    #当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。
    #当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值，每个值含义如下：
    #    -5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =&gt; 1024 bytes）
    #    -4: 每个quicklist节点上的ziplist大小不能超过32 Kb。
    #    -3: 每个quicklist节点上的ziplist大小不能超过16 Kb。
    #    -2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值）
    #    -1: 每个quicklist节点上的ziplist大小不能超过4 Kb。

# Lists may also be compressed.
# Compress depth is the number of quicklist ziplist nodes from *each* side of
# the list to *exclude* from compression.  The head and tail of the list
# are always uncompressed for fast push/pop operations.  Settings are:
# 0: disable all list compression
# 1: depth 1 means &quot;don&#39;t start compressing until after 1 node into the list,
#    going from either the head or tail&quot;
#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]
#    [head], [tail] will always be uncompressed; inner nodes will compress.
# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]
#    2 here means: don&#39;t compress head or head-&gt;next or tail-&gt;prev or tail,
#    but compress all nodes between them.
# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]
# etc.
list-compress-depth 0
#以上--list-compress-depth:
    #这个参数表示一个quicklist两端不被压缩的节点个数。
    #注：这里的节点个数是指quicklist双向链表的节点个数，而不是指ziplist里面的数据项个数。
    #实际上，一个quicklist节点上的ziplist，如果被压缩，就是整体被压缩的。
    #参数list-compress-depth的取值含义如下：
    #    0: 是个特殊值，表示都不压缩。这是Redis的默认值。
    #    1: 表示quicklist两端各有1个节点不压缩，中间的节点压缩。
    #    2: 表示quicklist两端各有2个节点不压缩，中间的节点压缩。
    #    3: 表示quicklist两端各有3个节点不压缩，中间的节点压缩。
    #    依此类推…
    #由于0是个特殊值，很容易看出quicklist的头节点和尾节点总是不被压缩的，以便于在表的两端进行快速存取。

# Sets have a special encoding in just one case: when a set is composed
# of just strings that happen to be integers in radix 10 in the range
# of 64 bit signed integers.
# The following configuration setting sets the limit in the size of the
# set in order to use this special memory saving encoding.
set-max-intset-entries 512
#以上--set-max-intset-entries： 数据量小于等于set-max-intset-entries用intset，大于set-max-intset-entries用set

# Similarly to hashes and lists, sorted sets are also specially encoded in
# order to save a lot of space. This encoding is only used when the length and
# elements of a sorted set are below the following limits:
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
#以上--：数据量小于等于zset-max-ziplist-entries用ziplist，大于zset-max-ziplist-entries用zset

# HyperLogLog sparse representation bytes limit. The limit includes the
# 16 bytes header. When an HyperLogLog using the sparse representation crosses
# this limit, it is converted into the dense representation.
#
# A value greater than 16000 is totally useless, since at that point the
# dense representation is more memory efficient.
#
# The suggested value is ~ 3000 in order to have the benefits of
# the space efficient encoding without slowing down too much PFADD,
# which is O(N) with the sparse encoding. The value can be raised to
# ~ 10000 when CPU is not a concern, but space is, and the data set is
# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.
hll-sparse-max-bytes 3000
#以上--hll-sparse-max-bytes:
  #value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse）
  #大于hll-sparse-max-bytes使用稠密的数据结构（dense），一个比16000大的value是几乎没用的，
  #建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右

# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in
# order to help rehashing the main Redis hash table (the one mapping top-level
# keys to values). The hash table implementation Redis uses (see dict.c)
# performs a lazy rehashing: the more operation you run into a hash table
# that is rehashing, the more rehashing &quot;steps&quot; are performed, so if the
# server is idle the rehashing is never complete and some more memory is used
# by the hash table.
#
# The default is to use this millisecond 10 times every second in order to
# actively rehash the main dictionaries, freeing memory when possible.
#
# If unsure:
# use &quot;activerehashing no&quot; if you have hard latency requirements and it is
# not a good thing in your environment that Redis can reply from time to time
# to queries with 2 milliseconds delay.
#
# use &quot;activerehashing yes&quot; if you don&#39;t have such hard requirements but
# want to free memory asap when possible.
activerehashing yes
#以上--activerehashing：
  #Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。
  #当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。
  #如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存

# The client output buffer limits can be used to force disconnection of clients
# that are not reading data from the server fast enough for some reason (a
# common reason is that a Pub/Sub client can&#39;t consume messages as fast as the
# publisher can produce them).
#
# The limit can be set differently for the three different classes of clients:
#
# normal -&gt; normal clients including MONITOR clients
# slave  -&gt; slave clients
# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern
#
# The syntax of every client-output-buffer-limit directive is the following:
#
# client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;
#
# A client is immediately disconnected once the hard limit is reached, or if
# the soft limit is reached and remains reached for the specified number of
# seconds (continuously).
# So for instance if the hard limit is 32 megabytes and the soft limit is
# 16 megabytes / 10 seconds, the client will get disconnected immediately
# if the size of the output buffers reach 32 megabytes, but will also get
# disconnected if the client reaches 16 megabytes and continuously overcomes
# the limit for 10 seconds.
#
# By default normal clients are not limited because they don&#39;t receive data
# without asking (in a push way), but just after a request, so only
# asynchronous clients may create a scenario where data is requested faster
# than it can read.
#
# Instead there is a default limit for pubsub and slave clients, since
# subscribers and slaves receive data in a push fashion.
#
# Both the hard or the soft limit can be disabled by setting them to zero.
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit slave 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
#以上--client-output-buffer-limit normal：
 #对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。
 #对于normal client，第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的
#以上--client-output-buffer-limit slave：对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接。
#以上--client-output-buffer-limit pubsub：对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接

# Redis calls an internal function to perform many background tasks, like
# closing connections of clients in timeout, purging expired keys that are
# never requested, and so forth.
#
# Not all tasks are performed with the same frequency, but Redis checks for
# tasks to perform according to the specified &quot;hz&quot; value.
#
# By default &quot;hz&quot; is set to 10. Raising the value will use more CPU when
# Redis is idle, but at the same time will make Redis more responsive when
# there are many keys expiring at the same time, and timeouts may be
# handled with more precision.
#
# The range is between 1 and 500, however a value over 100 is usually not
# a good idea. Most users should use the default of 10 and raise this up to
# 100 only in environments where very low latency is required.
hz 10
#以上--hz ：redis执行任务的频率为1s除以hz

# When a child rewrites the AOF file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
aof-rewrite-incremental-fsync yes
#以上--aof-rewrite-incremental-fsync：
  #在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。
  #这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[redis.conf 详解]]></title>
    <link href="http://www.throne4j.com/15991181642194.html"/>
    <updated>2020-09-03T15:29:24+08:00</updated>
    <id>http://www.throne4j.com/15991181642194.html</id>
    <content type="html"><![CDATA[
<pre><code class="language-text">#以上--redis启动说明：redis启动指令的第一个参数必须是配置文件路径
# ./redis-server /path/to/redis.conf

# 引入配置，可以将公共配置抽取出来，采用引入的方式，存在参数覆盖，注意include放置的位置，覆盖效果不同。
# include /path/to/local.conf

################################## MODULES #####################################

# 启动时加载so模块，如果服务不能加载指定模块
# 服务器将忽略该模块
# loadmodule /path/to/my_module.so
# loadmodule /path/to/other_module.so

################################## NETWORK #####################################
# 
# 如果，bind没有特别指定，redis可以接受任意可访问到该服务IP的请求，
# 一般来说，只可能只监听一个或者多个IP的请求，不要完全开放。
#
#  ~~~ 注意 ~~~ 如果redis服务是运行在互联网可访问的环境下，暴露任意IP可访问是相当危险的。
# 所以，默认情况下，我们只开放127.0.0.1的可访问IP，那就意味着只有本地才能访问redis服务。
#
# 如果你非要开放，你就需要注释下面这段配置。
bind 127.0.0.1


# 保护模式是一个避免redis暴露在公网后可以任意访问的安全层。 
#
# 当在如下条件下，保护模式将开启：
# 1.服务没有明确绑定具体IP
# 2.服务没有配置密码
#
# 保护模式开启后，服务只能接受ipv4/v6的环路路由，或者unix socket。
#
# 默认情况下，保护模式是开启的，如果你确信要让客户端可以不需要密码访问
# redis服务，或者不明确bindIP的化，可以关闭保护模式。
protected-mode yes

# 监听端口
port 6379

# TCP listen() backlog.
# backlog其实是一个连接监听队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。
# 在高并发的redis访问场景下，你需要提高tcp的监听队列大小，来避免慢客户端连接问题，否则将出现tcp连接耗尽问题
# 同时修改此处配置的时候，也要一并修改linux的系统参数/proc/sys/net/core/somaxconn
# 否则不生效。somaxconn &gt;= tcp-backlog
tcp-backlog 511

# Unix socket.
#
# redis采用unix socket作为客户端的数据传输通道，据说可以提高25%的性能，但是只能用于本机进程间通信，
# 用处不大
# 默认不开启
# unixsocket /tmp/redis.sock
# unixsocketperm 700


# Close the connection after a client is idle for N seconds (0 to disable)

# 客户端连接空闲后自动关闭的等待时间，0表示不关闭。 
timeout 0

# TCP keepalive， tcp长连接
# 如果非0，redis的tcp连接将在长时间未通信的情况下发送心跳包给客户端
# 这样做有两个好处:
# 1.回收已断开的连接
# 2.在存在网络中间件，比如路由器，网关的条件下，保证连接的可用
# 在Linux系统中，这个数值标识TCP发送心跳包的时间间隔，在两次发送心跳包无响应时，将废弃该连接
# 在其他系统，可能有Kernels的内核参数决定心跳包时间，该参数无效。
tcp-keepalive 300

################################# GENERAL #####################################

# 默认情况下，redis不在后台运行，如果你需要后台静默运行，设置为yes.
# 后台运行的状态，redis将pid写入/var/run/redis.pid 文件
daemonize yes

# 如果redis是通过upstart或者systemd开机自启动，你可以将redis的运行状态，写入开机启动服务的状态数中
# 有四种选择
#   supervised no      - no supervision interaction
#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode
#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET
#   supervised auto    - detect upstart or systemd method based on
#                        UPSTART_JOB or NOTIFY_SOCKET environment variables
# 注意：redis在开机启动树只有“运行中”这样的状态，没有是否可联通的状态，
# `个人理解:这块做关联启动，有些开机启动服务需要依赖redis的启动，所以增加这个配置`
supervised no


# 如果pid文件有显式指定，redis在启动后，写入进程号，退出时，删除文件
# 当服务是非后台模式运行时，如果没有指定pid文件，redis将不会创建该文件，当服务是后台模式运行时，
# 即使没有指定pid文件，redis也会创建该文件，同时默认值为&quot;/var/run/redis.pid&quot;
# 创建pid是将会对redis的管理有好处，但是不创建也不会对redis运行有影响。
pidfile /var/run/redis_6379.pid

# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
# 日志级别
loglevel notice

# 指定日志文件的名称，如果是空字符串，redis的日志将写入Linux的标准输出，
# 如果redis是后台模式运行，日志文件为&quot;&quot;,日志将输出到/dev/null，也就是不输出日志
logfile &quot;&quot;


# 要想把日志记录到系统日志，就把它改成 yes，也可以可选择性的更新其他的syslog 参数以达到你的要求
# syslog-enabled no


# Specify the syslog identity.
# 系统日志的标识
# syslog-ident redis


# 产生系统日志的设施，必须是Linux的用户或者从local0 ~ local7
# syslog-facility local0

# 设置数据库的数目。默认的数据库是DB 0 ，可以在每个连接上使用select  &lt;dbid&gt; 命令选择一个不同的数据库，dbid是一个介于0到databases - 1 之间的数值
databases 16

#  控制台显示LOGO
always-show-logo yes

################################ SNAPSHOTTING  ################################
#
# Save the DB on disk:
#
#   save &lt;seconds&gt; &lt;changes&gt;
#
# 格式：save &lt;间隔时间（秒）&gt; &lt;写入次数&gt;
# 根据给定的时间间隔和写入次数将数据保存到磁盘
# 下面的例子的意思是：
# 900 秒内如果至少有 1 个 key 的值变化，则保存
# 300 秒内如果至少有 10 个 key 的值变化，则保存
# 60 秒内如果至少有 10000 个 key 的值变化，则保存
# 注意：你可以注释掉所有的 save 行来停用保存功能。
# 也可以直接一个空字符串来实现停用：
#  数据的持久化的规则

save 900 1
save 300 10
save 60 10000

# 如果用户开启了RDB快照功能，那么在redis持久化数据到磁盘时如果出现失败，默认情况下，redis会停止接受所有的写请求。
# 这样做的好处在于可以让用户很明确的知道内存中的数据和磁盘上的数据已经存在不一致了。
# 如果redis不顾这种不一致，一意孤行的继续接收写请求，就可能会引起一些灾难性的后果。
# 如果下一次RDB持久化成功，redis会自动恢复接受写请求。
# 如果不在乎这种数据不一致或者有其他的手段发现和控制这种不一致的话，可以关闭这个功能，
# 以便在快照写入失败时，也能确保redis继续接受新的写请求。
stop-writes-on-bgsave-error yes


# dump.rdb数据库采用LZF算法进行字符压缩
# 默认是开启rdb压缩
# 如果你想在保存rdb时，节省CPU，可以设置为no
rdbcompression yes

#
# 从redis5开始，rdb文件采用CRC64算法校验文件的完整性。
# 这将保证rdb文件的完整性和不可篡改，但是将保存和加载rdb文件时，多耗费10%的性能损耗。
# 如果希望发挥REDIS最大性能，可以关闭该请求
rdbchecksum yes

#
# The filename where to dump the DB
# rdb文件的存储文件名
dbfilename dump.rdb

# The working directory.
# RDB文件将写入这个目录,文件名就是前面dbfilename定义的。
# 同时redis的增量文件页也写入这个目录
# 注意，这个参数必须是一个目录，不能是一个文件
dir ./

################################# REPLICATION （主从复制）#################################

# Master-Replica replication. Use replicaof to make a Redis instance a copy of
# another Redis server. A few things to understand ASAP about Redis replication.
#
#   +------------------+      +---------------+
#   |      Master      | ---&gt; |    Replica    |
#   | (receive writes) |      |  (exact copy) |
#   +------------------+      +---------------+
#
#
# 1）redis 主从复制是异步的，但是你可以设置，主节点没有一个正常运行的从节点时，禁止主节点写操作
# 2）redis从节点可以向主节点进行部分同步，这块你需要在下一个配置中指定同步块大小。
# 3）主从复制是自动进行的，不需要用户介入。

# replicaof &lt;masterip&gt; &lt;masterport&gt;

# 如果主节点设置了requirepass，从节点需要配置主节点的接入密码

# masterauth &lt;master-password&gt;

# 当一个 slave 与 master 失去联系，或者复制正在进行的时候，
# slave 可能会有两种表现：
# 1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，
#    或者数据可能是空的在第一次同步的时候
# 2) 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，
#    slave 都将返回一个 &quot;SYNC with master in progress&quot; 的错误
replica-serve-stale-data yes

#你可以配置一个 slave 实体是否接受写入操作。
#通过写入操作来存储一些短暂的数据对于一个 slave 实例来说可能是有用的，
#因为相对从 master 重新同步数而言，据数据写入到 slave 会更容易被删除。
#但是如果客户端因为一个错误的配置写入，也可能会导致一些问题。
#从 redis 2.6 版起，默认 slaves 都是只读的。
replica-read-only yes

# 主从同步策略：disk和socket
#
# -------------------------------------------------------
# 注意：socket同步是实验性功能
# -------------------------------------------------------
#
# Disk-backed策略在新同步和重连同步无法进行增量同步，只能进行全量同步。
# 主从同步有两种方式，默认采用Disk-backed
#
# 1) Disk-backed: redis新建一个独立进程，将RDB写入到磁盘，稍后由父进程将数据传输给各个节点。
# 
# 2) Diskless: redis创建一个独立进程，直接将数据通过与从节点的socket通道传递，无需写入硬盘。
#
# 在disk-backed的策略下，RDB数据是持有化到磁盘的，多个从节点再逐个接收数据，无法同时传输。
# 在diskless的策略下，从节点一旦接入主节点，在等待指定的时间后，主从开始通过socket传递数据，多个从节点可以同时进行。
#
# 如果在磁盘读写慢，网络速度快的环境下，可以采用diskless
# works better.
repl-diskless-sync no

# 当采用diskless的同步策略启动时，可以配置从节点接入主节点后，等待多少时间后，进行同步。
# 当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。
# 这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段
# 时间以期更多的从站到达。
# 延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动。
repl-diskless-sync-delay 5

# 从redis会周期性的向主redis发出PING包，你可以通过repl_ping_slave_period指令来控制其周期，默认是10秒
# repl-ping-replica-period 10

# 接下来的选项为以下内容设置备份的超时时间：
# 1）从从站的角度，同步期间的批量传输的I/O
# 2）从站角度认为的主站超时（数据，ping）
# 3）主站角度认为的从站超时（REPLCONF ACK pings)
# 确认这些值比定义的repl-ping-slave-period要大，否则每次主站和从站之间通信低速时都会被检测为超时。
# repl-timeout 60

#同步之后是否禁用从站上的TCP_NODELAY
#如果你选择yes，redis会使用较少量的TCP包和带宽向从站发送数据。但这会导致在从站增加一点数据的延时。
#Linux内核默认配置情况下最多40毫秒的延时。
#如果选择no，从站的数据延时不会那么多，但备份需要的带宽相对较多。
#默认情况下我们将潜在因素优化，但在高负载情况下或者在主从站都跳的情况下，把它切换为yes是个好主意。
repl-disable-tcp-nodelay no


# 设置备份的工作储备大小。工作储备是一个缓冲区，当从站断开一段时间的情况时，它替从站接收存储数据，
# 因此当从站重连时，通常不需要完全备份，只需要一个部分同步就可以，即把从站断开时错过的一部分数据接收。
# 工作储备越大，从站可以断开并稍后执行部分同步的断开时间就越长。
# 只要有一个从站连接，就会立刻分配一个工作储备。
# repl-backlog-size 1mb


# 主站有一段时间没有与从站连接，对应的工作储备就会自动释放。
# 这个选项用于配置释放前等待的秒数，秒数从断开的那一刻开始计算，值为0表示不释放。
# repl-backlog-ttl 3600

#从站优先级是可以从redis的INFO命令输出中查到的一个整数。当主站不能正常工作时
#redis sentinel使用它来选择一个从站并将它提升为主站。
#优先级的从站被认为更适合于提升，因此如果有三个从站优先级分别是10，100，25，sentinel会选择优先级为10的从站，因为它的优先级最低。
#然而优先级值为0的从站不能执行主站的角色，因此优先级为0的从站永远不会被redis sentinel提升。
#默认优先级是100
replica-priority 100

# It is possible for a master to stop accepting writes if there are less than
# N replicas connected, having a lag less or equal than M seconds.
#
# The N replicas need to be in &quot;online&quot; state.
#
# The lag in seconds, that must be &lt;= the specified value, is calculated from
# the last ping received from the replica, that is usually sent every second.
#
# This option does not GUARANTEE that N replicas will accept the write, but
# will limit the window of exposure for lost writes in case not enough replicas
# are available, to the specified number of seconds.
#
# For example to require at least 3 replicas with a lag &lt;= 10 seconds use:
#
# min-replicas-to-write 3
# min-replicas-max-lag 10
#
# Setting one or the other to 0 disables the feature.
#
# By default min-replicas-to-write is set to 0 (feature disabled) and
# min-replicas-max-lag is set to 10.

# A Redis master is able to list the address and port of the attached
# replicas in different ways. For example the &quot;INFO replication&quot; section
# offers this information, which is used, among other tools, by
# Redis Sentinel in order to discover replica instances.
# Another place where this info is available is in the output of the
# &quot;ROLE&quot; command of a master.
#
# The listed IP and address normally reported by a replica is obtained
# in the following way:
#
#   IP: The address is auto detected by checking the peer address
#   of the socket used by the replica to connect with the master.
#
#   Port: The port is communicated by the replica during the replication
#   handshake, and is normally the port that the replica is using to
#   listen for connections.
#
# However when port forwarding or Network Address Translation (NAT) is
# used, the replica may be actually reachable via different IP and port
# pairs. The following two options can be used by a replica in order to
# report to its master a specific set of IP and port, so that both INFO
# and ROLE will report those values.
#
# There is no need to use both the options if you need to override just
# the port or the IP address.
#
# replica-announce-ip 5.5.5.5
# replica-announce-port 1234

################################## SECURITY ###################################

#
# 要求客户端调用时需要进行auth认证，这个特性用于你开放redis服务给非完全信任的客户端接
#
# 警告：由于redis的运行高效性，它可以支持每秒150K次的密码验证，所以你必须设置足够复杂的密码防止暴力破解
#
# requirepass foobared

# Command renaming.
#
# It is possible to change the name of dangerous commands in a shared
# environment. For instance the CONFIG command may be renamed into something
# hard to guess so that it will still be available for internal-use tools
# but not available for general clients.
#
# Example:
#
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#
# It is also possible to completely kill a command by renaming it into
# an empty string:
#
# rename-command CONFIG &quot;&quot;
#
# Please note that changing the name of commands that are logged into the
# AOF file or transmitted to replicas may cause problems.

################################### CLIENTS ####################################


# 设置redis最大同时接入的客户端，默认是10000个，如果redis没有设置这个参数，
# 最大的客户端数量是Linux进程的最大文件句柄数-32，因为redis内部需要占用一定的文件句柄
#
# 当连接客户端超过最大数，将提示  &#39;max number of clients reached&#39;
#
# maxclients 10000

############################## MEMORY MANAGEMENT ################################

# maxmemory 可以设置redis的最大占用内存，如果redis实际使用达到阈值，
# 将按照maxmemory-policy策略移除key
# 如果redis不能通过策略移除，或者策略采用的是noeviction，redis将回报错误，对于一些写的指令
# 比如SET，LPUSH这些指令，但是读的指令可以正常回报
#
# 这个选项一般让redis作为LRU或者LFU的缓存服务，如果策略设置为noeviction，限制将是物理内存大小。
#
# WARNING: If you have replicas attached to an instance with maxmemory on,
# the size of the output buffers needed to feed the replicas are subtracted
# from the used memory count, so that network problems / resyncs will
# not trigger a loop where keys are evicted, and in turn the output
# buffer of replicas is full with DELs of keys evicted triggering the deletion
# of more keys, and so forth until the database is completely emptied.
#
# In short... if you have replicas attached it is suggested that you set a lower
# limit for maxmemory so that there is some free RAM on the system for replica
# output buffers (but this is not needed if the policy is &#39;noeviction&#39;).
#
# maxmemory &lt;bytes&gt;

# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory
# is reached. You can select among five behaviors:
#
# volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.
# allkeys-lru -&gt; Evict any key using approximated LRU.
# volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.
# allkeys-lfu -&gt; Evict any key using approximated LFU.
# volatile-random -&gt; Remove a random key among the ones with an expire set.
# allkeys-random -&gt; Remove a random key, any key.
# volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)
# noeviction -&gt; Don&#39;t evict anything, just return an error on write operations.
#
# LRU means Least Recently Used
# LFU means Least Frequently Used
#
# Both LRU, LFU and volatile-ttl are implemented using approximated
# randomized algorithms.
#
# Note: with any of the above policies, Redis will return an error on write
#       operations, when there are no suitable keys for eviction.
#
#       At the date of writing these commands are: set setnx setex append
#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
#       getset mset msetnx exec sort
#
# The default is:
#
# maxmemory-policy noeviction

# LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated
# algorithms (in order to save memory), so you can tune it for speed or
# accuracy. For default Redis will check five keys and pick the one that was
# used less recently, you can change the sample size using the following
# configuration directive.
#
# The default of 5 produces good enough results. 10 Approximates very closely
# true LRU but costs more CPU. 3 is faster but not very accurate.
#
# maxmemory-samples 5

# Starting from Redis 5, by default a replica will ignore its maxmemory setting
# (unless it is promoted to master after a failover or manually). It means
# that the eviction of keys will be just handled by the master, sending the
# DEL commands to the replica as keys evict in the master side.
#
# This behavior ensures that masters and replicas stay consistent, and is usually
# what you want, however if your replica is writable, or you want the replica to have
# a different memory setting, and you are sure all the writes performed to the
# replica are idempotent, then you may change this default (but be sure to understand
# what you are doing).
#
# Note that since the replica by default does not evict, it may end using more
# memory than the one set via maxmemory (there are certain buffers that may
# be larger on the replica, or data structures may sometimes take more memory and so
# forth). So make sure you monitor your replicas and make sure they have enough
# memory to never hit a real out-of-memory condition before the master hits
# the configured maxmemory setting.
#
# replica-ignore-maxmemory yes

############################# LAZY FREEING ####################################

# Redis has two primitives to delete keys. One is called DEL and is a blocking
# deletion of the object. It means that the server stops processing new commands
# in order to reclaim all the memory associated with an object in a synchronous
# way. If the key deleted is associated with a small object, the time needed
# in order to execute the DEL command is very small and comparable to most other
# O(1) or O(log_N) commands in Redis. However if the key is associated with an
# aggregated value containing millions of elements, the server can block for
# a long time (even seconds) in order to complete the operation.
#
# For the above reasons Redis also offers non blocking deletion primitives
# such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and
# FLUSHDB commands, in order to reclaim memory in background. Those commands
# are executed in constant time. Another thread will incrementally free the
# object in the background as fast as possible.
#
# DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.
# It&#39;s up to the design of the application to understand when it is a good
# idea to use one or the other. However the Redis server sometimes has to
# delete keys or flush the whole database as a side effect of other operations.
# Specifically Redis deletes objects independently of a user call in the
# following scenarios:
#
# 1) On eviction, because of the maxmemory and maxmemory policy configurations,
#    in order to make room for new data, without going over the specified
#    memory limit.
# 2) Because of expire: when a key with an associated time to live (see the
#    EXPIRE command) must be deleted from memory.
# 3) Because of a side effect of a command that stores data on a key that may
#    already exist. For example the RENAME command may delete the old key
#    content when it is replaced with another one. Similarly SUNIONSTORE
#    or SORT with STORE option may delete existing keys. The SET command
#    itself removes any old content of the specified key in order to replace
#    it with the specified string.
# 4) During replication, when a replica performs a full resynchronization with
#    its master, the content of the whole database is removed in order to
#    load the RDB file just transferred.
#
# In all the above cases the default is to delete objects in a blocking way,
# like if DEL was called. However you can configure each case specifically
# in order to instead release memory in a non-blocking way like if UNLINK
# was called, using the following configuration directives:

lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no

############################## APPEND ONLY MODE ###############################

# By default Redis asynchronously dumps the dataset on disk. This mode is
# good enough in many applications, but an issue with the Redis process or
# a power outage may result into a few minutes of writes lost (depending on
# the configured save points).
#
# The Append Only File is an alternative persistence mode that provides
# much better durability. For instance using the default data fsync policy
# (see later in the config file) Redis can lose just one second of writes in a
# dramatic event like a server power outage, or a single write if something
# wrong with the Redis process itself happens, but the operating system is
# still running correctly.
#
# AOF and RDB persistence can be enabled at the same time without problems.
# If the AOF is enabled on startup Redis will load the AOF, that is the file
# with the better durability guarantees.
#
# Please check http://redis.io/topics/persistence for more information.

appendonly no

# The name of the append only file (default: &quot;appendonly.aof&quot;)

appendfilename &quot;appendonly.aof&quot;

# The fsync() call tells the Operating System to actually write data on disk
# instead of waiting for more data in the output buffer. Some OS will really flush
# data on disk, some other OS will just try to do it ASAP.
#
# Redis supports three different modes:
#
# no: don&#39;t fsync, just let the OS flush the data when it wants. Faster.
# always: fsync after every write to the append only log. Slow, Safest.
# everysec: fsync only one time every second. Compromise.
#
# The default is &quot;everysec&quot;, as that&#39;s usually the right compromise between
# speed and data safety. It&#39;s up to you to understand if you can relax this to
# &quot;no&quot; that will let the operating system flush the output buffer when
# it wants, for better performances (but if you can live with the idea of
# some data loss consider the default persistence mode that&#39;s snapshotting),
# or on the contrary, use &quot;always&quot; that&#39;s very slow but a bit safer than
# everysec.
#
# More details please check the following article:
# http://antirez.com/post/redis-persistence-demystified.html
#
# If unsure, use &quot;everysec&quot;.

# appendfsync always
appendfsync everysec
# appendfsync no

# When the AOF fsync policy is set to always or everysec, and a background
# saving process (a background save or AOF log background rewriting) is
# performing a lot of I/O against the disk, in some Linux configurations
# Redis may block too long on the fsync() call. Note that there is no fix for
# this currently, as even performing fsync in a different thread will block
# our synchronous write(2) call.
#
# In order to mitigate this problem it&#39;s possible to use the following option
# that will prevent fsync() from being called in the main process while a
# BGSAVE or BGREWRITEAOF is in progress.
#
# This means that while another child is saving, the durability of Redis is
# the same as &quot;appendfsync none&quot;. In practical terms, this means that it is
# possible to lose up to 30 seconds of log in the worst scenario (with the
# default Linux settings).
#
# If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as
# &quot;no&quot; that is the safest pick from the point of view of durability.

no-appendfsync-on-rewrite no

# Automatic rewrite of the append only file.
# Redis is able to automatically rewrite the log file implicitly calling
# BGREWRITEAOF when the AOF log size grows by the specified percentage.
#
# This is how it works: Redis remembers the size of the AOF file after the
# latest rewrite (if no rewrite has happened since the restart, the size of
# the AOF at startup is used).
#
# This base size is compared to the current size. If the current size is
# bigger than the specified percentage, the rewrite is triggered. Also
# you need to specify a minimal size for the AOF file to be rewritten, this
# is useful to avoid rewriting the AOF file even if the percentage increase
# is reached but it is still pretty small.
#
# Specify a percentage of zero in order to disable the automatic AOF
# rewrite feature.

auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# An AOF file may be found to be truncated at the end during the Redis
# startup process, when the AOF data gets loaded back into memory.
# This may happen when the system where Redis is running
# crashes, especially when an ext4 filesystem is mounted without the
# data=ordered option (however this can&#39;t happen when Redis itself
# crashes or aborts but the operating system still works correctly).
#
# Redis can either exit with an error when this happens, or load as much
# data as possible (the default now) and start if the AOF file is found
# to be truncated at the end. The following option controls this behavior.
#
# If aof-load-truncated is set to yes, a truncated AOF file is loaded and
# the Redis server starts emitting a log to inform the user of the event.
# Otherwise if the option is set to no, the server aborts with an error
# and refuses to start. When the option is set to no, the user requires
# to fix the AOF file using the &quot;redis-check-aof&quot; utility before to restart
# the server.
#
# Note that if the AOF file will be found to be corrupted in the middle
# the server will still exit with an error. This option only applies when
# Redis will try to read more data from the AOF file but not enough bytes
# will be found.
aof-load-truncated yes

# When rewriting the AOF file, Redis is able to use an RDB preamble in the
# AOF file for faster rewrites and recoveries. When this option is turned
# on the rewritten AOF file is composed of two different stanzas:
#
#   [RDB file][AOF tail]
#
# When loading Redis recognizes that the AOF file starts with the &quot;REDIS&quot;
# string and loads the prefixed RDB file, and continues loading the AOF
# tail.
aof-use-rdb-preamble yes

################################ LUA SCRIPTING  ###############################

# Max execution time of a Lua script in milliseconds.
#
# If the maximum execution time is reached Redis will log that a script is
# still in execution after the maximum allowed time and will start to
# reply to queries with an error.
#
# When a long running script exceeds the maximum execution time only the
# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be
# used to stop a script that did not yet called write commands. The second
# is the only way to shut down the server in the case a write command was
# already issued by the script but the user doesn&#39;t want to wait for the natural
# termination of the script.
#
# Set it to 0 or a negative value for unlimited execution without warnings.
lua-time-limit 5000

################################ REDIS CLUSTER  ###############################
#
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however
# in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage
# of users to deploy it in production.
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#
# 一般情况下，redis未开启集群模式，只有开启如下参数，才能开启集群模式。
#
# cluster-enabled yes

#
# 每个集群节点都有集群配置文件，这个文件不是用来提供给使用者编辑，
# 它将由集群节点自身创建并通过集群通信后修改。
# 每个集群节点如果在同一个宿主机上都要有不同的文件，否则将会被覆盖。
# cluster-config-file nodes-6379.conf


# 集群节点被认定为不可达的时间阈值，单位是毫秒。
# 大多数时间节点的阈值都是超时时间的整数倍。
# cluster-node-timeout 15000

# A replica of a failing master will avoid to start a failover if its data
# looks too old.
# 故障主节点的备份将在数据太旧的时候启动失败。
#
# 目前没有简易的方法判断数据是否过旧，一般采用如下两种判定：
# 1）如果有多个故障备份，他们将交换数据对备份数据的时间进行排序，
#     取最新的故障节点作为主节点。
# 1) If there are multiple replicas able to failover, they exchange messages
#    in order to try to give an advantage to the replica with the best
#    replication offset (more data from the master processed).
#    Replicas will try to get their rank by offset, and apply to the start
#    of the failover a delay proportional to their rank.
# 2）
# 2) Every single replica computes the time of the last interaction with
#    its master. This can be the last ping or command received (if the master
#    is still in the &quot;connected&quot; state), or the time that elapsed since the
#    disconnection with the master (if the replication link is currently down).
#    If the last interaction is too old, the replica will not try to failover
#    at all.
#
# The point &quot;2&quot; can be tuned by user. Specifically a replica will not perform
# the failover if, since the last interaction with the master, the time
# elapsed is greater than:
#
#   (node-timeout * replica-validity-factor) + repl-ping-replica-period
#
# So for example if node-timeout is 30 seconds, and the replica-validity-factor
# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the
# replica will not try to failover if it was not able to talk with the master
# for longer than 310 seconds.
#
# A large replica-validity-factor may allow replicas with too old data to failover
# a master, while a too small value may prevent the cluster from being able to
# elect a replica at all.
#
# For maximum availability, it is possible to set the replica-validity-factor
# to a value of 0, which means, that replicas will always try to failover the
# master regardless of the last time they interacted with the master.
# (However they&#39;ll always try to apply a delay proportional to their
# offset rank).
#
# Zero is the only value able to guarantee that when all the partitions heal
# the cluster will always be able to continue.
#
# cluster-replica-validity-factor 10

# Cluster replicas are able to migrate to orphaned masters, that are masters
# that are left without working replicas. This improves the cluster ability
# to resist to failures as otherwise an orphaned master can&#39;t be failed over
# in case of failure if it has no working replicas.
#
# Replicas migrate to orphaned masters only if there are still at least a
# given number of other working replicas for their old master. This number
# is the &quot;migration barrier&quot;. A migration barrier of 1 means that a replica
# will migrate only if there is at least 1 other working replica for its master
# and so forth. It usually reflects the number of replicas you want for every
# master in your cluster.
#
# Default is 1 (replicas migrate only if their masters remain with at least
# one replica). To disable migration just set it to a very large value.
# A value of 0 can be set but is useful only for debugging and dangerous
# in production.
#
# cluster-migration-barrier 1

# By default Redis Cluster nodes stop accepting queries if they detect there
# is at least an hash slot uncovered (no available node is serving it).
# This way if the cluster is partially down (for example a range of hash slots
# are no longer covered) all the cluster becomes, eventually, unavailable.
# It automatically returns available as soon as all the slots are covered again.
#
# However sometimes you want the subset of the cluster which is working,
# to continue to accept queries for the part of the key space that is still
# covered. In order to do so, just set the cluster-require-full-coverage
# option to no.
#
# cluster-require-full-coverage yes

# This option, when set to yes, prevents replicas from trying to failover its
# master during master failures. However the master can still perform a
# manual failover, if forced to do so.
#
# This is useful in different scenarios, especially in the case of multiple
# data center operations, where we want one side to never be promoted if not
# in the case of a total DC failure.
#
# cluster-replica-no-failover no

# In order to setup your cluster make sure to read the documentation
# available at http://redis.io web site.

########################## CLUSTER DOCKER/NAT support  ########################

# 在某些环境，redis集群节点的地址发现是失败的。主要原因是NAT网络或者Docker等容器化环境，导致地址发现是错误的。
# 
# 为了解决redis在这些网络环境的正常运行，redis提供的可配置化的可访问IP配置。
# 如下是配置参数：
#
# * cluster-announce-ip
# * cluster-announce-port
# * cluster-announce-bus-port
# 
#
# 如果这些配置未开启，使用默认的集群自动发现。
# 
# Note that when remapped, the bus port may not be at the fixed offset of
# clients port + 10000, so you can specify any port and bus-port depending
# on how they get remapped. If the bus-port is not set, a fixed offset of
# 10000 will be used as usually.
#
# 一般来说，数据端口(port)和集群信息交换（bus-port）约定是port+10000.
# Example:
#
# cluster-announce-ip 10.1.1.5
# cluster-announce-port 6379
# cluster-announce-bus-port 6380

################################## SLOW LOG ###################################

# redis慢日志是为了记录执行时间过长的指令。这些指令不包含IO操作，比如和客户端的数据通，只是记录
# 指令在redis中的执行时间（因为redis是单线程的，每条指令执行都是堵塞其他指令，这样的机制，可以简单的记录下每条指令的执行时间）
#
# 你可以配置慢日志的两个参数，一个是慢日志的界定阈值，单位是微秒，另一个是慢日志的指令最大数量，
# 超过最大数量，旧的慢日志将被删除。


# 下面单位是微秒，1秒要写成1000000，如果数值为负数，表示不记录慢日志，如果数值为0，将会记录每条指令
slowlog-log-slower-than 10000


# 慢日志最大长度如果不设置，将没有限制，一直存储下去，这将导致内存暴增。
# 你可以通过SLOWLOG RESET来重置慢日志记录
slowlog-max-len 128

################################ LATENCY MONITOR ##############################

#
# redis延时监控是为了在运行状态收集redis的慢操作（和慢日志的区别，其监控范围更广，不仅包括命令耗时，还包括内部指令，比如key过期回收这些的耗时）
# 通过latency可以打印耗时图表
# 通过latency-monitor-threshold（单位毫秒）的阈值记录延时日志，如果设置0，表示关闭延时日志监控。
#
# 默认情况下，延时监控是关闭的，大多数情况下，没有必要开启，除非redis存在性能问题。
# 延时监控开启后，会有一定的性能损耗，不过相当小，即使在大负载运行的情
# 延时监控也可以通过CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;来进行热启动
latency-monitor-threshold 0

############################# EVENT NOTIFICATION ##############################

# Redis can notify Pub/Sub clients about events happening in the key space.
# This feature is documented at http://redis.io/topics/notifications
#
# For instance if keyspace events notification is enabled, and a client
# performs a DEL operation on key &quot;foo&quot; stored in the Database 0, two
# messages will be published via Pub/Sub:
#
# PUBLISH __keyspace@0__:foo del
# PUBLISH __keyevent@0__:del foo
#
# It is possible to select the events that Redis will notify among a set
# of classes. Every class is identified by a single character:
#
#  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.
#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.
#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...
#  $     String commands
#  l     List commands
#  s     Set commands
#  h     Hash commands
#  z     Sorted set commands
#  x     Expired events (events generated every time a key expires)
#  e     Evicted events (events generated when a key is evicted for maxmemory)
#  A     Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.
#
#  The &quot;notify-keyspace-events&quot; takes as argument a string that is composed
#  of zero or multiple characters. The empty string means that notifications
#  are disabled.
#
#  Example: to enable list and generic events, from the point of view of the
#           event name, use:
#
#  notify-keyspace-events Elg
#
#  Example 2: to get the stream of the expired keys subscribing to channel
#             name __keyevent@0__:expired use:
#
#  notify-keyspace-events Ex
#
#  By default all notifications are disabled because most users don&#39;t need
#  this feature and the feature has some overhead. Note that if you don&#39;t
#  specify at least one of K or E, no events will be delivered.
notify-keyspace-events &quot;&quot;

############################### ADVANCED CONFIG ###############################

# Hashes are encoded using a memory efficient data structure when they have a
# small number of entries, and the biggest entry does not exceed a given
# threshold. These thresholds can be configured using the following directives.
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# Lists are also encoded in a special way to save a lot of space.
# The number of entries allowed per internal list node can be specified
# as a fixed maximum size or a maximum number of elements.
# For a fixed maximum size, use -5 through -1, meaning:
# -5: max size: 64 Kb  &lt;-- not recommended for normal workloads
# -4: max size: 32 Kb  &lt;-- not recommended
# -3: max size: 16 Kb  &lt;-- probably not recommended
# -2: max size: 8 Kb   &lt;-- good
# -1: max size: 4 Kb   &lt;-- good
# Positive numbers mean store up to _exactly_ that number of elements
# per list node.
# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),
# but if your use case is unique, adjust the settings as necessary.
list-max-ziplist-size -2

# Lists may also be compressed.
# Compress depth is the number of quicklist ziplist nodes from *each* side of
# the list to *exclude* from compression.  The head and tail of the list
# are always uncompressed for fast push/pop operations.  Settings are:
# 0: disable all list compression
# 1: depth 1 means &quot;don&#39;t start compressing until after 1 node into the list,
#    going from either the head or tail&quot;
#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]
#    [head], [tail] will always be uncompressed; inner nodes will compress.
# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]
#    2 here means: don&#39;t compress head or head-&gt;next or tail-&gt;prev or tail,
#    but compress all nodes between them.
# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]
# etc.
list-compress-depth 0

# Sets have a special encoding in just one case: when a set is composed
# of just strings that happen to be integers in radix 10 in the range
# of 64 bit signed integers.
# The following configuration setting sets the limit in the size of the
# set in order to use this special memory saving encoding.
set-max-intset-entries 512

# Similarly to hashes and lists, sorted sets are also specially encoded in
# order to save a lot of space. This encoding is only used when the length and
# elements of a sorted set are below the following limits:
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

# HyperLogLog sparse representation bytes limit. The limit includes the
# 16 bytes header. When an HyperLogLog using the sparse representation crosses
# this limit, it is converted into the dense representation.
#
# A value greater than 16000 is totally useless, since at that point the
# dense representation is more memory efficient.
#
# The suggested value is ~ 3000 in order to have the benefits of
# the space efficient encoding without slowing down too much PFADD,
# which is O(N) with the sparse encoding. The value can be raised to
# ~ 10000 when CPU is not a concern, but space is, and the data set is
# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.
hll-sparse-max-bytes 3000

# Streams macro node max size / items. The stream data structure is a radix
# tree of big nodes that encode multiple items inside. Using this configuration
# it is possible to configure how big a single node can be in bytes, and the
# maximum number of items it may contain before switching to a new node when
# appending new stream entries. If any of the following settings are set to
# zero, the limit is ignored, so for instance it is possible to set just a
# max entires limit by setting max-bytes to 0 and max-entries to the desired
# value.
stream-node-max-bytes 4096
stream-node-max-entries 100

# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in
# order to help rehashing the main Redis hash table (the one mapping top-level
# keys to values). The hash table implementation Redis uses (see dict.c)
# performs a lazy rehashing: the more operation you run into a hash table
# that is rehashing, the more rehashing &quot;steps&quot; are performed, so if the
# server is idle the rehashing is never complete and some more memory is used
# by the hash table.
#
# The default is to use this millisecond 10 times every second in order to
# actively rehash the main dictionaries, freeing memory when possible.
#
# If unsure:
# use &quot;activerehashing no&quot; if you have hard latency requirements and it is
# not a good thing in your environment that Redis can reply from time to time
# to queries with 2 milliseconds delay.
#
# use &quot;activerehashing yes&quot; if you don&#39;t have such hard requirements but
# want to free memory asap when possible.
activerehashing yes

# The client output buffer limits can be used to force disconnection of clients
# that are not reading data from the server fast enough for some reason (a
# common reason is that a Pub/Sub client can&#39;t consume messages as fast as the
# publisher can produce them).
#
# The limit can be set differently for the three different classes of clients:
#
# normal -&gt; normal clients including MONITOR clients
# replica  -&gt; replica clients
# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern
#
# The syntax of every client-output-buffer-limit directive is the following:
#
# client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;
#
# A client is immediately disconnected once the hard limit is reached, or if
# the soft limit is reached and remains reached for the specified number of
# seconds (continuously).
# So for instance if the hard limit is 32 megabytes and the soft limit is
# 16 megabytes / 10 seconds, the client will get disconnected immediately
# if the size of the output buffers reach 32 megabytes, but will also get
# disconnected if the client reaches 16 megabytes and continuously overcomes
# the limit for 10 seconds.
#
# By default normal clients are not limited because they don&#39;t receive data
# without asking (in a push way), but just after a request, so only
# asynchronous clients may create a scenario where data is requested faster
# than it can read.
#
# Instead there is a default limit for pubsub and replica clients, since
# subscribers and replicas receive data in a push fashion.
#
# Both the hard or the soft limit can be disabled by setting them to zero.
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

# Client query buffers accumulate new commands. They are limited to a fixed
# amount by default in order to avoid that a protocol desynchronization (for
# instance due to a bug in the client) will lead to unbound memory usage in
# the query buffer. However you can configure it here if you have very special
# needs, such us huge multi/exec requests or alike.
#
# client-query-buffer-limit 1gb

# In the Redis protocol, bulk requests, that are, elements representing single
# strings, are normally limited ot 512 mb. However you can change this limit
# here.
#
# proto-max-bulk-len 512mb

# Redis calls an internal function to perform many background tasks, like
# closing connections of clients in timeout, purging expired keys that are
# never requested, and so forth.
#
# Not all tasks are performed with the same frequency, but Redis checks for
# tasks to perform according to the specified &quot;hz&quot; value.
#
# By default &quot;hz&quot; is set to 10. Raising the value will use more CPU when
# Redis is idle, but at the same time will make Redis more responsive when
# there are many keys expiring at the same time, and timeouts may be
# handled with more precision.
#
# The range is between 1 and 500, however a value over 100 is usually not
# a good idea. Most users should use the default of 10 and raise this up to
# 100 only in environments where very low latency is required.
hz 10

# Normally it is useful to have an HZ value which is proportional to the
# number of clients connected. This is useful in order, for instance, to
# avoid too many clients are processed for each background task invocation
# in order to avoid latency spikes.
#
# Since the default HZ value by default is conservatively set to 10, Redis
# offers, and enables by default, the ability to use an adaptive HZ value
# which will temporary raise when there are many connected clients.
#
# When dynamic HZ is enabled, the actual configured HZ will be used as
# as a baseline, but multiples of the configured HZ value will be actually
# used as needed once more clients are connected. In this way an idle
# instance will use very little CPU time while a busy instance will be
# more responsive.
dynamic-hz yes

# When a child rewrites the AOF file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
aof-rewrite-incremental-fsync yes

# When redis saves RDB file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
rdb-save-incremental-fsync yes

# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good
# idea to start with the default settings and only change them after investigating
# how to improve the performances and how the keys LFU change over time, which
# is possible to inspect via the OBJECT FREQ command.
#
# There are two tunable parameters in the Redis LFU implementation: the
# counter logarithm factor and the counter decay time. It is important to
# understand what the two parameters mean before changing them.
#
# The LFU counter is just 8 bits per key, it&#39;s maximum value is 255, so Redis
# uses a probabilistic increment with logarithmic behavior. Given the value
# of the old counter, when a key is accessed, the counter is incremented in
# this way:
#
# 1. A random number R between 0 and 1 is extracted.
# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).
# 3. The counter is incremented only if R &lt; P.
#
# The default lfu-log-factor is 10. This is a table of how the frequency
# counter changes with a different number of accesses with different
# logarithmic factors:
#
# +--------+------------+------------+------------+------------+------------+
# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |
# +--------+------------+------------+------------+------------+------------+
# | 0      | 104        | 255        | 255        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 1      | 18         | 49         | 255        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 10     | 10         | 18         | 142        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 100    | 8          | 11         | 49         | 143        | 255        |
# +--------+------------+------------+------------+------------+------------+
#
# NOTE: The above table was obtained by running the following commands:
#
#   redis-benchmark -n 1000000 incr foo
#   redis-cli object freq foo
#
# NOTE 2: The counter initial value is 5 in order to give new objects a chance
# to accumulate hits.
#
# The counter decay time is the time, in minutes, that must elapse in order
# for the key counter to be divided by two (or decremented if it has a value
# less &lt;= 10).
#
# The default value for the lfu-decay-time is 1. A Special value of 0 means to
# decay the counter every time it happens to be scanned.
#
# lfu-log-factor 10
# lfu-decay-time 1

########################### ACTIVE DEFRAGMENTATION #######################
#
# 注意，该特性是实验性的，尽管经过了众多开发者生产环境验证和人工测试，但还是不能保证没问题。
#
# 什么是碎片热整理？
# -------------------------------
# 碎片热整理是让redis整合内存空间的碎片化数据块和废弃数据，这样可以回收更大的内存空间用于分配。
# 
# 
# Fragmentation is a natural process that happens with every allocator (but
# less so with Jemalloc, fortunately) and certain workloads. 
# 一般来说，服务需要重启才能减少内存碎片，或至少要释放所有数据内存，再次重新构建一次内存数据。
# 然而，感谢Oran Agra在redis4.0实现了服务在运行时可整理碎片的机制。
#
# 基本上，当碎片达到一定级别（看下方的配置），redis将在临近的内存区域通过Jemalloc（可以更好的实现内存回收和碎片整理）构建一个备份，
# 同时，将释放旧的内存数据，这个进程采用递增的方式逐个处理key值直到内存碎片降低的合理值。
#
# 重要的知识点:
#
# 1. This feature is disabled by default, and only works if you compiled Redis
#    to use the copy of Jemalloc we ship with the source code of Redis.
#    This is the default with Linux builds.
# 2.你不需要开启该特性，如果你的系统没有碎片问题。
# 3.一旦你想体验该特性，你可以通过CONFIG SET activedefrag yes指令开启
#
# 如下配置将更好的调整碎片整理的行为。如果你不确定参数的作用，建议采用默认值。

# 开启碎片整理
# activedefrag yes

# 碎片大小下限值，碎片大小&gt;=100M,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-ignore-bytes 100mb

# 碎片占比下限值，&gt;=10%,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-threshold-lower 10

# 碎片占比上限值，&lt;=100%,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-threshold-upper 100

# CPU的使用率下限值，&gt;=5%,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-cycle-min 5

# CPU的使用率上限值，&lt;=75%,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-cycle-max 75

# Maximum number of set/hash/zset/list fields that will be processed from
# the main dictionary scan
# active-defrag-max-scan-fields 1000
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RPC框架]]></title>
    <link href="http://www.throne4j.com/15991122990129.html"/>
    <updated>2020-09-03T13:51:39+08:00</updated>
    <id>http://www.throne4j.com/15991122990129.html</id>
    <content type="html"><![CDATA[
<p>remote procedure call 远程过程调用。</p>

<p>首先我们看一下 一次完整的 RPC 同步调用流程:</p>

<ul>
<li>服务消费方(client)以本地调用方式调用客户端存根;</li>
<li>什么叫客户端存根?就是远程方法在本地的模拟对象，一样的也有方法名，也有方法参数，client stub 接收到调用后负责将方法名、方法的参数等包装， 并将包装后的信息通过网络发送到服务端;</li>
<li>服务端收到消息后，交给代理存根在服务器的部分后进行解码为实际的方法名和参数</li>
<li>server stub 根据解码结果调用服务器上本地的实际服务; </li>
<li>本地服务执行并将结果返回给 server stub;</li>
<li>server stub 将返回结果打包成消息并发送至消费方; </li>
<li>client stub 接收到消息，并进行解码; </li>
<li>服务消费方得到最终结果。</li>
</ul>

<p>RPC 框架的目标就是要中间步骤都封装起来，让我们进行远程方法调用的时 候感觉到就像在本地调用一样。</p>

<p>RPC框架需要解决的问题有哪些？</p>

<ul>
<li>代理问题, 隐藏底层实现</li>
<li>序列化问题，</li>
<li>通信问题</li>
<li>服务实例化</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式和集群的概念区别]]></title>
    <link href="http://www.throne4j.com/15990991988342.html"/>
    <updated>2020-09-03T10:13:18+08:00</updated>
    <id>http://www.throne4j.com/15990991988342.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">　　一、集群概念</h2>

<h2 id="toc_1">1、两大关键特性</h2>

<p>集群是一组协同工作的服务实体，用以提供比单一服务实体更具扩展性与可用性的服务平台。在客户端看来，一个集群就象是一个服务实体，但事实上集群由一组服务实体组成。与单一服务实体相比较，集群提供了以下两个关键特性：</p>

<ul>
<li>可扩展性－－集群的性能不限于单一的服务实体，新的服务实体可以动态地加入到集群，从而增强集群的性能。</li>
<li>高可用性－－集群通过服务实体冗余使客户端免于轻易遇到out of service的警告。在集群中，同样的服务可以由多个服务实体提供。如果一个服务实体失败了，另一个服务实体会接管失败的服务实体。集群提供的从一个出 错的服务实体恢复到另一个服务实体的功能增强了应用的可用性。</li>
</ul>

<p>　　2. 两大能力 </p>

<p>　　为了具有可扩展性和高可用性特点，集群的必须具备以下两大能力：</p>

<p>　　·  负载均衡－－负载均衡能把任务比较均衡地分布到集群环境下的计算和网络资源。</p>

<p>　　·  错误恢复－－由于某种原因，执行某个任务的资源出现故障，另一服务实体中执行同一任务的资源接着完成任务。这种由于一个实体中的资源不能工作，另一个实体中的资源透明的继续完成任务的过程叫错误恢复。</p>

<p>　　负载均衡和错误恢复都要求各服务实体中有执行同一任务的资源存在，而且对于同一任务的各个资源来说，执行任务所需的信息视图（信息上下文）必须是一样的。</p>

<p>　　3. 两大技术</p>

<p>　　实现集群务必要有以下两大技术：</p>

<p>　　·  集群地址－－集群由多个服务实体组成，集群客户端通过访问集群的集群地址获取集群内部各服务实体的功能。具有单一集群地址（也叫单一影像）是集群的一个基 本特征。维护集群地址的设置被称为负载均衡器。负载均衡器内部负责管理各个服务实体的加入和退出，外部负责集群地址向内部服务实体地址的转换。有的负载均 衡器实现真正的负载均衡算法，有的只支持任务的转换。只实现任务转换的负载均衡器适用于支持ACTIVE-STANDBY的集群环境，在那里，集群中只有 一个服务实体工作，当正在工作的服务实体发生故障时，负载均衡器把后来的任务转向另外一个服务实体。</p>

<p>　　·  内部通信－－为了能协同工作、实现负载均衡和错误恢复，集群各实体间必须时常通信，比如负载均衡器对服务实体心跳测试信息、服务实体间任务执行上下文信息的通信。</p>

<p>　　具有同一个集群地址使得客户端能访问集群提供的计算服务，一个集群地址下隐藏了各个服务实体的内部地址，使得客户要求的计算服务能在各个服务实体之间分布。内部通信是集群能正常运转的基础，它使得集群具有均衡负载和错误恢复的能力。</p>

<h2 id="toc_2">　　二、集群分类</h2>

<p>　　Linux集群主要分成三大类(高可用集群， 负载均衡集群，科学计算集群)</p>

<p>高可用集群(High Availability Cluster)<br/>
负载均衡集群(Load Balance Cluster)<br/>
科学计算集群(High Performance Computing Cluster)<br/>
　　具体包括：</p>

<p>　　Linux High Availability 高可用集群<br/><br/>
　　(普通两节点双机热备，多节点HA集群，RAC, shared, share-nothing集群等)</p>

<p>　　Linux Load Balance 负载均衡集群<br/><br/>
　　 (LVS等....)</p>

<p>　　Linux High Performance Computing 高性能科学计算集群<br/><br/>
　　 (Beowulf 类集群....)</p>

<h2 id="toc_3">　　三、详细介绍</h2>

<p>　　1. 高可用集群(High Availability Cluster)</p>

<p>　　常见的就是2个节点做成的HA集群，有很多通俗的不科学的名称，比如&quot;双机热备&quot;，&quot;双机互备&quot;，&quot;双机&quot;。</p>

<p>　　高可用集群解决的是保障用户的应用程序持续对外提供服务的能力。 (请注意高可用集群既不是用来保护业务数据的，保护的是用户的业务程序对外不间断提供服务，把因软件/硬件/人为造成的故障对业务的影响降低到最小程度)。</p>

<p>　　2. 负载均衡集群(Load Balance Cluster)</p>

<p>　　负载均衡系统：集群中所有的节点都处于活动状态，它们分摊系统的工作负载。一般Web服务器集群、数据库集群和应用服务器集群都属于这种类型。</p>

<p>　　负载均衡集群一般用于相应网络请求的网页服务器，数据库服务器。这种集群可以在接到请求时，检查接受请求较少，不繁忙的服务器，并把请求转到这些服务器上。从检查其他服务器状态这一点上看，负载均衡和容错集群很接近，不同之处是数量上更多。</p>

<p>　　3. 科学计算集群(High Performance Computing Cluster)</p>

<p>　　高性能计算(High Perfermance Computing)集群，简称HPC集群。这类集群致力于提供单个计算机所不能提供的强大的计算能力。</p>

<p>　　3.1 高性能计算分类　　　</p>

<p>　　3.1.1 高吞吐计算(High-throughput Computing)</p>

<p>　　有一类高性能计算，可以把它分成若干可以并行的子任务，而且各个子任务彼此间没有什么关联。象在家搜寻外星人（ SETI@HOME -- Search for Extraterrestrial Intelligence at Home ）就是这一类型应用。这一项目是利用Internet上的闲置的计算资源来搜寻外星人。SETI项目的服务器将一组数据和数据模式发给Internet上 参加SETI的计算节点，计算节点在给定的数据上用给定的模式进行搜索，然后将搜索的结果发给服务器。服务器负责将从各个计算节点返回的数据汇集成完整的 数据。因为这种类型应用的一个共同特征是在海量数据上搜索某些模式，所以把这类计算称为高吞吐计算。所谓的Internet计算都属于这一类。按照 Flynn的分类，高吞吐计算属于SIMD（Single Instruction/Multiple Data）的范畴。</p>

<p>　　3.1.2 分布计算(Distributed Computing)</p>

<p>　　另一类计算刚好和高吞吐计算相反，它们虽然可以给分成若干并行的子任务，但是子任务间联系很紧密，需要大量的数据交换。按照Flynn的分类，分布式的高性能计算属于MIMD（Multiple Instruction/Multiple Data）的范畴。</p>

<h2 id="toc_4">　　四、分布式（集群）与集群的联系与区别</h2>

<p>　　分布式是指将不同的业务分布在不同的地方；而集群指的是将几台服务器集中在一起，实现同一业务。</p>

<p>　　分布式中的每一个节点，都可以做集群。 而集群并不一定就是分布式的。 </p>

<p>　　举例：就比如新浪网，访问的人多了，他可以做一个群集，前面放一个响应服务器，后面几台服务器完成同一业务，如果有业务访问的时候，响应服务器看哪台服务器的负载不是很重，就将给哪一台去完成。 </p>

<p>　　而分布式，从窄意上理解，也跟集群差不多， 但是它的组织比较松散，不像集群，有一个组织性，一台服务器垮了，其它的服务器可以顶上来。</p>

<p>　　分布式的每一个节点，都完成不同的业务，一个节点垮了，那这个业务就不可访问了。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[linux和macOS下top命令区别]]></title>
    <link href="http://www.throne4j.com/15983681960215.html"/>
    <updated>2020-08-25T23:09:56+08:00</updated>
    <id>http://www.throne4j.com/15983681960215.html</id>
    <content type="html"><![CDATA[
<p>top命令是常用的性能分析工具，被广泛用于监视服务器的负载，能够实时显示系统中各个进程的资源占用情况。</p>

<p>前言<br/>
开发环境使用Mac后，经常使用 活动监视器 查看所有进程CPU、内存等。top命令的快捷键在Mac下的快捷键不生效。一直这样用下来，感觉不是很顺手。整理记录。</p>

<h2 id="toc_0">1、linux top</h2>

<pre><code class="language-text">P 键 按照cpu使用率排序
M 键 按照内存使用率排序
l 键 切换显示平均负载和启动时间信息
m 键 切换显示内存信息
t 键 切换显示进程和cpu状态信息
c 键 切换显示命令名称和完成命令行信息
</code></pre>

<pre><code class="language-text">top - 11:15:45 up 14 min,  1 user,  load average: 0.74, 0.58, 0.31
Tasks: 143 total,   1 running, 142 sleeping,   0 stopped,   0 zombie
%Cpu(s):  2.4 us,  2.2 sy,  0.0 ni, 95.3 id,  0.0 wa,  0.0 hi,  0.2 si,  0.0 st
</code></pre>

<h2 id="toc_1">2、Mac top</h2>

<p>先输入 o 键 ,再输入 cpu 则按cpu使用量排序，输入 rsize 按内存使用量排序。</p>

<h2 id="toc_2">3、 字符含义</h2>

<pre><code class="language-shell">top - 11:25:56 up 25 min,  1 user,  load average: 0.22, 0.36, 0.31
Tasks: 144 total,   1 running, 143 sleeping,   0 stopped,   0 zombie
%Cpu(s):  2.2 us,  1.7 sy,  0.0 ni, 95.9 id,  0.0 wa,  0.0 hi,  0.2 si,  0.0 st
KiB Mem :  1863088 total,    97124 free,   934460 used,   831504 buff/cache
KiB Swap:        0 total,        0 free,        0 used.   767876 avail Mem

   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
  2383 root      20   0  481976 274180  39152 S   3.3 14.7   0:48.03 kube-apiserver --advertise-address=172.16.65.134 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enabl+
   738 root      20   0 1225828  73716  34748 S   2.0  4.0   0:32.22 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --cgroup-driver=systemd --network-plugi+
  1002 root      20   0  566956  87928  26144 S   1.0  4.7   0:15.37 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
  2384 root      20   0   10.1g  50352  12152 S   1.0  2.7   0:18.25 etcd --advertise-client-urls=https://172.16.65.134:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --initial-advertise-peer-urls=https://172.16.+
  2429 root      20   0  221900  65236  30152 S   1.0  3.5   0:18.03 kube-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf --bind-addre+
   442 root      20   0       0      0      0 S   0.3  0.0   0:01.02 [xfsaild/dm-0]
  1000 root      20   0 1155792  44968  14332 S   0.3  2.4   0:00.95 /usr/bin/containerd
  2188 root      20   0  107688   6524   2700 S   0.3  0.4   0:00.04 containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/4cbd4244ccf55f156b620e442678e20a85fc2f28c4edb5e7f517c3539b5fdea1 -address /run/containerd/containerd.+
  
</code></pre>

<p>l 键 切换显示平均负载和启动时间信息:</p>

<table>
<thead>
<tr>
<th>top - 11:12:47</th>
<th>up 11 min,</th>
<th>1 user,</th>
<th>load average: 0.17, 0.23, 0.15</th>
</tr>
</thead>

<tbody>
<tr>
<td>当前系统时间</td>
<td>系统已运行时间</td>
<td>在线用户，包含系统用户</td>
<td>系统负载。分别是1，5，15分钟前到潜在的平均值</td>
</tr>
</tbody>
</table>

<table>
<thead>
<tr>
<th>Tasks</th>
<th>227 total</th>
<th>1 running</th>
<th>225 sleeping</th>
<th>1 stopped</th>
<th>0 zombie</th>
</tr>
</thead>

<tbody>
<tr>
<td>-</td>
<td>总进程数</td>
<td>正在运行的进程数</td>
<td>正在睡眠的进程数</td>
<td>停止的进程数</td>
<td>僵死进程数</td>
</tr>
</tbody>
</table>

<p>t键，cpu信息：</p>

<table>
<thead>
<tr>
<th>%Cpu(s)</th>
<th>0.8 us</th>
<th>1.0 sy</th>
<th>0.0 ni</th>
<th>98.2 id</th>
<th>0.0 wa</th>
<th>0.0 hi</th>
<th>0.0 si</th>
<th>0.0 st</th>
</tr>
</thead>

<tbody>
<tr>
<td>-</td>
<td>cpu占用率(%)，用户进程占用cpu百分率</td>
<td>系统占用cpu百分率</td>
<td>用户进程空间内改变过优先级的进程占用CPU百分比</td>
<td>cpu空闲率</td>
<td>等待IO的CPU时间百分比</td>
<td>硬中断（Hardware IRQ）占用CPU的百分比</td>
<td>软中断（Software Interrupts）占用CPU的百分比</td>
<td>虚拟机占用百分比</td>
</tr>
</tbody>
</table>

<p>m键 内存信息：</p>

<table>
<thead>
<tr>
<th>KiB Mem</th>
<th>8175028 total</th>
<th>635844 free</th>
<th>3024460 used</th>
<th>4514724 buff/cache</th>
</tr>
</thead>

<tbody>
<tr>
<td>-</td>
<td>内存总量</td>
<td>内存空闲量</td>
<td>内存使用量</td>
<td>缓存的内存量</td>
</tr>
</tbody>
</table>

<p>交换区信息：</p>

<table>
<thead>
<tr>
<th>KiB Swap</th>
<th>15624016 total</th>
<th>15606756 free</th>
<th>17260 used</th>
<th>4678020 avail Mem</th>
</tr>
</thead>

<tbody>
<tr>
<td>-</td>
<td>交换区总量</td>
<td>交换区空闲量</td>
<td>交换区使用量</td>
<td>缓冲交换区总量</td>
</tr>
</tbody>
</table>

<table>
<thead>
<tr>
<th>PID</th>
<th>USER</th>
<th>PR</th>
<th>NI</th>
<th>VIRT</th>
<th>RES</th>
<th>SHR</th>
<th>S</th>
<th>%CPU</th>
<th>%MEM</th>
<th>TIME+</th>
<th>COMMAND</th>
</tr>
</thead>

<tbody>
<tr>
<td>进程号</td>
<td>进程创建者</td>
<td>进程优先级</td>
<td>nice值</td>
<td>进程使用的虚拟内存总量</td>
<td>进程使用的、未被换出的物理内存大小</td>
<td>共享内存大小</td>
<td>进程状态</td>
<td>进程占用cpu百分比</td>
<td>进程占用内存百分比</td>
<td>进程运行时间</td>
<td>进程名称</td>
</tr>
</tbody>
</table>

<ul>
<li>NI nice值。越小优先级越高，最小-20，最大20（用户设置最大19）</li>
<li>VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES</li>
<li>RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA</li>
<li>SHR 共享内存大小，单位kb</li>
<li>S 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一致性算法]]></title>
    <link href="http://www.throne4j.com/15983668905198.html"/>
    <updated>2020-08-25T22:48:10+08:00</updated>
    <id>http://www.throne4j.com/15983668905198.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、什么是一致性</h2>

<p>CAP理论，对于一个分布式系统，不能同时满足一下三点</p>

<ul>
<li>一致性（Consistency）</li>
<li>可用性（Availability）</li>
<li>分区容错性（Partition Tolerance）</li>
</ul>

<p><figure><img src="media/15983668905198/16008790045537.jpg" alt=""/></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[幂等方案]]></title>
    <link href="http://www.throne4j.com/15979251824377.html"/>
    <updated>2020-08-20T20:06:22+08:00</updated>
    <id>http://www.throne4j.com/15979251824377.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Arthas]]></title>
    <link href="http://www.throne4j.com/15978529329852.html"/>
    <updated>2020-08-20T00:02:12+08:00</updated>
    <id>http://www.throne4j.com/15978529329852.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">简介</h2>

<p>Arthas 是 Alibaba 开源的 Java 诊断工具,在线排查问题，无需重启；动态跟踪Java代码；实时监控JVM状态。</p>

<p><a href="https://alibaba.github.io/arthas/">官方文档参考</a><br/>
<a href="https://arthas.aliyun.com/doc/quick-start.html">快速入门</a></p>

<p>当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决：</p>

<p>这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？<br/>
我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？<br/>
遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？<br/>
线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！<br/>
是否有一个全局视角来查看系统的运行状况？<br/>
有什么办法可以监控到JVM的实时运行状态？<br/>
怎么快速定位应用的热点，生成火焰图？</p>

<h2 id="toc_1">下载和安装</h2>

<p>不需要安装，就是一个 jar 包</p>

<pre><code class="language-text">curl -O https://alibaba.github.io/arthas/arthas-boot.jar 

java -jar arthas-boot.jar
</code></pre>

<p>启动 arthas 的 jar 包是 arthas-boot.jar</p>

<p>直接 java -jar arthas-boot.jar。选择 attach 的进程绑定<br/>
<figure><img src="media/15773440983590/15976833500370.jpg" alt=""/></figure></p>

<h2 id="toc_2">arthas 命令</h2>

<p>输入help查看 arthas 支持的命令</p>

<pre><code class="language-shell">[arthas@29087]$ help
 NAME         DESCRIPTION
 help         Display Arthas Help
 keymap       Display all the available keymap for the specified connection.
 sc           Search all the classes loaded by JVM
 sm           Search the method of classes loaded by JVM
 classloader  Show classloader info
 jad          Decompile class
 getstatic    Show the static field of a class
 monitor      Monitor method execution statistics, e.g. total/success/failure count, average rt, fail rate, etc.
 stack        Display the stack trace for the specified class and method
 thread       Display thread info, thread stack
 trace        Trace the execution time of specified method invocation.
 watch        Display the input/output parameter, return object, and thrown exception of specified method invocation
 tt           Time Tunnel
 jvm          Display the target JVM information
 perfcounter  Display the perf counter infornation.
 ognl         Execute ognl expression.
 mc           Memory compiler, compiles java files into bytecode and class files in memory.
 redefine     Redefine classes. @see Instrumentation#redefineClasses(ClassDefinition...)
 dashboard    Overview of target jvm&#39;s thread, memory, gc, vm, tomcat info.
 dump         Dump class byte array from JVM
 heapdump     Heap dump
 options      View and change various Arthas options
 cls          Clear the screen
 reset        Reset all the enhanced classes
 version      Display Arthas version
 session      Display current session information
 sysprop      Display, and change the system properties.
 sysenv       Display the system env.
 vmoption     Display, and update the vm diagnostic options.
 logger       Print logger info, and update the logger level
 history      Display command history
 cat          Concatenate and print files
 echo         write arguments to the standard output
 pwd          Return working directory name
 mbean        Display the mbean information
 grep         grep command for pipes.
 tee          tee command for pipes.
 profiler     Async Profiler. https://github.com/jvm-profiling-tools/async-profiler
 stop         Stop/Shutdown Arthas server and exit the console.
</code></pre>

<h3 id="toc_3">dashboard</h3>

<p><figure><img src="media/15773440983590/15976836704891.jpg" alt="" style="width:1891px;"/></figure></p>

<h3 id="toc_4">thread</h3>

<p>这个命令和 jstack 很相似，但是功能更加强大，主要是查看当前 JVM 的线程堆栈信息 同时可以结合使用 thread –b 来进行死锁的排查死锁。</p>

<p>参数说明:</p>

<pre><code class="language-text">-n 指定最忙的前 n 个线程并打印堆栈
-b 找出阻塞当前线程的线程
-i 指定 cpu 占比统计的采样间隔，单位为毫秒
</code></pre>

<pre><code class="language-text">[arthas@29087]$ thread -b
&quot;Thread-0&quot; Id=11 BLOCKED on java.lang.Object@602bace6 owned by &quot;Thread-1&quot; Id=12
    at com.goddess.base.concurrent.SynchronizedObjDeadLock.lambda$deadLock$0(SynchronizedObjDeadLock.java:27)
    -  blocked on java.lang.Object@602bace6
    -  locked java.lang.Object@12487489 &lt;---- but blocks 1 other threads!
    at com.goddess.base.concurrent.SynchronizedObjDeadLock$$Lambda$1/122883338.run(Unknown Source)
    at java.lang.Thread.run(Thread.java:745)
</code></pre>

<p>thread -i 1000 -n 3 每过 1000 毫秒进行采样，显示最占 CPU 时间的前 3 个线程</p>

<p>thread --state WAITING 查看处于等待状态的线程</p>

<h3 id="toc_5">jvm</h3>

<p>查看jvm信息<br/>
<figure><img src="media/15773440983590/15976840064874.jpg" alt=""/></figure></p>

<h3 id="toc_6">jad 反编译指定已加载类的源码</h3>

<p><figure><img src="media/15773440983590/15976841522972.jpg" alt="" style="width:1293px;"/></figure></p>

<h3 id="toc_7">trace</h3>

<p>使用 trace 命令可以跟踪统计方法耗时。</p>

<p>例如：trace com.goddess.base.controller.UserController get</p>

<h3 id="toc_8">monitor 方法监控</h3>

<p>监控的维度说明：</p>

<table>
<thead>
<tr>
<th>监控项</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>timestamp</td>
<td>时间戳</td>
</tr>
<tr>
<td>class</td>
<td>Java类</td>
</tr>
<tr>
<td>method</td>
<td>方法（构造方法、普通方法）</td>
</tr>
<tr>
<td>total</td>
<td>调用次数</td>
</tr>
<tr>
<td>success</td>
<td>成功次数</td>
</tr>
<tr>
<td>fail</td>
<td>失败次数</td>
</tr>
<tr>
<td>rt</td>
<td>平均RT</td>
</tr>
<tr>
<td>fail-rate</td>
<td>失败率</td>
</tr>
</tbody>
</table>

<p>每 5 秒统计一次 com.goddess.base.controller.UserController 类的 get 方法执行情况</p>

<pre><code class="language-text">&gt; monitor -c 5 com.goddess.base.controller.UserController get
timestamp            class          method        total  success  fail  avg-rt(ms)  fail-rate
-----------------------------------------------------------------------------------------------
 2018-12-03 19:06:38  demo.MathGame  primeFactors  5      1        4     1.15        80.00%
</code></pre>

<h3 id="toc_9">watch</h3>

<p>让你能方便的观察到指定方法的调用情况。能观察到的范围为：返回值、抛出异常、入参，通过编写 OGNL 表达式进行对应变量的查看。</p>

<p>参数说明：</p>

<ul>
<li>class-pattern 类名表达式</li>
<li>method-pattern 方法名表达式匹配</li>
<li>express 观察表达式</li>
<li>condition-express 条件表达式</li>
<li>b 在方法调用之前观察</li>
<li>e 在方法调用之后观察,异常抛出时才触发</li>
<li>s 在方法返回之后观察</li>
<li>f 在方法结束之后观察</li>
<li>E 开启正则表达式匹配，默认为通配符匹配</li>
<li>[x:] 指定输出结果的属性遍历深度，默认为1</li>
</ul>

<p>特别说明：</p>

<ul>
<li><p>watch 命令定义了4个观察事件点，即 -b 方法调用前，-e 方法异常后，-s 方法返回后，-f 方法结束后</p></li>
<li><p>4个观察事件点 -b、-e、-s 默认关闭，-f 默认打开，当指定观察点被打开后，在相应事件点会对观察表达式进行求值并输出</p></li>
<li><p>这里要注意方法入参和方法出参的区别，有可能在中间被修改导致前后不一致，除了 -b 事件点 params 代表方法入参外，其余事件都代表方法出参</p></li>
<li><p>当使用 -b 时，由于观察事件点是在方法调用前，此时返回值或异常均不存在</p></li>
</ul>

<p>变量说明：</p>

<table>
<thead>
<tr>
<th>变量名</th>
<th>变量解释</th>
</tr>
</thead>

<tbody>
<tr>
<td>loader</td>
<td>本次调用类所在的 ClassLoader</td>
</tr>
<tr>
<td>clazz</td>
<td>本次调用类的 Class 引用</td>
</tr>
<tr>
<td>method</td>
<td>本次调用方法反射引用</td>
</tr>
<tr>
<td>target</td>
<td>本次调用类的实例</td>
</tr>
<tr>
<td>params</td>
<td>本次调用参数列表，这是一个数组，如果方法是无参方法则为空数组</td>
</tr>
<tr>
<td>returnObj</td>
<td><code>本次调用返回的对象。当且仅当 isReturn==true 成立时候有效，表明方法调用是以正常返回的方式结束。如果当前方法无返回值 void，则值为 null</code></td>
</tr>
<tr>
<td>throwExp</td>
<td><code>本次调用抛出的异常。当且仅当 isThrow==true 成立时有效，表明方法调用是以抛出异常的方式结束。</code></td>
</tr>
<tr>
<td>isBefore</td>
<td><code>辅助判断标记，当前的通知节点有可能是在方法一开始就通知，此时 isBefore==true 成立，同时 isThrow==false 和 isReturn==false，因为在方法刚开始时，还无法确定方法调用将会如何结束。</code></td>
</tr>
<tr>
<td>isThrow</td>
<td>辅助判断标记，当前的方法调用以抛异常的形式结束。</td>
</tr>
<tr>
<td>isReturn</td>
<td>辅助判断标记，当前的方法调用以正常返回的形式结束。</td>
</tr>
</tbody>
</table>

<pre><code class="language-shell"># 查看get方法的入参和出参
&gt; watch com.goddess.base.controller.UserController get &#39;{params[0],returnObj}&#39; -x 2

# 按照耗时进行过滤,#cost&gt;200(单位是ms)表示只有当耗时大于200ms时才会输出，过滤掉执行时间小于200ms的调用
&gt; watch com.goddess.base.controller.UserController get &#39;{params[0],returnObj}&#39; &#39;#cost&gt;200&#39; -x 2
&gt; 
</code></pre>

<h3 id="toc_10">stack 输出当前方法被调用的调用路径</h3>

<p>参数说明：</p>

<ul>
<li>class-pattern 类名表达式匹配</li>
<li>method-pattern 方法名表达式匹配</li>
<li>condition-express 条件表达式</li>
<li>[n:] 执行次数限制</li>
<li>[E] 开启正则表达式匹配，默认为通配符匹配</li>
</ul>

<p>据执行时间来过滤：<br/>
stack demo.MathGame primeFactors &#39;#cost&gt;5&#39;</p>

<h3 id="toc_11">tt</h3>

<p>方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测</p>

<h3 id="toc_12">vmoption 查看，更新JVM 诊断相关参数</h3>

<p>查看JVM诊断相关参数：</p>

<pre><code class="language-shell">[arthas@56963]$ vmoption
 KEY                    VALUE                   ORIGIN                 WRITEABLE
---------------------------------------------------------------------------------------------
 HeapDumpBeforeFullGC   false                   DEFAULT                true
 HeapDumpAfterFullGC    false                   DEFAULT                true
 HeapDumpOnOutOfMemory  false                   DEFAULT                true
 Error
 HeapDumpPath                                   DEFAULT                true
 CMSAbortablePrecleanW  100                     DEFAULT                true
 aitMillis
 CMSWaitDuration        2000                    DEFAULT                true
 CMSTriggerInterval     -1                      DEFAULT                true
 PrintGC                false                   DEFAULT                true
 PrintGCDetails         true                    MANAGEMENT             true
 PrintGCDateStamps      false                   DEFAULT                true
 PrintGCTimeStamps      false                   DEFAULT                true
 PrintGCID              false                   DEFAULT                true
 PrintClassHistogramBe  false                   DEFAULT                true
 foreFullGC
 PrintClassHistogramAf  false                   DEFAULT                true
 terFullGC
 PrintClassHistogram    false                   DEFAULT                true
 MinHeapFreeRatio       0                       DEFAULT                true
 MaxHeapFreeRatio       100                     DEFAULT                true
 PrintConcurrentLocks   false                   DEFAULT                true
</code></pre>

<p>查看指定option</p>

<pre><code class="language-shell">[arthas@56963]$ vmoption PrintGCDetails
 KEY                    VALUE                   ORIGIN                 WRITEABLE
---------------------------------------------------------------------------------------------
 PrintGCDetails         false                   MANAGEMENT             true

</code></pre>

<p>更新指定option：</p>

<pre><code class="language-shell">[arthas@56963]$ vmoption PrintGCDetails true
Successfully updated the vm option.
PrintGCDetails=true
</code></pre>

<h3 id="toc_13">sc 查看jvm已加载的类信息</h3>

<p>参数说明：<br/>
<figure><img src="media/15773440983590/15978503405145.jpg" alt=""/></figure></p>

<pre><code class="language-text">#模糊搜索
$ sc demo.*
demo.MathGame
Affect(row-cnt:1) cost in 55 ms.

</code></pre>

<h3 id="toc_14">sm 查看已加载类的方法信息</h3>

<h3 id="toc_15">classloader 查看 classloader的继承树，urls，类加载信息</h3>

<h3 id="toc_16">heapdum 类似jmap命令的heap dump功能</h3>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[InnoDB 存储引擎]]></title>
    <link href="http://www.throne4j.com/15973328663419.html"/>
    <updated>2020-08-13T23:34:26+08:00</updated>
    <id>http://www.throne4j.com/15973328663419.html</id>
    <content type="html"><![CDATA[
<p>InnoDB存储引擎支持事务，其设计目标主要面向在线事务处理（OLTP）的应用。</p>

<p>其特点是</p>

<ul>
<li>行锁设计</li>
<li>支持外检- 支持外键</li>
<li>非锁定读（默认读取操作不会产生锁）</li>
</ul>

<p>InnoDB存储引擎将数据放在一个逻辑的表空间中，这块空间有它自己进行管理。</p>

<p>InnoDB使用多版本并发控制（MVCC）来获得高并发性，并且实现了sql的标准的4中隔离级别，默认 repeatable级别。</p>

<p>使用一种被称为next-key locking的策略来避免幻读现象的产生。</p>

<p>InnoDB关键特性提供高性能和高可用性：</p>

<ul>
<li>插入缓冲 </li>
<li>二次写</li>
<li>自适应哈希索引</li>
<li>异步IO</li>
<li>刷新临近页</li>
<li>预读</li>
</ul>

<p>InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。</p>

<p>InnoDB的整体架构包括多个内存组成的多个后台线程和缓冲池。</p>

<h2 id="toc_0">InnoDB 多后台线程</h2>

<p>InnoDB存储引擎是多线程模型，其后台线程执行不同的任务</p>

<ul>
<li>Master Thread：负责将缓冲池中的数据异步刷新到硬盘</li>
<li>IO Thread：负责InnoDB存储引擎中的大量的AIO的请求回调处理</li>
<li>Purge thread：事务提交后，其所使用的的undolog可能不在需要，此线程是回收已经使用并分配的undo页</li>
<li>Page cleaner thread：刷新脏页</li>
</ul>

<h2 id="toc_1">InnoDB 存储引擎的优化</h2>

<p>合理利用 Innodb 的行级锁定，做到扬长避短，我们必须做好以下工作：<br/>
a) 尽可能让所有的数据检索都通过索引来完成，从而避免 Innodb 因为无法通过索引键加锁而升级为表级锁定；</p>

<p>b) 合理设计索引，让 Innodb 在索引键上面加锁的时候尽可能准确，尽可能的缩小锁定范围，避免造成不必要的锁定而影响其他 Query 的执行；</p>

<p>c) 尽可能减少基于范围的数据检索过滤条件，避免因为间隙锁带来的负面影响而锁定了不该锁定的记录；</p>

<p>d) 尽量控制事务的大小，减少锁定的资源量和锁定时间长度；</p>

<p>e) 在业务环境允许的情况下，尽量使用较低级别的事务隔离，以减少 MySQL 因为实现事务隔离级别所带来的附加成本；</p>

<p>Innodb 的行级锁定和事务性，所以肯定会产生死锁，下面是一些比较常用的减少死锁产生概率的的小建议：</p>

<p>a) 类似业务模块中，尽可能按照相同的访问顺序来访问，防止产生死锁；<br/>
b) 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；<br/>
c) 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；</p>

<p>Innodb 所使用的行级锁定:<br/>
show status like &#39;innodb_row_lock%&#39;</p>

<table>
<thead>
<tr>
<th>Variable_name</th>
<th>Value</th>
</tr>
</thead>

<tbody>
<tr>
<td>Innodb_row_lock_current_waits</td>
<td>0</td>
</tr>
<tr>
<td>Innodb_row_lock_time</td>
<td>490578</td>
</tr>
<tr>
<td>Innodb_row_lock_time_avg</td>
<td>37736</td>
</tr>
<tr>
<td>Innodb_row_lock_time_max</td>
<td>121411</td>
</tr>
<tr>
<td>Innodb_row_lock_waits</td>
<td>13</td>
</tr>
</tbody>
</table>

<p>●Innodb_row_lock_current_waits：当前正在等待锁定的数量；●Innodb_row_lock_time：从系统启动到现在锁定总时间长度；●Innodb_row_lock_time_avg：每次等待所花平均时间；●Innodb_row_lock_time_max：从系统启动到现在等待最常的一次所花的时间；●Innodb_row_lock_waits：系统启动后到现在总共等待的次数；</p>

<h2 id="toc_2">缓冲池</h2>

<p>InnoDB是基于磁盘存储的，为了提高数据库的整体性能，引入了缓冲池技术。</p>

<p>在数据库中进行读取页的操作首先将从磁盘读取到的页存放在缓冲池中，这个过程称为“FIX”在缓冲池中，下次读取相同页的时候，首先判断页是否在缓冲池中，若在，称该页在缓冲池中被命中，否则从磁盘上读取该页数据。</p>

<p>对数据库中的页进行修改操作，首先修改缓冲池中的页，在以一定频路刷新到磁盘，但是并不是每次页发生改变的时候就进行刷新，而是通过一种称为 Checkpoint的机制刷新回磁盘。</p>

<p>因此缓冲池的大小直接影响着数据库的整体性能。</p>

<p>缓冲池中缓冲的数据页类型主要有如下几种：</p>

<ul>
<li>索引页</li>
<li>数据页</li>
<li>undo页</li>
<li>插入缓冲页（insert buffer）</li>
<li>自适应哈希索引（adaptive hash index）</li>
<li>InnoDB 存储的锁信息（lock info）</li>
<li>数据字典信息</li>
</ul>

<p>允许有多个缓冲池实例，每个页根据hash值平均分派到不同的缓冲池实例中，可以减少数据库内部资源的竞争，增加数据库的并发处理能力。</p>

<p>缓冲池中的页通过LRU（Latest recent used，最近最少使用）算法来进行管理的。使用最频繁的页放在 LRU 列表的前端。</p>

<p>缓冲池的默认大小是16KB,也可能将页进行压缩然后存放到unzip_LRU列表进行管理。</p>

<p>在LRU列表中的页被修改后，称该页为 脏页，即缓冲池中的页和磁盘中的页数据不一致了。这是数据库通过checkpoint机制将脏页刷新会磁盘。Flush列表中的页即为脏页列表。</p>

<p>通过 show engine innodb status命令查看innodb的状态</p>

<pre><code class="language-text">&gt; show engine innodb status;
.....
BUFFER POOL AND MEMORY
----------------------
Total large memory allocated 137363456
Dictionary memory allocated 415854
Buffer pool size   8191  缓冲池大小
Free buffers       6922  剩余缓存
Database pages     1264 页数量
Old database pages 486  
Modified db pages  0    脏页数量
Pending reads      0
Pending writes: LRU 0, flush list 0, single page 0
Pages made young 0, not young 0
0.00 youngs/s, 0.00 non-youngs/s
Pages read 1122, created 142, written 150
0.00 reads/s, 0.00 creates/s, 0.00 writes/s
No buffer pool page gets since the last printout
Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s
LRU len: 1264, unzip_LRU len: 0
I/O sum[0]:cur[0], unzip sum[0]:cur[0]

</code></pre>

<h3 id="toc_3">重做日志缓冲</h3>

<p>InnoDB 存储引擎的内存区域除了有缓冲池外，还有重做日志缓冲（redo log buffer）。innodb存储引擎首先将重做日志信息放入这个缓冲区，然后按照一定频率将其刷新到重做日志文件。这个区域不用设置很大，基本是每秒产生的事务量在这个缓冲大小之内即可(innodb_log_buffer_size参数设置其大小，通常8MB可以满足大部分应用)。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[初识 MySql数据库]]></title>
    <link href="http://www.throne4j.com/15973285844161.html"/>
    <updated>2020-08-13T22:23:04+08:00</updated>
    <id>http://www.throne4j.com/15973285844161.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">MySql 体系结构</h2>

<p>要了解 MySql 必须牢牢记住其体系结构，如下图所示：</p>

<p><figure><img src="media/15973285844161/15973287823877.jpg" alt=""/></figure></p>

<p>从上图中发现，MySql 有一下几部分组成：</p>

<ul>
<li>连接池组件</li>
<li>管理服务和工具组件</li>
<li>SQL接口组件</li>
<li>查询分析器组件</li>
<li>优化器组件</li>
<li>缓冲组件</li>
<li>插件式存储引擎</li>
<li><p>物理文件</p>
<p><figure><img src="media/15973285844161/15998149940012.jpg" alt="" style="width:908px;"/></figure></p></li>
</ul>

]]></content>
  </entry>
  
</feed>
