<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大爷来玩儿啊~]]></title>
  <link href="http://www.throne4j.com/atom.xml" rel="self"/>
  <link href="http://www.throne4j.com/"/>
  <updated>2020-08-04T01:18:55+08:00</updated>
  <id>http://www.throne4j.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[七、JVM类的加载机制]]></title>
    <link href="http://www.throne4j.com/15962980278783.html"/>
    <updated>2020-08-02T00:07:07+08:00</updated>
    <id>http://www.throne4j.com/15962980278783.html</id>
    <content type="html"><![CDATA[
<p>从类被加载到虚拟机内存中开始，到卸载出内存为止，类的生命周期包括加载(Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unloading)7个阶段，其中验证、准备和解析三部分称为连接。类的加载、连接、初始化过程都是在程序运行期间进行的</p>

<p>在如下几种情况下，Java虚拟机将结束生命周期</p>

<pre><code class="language-text">– 执行了System.exit()方法

– 程序正常执行结束

– 程序在执行过程中遇到了异常或错误而异常终止

– 由于操作系统出现错误而导致Java虚拟机进程终止
</code></pre>

<hr/>

<h2 id="toc_0">类加载器的类型</h2>

<ol>
<li>java虚拟机自带的加载器
<ul>
<li>启动类加载器 (Bootstrap Classloader)<br/>
此加载器没有父加载器，它的实现依赖于操作系统地城服务，是java虚拟机实现的一部分，负责加载虚拟机的核心类库。</li>
<li>扩展类加载器 (Extension Classloader)<br/>
扩展加载器负责加载系统属性java.ext.dirs指定位置的类库、加载jdk安装目录下面的jre/lib/ext目录下的类库，父类是java.lang.ClassLoader</li>
<li>应用程序类加载器 (application Classloader)<br/>
应用类加载器负责加载classpath或者系统属性java.class.path所指位置的类库。</li>
</ul></li>
<li>用户自定义的类加载器<br/>
继承java.lang.ClassLoader，通过重写方法findClass/loadClass方法来实现自定义的委派机制/破坏委派机制的类加载器</li>
</ol>

<p>加载器的加载阶段主要完成3件事：</p>

<pre><code class="language-text">1. 通过类的全限定名来获取定义此类的二进制字节流
2. 将这个类字节流代表的静态存储结构转为 方法区的运行时数据结构
3. 在堆中生成一个代表此类的java.lang.Class对象，作为访问方法区这些数据结构的入口。
</code></pre>

<p>JVM 规范允许加载器预测到某个类将要被使用就会预先加载这个类，在加载这个类的时候，如果发现这个class类有缺失或存在错误，类加载器必须在<strong><em>这个类被首次被使用的时候才会抛出错误信息</em></strong>。如果这类一直没有被程序主动使用，则加载器不会跑抛出错误。</p>

<p><strong>获取ClassLoader的方式</strong>：</p>

<ul>
<li>clazz.getClassLoader() 获取当前类的加载器</li>
<li>Thread.currentThread().getContextClassLoader() 获取当前线程的加载器</li>
<li>ClassLoader.getSystemClassLoader() 获取系统的加载器</li>
<li>DriverManager.getCallerClassLoader 获取调用者的ClassLoader</li>
</ul>

<h2 id="toc_1">jvm类加载器加载机制</h2>

<ul>
<li>全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载</li>
<li>父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类</li>
<li>缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效</li>
</ul>

<p>类加载有三种方式：</p>

<pre><code class="language-text">1、命令行启动应用时候由JVM初始化加载
2、通过Class.forName()方法动态加载
3、通过ClassLoader.loadClass()方法动态加载
</code></pre>

<p>对于数组类而言， 情况就有所不同， 数组类本身不通过类加载器创建， 它是由 Java 虚拟机直接创建的。 但数组类与类加载器仍然有很密切的关系， 因为数组类的元素类型 (Element一个数组类（下面简Type, 指的是数组去掉所有维度的类型）最终是要靠类加载器去创建，一个数组类（简称为C)创建过程就遵循以下规则：</p>

<ol>
<li><p>如果数组的组件类型（Component Type, 指的是数组去掉一个维度的类型）是引用类型， 那就递归采用本节中定义的加载过程去加载这个组件类型， 数组C将在加载该组件类型的类加载器的类名称空间上被标识（ 一个类必须与类加载器一起确定唯一性）．</p></li>
<li><p>如果数组的组件类型不是引用类型（假如是int[] 数组）， 数组是没有加载器的。</p></li>
<li><p>数组类的可见性与它的组件类型的可见性一致， 如果组件类型不是引用类型， 那数组类的可见性将默认为public 。</p></li>
</ol>

<p>下面我们看下Class.forName(String name, boolean initialize, ClassLoader loader)方法的实现</p>

<pre><code class="language-text">/**
* name: 要加载类的名称
* initalize: 是否要进行初始化操作，true：加载完之后要进行初始化操作，false不进行初始化操作
* loader: 指定类加载加载器，如果为null，则使用启动加载器进行加载。
* 
*/
public static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader) throws ClassNotFoundException {
        Class&lt;?&gt; caller = null;
        SecurityManager sm = System.getSecurityManager();
        if (sm != null) {
            // Reflective call to get caller class is only needed if a security manager
            // is present.  Avoid the overhead of making this call otherwise.
            caller = Reflection.getCallerClass();
            if (sun.misc.VM.isSystemDomainLoader(loader)) {
                ClassLoader ccl = ClassLoader.getClassLoader(caller);
                if (!sun.misc.VM.isSystemDomainLoader(ccl)) {
                    sm.checkPermission(
                        SecurityConstants.GET_CLASSLOADER_PERMISSION);
                }
            }
        }
        return forName0(name, initialize, loader, caller);
    }
    
    /** Called after security check for system loader access checks have been made. */
    private static native Class&lt;?&gt; forName0(String name, boolean initialize,
                                            ClassLoader loader,
                                            Class&lt;?&gt; caller)
        throws ClassNotFoundException;
</code></pre>

<h2 id="toc_2">双亲委派模型</h2>

<p>JVM的类加载器的实现方式采用双亲委派机制，所谓双亲委派机制是加载器在收到加载某个类的请求时，首先，它自己不会尝试去加载这个类，而是将请求委派给父加载器去完成，最终会委派给启动加载器(bootstrap classloader)去完成，如果父加载器无法完成加载请求，则在将请求委派给子加载器去完成。</p>

<p>双亲委派模型意义：</p>

<ul>
<li>可以确保java核心类库所提供的类不会被自定义的类所代替</li>
<li>不同的类加载器可以为相同名称的类创建额外的命名空间。相同名称的类可以并存在java虚拟机中，但需要不同的类加载器来加载他们</li>
<li>不同类加载器所加载的类之间是不兼容的，这就相当于在java虚拟机内部创建了多个相互隔离的java类空间</li>
</ul>

<p>通过重写方法findClass/loadClass方法可以实现自定义的委派机制/破坏委派机制的类加载器</p>

<p><strong>子加载器能访问到父加载器加载的类，但是反过来父加载器无法访问到子加载器所加载的类</strong><br/>
每个加载器都有属于它自己的命名空间</p>

<p>在运行期，一个java类的唯一性是由该类的完全限定名称(二进制名),和用于加载该类的定义类加载器所共同决定的。</p>

<p>父ClassLoader可以使用当前线程Thread.currentThread().getContextClassLoader()所制定的ClassLoader加载的类，这就改变了父classLoader不能使用子classLoader或其他没有直接父子关系的ClassLoader加载的类的情况.</p>

<p>如果没有通过setContextClassLoader(ClassLoader cl)进行设置的话，线程将继承其父线程的上下文加载器(在Laucher启动类中设置的)。java应用运行时的初始线程的上下文加载器是系统类加载器。在线程中运行的代码可以通过该类的加载器来加载类与资源。</p>

<p><strong>SPI(service provider interface)</strong></p>

<p>在双亲委托模型下，类加载是右下至上的，即下层的类加载器会委托上层加载器进行加载。但对于SPI来说，有些接口是Java和兴库所提供的，而java核心库是由启动类加载器来加载的，而这些接口的实现却来自于不同的jar包，java的启动类加载器是不会加载其他来源的jar包，这样传统的双亲委托模型就无法满足SPI要求。</p>

<p>通过给当前线程设置上下文类加载器，就可以由设置的上下文类加载器来实现对接口实现类的加载,在SPI开发中经常使用到。</p>

<p>关于线程上下文类加载器的使用模式</p>

<p>如果一个类由加载器A加载，那么这个类的依赖类也是由相同的累啊加载器A加载的。ContextClassLoader 的作用就是为了破坏java的类加载机制。</p>

<p>当高层提供了统一的接口让低层去实现，同时又要在搞成加载低层的类，就必须通过线程上下文类加载器来帮助高层ClassLoader找到并加载类。</p>

<p>ServiceLoader类在jvm中是很重要的类,一个简单的服务提供者 加载工具。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TCP/IP协议]]></title>
    <link href="http://www.throne4j.com/15957430515176.html"/>
    <updated>2020-07-26T13:57:31+08:00</updated>
    <id>http://www.throne4j.com/15957430515176.html</id>
    <content type="html"><![CDATA[
<p><figure><img src="media/15955594725422/15955601439229.jpg" alt=""/></figure></p>

<h2 id="toc_0">1、计算机网络体系结构分层</h2>

<p><figure><img src="media/15955594725422/15955601585104.jpg" alt=""/></figure></p>

<p><figure><img src="media/15955594725422/15955601789832.jpg" alt=""/></figure><br/>
TCP/IP 与 OSI 在分层模块上稍有区别。OSI 参考模型注重“通信协议必要的功能是什么”，而 TCP/IP 则更强调“在计算机上实现协议应该开发哪种程序”。</p>

<h2 id="toc_1">2、 TCP/IP基础</h2>

<h3 id="toc_2">2.1、TCP/IP 的具体含义</h3>

<p>从字面意义上讲，有人可能会认为 TCP/IP 是指 TCP 和 IP 两种协议。实际生活当中有时也确实就是指这两种协议。然而在很多情况下，它只是利用 IP 进行通信时所必须用到的协议群的统称。具体来说，IP 或 ICMP、TCP 或 UDP、TELNET 或 FTP、以及 HTTP 等都属于 TCP/IP 协议。他们与 TCP 或 IP 的关系紧密，是互联网必不可少的组成部分。TCP/IP 一词泛指这些协议，因此，有时也称 TCP/IP 为网际协议群。互联网进行通信时，需要相应的网络协议，TCP/IP 原本就是为使用互联网而开发制定的协议族。因此，互联网的协议就是 TCP/IP，TCP/IP 就是互联网的协议。</p>

<p><figure><img src="media/15955594725422/15955738573555.jpg" alt=""/></figure></p>

<h3 id="toc_3">2.2、数据包</h3>

<p>包、帧、数据包、段、消息以上五个术语都用来表述数据的单位，大致区分如下：</p>

<ul>
<li>包可以说是全能性术语；</li>
<li>帧用于表示数据链路层中包的单位；</li>
<li>数据包是 IP 和 UDP 等网络层以上的分层中包的单位；</li>
<li>段则表示 TCP 数据流中的信息；</li>
<li>消息是指应用协议中数据的单位。</li>
</ul>

<p>每个分层中，都会对所发送的数据附加一个首部，在这个首部中包含了该层必要的信息，如发送的目标地址以及协议相关信息。通常，为协议提供的信息为包首部，所要发送的内容为数据。在下一层的角度看，从上一层收到的包全部都被认为是本层的数据。</p>

<p><figure><img src="media/15955594725422/15955739013238.jpg" alt=""/></figure></p>

<p>网络中传输的数据包由两部分组成：一部分是协议所要用到的首部，另一部分是上一层传过来的数据。首部的结构由协议的具体规范详细定义。在数据包的首部，明确标明了协议应该如何读取数据。反过来说，看到首部，也就能够了解该协议必要的信息以及所要处理的数据。包首部就像协议的脸。</p>

<h3 id="toc_4">2.3、 数据处理流程</h3>

<p>下图以用户a 向 用户b 发送邮件为例子<br/>
<figure><img src="media/15955594725422/15955739368710.jpg" alt=""/></figure></p>

<p>① 应用程序处理首先应用程序会进行编码处理，这些编码相当于 OSI 的表示层功能；编码转化后，邮件不一定马上被发送出去，这种何时建立通信连接何时发送数据的管理功能，相当于 OSI 的会话层功能。<br/>
② TCP 模块的处理TCP 根据应用的指示，负责建立连接、发送数据以及断开连接。TCP 提供将应用层发来的数据顺利发送至对端的可靠传输。为了实现这一功能，需要在应用层数据的前端附加一个 TCP 首部。<br/>
③ IP 模块的处理IP 将 TCP 传过来的 TCP 首部和 TCP 数据合起来当做自己的数据，并在 TCP 首部的前端加上自己的 IP 首部。IP 包生成后，参考路由控制表决定接受此 IP 包的路由或主机。<br/>
④ 网络接口（以太网驱动）的处理从 IP 传过来的 IP 包对于以太网来说就是数据。给这些数据附加上以太网首部并进行发送处理，生成的以太网数据包将通过物理层传输给接收端。<br/>
⑤ 网络接口（以太网驱动）的处理主机收到以太网包后，首先从以太网包首部找到 MAC 地址判断是否为发送给自己的包，若不是则丢弃数据。如果是发送给自己的包，则从以太网包首部中的类型确定数据类型，再传给相应的模块，如 IP、ARP 等。这里的例子则是 IP 。<br/>
⑥ IP 模块的处理IP 模块接收到 数据后也做类似的处理。从包首部中判断此 IP 地址是否与自己的 IP 地址匹配，如果匹配则根据首部的协议类型将数据发送给对应的模块，如 TCP、UDP。这里的例子则是 TCP。另外吗，对于有路由器的情况，接收端地址往往不是自己的地址，此时，需要借助路由控制表，在调查应该送往的主机或路由器之后再进行转发数据。<br/>
⑦ TCP 模块的处理在 TCP 模块中，首先会计算一下校验和，判断数据是否被破坏。然后检查是否在按照序号接收数据。最后检查端口号，确定具体的应用程序。数据被完整地接收以后，会传给由端口号识别的应用程序。<br/>
⑧ 应用程序的处理接收端应用程序会直接接收发送端发送的数据。通过解析数据，展示相应的内容。</p>

<h2 id="toc_5">3、传输层中的 TCP 和 UDP</h2>

<p>TCP/IP 中有两个具有代表性的传输层协议，分别是 TCP 和 UDP。</p>

<ul>
<li>TCP 是面向连接的、可靠的流协议。流就是指不间断的数据结构，当应用程序采用 TCP 发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端。TCP 为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。</li>
<li>UDP 是不具有可靠性的数据报协议。细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。</li>
<li>TCP 和 UDP 的优缺点无法简单地、绝对地去做比较：TCP 用于在传输层有必要实现可靠传输的情况；而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。TCP 和 UDP 应该根据应用的目的按需使用。</li>
</ul>

<h3 id="toc_6">3.1、端口号</h3>

<p>数据链路和 IP 中的地址，分别指的是 MAC 地址和 IP 地址。前者用来识别同一链路中不同的计算机，后者用来识别 TCP/IP  网络中互连的主机和路由器。在传输层也有这种类似于地址的概念，那就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。</p>

<h4 id="toc_7">3.1.1、根据端口号识别应用</h4>

<p>一台计算机上同时可以运行多个程序。传输层协议正是利用这些端口号识别本机中正在进行通信的应用程序，并准确地将数据传输。</p>

<p><figure><img src="media/15955594725422/15955776803707.jpg" alt=""/></figure></p>

<h4 id="toc_8">3.1.2、通过IP地址、端口号、协议号进行通信识别</h4>

<p>仅凭目标端口好识别某一个通信是远远不够的。</p>

<p><figure><img src="media/15955594725422/15955782698920.jpg" alt=""/></figure></p>

<p><figure><img src="media/15955594725422/15955782793025.jpg" alt="通过源IP地址、目标IP地址、协议号、源端口号以及目标端口号这五个元素识别一个通信"/><figcaption>通过源IP地址、目标IP地址、协议号、源端口号以及目标端口号这五个元素识别一个通信</figcaption></figure></p>

<p>① 和② 的通信是在两台计算机上进行的。它们的目标端口号相同，都是80。这里可以根据源端口号加以区分。<br/>
③ 和 ① 的目标端口号和源端口号完全相同，但它们各自的源 IP 地址不同。<br/>
此外，当 IP 地址和端口号全都一样时，我们还可以通过协议号来区分（TCP 和 UDP）。</p>

<h4 id="toc_9">3.1.3、 端口号的确定</h4>

<ul>
<li><p>标准既定的端口号<br/>
这种方法也叫静态方法。它是指每个应用程序都有其指定的端口号。但并不是说可以随意使用任何一个端口号。例如 HTTP、FTP、TELNET 等广为使用的应用协议中所使用的端口号就是固定的。这些端口号被称为知名端口号，分布在 0~1023 之间；除知名端口号之外，还有一些端口号被正式注册，它们分布在 1024~49151 之间，不过这些端口号可用于任何通信用途。</p></li>
<li><p>时序分配法<br/>
服务器有必要确定监听端口号，但是接受服务的客户端没必要确定端口号。在这种方法下，客户端应用程序完全可以不用自己设置端口号，而全权交给操作系统进行分配。动态分配的端口号范围在 49152~65535 之间。</p></li>
</ul>

<h4 id="toc_10">3.1.4、端口号与协议</h4>

<ul>
<li>端口号由其使用的传输层协议决定。因此，不同的传输层协议可以使用相同的端口号。<br/>
此外，那些知名端口号与传输层协议并无关系。只要端口一致都将分配同一种应用程序进行处理。</li>
</ul>

<h3 id="toc_11">3.2、UDP</h3>

<p>UDP 不提供复杂的控制机制，利用IP提供面向无连接的通信服务，并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为。此外，传输途中出现丢包，UDP 也不负责重发。甚至当包的到达顺序出现乱序时也没有纠正的功能。如果需要以上的细节控制，不得不交由采用 UDP 的应用程序去处理。</p>

<p>UDP 常用于一下几个方面：1.包总量较少的通信（DNS、SNMP等）；2.视频、音频等多媒体通信（即时通信）；3.限定于 LAN 等特定网络中的应用通信；4.广播通信（广播、多播）。</p>

<h3 id="toc_12">3.3、TCP</h3>

<p>TCP 与 UDP 的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。</p>

<p>根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信，主要通过一下机制来保证：</p>

<ul>
<li>检验和<br/>
TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。</li>
<li>序列号</li>
<li>确认应答</li>
<li>重发控制</li>
<li>连接管理</li>
<li>窗口控制</li>
</ul>

<h4 id="toc_13">3.3.1、三次握手</h4>

<p>TCP 提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好两端之间的准备工作。</p>

<p>所谓三次握手是指建立一个 TCP 连接时需要客户端和服务器端总共发送三个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发。</p>

<p>三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。</p>

<p>下面来看看三次握手的流程图：</p>

<p><figure><img src="media/15955594725422/15956910155926.jpg" alt=""/></figure></p>

<ul>
<li>第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给服务器端，客户端进入SYN_SENT状态，等待服务器端确认。</li>
<li>第二次握手：服务器端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器端将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务器端进入SYN_RCVD状态。</li>
<li>第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务器端，服务器端检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器端进入ESTABLISHED状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。</li>
</ul>

<h4 id="toc_14">3.3.2、四次挥手</h4>

<p>四次挥手即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发。</p>

<p>由于TCP连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。</p>

<p>下面来看看四次挥手的流程图：</p>

<p><figure><img src="media/15955594725422/15956917850227.jpg" alt=""/></figure></p>

<p>中断连接端可以是客户端，也可以是服务器端。</p>

<ul>
<li>第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说&quot;我客户端没有数据要发给你了&quot;，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。</li>
<li>第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。</li>
<li>第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。</li>
<li>第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。</li>
</ul>

<p>上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况：<br/>
<figure><img src="media/15955594725422/15956918440314.jpg" alt=""/></figure></p>

<h4 id="toc_15">3.3.3、 通过序列号与确认应答提高可靠性</h4>

<p>在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。这个消息叫做确认应答（ACK）。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。反之，则数据丢失的可能性很大。</p>

<p>在一定时间内没有等待到确认应答，发送端就可以认为数据已经丢失，并进行重发。由此，即使产生了丢包，仍然能够保证数据能够到达对端，实现可靠传输。</p>

<p>未收到确认应答并不意味着数据一定丢失。也有可能是数据对方已经收到，只是返回的确认应答在途中丢失。这种情况也会导致发送端误以为数据没有到达目的地而重发数据。</p>

<p>此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也屡见不鲜。此时，源主机只要按照机制重发数据即可。</p>

<p>对于目标主机来说，反复收到相同的数据是不可取的。为了对上层应用提供可靠的传输，目标主机必须放弃重复的数据包。为此我们引入了序列号。<br/>
序列号是按照顺序给发送数据的每一个字节（8位字节）都标上号码的编号。接收端查询接收数据 TCP 首部中的序列号和数据的长度，将自己下一步应该接收的序列号作为确认应答返送回去。通过序列号和确认应答号，TCP 能够识别是否已经接收数据，又能够判断是否需要接收，从而实现可靠传输。</p>

<p><figure><img src="media/15955594725422/15956919436214.jpg" alt=""/></figure></p>

<h4 id="toc_16">3.3.4、 重发超时的确定</h4>

<p>重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。如果超过这个时间仍未收到确认应答，发送端将进行数据重发。最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。</p>

<p>TCP 要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差。将这个往返时间和偏差时间相加，重发超时的时间就是比这个总和要稍大一点的值。</p>

<p>在 BSD 的 Unix 以及 Windows 系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍。不过，最初其重发超时的默认值一般设置为6秒左右。</p>

<p>数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。</p>

<p>此外，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。</p>

<h4 id="toc_17">3.3.5、 以段为单位发送数据</h4>

<p>在建立 TCP 连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS）。最理想的情况是，最大消息长度正好是 IP 中不会被分片处理的最大数据长度。</p>

<p>TCP 在传送大量数据时，是以 MSS 的大小将数据进行分割发送。进行重发时也是以 MSS  为单位。</p>

<p>MSS 在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写入 MSS  选项，告诉对方自己的接口能够适应的 MSS 的大小。然后会在两者之间选择一个较小的值投入使用。</p>

<h4 id="toc_18">3.3.6、利用窗口控制提高速度</h4>

<p>TCP 以1个段为单位，每发送一个段进行一次确认应答的处理。这样的传输方式有一个缺点，就是包的往返时间越长通信性能就越低。</p>

<p>为解决这个问题，TCP 引入了窗口这个概念。确认应答不再是以每个分段，而是以更大的单位进行确认，转发时间将会被大幅地缩短。也就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送。如下图所示：<br/>
<figure><img src="media/15955594725422/15956920512186.jpg" alt=""/></figure></p>

<p>窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。上图中窗口大小为4个段。这个机制实现了使用大量的缓冲区，通过对多个段同时进行确认应答的功能。</p>

<h4 id="toc_19">3.3.7、滑动窗口控制</h4>

<p><figure><img src="media/15955594725422/15957306505366.jpg" alt=""/></figure></p>

<p>上图中的窗口内的数据即便没有收到确认应答也可以被发送出去。不过，在整个窗口的确认应答没有到达之前，如果其中部分数据出现丢包，那么发送端仍然要负责重传。为此，发送端主机需要设置缓存保留这些待被重传的数据，直到收到他们的确认应答。</p>

<p>在滑动窗口以外的部分包括未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再进行重发，此时数据就可以从缓存区清除。</p>

<p>收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也别称为滑动窗口控制。</p>

<h4 id="toc_20">3.3.8、窗口控制中的重发控制</h4>

<p>在使用窗口控制中， 出现丢包一般分为两种情况：</p>

<ul>
<li><p>① 确认应答未能返回的情况。在这种情况下，数据已经到达对端，是不需要再进行重发的，如下图：<br/>
<figure><img src="media/15955594725422/15957353198269.jpg" alt=""/></figure></p></li>
<li><p>② 某个报文段丢失的情况。接收主机如果收到一个自己应该接收的序列号以外的数据时，会针对当前为止收到数据返回确认应答。如下图所示，当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，因此，在窗口比较大，又出现报文段丢失的情况下，同一个序列号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答，就会将其对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称为高速重发控制。<br/>
<figure><img src="media/15955594725422/15957353491515.jpg" alt=""/></figure></p></li>
</ul>

<h2 id="toc_21">4、网络层的IP协议</h2>

<p>IP（IPv4、IPv6）相当于 OSI 参考模型中的第3层——网络层。网络层的主要作用是“实现终端节点之间的通信”。这种终端节点之间的通信也叫“点对点通信”。</p>

<p>网络的下一层——数据链路层的主要作用是在互连同一种数据链路的节点之间进行包传递。而一旦跨越多种数据链路，就需要借助网络层。网络层可以跨越不同的数据链路，即使是在不同的数据链路上也能实现两端节点之间的数据包传输。</p>

<p>IP 大致分为三大作用模块，它们是 IP 寻址、路由（最终节点为止的转发）以及 IP 分包与组包。</p>

<h3 id="toc_22">4.1、IP地址</h3>

<p>在计算机通信中，为了识别通信对端，必须要有一个类似于地址的识别码进行标识。在数据链路中的 MAC 地址正是用来标识同一个链路中不同计算机的一种识别码。<br/>
作为网络层的 IP ,也有这种地址信息，一般叫做 IP 地址。IP 地址用于在“连接到网络中的所有主机中识别出进行通信的目标地址”。因此，在 TCP/IP 通信中所有主机或路由器必须设定自己的 IP 地址。<br/>
不论一台主机与哪种数据链路连接，其 IP 地址的形式都保持不变。<br/>
IP 地址（IPv4 地址）由32位正整数来表示。IP 地址在计算机内部以二进制方式被处理。然而，由于我们并不习惯于采用二进制方式，我们将32位的 IP 地址以每8位为一组，分成4组，每组以 “.” 隔开，再将每组数转换成十进制数。如下：<br/>
<figure><img src="media/15955594725422/15957356769851.jpg" alt=""/></figure></p>

<h4 id="toc_23">4.1.1、 IP 地址由网络和主机两部分标识组成</h4>

<p>如下图，网络标识在数据链路的每个段配置不同的值。网络标识必须保证相互连接的每个段的地址不相重复。而相同段内相连的主机必须有相同的网络地址。IP 地址的“主机标识”则不允许在同一个网段内重复出现。由此，可以通过设置网络地址和主机地址，在相互连接的整个网络中保证每台主机的 IP 地址都不会相互重叠。即 IP 地址具有了唯一性。<br/>
<figure><img src="media/15955594725422/15957356923189.jpg" alt="IP地址的主机标识"/><figcaption>IP地址的主机标识</figcaption></figure></p>

<p>如下图，IP 包被转发到途中某个路由器时，正是利用目标 IP 地址的网络标识进行路由。因为即使不看主机标识，只要一见到网络标识就能判断出是否为该网段内的主机。<br/>
<figure><img src="media/15955594725422/15957357130579.jpg" alt="IP地址的网络标识"/><figcaption>IP地址的网络标识</figcaption></figure></p>

<h4 id="toc_24">4.1.2、 IP 地址的分类</h4>

<p>IP 地址分为四个级别，分别为A类、B类、C类、D类。它根据 IP 地址中从第 1 位到第 4 位的比特列对其网络标识和主机标识进行区分。<br/>
A 类 IP 地址是首位以 “0” 开头的地址。从第 1 位到第 8 位是它的网络标识。用十进制表示的话，0.0.0.0~127.0.0.0 是 A 类的网络地址。A 类地址的后 24 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为16,777,214个。<br/>
B 类 IP 地址是前两位 “10” 的地址。从第 1 位到第 16 位是它的网络标识。用十进制表示的话，128.0.0.0~191.255.0.0 是 B 类的网络地址。B 类地址的后 16 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为65,534个。<br/>
C 类 IP 地址是前三位为 “110” 的地址。从第 1 位到第 24 位是它的网络标识。用十进制表示的话，192.0.0.0~223.255.255.0 是 C 类的网络地址。C 类地址的后 8 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为254个。<br/>
D 类 IP 地址是前四位为 “1110” 的地址。从第 1 位到第 32 位是它的网络标识。用十进制表示的话，224.0.0.0~239.255.255.255 是 D 类的网络地址。D 类地址没有主机标识，常用于多播。<br/>
在分配 IP 地址时关于主机标识有一点需要注意。即要用比特位表示主机地址时，不可以全部为 0 或全部为 1。因为全部为 0 只有在表示对应的网络地址或 IP 地址不可以获知的情况下才使用。而全部为 1 的主机通常作为广播地址。因此，在分配过程中，应该去掉这两种情况。这也是为什么 C 类地址每个网段最多只能有 254（ 28 - 2 = 254）个主机地址的原因。</p>

<h4 id="toc_25">4.1.3、 广播地址</h4>

<p>广播地址用于在同一个链路中相互连接的主机之间发送数据包。将 IP 地址中的主机地址部分全部设置为 1，就成了广播地址。<br/>
广播分为本地广播和直接广播两种。在本网络内的广播叫做本地广播；在不同网络之间的广播叫做直接广播。</p>

<h4 id="toc_26">4.1.4、 IP 多播</h4>

<p>多播用于将包发送给特定组内的所有主机。由于其直接使用 IP 地址，因此也不存在可靠传输。</p>

<p>相比于广播，多播既可以穿透路由器，又可以实现只给那些必要的组发送数据包。请看下图：IP 多播<br/>
<figure><img src="media/15955594725422/15957357583375.jpg" alt=""/></figure></p>

<p>多播使用 D 类地址。因此，如果从首位开始到第 4 位是 “1110”，就可以认为是多播地址。而剩下的 28 位可以成为多播的组编号。<br/>
x<br/>
此外， 对于多播，所有的主机（路由器以外的主机和终端主机）必须属于 224.0.0.1 的组，所有的路由器必须属于 224.0.0.2 的组。</p>

<h4 id="toc_27">4.1.5、 子网掩码</h4>

<p>现在一个 IP 地址的网络标识和主机标识已不再受限于该地址的类别，而是由一个叫做“子网掩码”的识别码通过子网网络地址细分出比 A 类、B 类、C 类更小粒度的网络。这种方式实际上就是将原来 A 类、B 类、C 类等分类中的主机地址部分用作子网地址，可以将原网络分为多个物理网络的一种机制。<br/>
子网掩码用二进制方式表示的话，也是一个 32 位的数字。它对应 IP 地址网络标识部分的位全部为 “1”，对应 IP 地址主机标识的部分则全部为 “0”。由此，一个 IP 地址可以不再受限于自己的类别，而是可以用这样的子网掩码自由地定位自己的网络标识长度。当然，子网掩码必须是 IP 地址的首位开始连续的 “1”。<br/>
对于子网掩码，目前有两种表示方式。第一种是，将 IP 地址与子网掩码的地址分别用两行来表示。以 172.20.100.52 的前 26 位是网络地址的情况为例，如下：<br/>
<figure><img src="media/15955594725422/15957358144400.jpg" alt=""/></figure></p>

<p>第二种表示方式是，在每个 IP 地址后面追加网络地址的位数用 “/ ” 隔开，如下：</p>

<p><figure><img src="media/15955594725422/15957358402864.jpg" alt=""/></figure></p>

<p>另外，在第二种方式下记述网络地址时可以省略后面的 “0” 。例如：172.20.0.0/26 跟 172.20/26 其实是一个意思。</p>

<h3 id="toc_28">4.2、 路由</h3>

<p>发送数据包时所使用的地址是网络层的地址，即 IP 地址。然而仅仅有 IP 地址还不足以实现将数据包发送到对端目标地址，在数据发送过程中还需要类似于“指明路由器或主机”的信息，以便真正发往目标地址。保存这种信息的就是路由控制表。</p>

<p>该路由控制表的形成方式有两种：一种是管理员手动设置，另一种是路由器与其他路由器相互交换信息时自动刷新。前者也叫做静态路由控制，而后者叫做动态路由控制。</p>

<p>IP 协议始终认为路由表是正确的。然后，IP 本身并没有定义制作路由控制表的协议。即 IP 没有制作路由控制表的机制。该表示由一个叫做“路由协议”的协议制作而成。</p>

<h4 id="toc_29">4.2.1、 IP 地址与路由控制</h4>

<p>IP 地址的网络地址部分用于进行路由控制。<br/>
路由控制表中记录着网络地址与下一步应该发送至路由器的地址。<br/>
在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择一个最为吻合的网络地址。<br/>
<figure><img src="media/15955594725422/15957359215309.jpg" alt="路由控制表与 IP 包发送"/><figcaption>路由控制表与 IP 包发送</figcaption></figure></p>

<h3 id="toc_30">4.3、 IP 分包与组包</h3>

<p>每种数据链路的最大传输单元（MTU）都不尽相同，因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。</p>

<p>任何一台主机都有必要对 IP 分片进行相应的处理。分片往往在网络上遇到比较大的报文无法一下子发送出去时才会进行处理。</p>

<p>经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行。路由器虽然做分片但不会进行重组。</p>

<h4 id="toc_31">4.3.1、 路径 MTU 发现</h4>

<p>分片机制也有它的不足。如路由器的处理负荷加重之类。因此，只要允许，是不希望由路由器进行 IP 数据包的分片处理的。<br/>
为了应对分片机制的不足，“路径 MTU 发现” 技术应运而生。路径 MTU 指的是，从发送端主机到接收端主机之间不需要分片是最大 MTU 的大小。即路径中存在的所有数据链路中最小的 MTU 。<br/>
进行路径 MTU 发现，就可以避免在中途的路由器上进行分片处理，也可以在 TCP 中发送更大的包。</p>

<h3 id="toc_32">4.4、 IPv6</h3>

<p>IPv6（IP version 6）是为了根本解决 IPv4 地址耗尽的问题而被标准化的网际协议。IPv4 的地址长度为 4 个 8 位字节，即 32 比特。而 IPv6 的地址长度则是原来的 4 倍，即 128 比特，一般写成 8 个 16 位字节。</p>

<h4 id="toc_33">4.4.1、 IPv6 的特点</h4>

<p>IP 得知的扩大与路由控制表的聚合。<br/>
性能提升。包首部长度采用固定的值（40字节），不再采用首部检验码。简化首部结构，减轻路由器负担。路由器不再做分片处理。<br/>
支持即插即用功能。即使没有DHCP服务器也可以实现自动分配 IP 地址。<br/>
采用认证与加密功能。应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能。<br/>
多播、Mobile IP 成为扩展功能。</p>

<h4 id="toc_34">4.4.2、 IPv6 中 IP 地址的标记方法</h4>

<p>一般人们将 128 比特 IP 地址以每 16 比特为一组，每组用冒号（“：”）隔开进行标记。<br/>
而且如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号（“：：”）隔开。但是，一个 IP 地址中只允许出现一次两个连续的冒号。</p>

<h4 id="toc_35">4.4.3、 IPv6 地址的结构</h4>

<p>IPv6 类似 IPv4，也是通过 IP 地址的前几位标识 IP 地址的种类。<br/>
在互联网通信中，使用一种全局的单播地址。它是互联网中唯一的一个地址，不需要正式分配 IP 地址。</p>

<p><figure><img src="media/15955594725422/15957360738922.jpg" alt=""/></figure></p>

<h4 id="toc_36">4.4.4、 全局单播地址</h4>

<p>全局单播地址是指世界上唯一的一个地址。它是互联网通信以及各个域内部通信中最为常用的一个 IPv6 地址。<br/>
格式如下图所示，现在 IPv6 的网络中所使用的格式为，n = 48，m = 16 以及 128 - n - m = 64。即前 64 比特为网络标识，后 64 比特为主机标识。<br/>
<figure><img src="media/15955594725422/15957360990321.jpg" alt="全局单播地址"/><figcaption>全局单播地址</figcaption></figure></p>

<h4 id="toc_37">4.4.5、 链路本地单播地址</h4>

<p>链路本地单播地址是指在同一个数据链路内唯一的地址。它用于不经过路由器，在同一个链路中的通信。通常接口 ID 保存 64 比特版的 MAC 地址。<br/>
<figure><img src="media/15955594725422/15957361211675.jpg" alt="链路本地单播地址"/><figcaption>链路本地单播地址</figcaption></figure></p>

<h4 id="toc_38">4.4.6、 唯一本地地址</h4>

<p>唯一本地地址是不进行互联网通信时所用的地址。<br/>
唯一本地地址虽然不会与互联网连接，但是也会尽可能地随机生成一个唯一的全局 ID。<br/>
L 通常被置为 1 <br/>
全局 ID 的值随机决定<br/>
子网 ID 是指该域子网地址<br/>
接口 ID 即为接口的 ID<br/>
<figure><img src="media/15955594725422/15957361414840.jpg" alt="唯一本地地址"/><figcaption>唯一本地地址</figcaption></figure></p>

<h4 id="toc_39">4.4.7、 IPv6 分段处理</h4>

<p>IPv6 的分片处理只在作为起点的发送端主机上进行，路由器不参与分片。<br/>
IPv6 中最小 MTU 为 1280 字节，因此，在嵌入式系统中对于那些有一定系统资源限制的设备来说，不需要进行“路径 MTU 发现”，而是在发送 IP 包时直接以 1280 字节为单位分片送出。</p>

<h2 id="toc_40">5、 IP 协议相关技术</h2>

<p>IP 旨在让最终目标主机收到数据包，但是在这一过程中仅仅有 IP 是无法实现通信的。必须还有能够解析主机名称和 MAC 地址的功能，以及数据包在发送过程中异常情况处理的功能。</p>

<h3 id="toc_41">5.1、 DNS</h3>

<p>我们平常在访问某个网站时不适用 IP 地址，而是用一串由罗马字和点号组成的字符串。而一般用户在使用 TCP/IP 进行通信时也不使用 IP 地址。能够这样做是因为有了 DNS （Domain Name System）功能的支持。DNS 可以将那串字符串自动转换为具体的 IP 地址。<br/>
这种 DNS 不仅适用于 IPv4，还适用于 IPv6。</p>

<h3 id="toc_42">5.2、 ARP</h3>

<p>只要确定了 IP 地址，就可以向这个目标地址发送 IP 数据报。然而，在底层数据链路层，进行实际通信时却有必要了解每个 IP 地址所对应的 MAC 地址。<br/>
ARP 是一种解决地址问题的协议。以目标 IP 地址为线索，用来定位下一个应该接收数据分包的网络设备对应的 MAC 地址。不过 ARP 只适用于 IPv4，不能用于 IPv6。IPv6 中可以用 ICMPv6 替代 ARP 发送邻居探索消息。<br/>
RARP 是将 ARP 反过来，从 MAC 地址定位 IP 地址的一种协议。</p>

<h3 id="toc_43">5.3、 ICMP</h3>

<p>ICMP 的主要功能包括，确认 IP 包是否成功送达目标地址，通知在发送过程当中 IP 包被废弃的具体原因，改善网络设置等。<br/>
IPv4 中 ICMP 仅作为一个辅助作用支持 IPv4。也就是说，在 IPv4 时期，即使没有 ICMP，仍然可以实现 IP 通信。然而，在 IPv6 中，ICMP 的作用被扩大，如果没有 ICMPv6，IPv6 就无法进行正常通信。</p>

<h3 id="toc_44">5.4、 DHCP</h3>

<p>如果逐一为每一台主机设置 IP 地址会是非常繁琐的事情。特别是在移动使用笔记本电脑、只能终端以及平板电脑等设备时，每移动到一个新的地方，都要重新设置 IP 地址。<br/>
于是，为了实现自动设置 IP 地址、统一管理 IP 地址分配，就产生了 DHCP（Dynamic Host Configuration Protocol）协议。有了 DHCP，计算机只要连接到网络，就可以进行 TCP/IP 通信。也就是说，DHCP 让即插即用变得可能。<br/>
DHCP 不仅在 IPv4 中，在 IPv6 中也可以使用。</p>

<h3 id="toc_45">5.5、 NAT</h3>

<p>NAT（Network Address Translator）是用于在本地网络中使用私有地址，在连接互联网时转而使用全局 IP 地址的技术。<br/>
除转换 IP 地址外，还出现了可以转换 TCP、UDP 端口号的 NAPT（Network Address Ports Translator）技术，由此可以实现用一个全局 IP 地址与多个主机的通信。<br/>
NAT（NAPT）实际上是为正在面临地址枯竭的 IPv4 而开发的技术。不过，在 IPv6 中为了提高网络安全也在使用 NAT，在 IPv4 和 IPv6 之间的相互通信当中常常使用 NAT-PT。</p>

<h3 id="toc_46">5.6、 IP 隧道夹着 IPv4 网络的两个 IPv6 网络</h3>

<p><figure><img src="media/15955594725422/15957362138379.jpg" alt=""/></figure></p>

<p>如上图的网络环境中，网络 A 与网络 B 之间无法直接进行通信，为了让它们之间正常通信，这时必须得采用 IP 隧道的功能。<br/>
IP 隧道可以将那些从网络 A 发过来的 IPv6 的包统合为一个数据，再为之追加一个 IPv4 的首部以后转发给网络 C。<br/>
一般情况下，紧接着 IP 首部的是 TCP 或 UDP 的首部。然而，现在的应用当中“ IP 首部的后面还是 IP 首部”或者“ IP 首部的后面是 IPv6 的首部”等情况与日俱增。这种在网络层的首部后面追加网络层首部的通信方法就叫做“ IP 隧道”。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP协议（六）-- 与 HTTP 协作的 Web 服务器]]></title>
    <link href="http://www.throne4j.com/15957418105856.html"/>
    <updated>2020-07-26T13:36:50+08:00</updated>
    <id>http://www.throne4j.com/15957418105856.html</id>
    <content type="html"><![CDATA[
<p>HTTP 通信时，除客户端和服务器外，还有一些用于协助通信的应用程序。如下列出比较重要的几个：代理、缓存、网关、隧道、Agent 代理。</p>

<p>1.代理<br/>
<figure><img src="media/15955168840534/15957390472021.jpg" alt="代理"/><figcaption>代理</figcaption></figure></p>

<p>HTTP 代理服务器是 Web 安全、应用集成以及性能优化的重要组成模块。代理位于客户端和服务器端之间，接收客户端所有的 HTTP 请求，并将这些请求转发给服务器（可能会对请求进行修改之后再进行转发）。对用户来说，这些应用程序就是一个代理，代表用户访问服务器。<br/>
出于安全考虑，通常会将代理作为转发所有 Web 流量的可信任中间节点使用。代理还可以对请求和响应进行过滤，安全上网或绿色上网。</p>

<ol>
<li>缓存<br/>
浏览器第一次请求：
<figure><img src="media/15955168840534/15957390923745.jpg" alt="浏览器第一次请求"/><figcaption>浏览器第一次请求</figcaption></figure></li>
</ol>

<p>浏览器再次请求：<br/>
<figure><img src="media/15955168840534/15957391037011.jpg" alt="浏览器再次请求"/><figcaption>浏览器再次请求</figcaption></figure></p>

<p>Web 缓存或代理缓存是一种特殊的 HTTP 代理服务器，可以将经过代理传输的常用文档复制保存起来。下一个请求同一文档的客户端就可以享受缓存的私有副本所提供的服务了。客户端从附近的缓存下载文档会比从远程 Web 服务器下载快得多。</p>

<ol>
<li>网关
<figure><img src="media/15955168840534/15957391163572.jpg" alt="HTTP / FTP 网关"/><figcaption>HTTP / FTP 网关</figcaption></figure></li>
</ol>

<p>网关是一种特殊的服务器，作为其他服务器的中间实体使用。通常用于将 HTTP 流量转换成其他的协议。网关接收请求时就好像自己是资源的源服务器一样。客户端可能并不知道自己正在跟一个网关进行通信。</p>

<ol>
<li>隧道
<figure><img src="media/15955168840534/15957391265275.jpg" alt="HTTP/SSL 隧道"/><figcaption>HTTP/SSL 隧道</figcaption></figure></li>
</ol>

<p>隧道是会在建立起来之后，就会在两条连接之间对原始数据进行盲转发的 HTTP 应用程序。HTTP 隧道通常用来在一条或多条 HTTP 连接上转发非 HTTP 数据，转发时不会窥探数据。</p>

<p>HTTP 隧道的一种常见用途就是通过 HTTP 连接承载加密的安全套接字层（SSL）流量，这样 SSL 流量就可以穿过只允许 Web 流量通过的防火墙了。</p>

<ol>
<li>Agent 代理
<figure><img src="media/15955168840534/15957391378461.jpg" alt="自动搜索引擎“网络蜘蛛”"/><figcaption>自动搜索引擎“网络蜘蛛”</figcaption></figure></li>
</ol>

<p>Agent 代理是代表用户发起 HTTP 请求的客户端应用程序。所有发布 Web 请求的应用程序都是 HTTP Agent 代理。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP协议（五）-- 响应状态码]]></title>
    <link href="http://www.throne4j.com/15957408756364.html"/>
    <updated>2020-07-26T13:21:15+08:00</updated>
    <id>http://www.throne4j.com/15957408756364.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">HTTP 响应状态码（重点分析）</h2>

<h3 id="toc_1">1. 状态码概述</h3>

<p>HTTP 状态码负责表示客户端 HTTP 请求的返回结果、标记服务器端的处理是否正常、通知出现的错误等工作。</p>

<p>HTTP 状态码如 200 OK ，以 3 位数字和原因短语组成。数字中的第一位指定了响应类别，后两位无分类。</p>

<p>不少返回的响应状态码都是错误的，但是用户可能察觉不到这点。比如 Web 应用程序内部发生错误，状态码依然返回 200 OK。</p>

<h3 id="toc_2">2. 状态码类别</h3>

<table>
<thead>
<tr>
<th>响应码</th>
<th>类别</th>
<th>原因短语</th>
</tr>
</thead>

<tbody>
<tr>
<td>1xx</td>
<td>Informational(信息性状态码)</td>
<td>接收的请求正在处理</td>
</tr>
<tr>
<td>2xx</td>
<td>Success(成功状态码)</td>
<td>请求正常处理完毕</td>
</tr>
<tr>
<td>3xx</td>
<td>Redirection(重定向状态码)</td>
<td>需要进行附加操作以完成请求</td>
</tr>
<tr>
<td>4xx</td>
<td>Client Error(客户端错误状态码）</td>
<td>服务器无法处理请求</td>
</tr>
<tr>
<td>5xx</td>
<td>Server Error(服务器错误状态码)</td>
<td>服务器处理请求出错</td>
</tr>
</tbody>
</table>

<p>我们可以自行改变 RFC2616 中定义的状态码或者服务器端自行创建状态码，只要遵守状态码的类别定义就可以了。</p>

<h3 id="toc_3">3. 常用状态码解析</h3>

<p>HTTP 状态码种类繁多，数量达几十种。其中最常用的有以下 14 种，一起来看看。</p>

<h4 id="toc_4">3.1 、200 OK</h4>

<p>表示从客户端发来的请求在服务器端被正常处理了。</p>

<h4 id="toc_5">3.2、 204 No Content</h4>

<p>代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。<br/>
一般在只需要从客户端向服务器端发送消息，而服务器端不需要向客户端发送新消息内容的情况下使用。</p>

<h4 id="toc_6">3.3、 206 Partial Content</h4>

<p>表示客户端进行了范围请求，而服务器成功执行了这部分的 GET 请求。响应报文中包含由 Content-Range 首部字段指定范围的实体内容。</p>

<h4 id="toc_7">3.4、 301 Moved Permanently</h4>

<p>永久性重定向。表示请求的资源已被分配了新的 URI。以后应使用资源现在所指的 URI。也就是说，如果已经把资源对应的 URI 保存为书签了，这时应该按 Location 首部字段提示的 URI 重新保存。</p>

<h4 id="toc_8">3.5、 302 Found</h4>

<p>临时性重定向。表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。</p>

<p>和 301 Moved Permanently 状态码相似，但 302 Found 状态码代表资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的 URI 将来还有可能发生改变。</p>

<h4 id="toc_9">3.6、 303 See Other</h4>

<p>表示由于请求的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源。</p>

<p>303 See Other 和 302 Found 状态码有着相同的功能，但 303 See Other 状态码明确表示客户端应采用 GET 方法获取资源，这点与 302 Found 状态码有区别。</p>

<h4 id="toc_10">3.7、 304 Not Modified</h4>

<p>表示客户端发送附带条件的请求时，服务器端允许请求访问的资源，但未满足条件的情况。</p>

<p>304 Not Modified 状态码返回时，不包含任何响应的主体部分。</p>

<p>304 Not Modified 虽然被划分到 3xx 类别中，但和重定向没有关系。</p>

<h4 id="toc_11">3.8、 307 Temporary Redirect</h4>

<p>临时重定向。该状态码与 302 Found 有着相同的含义。</p>

<h4 id="toc_12">3.9、 400 Bad Request</h4>

<p>表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。<br/>
另外，浏览器会像 200 OK 一样对待该状态码。</p>

<h4 id="toc_13">3.10、 401 Unauthorized</h4>

<p>表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。<br/>
另外，若之前已进行过 1 次请求，则表示用户认证失败。<br/>
返回含有 401 Unauthorized 的响应必须包含一个适用于被请求资源的 WWW-Authenticate 首部用以质询（challenge）用户信息。</p>

<h4 id="toc_14">3.11、 403 Forbidden</h4>

<p>表明对请求资源的访问被服务器拒绝了。服务器端没有必要给出详细的拒绝理由，当然也可以在响应报文的实体主体部分对原因进行描述。</p>

<h4 id="toc_15">3.12、 404 Not Found</h4>

<p>表明服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由的时候使用。</p>

<h4 id="toc_16">3.13、 500 Internal Server Error</h4>

<p>表明服务器端在执行请求时发生了错误。也可能是 Web 应用存在的 bug 或某些临时的故障。</p>

<h4 id="toc_17">3.14、 503 Service Unavailable</h4>

<p>表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入 Retry-After 首部字段再返回给客户端。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP协议(四)--HTTP 报文实体]]></title>
    <link href="http://www.throne4j.com/15957408714359.html"/>
    <updated>2020-07-26T13:21:11+08:00</updated>
    <id>http://www.throne4j.com/15957408714359.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1. HTTP 报文实体概述</h2>

<p><figure><img src="media/15955168840534/15957385627780.jpg" alt="HTTP 报文结构"/><figcaption>HTTP 报文结构</figcaption></figure></p>

<p>大家请仔细看看上面示例中，各个组成部分对应的内容。<br/>
接着，我们来看看报文和实体的概念。如果把 HTTP 报文想象成因特网货运系统中的箱子，那么 HTTP 实体就是报文中实际的货物。</p>

<ul>
<li><p>报文：是网络中交换和传输的数据单元，即站点一次性要发送的数据块。报文包含了将要发送的完整的数据信息，其长短很不一致，长度不限且可变。</p></li>
<li><p>实体：作为请求或响应的有效载荷数据（补充项）被传输，其内容由实体首部和实体主体组成。（实体首部相关内容在上面第六点中已有阐述。）</p></li>
</ul>

<p>我们可以看到，上面示例右图中深红色框的内容就是报文的实体部分，而蓝色框的两部分内容分别就是实体首部和实体主体。而左图中粉红框内容就是报文主体。<br/>
通常，报文主体等于实体主体。只有当传输中进行编码操作时，实体主体的内容发生变化，才导致它和报文主体产生差异。</p>

<h2 id="toc_1">2. 内容编码</h2>

<p>HTTP 应用程序有时在发送之前需要对内容进行编码。例如，在把很大的 HTML 文档发送给通过慢速连接上来的客户端之前，服务器可能会对其进行压缩，这样有助于减少传输实体的时间。服务器还可以把内容搅乱或加密，以此来防止未授权的第三方看到文档的内容。</p>

<p>这种类型的编码是在发送方应用到内容之上的。当内容经过内容编码后，编好码的数据就放在实体主体中，像往常一样发送给接收方。<br/>
内容编码类型：</p>

<table>
<thead>
<tr>
<th>编码方式</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>gzip</td>
<td>表明实体采用 GNU zip 编码</td>
</tr>
<tr>
<td>compress</td>
<td>表明实体采用 Unix 的文件压缩程序</td>
</tr>
<tr>
<td>deflate</td>
<td>表明实体采用 zlib 的格式压缩的</td>
</tr>
<tr>
<td>identity</td>
<td>表明没有对实体进行编码，当没有 Content-Encoding 首部字段时，默认采用此编码方式</td>
</tr>
</tbody>
</table>

<h2 id="toc_2">3. 传输编码</h2>

<p>内容编码是对报文的主体进行的可逆变换，是和内容的具体格式细节紧密相关的。<br/>
传输编码也是作用在实体主体上的可逆变换，但使用它们是由于架构方面的原因，同内容的格式无关。使用传输编码是为了改变报文中的数据在网络上传输的方式。</p>

<p><figure><img src="media/15955168840534/15957385792865.jpg" alt="内容编码和传输编码的对比"/><figcaption>内容编码和传输编码的对比</figcaption></figure></p>

<h2 id="toc_3">4. 分块编码</h2>

<p>分块编码把报文分割成若干已知大小的块。块之间是紧挨着发送的，这样就不需要在发送之前知道整个报文的大小了。分块编码是一种传输编码，是报文的属性。</p>

<p>分块编码与持久连接<br/>
若客户端与服务器端之间不是持久连接，客户端就不需要知道它在读取的主体的长度，而只需要读取到服务器关闭主体连接为止。<br/>
当使用持久连接时，在服务器写主体之前，必须知道它的大小并在 Content-Length 首部中发送。如果服务器动态创建内容，就可能在发送之前无法知道主体的长度。<br/>
分块编码为这种困难提供了解决方案，只要允许服务器把主体分块发送，说明每块的大小就可以了。因为主体是动态创建的，服务器可以缓冲它的一部分，发送其大小和相应的块，然后在主体发送完之前重复这个过程。服务器可以用大小为 0 的块作为主体结束的信号，这样就可以继续保持连接，为下一个响应做准备。<br/>
来看看一个分块编码的报文示例：<br/>
<figure><img src="media/15955168840534/15957390124186.jpg" alt=""/></figure></p>

<p>分块编码的报文</p>

<h2 id="toc_4">5.多部分媒体类型</h2>

<p>MIME 中的 multipart（多部分）电子邮件报文中包含多个报文，它们合在一起作为单一的复杂报文发送。每一部分都是独立的，有各自的描述其内容的集，不同部分之间用分界字符串连接在一起。<br/>
相应得，HTTP 协议中也采纳了多部分对象集合，发送的一份报文主体内可包含多种类型实体。<br/>
多部分对象集合包含的对象如下：</p>

<p>multipart/form-data：在 Web 表单文件上传时使用。<br/>
multipart/byteranges：状态码 206 Partial Content 响应报文包含了多个范围的内容时使用。</p>

<h2 id="toc_5">6. 范围请求</h2>

<p>假设你正在下载一个很大的文件，已经下了四分之三，忽然网络中断了，那下载就必须重头再来一遍。为了解决这个问题，需要一种可恢复的机制，即能从之前下载中断处恢复下载。要实现该功能，这就要用到范围请求。<br/>
有了范围请求， HTTP 客户端可以通过请求曾获取失败的实体的一个范围（或者说一部分），来恢复下载该实体。当然这有一个前提，那就是从客户端上一次请求该实体到这一次发出范围请求的时间段内，该对象没有改变过。例如：</p>

<pre><code class="language-text">GET  /bigfile.html  HTTP/1.1
Host: www.sample.com
Range: bytes=20224-
···
</code></pre>

<p><figure><img src="media/15955168840534/15957390372242.jpg" alt=""/></figure></p>

<p>实体范围请求示例<br/>
上面示例中，客户端请求的是文档开头20224字节之后的部分。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP协议(三)--HTTP 报文详析]]></title>
    <link href="http://www.throne4j.com/15957408699075.html"/>
    <updated>2020-07-26T13:21:09+08:00</updated>
    <id>http://www.throne4j.com/15957408699075.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">一、http 首部字段</h2>

<h3 id="toc_1">1.首部字段概述</h3>

<p>先来回顾一下首部字段在报文的位置，HTTP 报文包含报文首部和报文主体，报文首部包含请求行（或状态行）和首部字段。<br/>
在报文众多的字段当中，HTTP 首部字段包含的信息最为丰富。首部字段同时存在于请求和响应报文内，并涵盖 HTTP 报文相关的内容信息。使用首部字段是为了给客服端和服务器端提供报文主体大小、所使用的语言、认证信息等内容。</p>

<h3 id="toc_2">2.首部字段结构</h3>

<p>HTTP 首部字段是由首部字段名和字段值构成的，中间用冒号“：”分隔。<br/>
另外，字段值对应单个 HTTP 首部字段可以有多个值。<br/>
当 HTTP 报文首部中出现了两个或以上具有相同首部字段名的首部字段时，这种情况在规范内尚未明确，根据浏览器内部处理逻辑的不同，优先处理的顺序可能不同，结果可能并不一致。</p>

<table>
<thead>
<tr>
<th>首部字段名</th>
<th>字段值</th>
</tr>
</thead>

<tbody>
<tr>
<td>Content-Type</td>
<td>text/html</td>
</tr>
<tr>
<td>Keep-Alive</td>
<td>timeout=30, max=120</td>
</tr>
</tbody>
</table>

<h3 id="toc_3">3.首部字段类型</h3>

<p>首部字段根据实际用途被分为以下4种类型：</p>

<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>通用首部字段</td>
<td>请求报文和响应报文两方都会使用的首部</td>
</tr>
<tr>
<td>请求首部字段</td>
<td>从客户端向服务器端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息</td>
</tr>
<tr>
<td>响应首部字段</td>
<td>从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息。</td>
</tr>
<tr>
<td>实体首部字段</td>
<td>针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的的信息。</td>
</tr>
</tbody>
</table>

<h3 id="toc_4">4.通用首部字段（HTTP/1.1）</h3>

<table>
<thead>
<tr>
<th>首部字段名</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>Cache-Control</td>
<td>控制缓存的行为</td>
</tr>
<tr>
<td>Connection</td>
<td>逐挑首部、连接的管理</td>
</tr>
<tr>
<td>Date</td>
<td>创建报文的日期时间</td>
</tr>
<tr>
<td>Pragma</td>
<td>报文指令</td>
</tr>
<tr>
<td>Trailer</td>
<td>报文末端的首部一览</td>
</tr>
<tr>
<td>Transfer-Encoding</td>
<td>指定报文主体的传输编码方式</td>
</tr>
<tr>
<td>Upgrade</td>
<td>升级为其他协议</td>
</tr>
<tr>
<td>Via</td>
<td>代理服务器的相关信息</td>
</tr>
<tr>
<td>Warning</td>
<td>错误通知</td>
</tr>
</tbody>
</table>

<h4 id="toc_5">4.1 Cache-Control</h4>

<p>通过指定首部字段 Cache-Control 的指令，就能操作缓存的工作机制。</p>

<h5 id="toc_6">4.1.1 可用的指令一览</h5>

<p>可用的指令按请求和响应分类如下：<br/>
缓存请求指令</p>

<table>
<thead>
<tr>
<th>指令</th>
<th>参数</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>no-cache</td>
<td>无</td>
<td>强制向服务器再次验证</td>
</tr>
<tr>
<td>no-store</td>
<td>无</td>
<td>不缓存请求或响应的任何内容</td>
</tr>
<tr>
<td>max-age = [秒]</td>
<td>必需</td>
<td>响应的最大Age值</td>
</tr>
<tr>
<td>max-stale( =[秒])</td>
<td>可省略</td>
<td>接收已过期的响应</td>
</tr>
<tr>
<td>min-fresh = [秒]</td>
<td>必需</td>
<td>期望在指定时间内的响应仍有效</td>
</tr>
<tr>
<td>no-transform</td>
<td>无</td>
<td>代理不可更改媒体类型</td>
</tr>
<tr>
<td>only-if-cached</td>
<td>无</td>
<td>从缓存获取资源</td>
</tr>
<tr>
<td>cache-extension</td>
<td>-</td>
<td>新指令标记（token）</td>
</tr>
</tbody>
</table>

<p>缓存响应指令：</p>

<table>
<thead>
<tr>
<th>指令</th>
<th>参数</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>public</td>
<td>无</td>
<td>可向任意方提供响应的缓存</td>
</tr>
<tr>
<td>private</td>
<td>可省略</td>
<td>仅向特定用户返回响应</td>
</tr>
<tr>
<td>no-cache</td>
<td>可省略</td>
<td>缓存前必须先确认其有效性</td>
</tr>
<tr>
<td>no-store</td>
<td>无</td>
<td>不缓存请求或响应的任何内容</td>
</tr>
<tr>
<td>no-transform</td>
<td>无</td>
<td>代理不可更改媒体类型</td>
</tr>
<tr>
<td>must-revalidate</td>
<td>无</td>
<td>可缓存但必须再向源服务器进行确认</td>
</tr>
<tr>
<td>proxy-revalidate</td>
<td>无</td>
<td>要求中间缓存服务器对缓存的响应有效性再进行确认</td>
</tr>
<tr>
<td>max-age = [秒]</td>
<td>必需</td>
<td>响应的最大Age值</td>
</tr>
<tr>
<td>s-maxage = [秒]</td>
<td>必需</td>
<td>公共缓存服务器响应的最大Age值</td>
</tr>
<tr>
<td>cache-extension</td>
<td>-</td>
<td>新指令标记（token）</td>
</tr>
</tbody>
</table>

<h5 id="toc_7">4.1.2 表示能否缓存的指令</h5>

<ul>
<li><p>public 指令<br/>
Cache-Control: public<br/>
当指定使用 public 指令时，则明确表明其他用户也可利用缓存。</p></li>
<li><p>private 指令<br/>
Cache-Control: private<br/>
当指定 private 指令后，响应只以特定的用户作为对象，这与 public 指令的行为相反。缓存服务器会对该特定用户提供资源缓存的服务，对于其他用户发送过来的请求，代理服务器则不会返回缓存。</p></li>
<li><p>no-cache 指令<br/>
Cache-Control: no-cache</p></li>
</ul>

<p>使用 no-cache 指令是为了防止从缓存中返回过期的资源。<br/>
客户端发送的请求中如果包含 no-cache 指令，则表示客户端将不会接收缓存过的响应。于是，“中间”的缓存服务器必须把客户端请求转发给源服务器。<br/>
如果服务器中返回的响应包含 no-cache 指令，那么缓存服务器不能对资源进行缓存。源服务器以后也将不再对缓存服务器请求中提出的资源有效性进行确认，且禁止其对响应资源进行缓存操作。</p>

<p>Cache-Control: no-cache=Location</p>

<p>由服务器返回的响应中，若报文首部字段 Cache-Control 中对 no-cache 字段名具体指定参数值，那么客户端在接收到这个被指定参数值的首部字段对应的响应报文后，就不能使用缓存。换言之，无参数值的首部字段可以使用缓存。只能在响应指令中指定该参数。</p>

<ul>
<li>no-store 指令<br/>
Cache-Control: no-store<br/>
当使用 no-store 指令时，暗示请求（和对应的响应）或响应中包含机密信息。因此，该指令规定缓存不能在本地存储请求或响应的任一部分。<br/>
注意：no-cache 指令代表不缓存过期的指令，缓存会向源服务器进行有效期确认后处理资源；no-store 指令才是真正的不进行缓存。</li>
</ul>

<h4 id="toc_8">4.1.3 指定缓存期限和认证的指令</h4>

<ul>
<li>s-maxage 指令<br/>
Cache-Control: s-maxage=604800（单位：秒）</li>
</ul>

<p>s-maxage 指令的功能和 max-age 指令的相同，它们的不同点是 s-maxage 指令只适用于供多位用户使用的公共缓存服务器（一般指代理）。也就是说，对于向同一用户重复返回响应的服务器来说，这个指令没有任何作用。<br/>
另外，当使用 s-maxage 指令后，则直接忽略对 Expires 首部字段及 max-age 指令的处理。</p>

<ul>
<li>max-age 指令<br/>
Cache-Control: max-age=604800（单位：秒）</li>
</ul>

<p>当客户端发送的请求中包含 max-age 指令时，如果判定缓存资源的缓存时间数值比指定的时间更小，那么客户端就接收缓存的资源。另外，当指定 max-age 的值为0，那么缓存服务器通常需要将请求转发给源服务器。<br/>
当服务器返回的响应中包含 max-age 指令时，缓存服务器将不对资源的有效性再作确认，而 max-age 数值代表资源保存为缓存的最长时间。<br/>
应用 HTTP/1.1 版本的缓存服务器遇到同时存在 Expires 首部字段的情况时，会优先处理 max-age 指令，并忽略掉 Expires 首部字段；而 HTTP/1.0 版本的缓存服务器则相反。</p>

<ul>
<li><p>min-fresh 指令<br/>
Cache-Control: min-fresh=60（单位：秒）<br/>
min-fresh 指令要求缓存服务器返回至少还未过指定时间的缓存资源。</p></li>
<li><p>max-stale 指令<br/>
Cache-Control: max-stale=3600（单位：秒）</p></li>
</ul>

<p>使用 max-stale 可指示缓存资源，即使过期也照常接收。<br/>
如果指令未指定参数值，那么无论经过多久，客户端都会接收响应；如果指定了具体参数值，那么即使过期，只要仍处于 max-stale 指定的时间内，仍旧会被客户端接收。</p>

<ul>
<li><p>only-if-cached 指令<br/>
Cache-Control: only-if-cached<br/>
表示客户端仅在缓存服务器本地缓存目标资源的情况下才会要求其返回。换言之，该指令要求缓存服务器不重新加载响应，也不会再次确认资源的有效性。</p></li>
<li><p>must-revalidate 指令<br/>
Cache-Control: must-revalidate<br/>
使用 must-revalidate 指令，代理会向源服务器再次验证即将返回的响应缓存目前是否仍有效。另外，使用 must-revalidate 指令会忽略请求的 max-stale 指令。</p></li>
<li><p>proxy-revalidate 指令<br/>
Cache-Control: proxy-revalidate<br/>
proxy-revalidate 指令要求所有的缓存服务器在接收到客户端带有该指令的请求返回响应之前，必须再次验证缓存的有效性。</p></li>
<li><p>no-transform 指令<br/>
Cache-Control: no-transform<br/>
使用 no-transform 指令规定无论是在请求还是响应中，缓存都不能改变实体主体的媒体类型。这样做可防止缓存或代理压缩图片等类似操作。</p></li>
</ul>

<h5 id="toc_9">4.1.4 Cache-Control 扩展</h5>

<p>Cache-Control: private, community=&quot;UCI&quot;<br/>
通过 cache-extension 标记（token），可以扩展 Cache-Control 首部字段内的指令。上述 community 指令即扩展的指令，如果缓存服务器不能理解这个新指令，就会直接忽略掉。</p>

<h4 id="toc_10">4.2 Connection</h4>

<p>Connection 首部字段具备以下两个作用：</p>

<h5 id="toc_11">控制不再转发的首部字段</h5>

<p>Connection: Upgrade<br/>
在客户端发送请求和服务器返回响应中，使用 Connection 首部字段，可控制不再转发给代理的首部字段，即删除后再转发（即Hop-by-hop首部）。</p>

<h5 id="toc_12">管理持久连接</h5>

<p>Connection: close<br/>
HTTP/1.1 版本的默认连接都是持久连接。当服务器端想明确断开连接时，则指定 Connection 首部字段的值为 close。<br/>
Connection: Keep-Alive<br/>
HTTP/1.1 之前的 HTTP 版本的默认连接都是非持久连接。为此，如果想在旧版本的 HTTP 协议上维持持续连接，则需要指定 Connection 首部字段的值为 Keep-Alive。</p>

<h4 id="toc_13">4.3 Date</h4>

<p>表明创建 HTTP 报文的日期和时间。<br/>
Date: Mon, 10 Jul 2017 15:50:06 GMT<br/>
HTTP/1.1 协议使用在 RFC1123 中规定的日期时间的格式。</p>

<h4 id="toc_14">4.4 Pragma</h4>

<p>Pragma 首部字段是 HTTP/1.1 版本之前的历史遗留字段，仅作为与 HTTP/1.0 的向后兼容而定义。<br/>
Pragma: no-cache</p>

<p>该首部字段属于通用首部字段，但只用在客户端发送的请求中，要求所有的中间服务器不返回缓存的资源。</p>

<p>所有的中间服务器如果都能以 HTTP/1.1 为基准，那直接采用 Cache-Control: no-cache 指定缓存的处理方式最为理想。但是要整体掌握所有中间服务器使用的 HTTP 协议版本却是不现实的，所以，发送的请求会同时包含下面两个首部字</p>

<pre><code class="language-text">Cache-Control: no-cache
Pragma: no-cache
</code></pre>

<h4 id="toc_15">4.5 Trailer</h4>

<p>Trailer: Expires</p>

<p>首部字段 Trailer 会事先说明在报文主体后记录了哪些首部字段。可应用在 HTTP/1.1 版本分块传输编码时。</p>

<h4 id="toc_16">4.6 Transfer-Encoding</h4>

<p>Transfer-Encoding: chunked</p>

<p>规定了传输报文主体时采用的编码方式。<br/>
HTTP/1.1 的传输编码方式仅对分块传输编码有效。</p>

<h4 id="toc_17">4.7 Upgrade</h4>

<p>Upgrade: TSL/1.0<br/>
用于检测 HTTP 协议及其他协议是否可使用更高的版本进行通信，其参数值可以用来指定一个完全不同的通信协议。</p>

<h4 id="toc_18">4.8 Via</h4>

<p>Via: 1.1 a1.sample.com(Squid/2.7)<br/>
为了追踪客户端和服务器端之间的请求和响应报文的传输路径。<br/>
报文经过代理或网关时，会现在首部字段 Via 中附加该服务器的信息，然后再进行转发。<br/>
首部字段 Via 不仅用于追踪报文的转发，还可避免请求回环的发生。</p>

<h4 id="toc_19">4.9 Warning</h4>

<p>该首部字段通常会告知用户一些与缓存相关的问题的警告。<br/>
Warning 首部字段的格式如下：<br/>
Warning：[警告码][警告的主机:端口号] &quot;[警告内容]&quot;([日期时间])<br/>
最后的日期时间可省略。<br/>
HTTP/1.1 中定义了7种警告，警告码对应的警告内容仅推荐参考，另外，警告码具备扩展性，今后有可能追加新的警告码。</p>

<table>
<thead>
<tr>
<th>警告码</th>
<th>警告内容</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>110</td>
<td>Response is stale(响应已过期)</td>
<td>代理返回已过期的资源</td>
</tr>
<tr>
<td>111</td>
<td>Revalidation failed(再验证失败)</td>
<td>代理再验证资源有效性时失败（服务器无法到达等原因）</td>
</tr>
<tr>
<td>112</td>
<td>Disconnection operation(断开连接操作)</td>
<td>代理与互联网连接被故意切断</td>
</tr>
<tr>
<td>113</td>
<td>Heuristic expiration(试探性过期)</td>
<td>响应的试用期超过24小时(有效缓存的设定时间大于24小时的情况下)</td>
</tr>
<tr>
<td>199</td>
<td>Miscellaneous warning(杂项警告)</td>
<td>任意的警告内容</td>
</tr>
<tr>
<td>214</td>
<td>Transformation applied(使用了转换)</td>
<td>代理对内容编码或媒体类型等执行了某些处理时</td>
</tr>
<tr>
<td>299</td>
<td>Miscellaneous persistent warning(持久杂项警告)</td>
<td>任意的警告内容</td>
</tr>
</tbody>
</table>

<h2 id="toc_20">二、  请求首部字段（HTTP/1.1）</h2>

<table>
<thead>
<tr>
<th>首部字段名</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>Accept</td>
<td>用户代理可处理的媒体类型</td>
</tr>
<tr>
<td>Accept-Charset</td>
<td>优先的字符集</td>
</tr>
<tr>
<td>Accept-Encoding</td>
<td>优先的内容编码</td>
</tr>
<tr>
<td>Accept-Language</td>
<td>优先的语言（自然语言）</td>
</tr>
<tr>
<td>Authorization</td>
<td>Web认证信息</td>
</tr>
<tr>
<td>Expect</td>
<td>期待服务器的特定行为</td>
</tr>
<tr>
<td>From</td>
<td>用户的电子邮箱地址</td>
</tr>
<tr>
<td>Host</td>
<td>请求资源所在服务器</td>
</tr>
<tr>
<td>If-Match</td>
<td>比较实体标记（ETag）</td>
</tr>
<tr>
<td>If-Modified-Since</td>
<td>比较资源的更新时间</td>
</tr>
<tr>
<td>If-None-Match</td>
<td>比较实体标记（与 If-Macth 相反）</td>
</tr>
<tr>
<td>If-Range</td>
<td>资源未更新时发送实体 Byte 的范围请求</td>
</tr>
<tr>
<td>If-Unmodified-Since</td>
<td>比较资源的更新时间(与 If-Modified-Since 相反)</td>
</tr>
<tr>
<td>Max-Forwards</td>
<td>最大传输逐跳数</td>
</tr>
<tr>
<td>Proxy-Authorization</td>
<td>代理服务器要求客户端的认证信息</td>
</tr>
<tr>
<td>Range</td>
<td>实体的字节范围请求</td>
</tr>
<tr>
<td>Referer</td>
<td>对请求中 URI 的原始获取方</td>
</tr>
<tr>
<td>TE</td>
<td>传输编码的优先级</td>
</tr>
<tr>
<td>User-Agent</td>
<td>HTTP</td>
</tr>
</tbody>
</table>

<h3 id="toc_21">1 Accept</h3>

<pre><code class="language-text">Accept: text/html, application/xhtml+xml, application/xml; q=0.5
</code></pre>

<p>Accept 首部字段可通知服务器，用户代理能够处理的媒体类型及媒体类型的相对优先级。可使用 type/subtype 这种形式，一次指定多种媒体类型。<br/>
若想要给显示的媒体类型增加优先级，则使用 q=[数值] 来表示权重值，用分号（;）进行分隔。权重值的范围 0~1（可精确到小数点后三位），且 1 为最大值。不指定权重值时，默认为 1。</p>

<h3 id="toc_22">2 Accept-Charset</h3>

<pre><code class="language-text">Accept-Charset: iso-8859-5, unicode-1-1; q=0.8
</code></pre>

<p>Accept-Charset 首部字段可用来通知服务器用户代理支持的字符集及字符集的相对优先顺序。另外，可一次性指定多种字符集。同样使用 q=[数值] 来表示相对优先级。</p>

<h3 id="toc_23">3 Accept-Encoding</h3>

<pre><code class="language-text">Accept-Encoding: gzip, deflate
</code></pre>

<p>Accept-Encoding 首部字段用来告知服务器用户代理支持的内容编码及内容编码的优先顺序，并可一次性指定多种内容编码。同样使用 q=[数值] 来表示相对优先级。也可使用星号（*）作为通配符，指定任意的编码格式。</p>

<h3 id="toc_24">4 Accept-Language</h3>

<pre><code class="language-text">Accept-Lanuage: zh-cn,zh;q=0.7,en=us,en;q=0.3
</code></pre>

<p>告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级，可一次性指定多种自然语言集。同样使用 q=[数值] 来表示相对优先级。</p>

<h3 id="toc_25">5 Authorization</h3>

<pre><code class="language-text">Authorization: Basic ldfKDHKfkDdasSAEdasd==
</code></pre>

<p>告知服务器用户代理的认证信息（证书值）。通常，想要通过服务器认证的用户代理会在接收到返回的 401 状态码响应后，把首部字段 Authorization 加入请求中。共用缓存在接收到含有 Authorization 首部字段的请求时的操作处理会略有差异。</p>

<h3 id="toc_26">6 Expect</h3>

<pre><code class="language-text">Expect: 100-continue
</code></pre>

<p>告知服务器客户端期望出现的某种特定行为。</p>

<h3 id="toc_27">7 From</h3>

<pre><code class="language-text">From: Deeson_Woo@163.com
</code></pre>

<p>告知服务器使用用户代理的电子邮件地址。</p>

<h3 id="toc_28">8 Host</h3>

<pre><code class="language-text">Host: www.jianshu.com
</code></pre>

<p>告知服务器，请求的资源所处的互联网主机和端口号。<br/>
Host 首部字段是 HTTP/1.1 规范内唯一一个必须被包含在请求内的首部字段。<br/>
若服务器未设定主机名，那直接发送一个空值即可 Host: 。</p>

<h3 id="toc_29">9 If-Match</h3>

<p>形如 If-xxx 这种样式的请求首部字段，都可称为条件请求。服务器接收到附带条件的请求后，只有判断指定条件为真时，才会执行请求。</p>

<pre><code class="language-text">If-Match: &quot;123456&quot;
</code></pre>

<p>首部字段 If-Match，属附带条件之一，它会告知服务器匹配资源所用的实体标记（ETag）值。这时的服务器无法使用弱 ETag 值。<br/>
服务器会比对 If-Match 的字段值和资源的 ETag 值，仅当两者一致时，才会执行请求。反之，则返回状态码 412 Precondition Failed 的响应。<br/>
还可以使用星号（*）指定 If-Match 的字段值。针对这种情况，服务器将会忽略 ETag 的值，只要资源存在就处理请求。</p>

<h3 id="toc_30">10 If-Modified-Since</h3>

<pre><code class="language-text">If-Modified-Since: Mon, 10 Jul 2017 15:50:06 GMT
</code></pre>

<p>首部字段 If-Modified-Since，属附带条件之一，用于确认代理或客户端拥有的本地资源的有效性。<br/>
它会告知服务器若 If-Modified-Since 字段值早于资源的更新时间，则希望能处理该请求。而在指定 If-Modified-Since 字段值的日期时间之后，如果请求的资源都没有过更新，则返回状态码 304 Not Modified 的响应。</p>

<h3 id="toc_31">11 If-None-Match</h3>

<pre><code class="language-text">If-None-Match: &quot;123456&quot;
</code></pre>

<p>首部字段 If-None-Match 属于附带条件之一。它和首部字段 If-Match 作用相反。用于指定 If-None-Match 字段值的实体标记（ETag）值与请求资源的 ETag 不一致时，它就告知服务器处理该请求。</p>

<h3 id="toc_32">12 If-Range</h3>

<pre><code class="language-text">If-Range: &quot;123456&quot;
</code></pre>

<p>首部字段 If-Range 属于附带条件之一。它告知服务器若指定的 If-Range 字段值（ETag 值或者时间）和请求资源的 ETag 值或时间相一致时，则作为范围请求处理。反之，则返回全体资源。</p>

<p>下面我们思考一下不使用首部字段 If-Range 发送请求的情况。服务器端的资源如果更新，那客户端持有资源中的一部分也会随之无效，当然，范围请求作为前提是无效的。这时，服务器会暂且以状态码 412 Precondition Failed 作为响应返回，其目的是催促客户端再次发送请求。这样一来，与使用首部字段 If-Range 比起来，就需要花费两倍的功夫。</p>

<h3 id="toc_33">13 If-Unmodified-Since</h3>

<pre><code class="language-text">If-Unmodified-Since: Mon, 10 Jul 2017 15:50:06 GMT
</code></pre>

<p>首部字段 If-Unmodified-Since 和首部字段 If-Modified-Since 的作用相反。它的作用的是告知服务器，指定的请求资源只有在字段值内指定的日期时间之后，未发生更新的情况下，才能处理请求。如果在指定日期时间后发生了更新，则以状态码 412 Precondition Failed 作为响应返回。</p>

<h3 id="toc_34">14 Max-Forwards</h3>

<pre><code class="language-text">Max-Forwards: 10
</code></pre>

<p>通过 TRACE 方法或 OPTIONS 方法，发送包含首部字段 Max-Forwards 的请求时，该字段以十进制整数形式指定可经过的服务器最大数目。服务器在往下一个服务器转发请求之前，Max-Forwards 的值减 1 后重新赋值。当服务器接收到 Max-Forwards 值为 0 的请求时，则不再进行转发，而是直接返回响应。</p>

<h3 id="toc_35">15 Proxy-Authorization</h3>

<pre><code class="language-text">Proxy-Authorization: Basic dGlwOjkpNLAGfFY5
</code></pre>

<p>接收到从代理服务器发来的认证质询时，客户端会发送包含首部字段 Proxy-Authorization 的请求，以告知服务器认证所需要的信息。<br/>
这个行为是与客户端和服务器之间的 HTTP 访问认证相类似的，不同之处在于，认证行为发生在客户端与代理之间。</p>

<h3 id="toc_36">16 Range</h3>

<pre><code class="language-text">Range: bytes=5001-10000
</code></pre>

<p>对于只需获取部分资源的范围请求，包含首部字段 Range 即可告知服务器资源的指定范围。<br/>
接收到附带 Range 首部字段请求的服务器，会在处理请求之后返回状态码为 206 Partial Content 的响应。无法处理该范围请求时，则会返回状态码 200 OK 的响应及全部资源。</p>

<h3 id="toc_37">17 Referer</h3>

<pre><code class="language-text">Referer: http://www.sample.com/index.html
</code></pre>

<p>首部字段 Referer 会告知服务器请求的原始资源的 URI。</p>

<h3 id="toc_38">18 TE</h3>

<pre><code class="language-text">TE: gzip, deflate; q=0.5
</code></pre>

<p>首部字段 TE 会告知服务器客户端能够处理响应的传输编码方式及相对优先级。它和首部字段 Accept-Encoding 的功能很相像，但是用于传输编码。<br/>
首部字段 TE 除指定传输编码之外，还可以指定伴随 trailer 字段的分块传输编码的方式。应用后者时，只需把 trailers 赋值给该字段值。TE: trailers</p>

<h3 id="toc_39">19 User-Agent</h3>

<pre><code class="language-text">User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:13.0) Gecko/20100101
</code></pre>

<p>首部字段 User-Agent 会将创建请求的浏览器和用户代理名称等信息传达给服务器。</p>

<p>由网络爬虫发起请求时，有可能会在字段内添加爬虫作者的电子邮件地址。此外，如果请求经过代理，那么中间也很可能被添加上代理服务器的名称。</p>

<h2 id="toc_40">三、 响应首部字段（HTTP/1.1）</h2>

<table>
<thead>
<tr>
<th>首部字段名</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>Accept-Ranges</td>
<td>是否接受字节范围请求</td>
</tr>
<tr>
<td>Age</td>
<td>推算资源创建经过时间</td>
</tr>
<tr>
<td>ETag</td>
<td>资源的匹配信息</td>
</tr>
<tr>
<td>Location</td>
<td>令客户端重定向至指定 URI</td>
</tr>
<tr>
<td>Proxy-Authenticate</td>
<td>代理服务器对客户端的认证信息</td>
</tr>
<tr>
<td>Retry-After</td>
<td>对再次发起请求的时机要求</td>
</tr>
<tr>
<td>Server</td>
<td>HTTP 服务器的安装信息</td>
</tr>
<tr>
<td>Vary</td>
<td>代理服务器缓存的管理信息</td>
</tr>
<tr>
<td>WWW-Authenticate</td>
<td>服务器对客户端的认证信息</td>
</tr>
</tbody>
</table>

<h3 id="toc_41">1 Accept-Ranges</h3>

<p>Accept-Ranges: bytes</p>

<p>首部字段 Accept-Ranges 是用来告知客户端服务器是否能处理范围请求，以指定获取服务器端某个部分的资源。<br/>
可指定的字段值有两种，可处理范围请求时指定其为 bytes，反之则指定其为 none。</p>

<h3 id="toc_42">2 Age</h3>

<p>Age: 1200</p>

<p>首部字段 Age 能告知客户端，源服务器在多久前创建了响应。字段值的单位为秒。<br/>
若创建该响应的服务器是缓存服务器，Age 值是指缓存后的响应再次发起认证到认证完成的时间值。代理创建响应时必须加上首部字段 Age。</p>

<h3 id="toc_43">3 ETag</h3>

<p>ETag: &quot;usagi-1234&quot;</p>

<p>首部字段 ETag 能告知客户端实体标识。它是一种可将资源以字符串形式做唯一性标识的方式。服务器会为每份资源分配对应的 ETag 值。</p>

<p>另外，当资源更新时，ETag 值也需要更新。生成 ETag 值时，并没有统一的算法规则，而仅仅是由服务器来分配。</p>

<p>ETag 中有强 ETag 值和弱 ETag 值之分。强 ETag 值，不论实体发生多么细微的变化都会改变其值；弱 ETag 值只用于提示资源是否相同。只有资源发生了根本改变，产生差异时才会改变 ETag 值。这时，会在字段值最开始处附加 W/： ETag: W/&quot;usagi-1234&quot;。</p>

<h3 id="toc_44">4 Location</h3>

<p>Location: <a href="http://www.sample.com/sample.html">http://www.sample.com/sample.html</a></p>

<p>使用首部字段 Location 可以将响应接收方引导至某个与请求 URI 位置不同的资源。<br/>
基本上，该字段会配合 3xx ：Redirection 的响应，提供重定向的 URI。<br/>
几乎所有的浏览器在接收到包含首部字段 Location 的响应后，都会强制性地尝试对已提示的重定向资源的访问。</p>

<h3 id="toc_45">5 Proxy-Authenticate</h3>

<p>Proxy-Authenticate: Basic realm=&quot;Usagidesign Auth&quot;</p>

<p>首部字段 Proxy-Authenticate 会把由代理服务器所要求的认证信息发送给客户端。<br/>
它与客户端和服务器之间的 HTTP 访问认证的行为相似，不同之处在于其认证行为是在客户端与代理之间进行的。</p>

<h3 id="toc_46">6 Retry-After</h3>

<p>Retry-After: 180</p>

<p>首部字段 Retry-After 告知客户端应该在多久之后再次发送请求。主要配合状态码 503 Service Unavailable 响应，或 3xx Redirect 响应一起使用。<br/>
字段值可以指定为具体的日期时间（Mon, 10 Jul 2017 15:50:06 GMT 等格式），也可以是创建响应后的秒数。</p>

<h3 id="toc_47">7 Server</h3>

<p>Server: Apache/2.2.6 (Unix) PHP/5.2.5<br/>
首部字段 Server 告知客户端当前服务器上安装的 HTTP 服务器应用程序的信息。不单单会标出服务器上的软件应用名称，还有可能包括版本号和安装时启用的可选项。</p>

<h3 id="toc_48">8 Vary</h3>

<p>Vary: Accept-Language</p>

<p>首部字段 Vary 可对缓存进行控制。源服务器会向代理服务器传达关于本地缓存使用方法的命令。<br/>
从代理服务器接收到源服务器返回包含 Vary 指定项的响应之后，若再要进行缓存，仅对请求中含有相同 Vary 指定首部字段的请求返回缓存。即使对相同资源发起请求，但由于 Vary 指定的首部字段不相同，因此必须要从源服务器重新获取资源。</p>

<h3 id="toc_49">9 WWW-Authenticate</h3>

<p>WWW-Authenticate: Basic realm=&quot;Usagidesign Auth&quot;<br/>
首部字段 WWW-Authenticate 用于 HTTP 访问认证。它会告知客户端适用于访问请求 URI 所指定资源的认证方案（Basic 或是 Digest）和带参数提示的质询（challenge）。</p>

<h2 id="toc_50">四、 实体首部字段（HTTP/1.1）</h2>

<table>
<thead>
<tr>
<th>首部字段名</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>Allow</td>
<td>资源可支持的 HTTP 方法</td>
</tr>
<tr>
<td>Content-Encoding</td>
<td>实体主体适用的编码方式</td>
</tr>
<tr>
<td>Content-Language</td>
<td>实体主体的自然语言</td>
</tr>
<tr>
<td>Content-Length</td>
<td>实体主体的大小（单位：字节）</td>
</tr>
<tr>
<td>Content-Location</td>
<td>替代对应资源的 URI</td>
</tr>
<tr>
<td>Content-MD5</td>
<td>实体主体的报文摘要</td>
</tr>
<tr>
<td>Content-Range</td>
<td>实体主体的位置范围</td>
</tr>
<tr>
<td>Content-Type</td>
<td>实体主体的媒体类型</td>
</tr>
<tr>
<td>Expires</td>
<td>实体主体过期的日期时间</td>
</tr>
<tr>
<td>Last-Modified</td>
<td>资源的最后修改日期时间</td>
</tr>
</tbody>
</table>

<h3 id="toc_51">1 Allow</h3>

<p>Allow: GET, HEAD</p>

<p>首部字段 Allow 用于通知客户端能够支持 Request-URI 指定资源的所有 HTTP 方法。<br/>
当服务器接收到不支持的 HTTP 方法时，会以状态码 405 Method Not Allowed 作为响应返回。与此同时，还会把所有能支持的 HTTP 方法写入首部字段 Allow 后返回。</p>

<h3 id="toc_52">2 Content-Encoding</h3>

<p>Content-Encoding: gzip</p>

<p>首部字段 Content-Encoding 会告知客户端服务器对实体的主体部分选用的内容编码方式。内容编码是指在不丢失实体信息的前提下所进行的压缩。<br/>
主要采用这 4 种内容编码的方式（gzip、compress、deflate、identity）。</p>

<h3 id="toc_53">3 Content-Language</h3>

<p>Content-Language: zh-CN<br/>
首部字段 Content-Language 会告知客户端，实体主体使用的自然语言（指中文或英文等语言）。</p>

<h3 id="toc_54">4 Content-Length</h3>

<p>Content-Length: 15000<br/>
首部字段 Content-Length 表明了实体主体部分的大小（单位是字节）。对实体主体进行内容编码传输时，不能再使用 Content-Length首部字段。</p>

<h3 id="toc_55">5 Content-Location</h3>

<p>Content-Location: <a href="http://www.sample.com/index.html">http://www.sample.com/index.html</a><br/>
首部字段 Content-Location 给出与报文主体部分相对应的 URI。和首部字段 Location 不同，Content-Location 表示的是报文主体返回资源对应的 URI。</p>

<h3 id="toc_56">6 Content-MD5</h3>

<p>Content-MD5: OGFkZDUwNGVhNGY3N2MxMDIwZmQ4NTBmY2IyTY==<br/>
首部字段 Content-MD5 是一串由 MD5 算法生成的值，其目的在于检查报文主体在传输过程中是否保持完整，以及确认传输到达。</p>

<h3 id="toc_57">7 Content-Range</h3>

<p>Content-Range: bytes 5001-10000/10000<br/>
针对范围请求，返回响应时使用的首部字段 Content-Range，能告知客户端作为响应返回的实体的哪个部分符合范围请求。字段值以字节为单位，表示当前发送部分及整个实体大小。</p>

<h3 id="toc_58">8 Content-Type</h3>

<p>Content-Type: text/html; charset=UTF-8<br/>
首部字段 Content-Type 说明了实体主体内对象的媒体类型。和首部字段 Accept 一样，字段值用 type/subtype 形式赋值。参数 charset 使用 iso-8859-1 或 euc-jp 等字符集进行赋值。</p>

<h3 id="toc_59">9 Expires</h3>

<p>Expires: Mon, 10 Jul 2017 15:50:06 GMT</p>

<p>首部字段 Expires 会将资源失效的日期告知客户端。<br/>
缓存服务器在接收到含有首部字段 Expires 的响应后，会以缓存来应答请求，在 Expires 字段值指定的时间之前，响应的副本会一直被保存。当超过指定的时间后，缓存服务器在请求发送过来时，会转向源服务器请求资源。<br/>
源服务器不希望缓存服务器对资源缓存时，最好在 Expires 字段内写入与首部字段 Date 相同的时间值。</p>

<h3 id="toc_60">10 Last-Modified</h3>

<p>Last-Modified: Mon, 10 Jul 2017 15:50:06 GMT<br/>
首部字段 Last-Modified 指明资源最终修改的时间。一般来说，这个值就是 Request-URI 指定资源被修改的时间。但类似使用 CGI 脚本进行动态数据处理时，该值有可能会变成数据最终修改时的时间</p>

<h2 id="toc_61">五、  Cookie 服务的首部字段</h2>

<table>
<thead>
<tr>
<th>首部字段名</th>
<th>说明</th>
<th>首部类型</th>
</tr>
</thead>

<tbody>
<tr>
<td>Set-Cookie</td>
<td>开始状态管理所使用的 Cookie 信息</td>
<td>响应首部字段</td>
</tr>
<tr>
<td>Cookie</td>
<td>服务器接收到的 Cookie 信息</td>
<td>请求首部字段</td>
</tr>
</tbody>
</table>

<h3 id="toc_62">1 Set-Cookie</h3>

<p>Set-Cookie: status=enable; expires=Mon, 10 Jul 2017 15:50:06 GMT; path=/;</p>

<p>下面的表格列举了 Set-Cookie 的字段值。</p>

<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>NAME=VALUE</td>
<td>赋予 Cookie 的名称和其值（必需项）</td>
</tr>
<tr>
<td>expires=DATE</td>
<td>Cookie 的有效期（若不明确指定则默认为浏览器关闭前为止）</td>
</tr>
<tr>
<td>path=PATH</td>
<td>将服务器上的文件目录作为Cookie的适用对象（若不指定则默认为文档所在的文件目录）</td>
</tr>
<tr>
<td>domain=域名</td>
<td>作为 Cookie 适用对象的域名 （若不指定则默认为创建 Cookie的服务器的域名）</td>
</tr>
<tr>
<td>Secure</td>
<td>仅在 HTTPS 安全通信时才会发送 Cookie</td>
</tr>
<tr>
<td>HttpOnly</td>
<td>加以限制，使 Cookie 不能被 JavaScript 脚本访问</td>
</tr>
</tbody>
</table>

<h4 id="toc_63">1.1 expires 属性</h4>

<p>Cookie 的 expires 属性指定浏览器可发送 Cookie 的有效期。<br/>
当省略 expires 属性时，其有效期仅限于维持浏览器会话（Session）时间段内。这通常限于浏览器应用程序被关闭之前。<br/>
另外，一旦 Cookie 从服务器端发送至客户端，服务器端就不存在可以显式删除 Cookie 的方法。但可通过覆盖已过期的 Cookie，实现对客户端 Cookie 的实质性删除操作。</p>

<h4 id="toc_64">1.2 path 属性</h4>

<p>Cookie 的 path 属性可用于限制指定 Cookie 的发送范围的文件目录。</p>

<h4 id="toc_65">1.3 domain 属性</h4>

<p>通过 Cookie 的 domain 属性指定的域名可做到与结尾匹配一致。比如，当指定 example.com 后，除example.com 以外，www.example.com 或 www2.example.com 等都可以发送 Cookie。</p>

<p>因此，除了针对具体指定的多个域名发送 Cookie 之 外，不指定 domain 属性显得更安全。</p>

<h4 id="toc_66">1.4 secure 属性</h4>

<p>Cookie 的 secure 属性用于限制 Web 页面仅在 HTTPS 安全连接时，才可以发送 Cookie。</p>

<h4 id="toc_67">1.5 HttpOnly 属性</h4>

<p>Cookie 的 HttpOnly 属性是 Cookie 的扩展功能，它使 JavaScript 脚本无法获得 Cookie。其主要目的为防止跨站脚本攻击（Cross-site scripting，XSS）对 Cookie 的信息窃取。</p>

<p>通过上述设置，通常从 Web 页面内还可以对 Cookie 进行读取操作。但使用 JavaScript 的 document.cookie 就无法读取附加 HttpOnly 属性后的 Cookie 的内容了。因此，也就无法在 XSS 中利用 JavaScript 劫持 Cookie 了。</p>

<h3 id="toc_68">2 Cookie</h3>

<p>Cookie: status=enable<br/>
首部字段 Cookie 会告知服务器，当客户端想获得 HTTP 状态管理支持时，就会在请求中包含从服务器接收到的 Cookie。接收到多个 Cookie 时，同样可以以多个 Cookie 形式发送。</p>

<h2 id="toc_69">六、 其他首部字段</h2>

<p>HTTP 首部字段是可以自行扩展的。所以在 Web 服务器和浏览器的应用上，会出现各种非标准的首部字段。<br/>
以下是最为常用的首部字段。</p>

<h3 id="toc_70">1 X-Frame-Options</h3>

<p>X-Frame-Options: DENY<br/>
首部字段 X-Frame-Options 属于 HTTP 响应首部，用于控制网站内容在其他 Web 网站的 Frame 标签内的显示问题。其主要目的是为了防止点击劫持（clickjacking）攻击。首部字段 X-Frame-Options 有以下两个可指定的字段值：</p>

<ul>
<li>DENY：拒绝</li>
<li>SAMEORIGIN：仅同源域名下的页面（Top-level-browsing-context）匹配时许可。（比如，当指定 <a href="http://sample.com/sample.html">http://sample.com/sample.html</a> 页面为 SAMEORIGIN 时，那么 sample.com 上所有页面的 frame 都被允许可加载该页面，而 example.com 等其他域名的页面就不行了）</li>
</ul>

<h3 id="toc_71">2 X-XSS-Protection</h3>

<p>X-XSS-Protection: 1<br/>
首部字段 X-XSS-Protection 属于 HTTP 响应首部，它是针对跨站脚本攻击（XSS）的一种对策，用于控制浏览器 XSS 防护机制的开关。首部字段 X-XSS-Protection 可指定的字段值如下:</p>

<ul>
<li>0 ：将 XSS 过滤设置成无效状态</li>
<li><p>1 ：将 XSS 过滤设置成有效状态</p>
<h3 id="toc_72">3 DNT</h3>
<p>DNT: 1<br/>
首部字段 DNT 属于 HTTP 请求首部，其中 DNT 是 Do Not Track 的简称，意为拒绝个人信息被收集，是表示拒绝被精准广告追踪的一种方法。首部字段 DNT 可指定的字段值如下：</p></li>
<li><p>0 ：同意被追踪<br/>
1-  ：拒绝被追踪<br/>
由于首部字段 DNT 的功能具备有效性，所以 Web 服务器需要对 DNT做对应的支持。</p></li>
</ul>

<h3 id="toc_73">4 P3P</h3>

<pre><code class="language-text">P3P: CP=&quot;CAO DSP LAW CURa ADMa DEVa TAIa PSAa PSDa IVAa IVDa OUR BUS IND
</code></pre>

<p>首部字段 P3P 属于 HTTP 响应首部，通过利用 P3P（The Platform for Privacy Preferences，在线隐私偏好平台）技术，可以让 Web 网站上的个人隐私变成一种仅供程序可理解的形式，以达到保护用户隐私的目的。<br/>
要进行 P3P 的设定，需按以下操作步骤进行：</p>

<ul>
<li>步骤 1：创建 P3P 隐私</li>
<li>步骤 2：创建 P3P 隐私对照文件后，保存命名在 /w3c/p3p.xml</li>
<li>步骤 3：从 P3P 隐私中新建 Compact policies 后，输出到 HTTP 响应中</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP协议（二）-- HTTP 协议报文结构]]></title>
    <link href="http://www.throne4j.com/15955594725422.html"/>
    <updated>2020-07-24T10:57:52+08:00</updated>
    <id>http://www.throne4j.com/15955594725422.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1.HTTP 报文</h2>

<p>用于 HTTP 协议交互的信息被称为 HTTP 报文。请求端（客户端）的 HTTP 报文叫做请求报文；响应端（服务器端）的叫做响应报文。HTTP 报文本身是由多行（用 CR+LF 作换行符）数据构成的字符串文本。</p>

<h2 id="toc_1">2.HTTP 报文结构</h2>

<p>HTTP 报文大致可分为报文首部和报文主体两部分。两者由最初出现的空行（CR+LF）来划分。通常，并不一定有报文主体。如下：</p>

<p><figure><img src="media/15955168840534/15957370382069.jpg" alt="HTTP 报文结构"/><figcaption>HTTP 报文结构</figcaption></figure></p>

<p><figure><img src="media/15955168840534/15957373454385.jpg" alt=""/></figure></p>

<h3 id="toc_2">2.1请求报文结构</h3>

<p><figure><img src="media/15955168840534/15957373620655.jpg" alt="请求报文结构"/><figcaption>请求报文结构</figcaption></figure></p>

<p>请求报文的首部内容由以下数据组成：</p>

<ul>
<li>请求行 —— 包含用于请求的方法、请求 URI 和 HTTP 版本。</li>
<li>首部字段 —— 包含表示请求的各种条件和属性的各类首部。（通用首部、请求首部、实体首部以及RFC里未定义的首部如 Cookie 等）<br/>
请求报文的示例，如下：
<figure><img src="media/15955168840534/15957373766248.jpg" alt="请求报文示例"/><figcaption>请求报文示例</figcaption></figure></li>
</ul>

<h3 id="toc_3">2.2响应报文结构</h3>

<p><figure><img src="media/15955168840534/15957373975954.jpg" alt="响应报文结构"/><figcaption>响应报文结构</figcaption></figure></p>

<p>响应报文的首部内容由以下数据组成：</p>

<ul>
<li>状态行 —— 包含表明响应结果的状态码、原因短语和 HTTP 版本。</li>
<li>首部字段 —— 包含表示请求的各种条件和属性的各类首部。（通用首部、响应首部、实体首部以及RFC里未定义的首部如 Cookie 等）<br/>
响应报文的示例，如下：
<figure><img src="media/15955168840534/15957375812162.jpg" alt=""/></figure></li>
</ul>

<h2 id="toc_4">HTTP 报文首部之请求行、状态行</h2>

<h3 id="toc_5">1.请求行</h3>

<p>举个栗子，下面是一个 HTTP 请求的报文：</p>

<pre><code class="language-text">GET  /index.htm  HTTP/1.1
Host: sample.com
</code></pre>

<p>其中，下面的这行就是请求行，</p>

<pre><code class="language-text">GET  /index.htm  HTTP/1.1
</code></pre>

<ul>
<li>开头的 GET 表示请求访问服务器的类型，称为方法；</li>
<li>随后的字符串 /index.htm 指明了请求访问的资源对象，也叫做请求 URI；</li>
<li>最后的 HTTP/1.1，即 HTTP 的版本号，用来提示客户端使用的 HTTP 协议功能。<br/>
综合来看，大意是请求访问某台 HTTP 服务器上的 /index.htm 页面资源。</li>
</ul>

<h3 id="toc_6">2.状态行</h3>

<p>同样举个栗子，下面是一个 HTTP 响应的报文：</p>

<pre><code class="language-text">HTTP/1.1  200  OK
Date: Mon, 10 Jul 2017 15:50:06 GMT
Content-Length: 256
Content-Type: text/html
    
&lt;html&gt;
...
</code></pre>

<p>其中，下面的这行就是状态行，</p>

<pre><code class="language-text">HTTP/1.1  200  OK
</code></pre>

<p>开头的 HTTP/1.1 表示服务器对应的 HTTP 版本；<br/>
紧挨着的 200 OK 表示请求的处理结果的状态码和原因短语。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP协议（一）-- HTTP协议概述]]></title>
    <link href="http://www.throne4j.com/15955168840534.html"/>
    <updated>2020-07-23T23:08:04+08:00</updated>
    <id>http://www.throne4j.com/15955168840534.html</id>
    <content type="html"><![CDATA[
<p><figure><img src="media/15955168840534/15957366995368.jpg" alt=""/></figure></p>

<h2 id="toc_0">一、概述</h2>

<h3 id="toc_1">1.计算机网络体系结构分层</h3>

<p><figure><img src="media/15955168840534/15957367250846.jpg" alt="网络体系结构分层"/><figcaption>网络体系结构分层</figcaption></figure></p>

<h3 id="toc_2">2.TCP/IP 通信传输流</h3>

<p>利用 TCP/IP 协议族进行网络通信时，会通过分层顺序与对方进行通信。发送端从应用层往下走，接收端则从链路层往上走。如下：<br/>
<figure><img src="media/15955168840534/15957367734847.jpg" alt="TCP/IP 通信传输流"/><figcaption>TCP/IP 通信传输流</figcaption></figure></p>

<p>首先作为发送端的客户端在应用层（HTTP 协议）发出一个想看某个 Web 页面的 HTTP 请求。</p>

<p>接着，为了传输方便，在传输层（TCP 协议）把从应用层处收到的数据（HTTP 请求报文）进行分割，并在各个报文上打上标记序号及端口号后转发给网络层。<br/>
在网络层（IP 协议），增加作为通信目的地的 MAC 地址后转发给链路层。这样一来，发往网络的通信请求就准备齐全了。</p>

<p>接收端的服务器在链路层接收到数据，按序往上层发送，一直到应用层。当传输到应用层，才能算真正接收到由客户端发送过来的 HTTP请求。</p>

<p>如下图所示：<br/>
<figure><img src="media/15955168840534/15957367985192.jpg" alt="HTTP 请求"/><figcaption>HTTP 请求</figcaption></figure></p>

<p>在网络体系结构中，包含了众多的网络协议，这篇文章主要围绕 HTTP 协议（HTTP/1.1版本）展开。</p>

<p><code>HTTP协议（HyperText Transfer Protocol，超文本传输协议）是用于从WWW服务器传输超文本到本地浏览器的传输协议。它可以使浏览器更加高效，使网络传输减少。它不仅保证计算机正确快速地传输超文本文档，还确定传输文档中的哪一部分，以及哪部分内容首先显示(如文本先于图形)等。<br/>
HTTP是客户端浏览器或其他程序与Web服务器之间的应用层通信协议。在Internet上的Web服务器上存放的都是超文本信息，客户机需要通过HTTP协议传输所要访问的超文本信息。HTTP包含命令和传输信息，不仅可用于Web访问，也可以用于其他因特网/内联网应用系统之间的通信，从而实现各类应用资源超媒体访问的集成。<br/>
我们在浏览器的地址栏里输入的网站地址叫做URL (Uniform Resource Locator，统一资源定位符)。就像每家每户都有一个门牌地址一样，每个网页也都有一个Internet地址。当你在浏览器的地址框中输入一个URL或是单击一个超级链接时，URL就确定了要浏览的地址。浏览器通过超文本传输协议(HTTP)，将Web服务器上站点的网页代码提取出来，并翻译成漂亮的网页。<br/>
</code></p>

<h2 id="toc_3">二、HTTP 工作过程</h2>

<p><figure><img src="media/15955168840534/15957369027873.jpg" alt="HTTP请求响应模型"/><figcaption>HTTP请求响应模型</figcaption></figure></p>

<p>HTTP通信机制是在一次完整的 HTTP 通信过程中，客户端与服务器之间将完成下列7个步骤：</p>

<ul>
<li><p>建立 TCP 连接<br/>
在HTTP工作开始之前，客户端首先要通过网络与服务器建立连接，该连接是通过 TCP 来完成的，该协议与 IP 协议共同构建 Internet，即著名的 TCP/IP 协议族，因此 Internet 又被称作是 TCP/IP 网络。HTTP 是比 TCP 更高层次的应用层协议，根据规则，只有低层协议建立之后，才能进行高层协议的连接，因此，首先要建立 TCP 连接，一般 TCP 连接的端口号是80；</p></li>
<li><p>客户端向服务器发送请求命令<br/>
一旦建立了TCP连接，客户端就会向服务器发送请求命令；<br/>
例如：GET/sample/hello.jsp HTTP/1.1</p></li>
<li><p>客户端发送请求头信息<br/>
客户端发送其请求命令之后，还要以头信息的形式向服务器发送一些别的信息，之后客户端发送了一空白行来通知服务器，它已经结束了该头信息的发送；</p></li>
<li><p>服务器应答<br/>
客户端向服务器发出请求后，服务器会客户端返回响应；<br/>
例如： HTTP/1.1 200 OK<br/>
响应的第一部分是协议的版本号和响应状态码</p></li>
<li><p>服务器返回响应头信息<br/>
正如客户端会随同请求发送关于自身的信息一样，服务器也会随同响应向用户发送关于它自己的数据及被请求的文档；</p></li>
<li><p>服务器向客户端发送数据<br/>
服务器向客户端发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，它就以 Content-Type 响应头信息所描述的格式发送用户所请求的实际数据；</p></li>
<li><p>服务器关闭 TCP 连接<br/>
一般情况下，一旦服务器向客户端返回了请求数据，它就要关闭 TCP 连接，然后如果客户端或者服务器在其头信息加入了这行代码 Connection:keep-alive ，TCP 连接在发送后将仍然保持打开状态，于是，客户端可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。</p></li>
</ul>

<h2 id="toc_4">三、HTTP 协议基础</h2>

<h3 id="toc_5">1.通过请求和响应的交换达成通信</h3>

<p>应用 HTTP 协议时，必定是一端担任客户端角色，另一端担任服务器端角色。仅从一条通信线路来说，服务器端和客服端的角色是确定的。HTTP 协议规定，请求从客户端发出，最后服务器端响应该请求并返回。换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应。</p>

<h3 id="toc_6">2.HTTP 是不保存状态的协议</h3>

<p>HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。<br/>
可是随着 Web 的不断发展，我们的很多业务都需要对通信状态进行保存。于是我们引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了。</p>

<h3 id="toc_7">3.使用 Cookie 的状态管理</h3>

<p>Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。</p>

<p><figure><img src="media/15955168840534/15957369673190.jpg" alt="Cookie 的流程"/><figcaption>Cookie 的流程</figcaption></figure></p>

<h3 id="toc_8">4.请求 URI 定位资源</h3>

<p>HTTP 协议使用 URI 定位互联网上的资源。正是因为 URI 的特定功能，在互联网上任意位置的资源都能访问到。</p>

<h3 id="toc_9">5.告知服务器意图的 HTTP 方法（HTTP/1.1）</h3>

<p><figure><img src="media/15955168840534/15957369934248.jpg" alt="HTTP 方法"/><figcaption>HTTP 方法</figcaption></figure></p>

<h3 id="toc_10">6.持久连接</h3>

<p>HTTP 协议的初始版本中，每进行一个 HTTP 通信都要断开一次 TCP 连接。比如使用浏览器浏览一个包含多张图片的 HTML 页面时，在发送请求访问 HTML 页面资源的同时，也会请求该 HTML 页面里包含的其他资源。因此，每次的请求都会造成无畏的 TCP 连接建立和断开，增加通信量的开销。<br/>
为了解决上述 TCP 连接的问题，HTTP/1.1 和部分 HTTP/1.0 想出了持久连接的方法。其特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。旨在建立一次 TCP 连接后进行多次请求和响应的交互。在 HTTP/1.1 中，所有的连接默认都是持久连接。</p>

<h3 id="toc_11">7.管线化</h3>

<p>持久连接使得多数请求以管线化方式发送成为可能。以前发送请求后需等待并接收到响应，才能发送下一个请求。管线化技术出现后，不用等待亦可发送下一个请求。这样就能做到同时并行发送多个请求，而不需要一个接一个地等待响应了。<br/>
比如，当请求一个包含多张图片的 HTML 页面时，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术要比持久连接速度更快。请求数越多，时间差就越明显。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[# HTTP访问控制（CORS）]]></title>
    <link href="http://www.throne4j.com/15955163850122.html"/>
    <updated>2020-07-23T22:59:45+08:00</updated>
    <id>http://www.throne4j.com/15955163850122.html</id>
    <content type="html"><![CDATA[
<p>跨域资源共享(CORS) 是一种机制，它使用额外的 HTTP 头来告诉浏览器  让运行在一个 origin (domain) 上的Web应用被准许访问来自不同源服务器上的指定的资源。当一个资源从与该资源本身所在的服务器不同的域、协议或端口请求一个资源时，资源会发起一个跨域 HTTP 请求。</p>

<p>比如，站点 <a href="http://domain-a.com">http://domain-a.com</a> 的某 HTML 页面又去请求 <a href="http://domain-b.com/xxx%E9%A1%B5%E9%9D%A2%E3%80%82%E7%BD%91%E7%BB%9C%E4%B8%8A%E7%9A%84%E8%AE%B8%E5%A4%9A%E9%A1%B5%E9%9D%A2%E9%83%BD%E4%BC%9A%E5%8A%A0%E8%BD%BD%E6%9D%A5%E8%87%AA%E4%B8%8D%E5%90%8C%E5%9F%9F%E7%9A%84CSS%E6%A0%B7%E5%BC%8F%E8%A1%A8%EF%BC%8C%E5%9B%BE%E5%83%8F%E5%92%8C%E8%84%9A%E6%9C%AC%E7%AD%89%E8%B5%84%E6%BA%90%E3%80%82">http://domain-b.com/xxx页面。网络上的许多页面都会加载来自不同域的CSS样式表，图像和脚本等资源。</a></p>

<p>出于安全原因，浏览器限制从脚本内发起的跨源HTTP请求。 例如，XMLHttpRequest和Fetch API遵循同源策略。 这意味着使用这些API的Web应用程序只能从加载应用程序的同一个域请求HTTP资源，除非响应报文包含了正确CORS响应头。</p>

<p><figure><img src="media/15955111272689/15955114749443.jpg" alt=""/></figure></p>

<p>跨域资源共享（ CORS ）机制允许 Web 应用服务器进行跨域访问控制，从而使跨域数据传输得以安全进行。现代浏览器支持在 API 容器中（例如 XMLHttpRequest 或 Fetch ）使用 CORS，以降低跨域 HTTP 请求所带来的风险。</p>

<hr/>

<h2 id="toc_0">什么情况下需要 CORS ？</h2>

<p>跨域资源共享标准（ cross-origin sharing standard ）允许在下列场景中使用跨域 HTTP 请求：</p>

<ul>
<li>由 XMLHttpRequest 或 Fetch 发起的跨域 HTTP 请求。</li>
<li>Web 字体 (CSS 中通过 @font-face 使用跨域字体资源), 因此，网站就可以发布 TrueType 字体资源，并只允许已授权网站进行跨站调用。</li>
<li>WebGL 贴图</li>
<li>使用 drawImage 将 Images/video 画面绘制到 canvas<br/>
本文概述了跨域资源共享机制及其所涉及的 HTTP 头。</li>
</ul>

<p>跨域资源共享标准新增了一组 HTTP 首部字段，允许服务器声明哪些源站通过浏览器有权限访问哪些资源。另外，规范要求，对那些可能对服务器数据产生副作用的 HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。在预检请求的返回中，服务器端也可以通知客户端，是否需要携带身份凭证（包括 Cookies 和 HTTP 认证相关数据）。</p>

<p>CORS请求失败会产生错误，但是为了安全，在JavaScript代码层面是无法获知到底具体是哪里出了问题。你只能查看浏览器的控制台以得知具体是哪里出现了错误。</p>

<hr/>

<h2 id="toc_1">HTTP 响应 header 字段</h2>

<p>使用 Origin 和 Access-Control-Allow-Origin 就能完成最简单的访问控制。</p>

<ul>
<li><p>Access-Control-Allow-Origin: <origin> | *<br/>
服务端设置 Access-Control-Allow-Origin 就是告诉浏览器允许向服务端请求资源的域名，浏览器通过 Response 中的 Access-Control-Allow-Origin 就可以知道能不能把数据吐出来。<br/>
例如：</p>
<pre><code class="language-text">Access-Control-Allow-Origin: http://mozilla.com
</code></pre>
<p>如果服务端指定了具体的域名而非“*”，那么响应首部中的 Vary 字段的值必须包含 Origin。这将告诉客户端：服务器对不同的源站返回不同的内容</p></li>
<li><p>Access-Control-Expose-Headers : 让服务器把允许浏览器访问的头放入白名单<br/>
在跨域访问时，XMLHttpRequest对象的getResponseHeader()方法只能拿到一些最基本的响应头，Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma，如果要访问其他头，则需要服务器设置本响应头。<br/>
例如：</p>
<pre><code class="language-text">Access-Control-Expose-Headers: X-My-Custom-Header, X-Another-Custom-Header
</code></pre>
<p>这样浏览器就能够通过getResponseHeader访问X-My-Custom-Header和 X-Another-Custom-Header 响应头了。</p></li>
<li><p>Access-Control-Max-Age: <delta-seconds> <br/>
指定了preflight请求的结果能够被缓存多久，delta-seconds 参数表示preflight请求的结果在多少秒内有效。</p></li>
<li><p>Access-Control-Allow-Credentials: true|false <br/>
指定了当浏览器的credentials设置为true时是否允许浏览器读取response的内容</p></li>
<li><p>Access-Control-Allow-Methods: <method>[, <method>]* <br/>
指明实际请求所允许使用的 HTTP 方法</p></li>
<li><p>Access-Control-Allow-Headers: <field-name>[, <field-name>]* <br/>
指明实际请求中允许携带的首部字段</p></li>
</ul>

<h2 id="toc_2">HTTP 请求header字段</h2>

<ul>
<li>Origin  表明预检请求或实际请求的源站 URI,不管是否跨域ORIGIN 字段总是被发送</li>
<li>Access-Control-Request-Method 将实际请求所使用的 HTTP 方法告诉服务器</li>
<li>Access-Control-Request-Headers  将实际请求所携带的首部字段告诉服务器</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redission 防止用户请求重复提交]]></title>
    <link href="http://www.throne4j.com/15955096929534.html"/>
    <updated>2020-07-23T21:08:12+08:00</updated>
    <id>http://www.throne4j.com/15955096929534.html</id>
    <content type="html"><![CDATA[
<pre><code class="language-text">package com.rongdu.cashloan.core.redisson;
 
import org.apache.commons.lang3.StringUtils;
import org.redisson.Redisson;
import org.redisson.api.*;
import org.redisson.config.Config;
import org.redisson.config.SingleServerConfig;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
 
/***
 * Redis client的辅助工具类
 * 用于连接Redis服务器 创建不同的Redis Server对应的客户端对象
 * @author wangnian
 * 博客地址：http://my.oschina.net/wangnian
 */
public class RedisUtils {
 
   private static  Logger logger= LoggerFactory.getLogger(RedisUtils.class);
 
   private static RedisUtils redisUtils;
 
   private static RedissonClient redissonClient;
 
   private RedisUtils(){}
 
   /**
    * 提供单例模式
    * @return
    */
   public static RedisUtils getInstance(){
      if(redisUtils==null) {
         synchronized (RedisUtils.class) {
            if(redisUtils==null){
               redisUtils=new RedisUtils();
            }
         }
      }
      return redisUtils;
   }
 
 
   /**
    * 使用config创建Redisson
    * Redisson是用于连接Redis Server的基础类
    * @param config
    * @return
    */
   public RedissonClient getRedisson(Config config){
      if(redissonClient==null){
         synchronized (RedisUtils.class) {
            if(redissonClient==null){
               redissonClient=Redisson.create(config);
            }
         }
      }
      return redissonClient;
   }
 
   /**
    * 使用ip地址和端口创建Redisson
    * @param ip
    * @param port
    * @return
    */
   public RedissonClient getRedisson(String ip,String port,String passwd){
 
      if(!ip.startsWith(&quot;http://&quot;)){
         ip = &quot;http://&quot;+ip;
      }
 
      logger.info(&quot;RedisUtils-getRedisson-传入参数-ip：&quot;+ip+&quot;-port:&quot;+port+&quot;-passwd:&quot;+passwd);
      Config config=new Config();
 
      SingleServerConfig singleServerConfig = config.useSingleServer();
 
      singleServerConfig.setAddress(ip+&quot;:&quot;+port).
              setTimeout(200000).
              setRetryAttempts(10).
              // .setIdleConnectionTimeout(10000)
                      setRetryInterval(2000).
              //.setFailedAttempts(20)
                      setSubscriptionsPerConnection(5).
              setSubscriptionConnectionPoolSize(10).
              setConnectionPoolSize(64).
              setDatabase(0);
 
      if(StringUtils.isNotBlank(passwd)){
         singleServerConfig.setPassword(passwd);
      }
 
      if(redissonClient==null){
         synchronized (RedisUtils.class) {
            if(redissonClient==null){
               redissonClient=Redisson.create(config);
            }
         }
      }
      return redissonClient;
   }
 
   /**
    * 关闭Redisson客户端连接
    * @param redisson
    */
   public void closeRedisson(RedissonClient redisson){
      redisson.shutdown();
   }
 
   /**
    * 获取字符串对象
    * @param redisson
    * @param objectName
    * @return
    */
   public &lt;T&gt; RBucket&lt;T&gt; getRBucket(RedissonClient redisson, String objectName){
      RBucket&lt;T&gt; bucket=redisson.getBucket(objectName);
      return bucket;
   }
 
   /**
    * 获取Map对象
    * @param redisson
    * @param objectName
    * @return
    */
   public &lt;K,V&gt; RMap&lt;K, V&gt; getRMap(RedissonClient redisson, String objectName){
      RMap&lt;K, V&gt; map=redisson.getMap(objectName);
      return map;
   }
 
   /**
    * 获取有序集合
    * @param redisson
    * @param objectName
    * @return
    */
   public &lt;V&gt; RSortedSet&lt;V&gt; getRSortedSet(RedissonClient redisson, String objectName){
      RSortedSet&lt;V&gt; sortedSet=redisson.getSortedSet(objectName);
      return sortedSet;
   }
 
   /**
    * 获取集合
    * @param redisson
    * @param objectName
    * @return
    */
   public &lt;V&gt; RSet&lt;V&gt; getRSet(RedissonClient redisson, String objectName){
      RSet&lt;V&gt; rSet=redisson.getSet(objectName);
      return rSet;
   }
 
   /**
    * 获取列表
    * @param redisson
    * @param objectName
    * @return
    */
   public &lt;V&gt; RList&lt;V&gt; getRList(RedissonClient redisson,String objectName){
      RList&lt;V&gt; rList=redisson.getList(objectName);
      return rList;
   }
 
   /**
    * 获取队列
    * @param redisson
    * @param objectName
    * @return
    */
   public &lt;V&gt; RQueue&lt;V&gt; getRQueue(RedissonClient redisson,String objectName){
      RQueue&lt;V&gt; rQueue=redisson.getQueue(objectName);
      return rQueue;
   }
 
   /**
    * 获取双端队列
    * @param redisson
    * @param objectName
    * @return
    */
   public &lt;V&gt; RDeque&lt;V&gt; getRDeque(RedissonClient redisson,String objectName){
      RDeque&lt;V&gt; rDeque=redisson.getDeque(objectName);
      return rDeque;
   }
 
   /**
    * 此方法不可用在Redisson 1.2 中 
    * 在1.2.2版本中 可用
    * @param redisson
    * @param objectName
    * @return
    */
   /**
    public &lt;V&gt; RBlockingQueue&lt;V&gt; getRBlockingQueue(RedissonClient redisson,String objectName){
    RBlockingQueue rb=redisson.getBlockingQueue(objectName);
    return rb;
    }*/
 
   /**
    * 获取锁
    * @param redisson
    * @param objectName
    * @return
    */
   public RLock getRLock(RedissonClient redisson,String objectName){
      RLock rLock=redisson.getLock(objectName);
      return rLock;
   }
 
   /**
    * 获取原子数
    * @param redisson
    * @param objectName
    * @return
    */
   public RAtomicLong getRAtomicLong(RedissonClient redisson,String objectName){
      RAtomicLong rAtomicLong=redisson.getAtomicLong(objectName);
      return rAtomicLong;
   }
 
   /**
    * 获取记数锁
    * @param redisson
    * @param objectName
    * @return
    */
   public RCountDownLatch getRCountDownLatch(RedissonClient redisson,String objectName){
      RCountDownLatch rCountDownLatch=redisson.getCountDownLatch(objectName);
      return rCountDownLatch;
   }
 
   /**
    * 获取消息的Topic
    * @param redisson
    * @param objectName
    * @return
    */
   public &lt;M&gt; RTopic&lt;M&gt; getRTopic(RedissonClient redisson,String objectName){
      RTopic&lt;M&gt; rTopic=redisson.getTopic(objectName);
      return rTopic;
   }
 
 
}
</code></pre>

<pre><code class="language-text">public void commitUserReq(HttpServletRequest request){
        final RedissonClient redisson = RedisUtils.getInstance().getRedisson(redisIp,redisPort,redisPasswd);
        // 防重复提交锁
        RLock lock = redisson.getLock(orderId + &quot;COMMIT_ORDER&quot; + userId);
        try {
            boolean res = lock.tryLock(0, 10, TimeUnit.SECONDS);
            if (!res){
                throw new SimpleMessageException(&quot;操作太频繁！&quot;);
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 防止正在请求过程再发起请求
        boolean isBack = false;
        RLock lock2 = redisson.getLock(orderId + &quot;LOCK_BUTTON&quot; + userId);
        lock2.lock(10,TimeUnit.SECONDS);
        if (redisClient.exists(&quot;BUTTON_PAY_&quot;+ userId)){
            isBack = true;
        }else{
            redisClient.setObject(&quot;BUTTON_PAY_&quot;+ userId,borrowId,20*60);
        }
        lock2.unlock();
        if (isBack){
            logger.info(&quot;系统提交已经开始&quot;);
            throw new SimpleMessageException(&quot;你有请求正在处理，请20分钟后再试！&quot;);
        }
        System.out.println(&quot;处理业务代码==========正常执行&quot;);
        
        }
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[十三、过期键的删除策略]]></title>
    <link href="http://www.throne4j.com/15952588914829.html"/>
    <updated>2020-07-20T23:28:11+08:00</updated>
    <id>http://www.throne4j.com/15952588914829.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">redis过期键删除策略</h2>

<p>一个键过期了，它什么时候被删除呢？</p>

<p>Redis 服务器采用惰性删除策略和定期删除两种策略，通过分配使用这两种删除策略，redis服务器可以很好的利用cpu时间和避免内存浪费之间取得一个较好的平衡</p>

<ul>
<li>定时删除:在设置键的过期时间的同时,创建一个定时器( timer),让定时器在键的过期时间来临时,立即执行对键的删除操作。</li>
<li>惰性删除:放任键过期不管,但是每次从键空间中获取健时,都检查取得的键是否过期,如果过期的话,就删除该键;如果没有过期,就返回该键。</li>
<li>定期删除:每隔一段时间,程序就对数据库进行一次检查,删除里面的过期键。至于要删除多少过期键,以及要检査多少个数据库,则由算法决定。<br/>
在这三种策略中,第一种和第三种为主动删除策略,而第二种则为被动删除策略。</li>
</ul>

<h2 id="toc_1">定时删除策略</h2>

<p>定时删除策略，设置键过期时间的同时，创建定时器，让定时器在键的过期时间来来临时立即执行对键的删除操作。</p>

<p>优点是：可以保证过期键会尽可能快的被删除，并释放过期键所占用的内存，</p>

<p>但缺点也很明显：会占用一定的cpu时间，影响服务器的响应时间和吞吐量，</p>

<p>除此之外，创建定时器需要用到 redis 服务器的时间事件，而当前时间事件的实现方式是无序链表，查找一个时间的时间复杂度为 O(N)，并不能高效的处理大量的时间事件。</p>

<h2 id="toc_2">惰性删除策略</h2>

<p>惰性删除策略，访问数据库键时，校验该键是否过期，如果过期则删除</p>

<p>优点是：对cpu时间来说最友好，程序只会在取出键时才对键进行过期检查，可以保证删除过期键的操作只会在费做不可的情况下进行，并且删除过期键的操作仅限当前处理的键，</p>

<p>但是此种策略非常占用内存，有内存泄漏的风险，已过期的键不会立马删除，占着内存直到下次访问时才会释放内存空间。</p>

<h2 id="toc_3">定期删除策略</h2>

<p>定期删除策略，周期性删除过期键，redisServer启动过程最后一步(开启事件循环，会触发Redis的定时任务的时间事件，查看 <a href="15934396305281.html">三、redis命令处理生命周期</a>) </p>

<ul>
<li>每个一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对cpu时间的影响</li>
<li>通过定期删除过期键，有效的减少了过期键带来的内存损耗。</li>
</ul>

<p>定期删除策略的难点是确定删除操作执行的时长和频率：</p>

<ul>
<li>如果删除操作执行得太频繁,或者执行的时间太长,定期删除策略就会退化成定时除策略,以至于将CPU时间过多地消耗在删除过期键上面。</li>
<li>如果删除操作执行得太少,或者执行的时间太短,定期删除策略又会和惰性删除策略一样,出现浪费内存的情况。</li>
</ul>

<h2 id="toc_4">AOF、RDB和复制功能对过期键的处理</h2>

<h3 id="toc_5">RDB 文件生成</h3>

<p>在执行SAⅣE命令或者 BGSAVE命令创建一个新的RDB文件时,程序会对数据库中的键进行检查,已过期的键不会被保存到新创建的RDB文件中。</p>

<h3 id="toc_6">载入RDB文件</h3>

<p>在启动 Redis服务器时,如果服务器开启了RDB功能,那么服务器将对RDB文件进行载人: </p>

<ul>
<li>如果服务器以主服务器模式运行,那么在载入RDB文件时,程序会对文件中保存的键进行检查,未过期的键会被载入到数据库中,而过期键则会被忽略,所以过期键对载入RDB文件的主服务器不会造成影响</li>
<li>如果服务器以从服务器模式运行,那么在载入RDB文件时,文件中保存的所有键, 不论是否过期,都会被载人到数据库中。不过,因为主从服务器在进行数据同步的时候,从服务器的数据库就会被清空,所以一般来讲,过期键对载人RDB文件的从服务器也不会造成影响。</li>
</ul>

<h3 id="toc_7">AOF 文件写入</h3>

<p>当服务器以AOF持久化模式运行时,如果数据库中的某个键已经过期,但它还没有被惰性删除或者定期删除,那么AOF文件不会因为这个过期键而产生任何影响。</p>

<p>当过期键被惰性删除或者定期删除之后, 程序会向AOF文件迫加( append)一条DEL 命令,来显式地记录该键已被删除。</p>

<p>举个例子,如果客户端使用 GET message命令,试图访向问过期的 message键,那么服务器将执行以下三个动作: </p>

<p>1)从数据库中删除 message键。<br/>
2)追加一条 DEL message命令到AOF文件。<br/>
3)向执行GET命令的客户端返回空回复。</p>

<p>和生成RDB文件时类似,在执行AOF重写的过程中,程序会对数据库中的键进行检査,已过期的键不会被保存到重写后的AOF文件中。</p>

<h2 id="toc_8">复制</h2>

<p>当服务器运行在复制模式下时,从服务器的过期键删除动作由主服务器控制</p>

<ul>
<li>主服务器在删除一个过期键之后,会显式地向所有从服务器发送一个DEL命令,告知从服务器删除这个过期键。</li>
<li>从服务器在执行客户端发送的读命令时,即使碰到过期键也不会将过期健删除,而是继续像处理未过期的键一样来处理过期键。</li>
<li>从服务器只有在接到主服务器发来的DEL命令之后,才会删除过期键。</li>
</ul>

<p>通过由主服务器来控制从服务器统一地删除过期键,可以保证主从服务器数据的一致性,也正是因为这个原因,当一个过期键仍然存在于主服务器的数据库时,这个过期键在从服务器里的复制品也会继续存在。</p>

<p>如果这时有客户端向从服务器发送命令 GET message,那么从服务器将发现 message 键已经过期,但从服务器并不会删除 message键,而是继续将 message键的值返回给客户端,就好像 message健并没有过期一样。</p>

<p>假设在此之后,有客户端向主服务器发送命令 GET message,那么主服务器将发现键message已经过期，主服务器会删除 message键,向客户端返回空回复,并向从服务器发送 DEL message命令。</p>

<p>从服务器在接收到主服务器发来的DEL message命令之后,也会从数据库中删除 message键,在这之后,主从服务器都不再保存过期键 message了。</p>

<h2 id="toc_9">总结</h2>

<p>Redis使用惰性删除和定期删除两种策略来删除过期的键:惰性删除策略只在碰到过期键时才进行删除操作,定期删除策略则每隔一段时间主动査找并删除过期键。</p>

<p>执行SAVE命令或者 BGSAVE命令所产生的新RDB文件不会包含已经过期的键。</p>

<p>执行 BGREWRITEAOF命令所产生的重写AOF文件不会包含已经过期的键。</p>

<p>当一个过期键被删除之后,服务器会追加一条DEL命令到现有AOF文件的末尾, 显式地删除过期键。</p>

<p>当主服务器删除一个过期键之后,它会向所有从服务器发送一条DEL命令,显式地删除过期键。</p>

<p>从服务器即使发现过期键也不会自作主张地删除它,而是等待主节点发来DEL命令, 这种统一、中心化的过期键删除策略可以保证主从服务器数据的一致性。</p>

<p>当 Redis命令对数据库进行修改之后,服务器会根据配置向客户端发送数据库通知。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[十二、集群]]></title>
    <link href="http://www.throne4j.com/15951723810785.html"/>
    <updated>2020-07-19T23:26:21+08:00</updated>
    <id>http://www.throne4j.com/15951723810785.html</id>
    <content type="html"><![CDATA[
<p>redis集群是在redis 3.0版本推出的一个功能，Redis 集群 提供的分布式数据库方案, 集群通过分片( sharding)来进行数据共享,并提供复制和故障转移功能。其有效的解决了redis在分布式方面的需求。</p>

<p>当遇到单机内存，并发和流量瓶颈等问题时，可采用Cluster方案达到负载均衡的目的。</p>

<p>从另一方面讲，redis中sentinel有效的解决了故障转移的问题，也解决了主节点下线客户端无法识别新的可用节点的问题，但是如果是从节点下线了，sentinel是不会对其进行故障转移的，并且连接从节点的客户端也无法获取到新的可用从节点，而这些问题在Cluster中都得到了有效的解决。</p>

<p>Redis 集群包括如下几个方面 节点、槽指派、命令执行、重新分片、转向、故障转移、消息等。</p>

<p>开启Redis的集群模式需要修改redis.conf文件：</p>

<pre><code class="language-text">cluster-enabled yes
</code></pre>

<p>如下是一个典型的集群部署方式：<br/>
<figure><img src="media/15951723810785/15952500358343.jpg" alt=""/></figure></p>

<p>集群用来提供横向扩展能力，即当数据量增多之后，通过增加服务节点就可以扩展服务能力。背后理论思想是将数据通过某种算法分布到不同的服务节点，这样当节点越多，单台节点所需提供服务的数据就越少。</p>

<p>集群首先需要解决如下问题：</p>

<ul>
<li>分槽（slot）：即如何决定某条数据应该由哪个节点提供服务；</li>
<li>端如何向集群发起请求(客户端并不知道某个数据应该由哪个节点提供服务，并且如果扩容或者节点发生故障后，不应该影响客户端的访问)</li>
<li>某个节点发生故障之后，该节点服务的数据该如何处理？</li>
<li>扩容，即向集群中添加新节点该如何操作？</li>
<li>同一条命令需要处理的key分布在不同的节点中（如Redis中集合取并集、交集的相关命令），如何操作？</li>
</ul>

<h2 id="toc_0">redis 节点</h2>

<p>一个 Redis集群通常有多个节点 （node）组成，一个正常工作的Redis集群通常由多个节点构成。连接各个节点的工作可以使用 cluster meet 命令来完成。</p>

<p>节点和单机服务器在数据库方面的一个区别是,节点只能使用0号数据库,而单机Redis服务器则没有这一限制。</p>

<pre><code class="language-shell">cluster meet &lt;ip&gt; &lt;port&gt;
</code></pre>

<p>向一个节点 node发送 cluster meet命令，可以让node节点与ip和port所指定的节点进行握手（handshake），当握手成功时，node节点就会将ip和port所指定的节点添加到node节点当前所在的集群中。</p>

<p>通过命令查看集群当前包含的节点信息</p>

<pre><code class="language-shell">127.0.0.1:6379&gt; cluster nodes
a3e1647af22358f9923f05779c2f36699361e969 :6379@16379 myself,master - 0 0 0 connected
</code></pre>

<p>通过 cluster meet 命令将 指定节点添加到集群后，cluster nodes 命令将返回多个节点信息。</p>

<p>收到命令的节点A将与节点B进行握手( handshake),以此来确认彼此的存在,并为将来的进一步通信打好基础: <br/>
1)节点A会为节点B创建一个c1 osterode结构,并将该结构添加到自己的c1 interstate. nodes字典里面。</p>

<p>2)之后,节点A将根据CLUSTER MEET命令给定的P地址和端口号,向节点B发送一条MET消息( message) </p>

<p>3)如果一切顺利,节点B将接收到节点A发送的MEET消息,节点B会为节点A创建一个c1 osterode结构,并将该结构添加到自己的c1 usterstate. nodes字典里面。</p>

<p>4)之后,节点B将向节点A返回一条PONG消息。</p>

<p>5)如果一切顺利,节点A将接收到节点B返回的PONG消息,通过这条PONG消息节点A可以知道节点B已经成功地接收到了自己发送的MEET消息。</p>

<p>6)之后,节点A将向节点B返回一条PING消息。</p>

<p>7)如果一切顺利,节点B将接收到节点A返回的PING消息,通过这条PING消息节点B可以知道节点A已经成功地接收到了自己返回的PONG消息,握手完成。</p>

<h2 id="toc_1">slot 槽</h2>

<p>redis集群中数据是和槽（slot）挂钩的，Redis将键空间分为了16384个slot槽，所有的数据根据一致哈希算法会被映射到这16384个槽中的某个槽中；另一方面，这16384个槽是按照设置被分配到不同的redis节点上的。</p>

<p>当数据库中的16384个槽都有节点在处理时,集群处于上线状态(ok);相反地,如果数据库中有任何一个槽没有得到处理,那么集群处于下线状态(fail)。</p>

<p>Redis 通过如下算法计算出每个key所属的slot</p>

<pre><code class="language-text">HASH_SLOT = CRC16(key) mod 16384
</code></pre>

<p>客户端可以请求任意一个节点，每个节点中都会保存所有16384个slot对应到哪一个节点的信息。如果一个key所属的slot正好由被请求的节点提供服务，则直接处理并返回结果，否则返回MOVED重定向信息。</p>

<pre><code class="language-text">-MOVED slot IP:PORT
</code></pre>

<p>由-MOVED开头，接着是该key计算出的slot，然后是该slot对应到的节点IP和Port。客户端应该处理该重定向信息，并且向拥有该key 的节点发起请求。</p>

<p>实际应用中，Redis客户端可以通过向集群请求slot 和节点的映射关系并缓存，然后通过本地计算要操作的key所属的slot，查询映射关系，直接向正确的节点发起请求，这样可以获得几乎等价于单节点部署的性能。</p>

<p>集群中的数据分片之后由不同的节点提供服务，即每个主节点的数据都不相同，此种情况下，为了确保没有单点故障，主服务必须挂载至少一个从服务。</p>

<p>客户端请求时可以向任意一个主节点或者从节点发起，当向从节点发起请求时，从节点会返回MOVED信息重定向到相应的主节点。</p>

<p><strong>注意：</strong>Redis集群中，客户端只能在主节点执行读写操作。如果需要在从节点中进行读操作，需要满足如下条件：</p>

<ul>
<li>首先在客户端中执行readonly命令</li>
<li>如果一个key所属的slot由主节点A提供服务，则请求该key时可以向A所属的从节点发起读请求。该请求不会被重定向。</li>
</ul>

<p>当一个主节点发生故障后，其挂载的从节点会切换为主节点继续提供服务。</p>

<p>当一条命令需要操作的key分属于不同的节点时，Redis会报错。<br/>
Redis提供了一种称为hash tags的机制，由业务方保证当需要进行多个key的处理时，将所有key分布到同一个节点。<br/>
该机制实现原理如下：如果一个key包括{substring}这种模式，则计算slot时只计算“{”和“}”之间的子字符串。即keys{sub}1、keys{sub}2、keys{sub}3 计算slot时都会按照sub串进行。这样保证这3个字符串会分布到同一个节点。</p>

<p>使用 CLUSTER KEYSLOT<kegy>命令可以査看一个给定键属于哪个槽:</p>

<pre><code class="language-text">127、0.0。1:7000&gt; CLUSTER KEYSLOT date 
(integer) 2022 
127.0.0.1: 7000&gt; CLUSTER KEYSLOT&quot;msgn 
(integer) 6257 
127.0.0.1:7000&gt; LUST5 R KEYSLOT&quot;name
 (integer) 5798 
127.0.0.1:7000&gt; CLUSTER KEYS &quot;fruits&quot;
 (integer) 14943
</code></pre>

<h3 id="toc_2">槽指派</h3>

<p>通过向节点发送 CLUTER ADDSLOS命令,我们可以将一个或多个槽指派( assign) 给节点负责:</p>

<pre><code class="language-text">cluster addslots &lt;slot&gt; [slot]
</code></pre>

<p>举个例子:</p>

<pre><code class="language-text">127.0.0.1:7000&gt; cluster addslots 0 1 2 3 4 5000 
127.0.0.1:7000&gt; cluster nodes 
9dfb4c4e016e627d9769e4c9bb0d4fa208e65c26 127.0.0.1:7002 master - 0 1388316664849  0 connected 
68eef66df23420a5862208ef5b1a7005b806f2ff  127.0.0.1:7001 mster -0  1388316665850  0 connected  
51549e625cfda318ad27423a3le7476fe3cd2939 :0  myself, master - 0 0 0 connected   0-5000
</code></pre>

<h3 id="toc_3">传播节点的槽指派信息</h3>

<p>个节点除了会将自己负责处理的槽记录在clusternode结构的s1ots属性和numslots属性之外,它还会将自己的s1ots数组通过消息发送给集群中的其他节点,以此来告知其他节点自己目前负责处理哪些槽。</p>

<h2 id="toc_4">在集群中执行命令</h2>

<p>在对数据库中的16384个槽都进行了指派之后,集群就会进人上线状态,这时客户端就可以向集群中的节点发送数据命令了。</p>

<p>当客户端向节点发送与数据库键有关的命令时,接收命令的节点会计算出命令要处理的数据库键属于哪个槽,并检査这个槽是否指派给了自己: </p>

<ul>
<li>如果键所在的槽正好就指派给了当前节点,那么节点直接执行这个命令。</li>
<li>如果键所在的槽并没有指派给当前节点,那么节点会向客户端返回一个 MOVED错误,指引客户端转向( redirect)至正确的节点,并再次发送之前想要执行的命令。</li>
</ul>

<p><figure><img src="media/15951723810785/15957684407998.jpg" alt=""/></figure></p>

<h2 id="toc_5">重新分片</h2>

<p>Redis集群的重新分片操作可以将任意数量已经指派给某个节点(源节点)的槽改为指派给另一个节点(目标节点),并且相关槽所属的键值对也会从源节点被移动到目标节点。</p>

<p>重新分片操作可以在线(online)进行,在重新分片的过程中,集群不需要下线,并且源节点和目标节点都可以继续处理命令请求。</p>

<h3 id="toc_6">重新分片的实现原理</h3>

<p>Redis集群的重新分片操作是由 Redis 的集群管理软件 redis-trib负责执行的, Redis提供了进行重新分片所需的所有命令,而 redis-trib则通过向源节点和目标节点发送命令来进行重新分片操作。</p>

<p>redis-trib对集群的单个槽s1ot进行重新分片的步骤如下: </p>

<p>1) redis-trib 对目标节点发送 </p>

<pre><code class="language-text">CLUSTER SETSLOT &lt;s1ot&gt; IMPORTING &lt;source_id&gt; 
</code></pre>

<p>命令,让目标节点准备好从源节点导人(import)属于槽s1ot的键值对。</p>

<p>2) redis-trib对源节点发送 </p>

<pre><code class="language-text">CLUSTER SETSLOT &lt;s1ot&gt; MIGRATING &lt;target_id&gt; 
</code></pre>

<p>命令,让源节点准备好将属于槽s1ot的键值对迁移(migrate)至目标节点。</p>

<p>3) redis-trib向源节点发送</p>

<pre><code class="language-text">CLUSTER GETKEYSINSLOT &lt;s1ot&gt; &lt;count&gt;
</code></pre>

<p>命令, 获得最多 count个属于槽s1t的键值对的键名( key name)。</p>

<p>4)对于步骤3获得的每个键名, redis-trib都向源节点发送一个 </p>

<pre><code class="language-text">MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt;
</code></pre>

<p>命令,将被选中的键原子地从源节点迁移至目标节点</p>

<p>5)重复执行步骤3和步骤4,直到源节点保存的所有属于槽s1ot的健值对都被迁移至目标节点为止。每次迁移键的过程如下图所示。</p>

<p><figure><img src="media/15951723810785/15957690921572.jpg" alt=""/></figure></p>

<p>如果重新分片涉及多个槽,那么 redis-trib将对每个给定的槽分别执行上面给出的步聚。</p>

<p>6) redis-trib向集群中的任意一个节点发送 </p>

<pre><code class="language-text">CLUSTER SETSLOT &lt;slot&gt; NODE &lt;target_id&gt; 
</code></pre>

<p>命令,将槽 s1ot 指派给目标节点,这一指派信息会通过消息发送至整个集群</p>

<p>对槽s1ot进行重新分片的整个过程:</p>

<p><figure><img src="media/15951723810785/15957692235238.jpg" alt=""/></figure></p>

<h3 id="toc_7">ASK错误</h3>

<p>在进行重新分片期间，源节点向目标节点迁移一个槽的过程中，可能会出现这样一种情况：属于被迁移槽的一部分键值对保存在源节点里面，而另一部分键值对则保存在目标节点里面。</p>

<p>当客户端向源节点发送一个与数据库键有关的命令，并且命令要处理的数据库键恰好就属于正在被迁移的槽时：</p>

<ul>
<li>源节点会先在自己的数据库里面查找指定的健,如果找到的话,就直接执行客户端发送的命令。</li>
<li>相反地,如果源节点没能在自己的数据库里面找到指定的键,那么这个键有可能已经被迁移到了目标节点,源节点将向客户端返回一个ASK错误,指引客户端转向正在导入槽的目标节点,并再次发送之前想要执行的命令。</li>
</ul>

<h2 id="toc_8">复制与故障转移</h2>

<p>Redis集群中的节点分为主节点(master)和从节点(slave),其中主节点用于处理槽,而从节点则用于复制某个主节点, 并在被复制的主节点下线时,代替下线主节点继续处理命令请求。<br/>
例如下图所示的集群结构：</p>

<p><figure><img src="media/15951723810785/15958629455311.jpg" alt="设置节点7004和节点7005 成为节点7000的从节点"/><figcaption>设置节点7004和节点7005 成为节点7000的从节点</figcaption></figure></p>

<p>此节点的工作状态如下表格所示：<br/>
<figure><img src="media/15951723810785/15958630271553.jpg" alt=""/></figure></p>

<p>如果这时，节点7000进入下线状态，那么集群中仍在正常运作的几个主节点将在节点7000的两个从节点(7004、7005)中选出一个节点作为新的主节点，加入7004选为新的主节点，7005将切换为7004的从节点，这个新的主节点将接管原来节点7000负责处理的槽，并继续处理客户端发送的命令请求。如果切换之后 7000重新上线，那么它将成为节点7004的从节点。</p>

<h2 id="toc_9">设置从节点</h2>

<p>向一个节点发送命令</p>

<pre><code class="language-text">cluster replicate &lt;node_id&gt;
</code></pre>

<p>可以让接收命令的节点成为 node_id 所指定节点的从节点,并开始对主节点进行复制。</p>

<ul>
<li>接收到该命令的节点 首先会在自己的 c1usterstate.nodes 字典中找到 node_id 所对应节点的c1usterNode结构,并将自己的 clusterstate.myself.slaveof 指针指向这个结构, 以此来记录这个节点正在复制的主节点。</li>
<li>然后节点会修改自己在c1usterState.myse1f.flags中的属性, 关闭原本的REDIS_NODE_MASTER标识,打开 REDIS_NODE_SLAVE标识,表示这个节点已经由原来的主节点变成了从节点。</li>
<li><p>最后,节点会调用复制代码,并根据c1usterState.myself.s1aveof指向的c1usterNode结构所保存的IP地址和端口号,对主节点进行复制。因为节点的复制功能和单机 Redis服务器的复制功能使用了相同的代码,所以让从节点复制主节点相当于向从节点发送命令 </p>
<pre><code class="language-text">SLAVEOF &lt;master_ip&gt; &lt;master_port&gt;
</code></pre></li>
</ul>

<h3 id="toc_10">故障检测</h3>

<p>集群中的每个节点都会定期的想集群中的其它节点发送 PING 消息，以次来检测对方是否在线，如果接收 ping 消息的节点没有在规定的时间内，想发送 ping 消息的节点返回 pong 消息，那么发送 ping 消息的节点就会将接收 ping 消息的节点标记为<strong>疑似下线（probable fail）</strong>。</p>

<p>集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点的状态信息,例如某个节点是处于在线状态、疑似下线状态(PFAIL),还是已下线状态(FAIL)。</p>

<p>当一个主节点A通过消息得知主节点B认为主节点C进入了疑似下线状态时,主节点A会在自己的c1usterState.nodes字典中找到主节点C所对应的c1usterNode结构, 并将主节点B的下线报告(failure report)添加到c1usterNode 结构的 fai1_reports 链表里面。</p>

<p>如果在一个集群里面,半数以上负责处理槽的主节点都将某个主节点x报告为疑似下线那么这个主节点x将被标记为已下线(FAIL),将主节点x标记为已下线的节点会向集群广播条关于主节点x的FAIL消息,所有收到这条FAIL消息的节点都会立即将主节点x标记为已下线。</p>

<h3 id="toc_11">故障转移</h3>

<p>当一个从节点发现自己正在复制的主节点进入了已下线状态时,从节点将开始对下线主节点进行故障转移,以下是故障转移的执行步骤: </p>

<p>1)复制下线主节点的所有从节点里面,会有一个从节点被选中。</p>

<p>2)被选中的从节点会执行 SLAVEOF no one命令,成为新的主节点。</p>

<p>3)新的主节点会撤销所有对已下线主节点的槽指派,并将这些槽全部指派给自己。</p>

<p>4)新的主节点向集群广播一条PONG消息,这条PONG消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点,并且这个主节点已经接管了原本由已下线节点负责处理的槽。</p>

<p>5)新的主节点开始接收和自己负责处理的槽有关的命令请求,故障转移完成。</p>

<h3 id="toc_12">选举新的主节点</h3>

<p>新的节点是如何通过选举产生的呢？</p>

<ul>
<li>集群的配置纪元是一个自增计数器，它的初始值为0。</li>
<li>当集群里的某个节点开始一次故障转移操作时，集群配置纪元的值会被增一。</li>
<li>对于每个配置纪元，集群里每个负责处理槽的主节点都有一次投票的机会，而第一个向主节点要求投票的从节点将获得主节点的投票。</li>
<li>当从节点发现自己正在复制的主节点进入已下线状态时，从节点会想集群广播一条clustermsg_type_failover_auth_request 消息，要求所有收到这条消息，并且具有投票权的主节点向这个从节点投票。</li>
<li>如果一个主节点具有投票权(它正在负责处理槽)，并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条cluster_type+failover_auth_ack 消息，表示这个主节点支持从节点成为新的主节点。</li>
<li>每个参与选举的从节点都会接受 clustermsg_type_failover_auth_ack 消息，并根据自己收到了多少条这种消息来捅进自己获得了多少主节点的支持。</li>
<li>如果集群里有N个具有投票权的主节点，那么当一个从节点收集到超过半数张支持票时(N/2 +1)，这个从节点就会当选为新的主节点。<br/>
因为在每一个配置纪元里面,每个具有投票权的主节点只能投一次票,所以如果有N个主节点进行投票,那么具有大于等于N/2+1张支持票的从节点只会有一个,这确保了新的主节点只会有一个。</li>
<li>如果在一个配置纪元里面没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，直到选出新的主节点位置。</li>
</ul>

<p>集群中的节点通过发送和接收消息来进行通信,常见的消息包括MEET、PING、PONG、 PUBLISH、FAエL五种。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[十一、哨兵]]></title>
    <link href="http://www.throne4j.com/15948275035029.html"/>
    <updated>2020-07-15T23:38:23+08:00</updated>
    <id>http://www.throne4j.com/15948275035029.html</id>
    <content type="html"><![CDATA[
<p>哨兵是Redis的高可用方案，可以在Redis Master发生故障时自动选择一个Redis Slave切换为Master，继续对外提供服务。</p>

<p>redis中 sentinel 有效的解决了故障转移的问题，也解决了主节点下线客户端无法识别新的可用节点的问题，但是如果是从节点下线了，sentinel是不会对其进行故障转移的，并且连接从节点的客户端也无法获取到新的可用从节点，而这些问题在Cluster中都得到了有效的解决。</p>

<h2 id="toc_0">Redis 哨兵</h2>

<p>首先我们看一个典型的哨兵部署方案，如下图所示：<br/>
<figure><img src="media/15948275035029/15949126995404.jpg" alt="" style="width:845px;"/></figure></p>

<p>该方案中，有一个Redis Master，该Master下有两个Slave。3个哨兵同时与Master和Slave建立连接，并且哨兵之间也互相建立了连接。</p>

<p>哨兵通过与Master和Slave的通信，能够清楚每个Redis服务的健康状态。这样，当Master发生故障时，哨兵能够知晓Master的此种情况，然后通过对Slave健康状态、优先级、同步数据状态等的综合判断，选取其中一个Slave切换为Master，并且修改其他Slave指向新的Master地址。</p>

<p>为什么实际中至少会部署3个以上哨兵并且哨兵数量最好是奇数呢？</p>

<p>哨兵是Redis的高可用机制，保证了Redis服务不出现单点故障。如果哨兵只部署一个，哨兵本身就成为了一个单点。那假如部署2个哨兵呢？当Redis的Master发生故障时，如果2个哨兵同时执行切换操作肯定不行，哨兵之间必须先约定好由谁来执行此次切换操作，此时就涉及了哨兵之间选leader的操作。</p>

<p>思考如下问题：<br/>
1、切换完成之后，客户端和其他哨兵如何知道现在提供服务的Redis Master是哪一个呢？<br/>
答: 可以通过subscribe__sentinel__:hello频道，知道当前提供服务的Master的IP和Port。<br/>
2、假设执行切换的哨兵发生了故障，切换操作是否会由其他哨兵继续完成呢？<br/>
答 ：执行切换的哨兵发生故障后，剩余哨兵会重新选主，并且重新开始执行切换流程<br/>
3、当故障Master恢复之后，会继续作为Master提供服务还是会作为一个Slave提供服务？<br/>
答 ：Redis中主从切换完成之后，当故障Master恢复之后，会作为新Master的一个Slave来提供服务。</p>

<p>这里有一份典型的哨兵配置文件（哨兵的配置文件必须具有可写权限。）：</p>

<pre><code class="language-conf">//监控一个名称为mymaster的Redis Master服务，地址和端口号为127.0.0.1:6379,quorum为2 
sentinel monitor mymaster 127.0.0.1 6379 2 
//如果哨兵60s内未收到mymaster的有效ping回复，则认为mymaster处于down的状态
sentinel down-after-milliseconds mymaster 60000 
//执行切换的超时时间为180s
sentinel failover-timeout mymaster 180000 
//切换完成后同时向新的Redis Master发起同步数据请求的Redis Slave个数为1，
//即切换完成后依次让每个Slave去同步数据，前一个Slave同步完成后下一个Slave才发起同步数据的请求
sentinel parallel-syncs mymaster 1 

//监控一个名称为resque的Redis Master服务，地址和端口号为127.0.0.1:6380,quorum为4 
sentinel monitor resque 192.168.1.3 6380 4 
sentinel down-after-milliseconds resque 10000 
sentinel failover-timeout resque 180000 
sentinel parallel-syncs resque 5
</code></pre>

<p>quorum在哨兵中有两层含义。</p>

<ul>
<li>第一层含义为：如果某个哨兵认为其监听的Master处于下线的状态，这个状态在Redis中标记为S_DOWN，即<strong>主观下线</strong>。假设quorum配置为2，则当有两个哨兵同时认为一个Master处于下线的状态时，会标记该Master为O_DOWN，即客观下线。只有一个Master处于客观下线状态时才会开始执行切换。</li>
<li>第二层含义为：假设有5个哨兵，quorum配置为4。首先，判断<strong>客观下线</strong>需要4个哨兵才能认定。其次，当开始执行切换时，会从5个哨兵中选择一个leader执行该次选举，此时一个哨兵也必须得到4票才能被选举为leader，而不是3票（即哨兵的大多数）。</li>
</ul>

<p>可以看到配置文件中首先配置了需要监控的Redis Master服务器，然后设置了一些服务相关的参数，并没有Redis Slave和其他哨兵的配置。而通过图22-1，我们看到每个哨兵都必须与所有监控的Redis Master下的Slave服务器以及其他监控该Master的哨兵建立连接。显然，哨兵只通过配置文件是不能知道这些信息的。进一步，如果在配置文件中硬编码写出从服务器和其他哨兵的信息，会丧失灵活性。</p>

<p>那么，Redis是如何实现如上所述的信息发现呢，我们通过下面的章节来了解一下。</p>

<h3 id="toc_1">哨兵机制的实现</h3>

<p>哨兵启动之后会先与配置文件中监控的Master建立两条连接，一条称为命令连接，另一条称为消息连接。哨兵就是通过如上两条连接发现其他哨兵和Redis Slave服务器，并且与每个Redis Slave也建立同样的两条连接。</p>

<p>哨兵可以直接使用 redis-server 命令启动，如下：</p>

<pre><code class="language-shell">redis-server /path/sentinel.conf --sentinel
或者
redis-sentinel /path/sentinel.conf
</code></pre>

<p>sentinel 启动时的执行步骤如下：<br/>
1)初始化服务器。<br/>
2)将普通 Redis服务器使用的代码替换成 Sentinel专用代码。<br/>
3)初始化 Sentinel状态。<br/>
4)根据给定的配置文件,初始化 Sentinel的监视主服务器列表。<br/>
5)创建连向主服务器的网络连接。</p>

<p>单个哨兵连接示意图：</p>

<p><figure><img src="media/15948275035029/15950831184191.jpg" alt=""/></figure></p>

<p>那么哨兵启动后两条连接是怎么建立的呢？</p>

<pre><code class="language-c">main() {     ...
    //检测是否以sentinel模式启动    
    server.sentinel_mode = checkForSentinelMode(argc,argv);    
     ...
    if (server.sentinel_mode) { 
        //将监听端口置为26379
        initSentinelConfig(); 
        //更改哨兵可执行命令。哨兵中只能执行有限的几种服务端命令，如ping,sentinel,subscribe,publish,info等等。该函数还会对哨兵进行一些初始化
        initSentinel();     
    }    
    ...
    sentinelHandleConfiguration();        //解析配置文件，进行初始化 
    ...
    sentinelIsRunning(); //随机生成一个40字节的哨兵ID，打印启动日志
    ...
}
</code></pre>

<p>查看哨兵启动的主流程发现，并没有建立连接相关的逻辑。那么只可能是 Redis的时间任务 serverCron了，</p>

<pre><code class="language-c">serverCron(){
    if (server.sentinel_mode) sentinelTimer();
}
</code></pre>

<p>哨兵中每次执行serverCron时，都会调用sentinelTimer()函数。该函数会建立连接，并且定时发送心跳包并采集信息。该函数主要功能如下：</p>

<ul>
<li>建立命令连接和消息连接。消息连接建立之后会订阅Redis服务的__sentinel__:hello频道。</li>
<li><p>在命令连接上每10s发送info命令进行信息采集；每1s在命令连接上发送ping命令探测存活性；每2s在命令连接上发布一条信息，信息格式如下:</p>
<pre><code class="language-text">sentinel_ip,sentinel_port,sentinel_runid,current_epoch,master_name,master_ip,master_port,master_config_epoch 
</code></pre>
<p>哨兵的IP、哨兵的端口、哨兵的ID（即上文所述40字节的随机字符串）、当前纪元（用于选举和主从切换）、Redis Master的名称、Redis Master的IP、Redis Master的端口、Redis Master的配置纪元（用于选举和主从切换）。</p></li>
<li><p>检测服务是否处于主观下线状态。<br/>
主观下线状态的探测针对所有的Master，Slave和哨兵。</p></li>
<li><p>检测服务是否处于客观下线状态并且需要进行主从切换。<br/>
只会对Master服务器进行客观下线的判断。</p></li>
</ul>

<p>哨兵启动之后通过info命令进行信息采集，据此能够知道一个Redis Master有多少Slaves，然后在下一次执行sentinelTimer函数时会和所有的Slaves分别建立命令连接与消息连接。而通过订阅消息连接上的消息可以知道其他的哨兵。哨兵与哨兵之间只会建立一条命令连接，每1s发送一个ping命令进行存活性探测，每2s推送（publish）一条消息。</p>

<p>对于哨兵来说，如果有大于等于quorum个哨兵同时认为一台Master处于主观下线状态，才会将该Master标记为客观下线。那么，一个哨兵如何知道其他哨兵对一台Master服务器的判断状态呢？</p>

<p>Redis会向监控同一台Master的所有哨兵通过命令连接发送如下格式的命令:</p>

<pre><code class="language-text">SENTINEL   is-master-down-by-addr    master_ip   master_port   current_epoch   sentinel_runid或者* 
</code></pre>

<p>其中最后一项当需要投票时发送sentinel_runid，否则发送一个* 号。</p>

<p>据此能够知道其他哨兵对该Master服务状态的判断，如果达到要求，就标记该Master为客观下线。</p>

<p>如果判断一个Redis Master处于客观下线状态，这时就需要开始执行主从切换了。</p>

<h2 id="toc_2">选举哨兵领头节点</h2>

<p>Sentinel系统选举领头 Sentinel的方法是对Raf算法的领头选举方法的实现。<br/>
当一个主服务器被判断为客观下线时,监视这个下线主服务器的各个 Sentinel会进行协商，选举出一个领头 Sentinel,并由领头 Sentinel对下线主服务器执行故障转移操作。</p>

<p>Redis选举领头 Sentinel的规则和方法：</p>

<ul>
<li>所有在线的 Sentinel都有被选为领头 Sentinel的资格,换句话说,监视同一个主服务器的多个在线 Sentinel中的任意一个都有可能成为领头 Sentinel 口每次进行领头 Sentinel选举之后,不论选举是否成功,所有 Sentinel的配置纪元( configuration epoch)的值都会自增一次。配置纪元实际上就是一个计数器,并没有什么特别的。</li>
<li>在一个配置纪元里面,所有 Sentinel都有一次将某个 Sentinel设置为局部领头Sentinel的机会,并且局部领头一旦设置,在这个配置纪元里面就不能再更改。</li>
<li>每个发现主服务器进人客观下线的 Sentinel都会要求其他 Sentinel将自己设置为局部领头 Sentinel。</li>
<li>当一个 Sentinel(源 Sentinel)向另一个 Sentinel(目标 Sentinel)发送 SENTINEL is- master-down-by-adr命令,并且命令中的 runid参数不是*符号而是源Sentinel的运行ID时,这表示源 Sentinel要求目标 Sentinel将前者设置为后者的局部领头 Sentinel</li>
<li>Sentinel设置局部领头 Sentinel的规则是先到先得:最先向目标 Sentinel发送设置要求的源 Sentinel将成为目标 Sentinel的局部领头 Sentinel,而之后接收到的所有设置要求都会被目标 Sentinel拒绝。</li>
<li>目标 Sentinel在接收到 SENTINEL is- master-down-by-addr命令之后,将向源 Sentinel返回一条命令回复,回复中的1 eader_ runid参数和 leader epoch 参数分别记录了目标 Sentinel的局部领头 Sentinel的运行ID和配置纪元。</li>
<li>源 Sentinel在接收到目标 Sentinel返回的命令回复之后,会检查回复中1 eader epoch参数的值和自己的配置纪元是否相同,如果相同的话,那么源 Sentinel g继续取出回复中的1 eader runid参数,如果1 eader runid参数的值和源 Sentinel 的运行D一致,那么表示目标 Sentinel将源 Sentinel设置成了局部领头 Sentinel</li>
<li>如果有某个 Sentinel被半数以上的 Sentinel设置成了局部领头 Sentinel,那么这个Sentinel成为领头 Sentinel。举个例子,在一个由10个 Sentinel组成的 Sentinel系统里面,只要有大于等于10/2+1=6个 Sentinel将某个 Sentinel设置为局部领头Sentinel,那么被设置的那个 Sentinel就会成为领头 Sentinel </li>
<li>因为领头 Sentinel的产生需要半数以上 Sentinel I的支持,并且每个 Sentinel在每个配置纪元里面只能设置一次局部领头 Sentinel,所以在一个配置纪元里面,只会出现个领头 Sentinel 在一段时间之后再次进行选举,直到选出领头 Sentinel为此。</li>
<li>那如果在给定时限内,没有一个 Sentinel被选举为领头 Sentinel，那么各个 Sentinel将在一段时间之后再次进行选举，直到选出领头sentinel为止。</li>
</ul>

<h2 id="toc_3">故障转移</h2>

<p>在选举产生出领头 Sentinel之后,领头 Sentinel将对已下线的主服务器执行故障转移操作,该操作包含以下三个步骤: <br/>
1)在已下线主服务器属下的所有从服务器里面,挑选出一个从服务器,并将其转换为主服务器。<br/>
2)让已下线主服务器属下的所有从服务器改为复制新的主服务器。<br/>
3)将已下线主服务器设置为新的主服务器的从服务器,当这个旧的主服务器重新上线时,它就会成为新的主服务器的从服务器。</p>

<h2 id="toc_4">主从切换</h2>

<p>当Redis哨兵方案中的Master处于客观下线状态，为了保证Redis 的高可用性，此时需要执行主从切换。即将其中一个Slave提升为Master，其他Slave从该提升的Slave继续同步数据，主从切换有一个状态迁移图，其所有状态定义如下：</p>

<pre><code class="language-c">//没有进行切换
#define SENTINEL_FAILOVER_STATE_NONE 0                  
//等待开始进行切换(等待哨兵之间进行选主) 
#define SENTINEL_FAILOVER_STATE_WAIT_START 1 
//选择一台从服务器作为新的主服务器
#define SENTINEL_FAILOVER_STATE_SELECT_SLAVE 2        
//将被选中的从服务器切换为主服务器
#define SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE 3 
//等待被选中的从服务器上报状态
#define SENTINEL_FAILOVER_STATE_WAIT_PROMOTION 4
//将其他Slave切换为向新的主服务器要求同步数据
#define SENTINEL_FAILOVER_STATE_RECONF_SLAVES 5  
//重置Master，将Master的IP：PORT设置为被选中从服务器的IP：PORT        
#define SENTINEL_FAILOVER_STATE_UPDATE_CONFIG 6
</code></pre>

<p>主从切换状态转换图</p>

<p><figure><img src="media/15948275035029/15951641443338.jpg" alt="" style="width:622px;"/></figure></p>

<p>当一个哨兵发现一台Master处于主观下线状态时，会首先将切换状态更新为SENTINEL_FAILOVER_STATE_WAIT_START，并且将当前纪元加1。然后发送如下命令要求其他哨兵给自己投票。</p>

<pre><code class="language-text">SENTINEL   is-master-down-by-addr    master_ip   master_port   current_epoch   sentinel_runid或者*
</code></pre>

<p>最后一项参数为sentinel_runid，即该哨兵的ID，第5项current_epoch在开始执行切换后会加1。 当从哨兵中选出一个主哨兵之后，接下来的切换都由该主哨兵执行。</p>

<p>主哨兵首先会将当前切换状态更改为SENTINEL_FAILOVER_STATE_SELECT_SLAVE，即开始选择一台从服务器作为新的主服务器。那么，假设有多台从服务器，该选择哪台呢？</p>

<p>Redis中选择主服务器的规则如下:</p>

<ul>
<li>如果该Slave处于主观下线状态，则不能被选中。</li>
<li>如果该Slave 5s之内没有有效回复ping命令或者与主服务器断开时间过长，则不能被选中</li>
<li>如果slave-prio-rity为0，则不能被选中（slave-priority可以在配置文件中指定。正整数，值越小优先级越高，当指定为0时，不能被选为主服务器）。</li>
<li>在剩余Slave中比较优先级，优先级高的被选中；如果优先级相同，则有较大复制偏移量的被选中；否则按字母序选择排名靠前的Slave。</li>
</ul>

<p>当选中从服务器之后，将当前切换状态更改为SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE，并且在下一次时间任务调度时执行该步骤。该状态需要把选择的Redis Slave切换为Redis Master。</p>

<pre><code class="language-text">//开启一个事务
MULTI
//关闭该从服务器的复制功能，将其转换为一个主服务器     
SLAVEOF NO ONE    
//将redis.conf文件重写(会根据当前运行中的配置重写原来的配置)     
CONFIG REWRITE          
//关闭连接到该服务的客户端(关闭之后客户端会重连，重连时会重新获取Redis Master的地址)
CLIENT KILL TYPE normal
//执行事务
EXEC                
</code></pre>

<p>执行完该步骤之后，会将切换状态更新为SENTINEL_FAILOVER_STATE_WAIT_PRO-MOTION, 上一步我们向被选中的从服务器发送了slaveof no one命令，执行完之后Redis中并没有处理返回值，而是在下一次info命令的返回中检查该从服务器的role字段，如果返回role:master，说明该从服务器已变更自己的角色为主服务器。于是切换状态变更为SENTINEL_FAILOVER_STATE_RECONF_SLAVES。</p>

<p>在该步骤设置SENTINEL_FAILOVER_STATE_RECONF_SLAVES后，哨兵会依次向其他从服务器发送切换主服务器的slaveof命令 ：</p>

<pre><code class="language-text">//开启一个事务
MULTI
//将该服务器设置为向新的主服务器请求数据
SLAVEOF IP PORT
//将redis.conf文件重写(会根据当前运行中的配置重写原来的配置) 
CONFIG REWRITE
//关闭连接到该服务的客户端(关闭之后客户端会重连，重连时会重新获取Redis Master的地址) 
CLIENT KILL TYPE normal
//执行事务
EXEC
</code></pre>

<p>如果所有的从服务器都已更新完毕，则切换状态更新为SENTINEL_FAILOVER_STATE_UPDATE_CONFIG。该步骤会将哨兵中监听的Master（旧Master）重置为被选中的从服务器（新Master），并且将旧Master也配置为新Master的从服务器。然后将切换状态更新为SENTINEL_FAILOVER_STATE_NONE。至此，主从切换已完成。</p>

<h2 id="toc_5">哨兵相关命令</h2>

<ul>
<li>SENTINEL MASTERS：返回该哨兵监控的所有Master的相关信息。</li>
<li>SENTINEL MASTER<name>：返回指定名称Master的相关信息。</li>
<li>SENTINEL SLAVES<master-name>：返回指定名称Master的所有Slave的相关信息。</li>
<li>SENTINEL SENTINELS<master-name>：返回指定名称Master 的所有哨兵的相关信息。</li>
<li>SENTINEL IS-MASTER-DOWN-BY-ADDR<ip><port> <current-epoch><runid>：如果runid是*，返回由IP和Port指定的Master 是否处于主观下线状态。如果runid是某个哨兵的ID，则同时会要求对该runid进行选举投票。</li>
<li>SENTINEL RESET<pattern>：重置所有该哨兵监控的匹配模式（pattern）的Masters（刷新状态，重新建立各类连接）</li>
<li>SENTINEL GET-MASTER-ADDR-BY-NAME<master- name>：返回指定名称的Master对应的IP和Port。</li>
<li>SENTINEL FAILOVER<master-name>：对指定的Mmaster手动强制执行一次切换。</li>
<li>SENTINEL MONITOR<name><ip><port><quorum>：指定该哨兵监听一个Master。</li>
<li>SENTINEL flushconfig：将配置文件刷新到磁盘。</li>
<li>SENTINEL REMOVE<name>：从监控中去除掉指定名称的Master。</li>
<li>SENTINEL CKQUORUM<name>：根据可用哨兵数量，计算哨兵可用数量是否满足配置数量（认定客观下线的数量）；是否满足切换数量（即哨兵数量的一半以上）。</li>
<li>SENTINEL SET<mastername>[<option><value>...]：设置指定名称的Master的各类参数（例如超时时间等）。</li>
<li>SENTINEL SIMULATE-FAILURE<flag><flag>...<flag>：模拟崩溃。flag可以为crash-after-election或者crash-after-promotion，分别代表切换时选举完成主哨兵之后崩溃以及将被选中的从服务器推举为Master之后崩溃。</li>
</ul>

<h2 id="toc_6">总结</h2>

<ul>
<li>Sentinel只是一个运行在特殊模式下的 Redis服务器,它使用了和普通模式不同的命第三部分多机据库的实现令表,所以 Sentinel模式能够使用的命令和普通 Redis服务器能够使用的命令不同。</li>
<li>Sentinel会读入用户指定的配置文件,为每个要被监视的主服务器创建相应的实例结构,并创建连向主服务器的命令连接和订阅连接,其中命令连接用于向主服务器发送命令请求,而订阅连接则用于接收指定频道的消息。</li>
<li>Sentinel通过向主服务器发送INFO命令来获得主服务器属下所有从服务器的地址信息,并为这些从服务器创建相应的实例结构,以及连向这些从服务器的命令连接和订阅连接。</li>
<li>在一般情况下, Sentinel以每十秒一次的频率向被监视的主服务器和从服务器发送INFO命令,当主服务器处于下线状态,或者 Sentinel正在对主服务器进行故障转移操作时, Sentinel I向从服务器发送INFO命令的频率会改为每秒一次。</li>
<li>对于监视同一个主服务器和从服务器的多个 Sentinel来说,它们会以每两秒一次的频率,通过向被监视服务器的 sentinel:he11o频道发送消息来向其他Sentinel宣告自己的存在。</li>
<li>每个 Sentinel也会从 sentinel1:he1o频道中接收其他 Sentinel发来的信息, 并根据这些信息为其他 Sentinel 1创建相应的实例结构,以及命令连接。</li>
<li>Sentinel只会与主服务器和从服务器创建命令连接和订阅连接, Sentinel与 Sentinel 之间则只创建命令连接。</li>
<li>Sentinel以每秒一次的频率向实例(包括主服务器、从服务器、其他 Sentinel)发送PING命令,并根据实例对PNG命令的回复来判断实例是否在线,当一个实例在指定的时长中连续向 Sentinel发送无效回复时, Sentinel会将这个实例判断为主观下线。</li>
<li>当 Sentinel将一个主服务器判断为主观下线时,它会向同样监视这个主服务器的其他Sentinel进行询问,看它们是否同意这个主服务器已经进入主观下线状态。</li>
<li>当 Sentinel l收集到足够多的主观下线投票之后,它会将主服务器判断为客观下线,并发起一次针对主服务器的故障转移操作。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[十、主从复制]]></title>
    <link href="http://www.throne4j.com/15945438416733.html"/>
    <updated>2020-07-12T16:50:41+08:00</updated>
    <id>http://www.throne4j.com/15945438416733.html</id>
    <content type="html"><![CDATA[
<p>Redis 支持主从复制功能，用户可以通过执行slaveof 命令或者在配置文件中设置slaveof选项来开启复制功能。例如</p>

<pre><code class="language-shell">127.0.0.1:6379&gt;slaveof 127.0.0.1  7000
OK
</code></pre>

<p>服务器127.0.0.1:6379 会成为服务器127.0.0.1:7000的从服务器(slaver)，127.0.0.1:7000 是主服务器(master),通过复制功能，从服务器127.0.0.1:6379的数据可以和主服务器127.0.0.1:7000的数据保持同步。</p>

<p>用户可以通过执行 slaveof  no one取消复制功能，此时主从服务器之间会断开连接，从服务器成为普通的Redis实例。</p>

<h2 id="toc_0">1、主从复制功能实现</h2>

<p>主从复制功能主要有以下两点作用</p>

<ul>
<li>读写分离，单台服务器能支撑的QPS是有上限的，我们可以部署一台主服务器、多台从服务器，主服务器只处理写请求，从服务器通过复制功能同步主服务器数据，只处理读请求，以此提升Redis 服务能力；另外我们还可以通过复制功能来让主服务器免于执行持久化操作：只要关闭主服务器的持久化功能，然后由从服务器去执行持久化操作即可。</li>
<li>数据容灾，任何服务器都有宕机的可能，我们同样可以通过主从复制功能提升Redis服务的可靠性；由于从服务器与主服务器数据保持同步，一旦主服务器宕机，可以立即将请求切换到从服务器，从而避免Redis服务中断。</li>
</ul>

<h3 id="toc_1">1.1、 老版Redis复制功能</h3>

<p>在redis 2.8之前的版本中实现主从复制功能分为同步(sync)和命令传播(command propagate)两个操作</p>

<ul>
<li>同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态。</li>
<li>命令传播操作则用于在主服务器的数据库状态被修改,导致主从服务器的数据库状态出现不一致时,让主从服务器的数据库重新回到一致状态。</li>
</ul>

<p>slaveof命令流程如下图所示：<br/>
<figure><img src="media/15945438416733/15947441756075.jpg" alt="" style="width:729px;"/></figure></p>

<p>此版本的slavof复制功能缺陷：</p>

<ul>
<li>初次复制: 从服务器以前没有复制过任何主服务器, 或者从服务器当前要复制的主服务器和上一次复制的主服务器不同。</li>
<li>断线后重复制: 处于命令传播阶段的主从服务器因为网络原因而中断了复制,但从服务器通过自动重连接重新连上了主服务器,并继续复制主服务器。<br/>
对于中断后重复制，假如在断开连接之前从服务已经复制了主服务器大部分数据，但是由于中断，在从服务器重新连接上主服务器之后，会重新发送sync命令，生成并发送RDB文件（包含从服务器已经复制过的那部分数据），但是这种续传的方式并不是必须得这样，对于从服务器已经复制过的数据，完全没必要再传输一遍。因此这种方式是比较效率的复制方式。</li>
</ul>

<p><strong>每次执行SYNC命令的耗时操作</strong>：<br/>
1)主服务器需要执行 BGSAVE命令来生成RDB文件,这个生成操作会耗费主服务器大量的CPU、内存和融盘IO资源。<br/>
2)主服务器需要将自已生成的RDB文件发送给从服务器,这个发送操作会耗费主从服务器大量的网络资源(带宽和流量),并对主服务器响应命令请求的时间产生彩响。<br/>
3)接收到RDB文件的从服务器需要載入主服务器发来的RDB文件,并且在載入期间,从服务器会因为阻塞而没办法处理命令请求。</p>

<p>因为SYVC命令是一个如此耗费资源的操作,所以 Redis有必要保证在真正有需要时才执行SYNC命令。</p>

<h3 id="toc_2">1.2、新版的复制功能</h3>

<p>为了解决老版本的效率低下问题，新版复制功能使用PSYNC命令代替SYNC命令来执行复制时的同步操作。</p>

<p>PSYNC命令具有完整重同步( full resynchronization)和部分重同步( partial resynchronization 两种模式:</p>

<ul>
<li>完整重同步用于处理初次复制情况: 完整重同步的执行步骤和SYNC命令的执行步骤基本一样, 它们都是通过让主服务器创建并发送RDB文件,以及向从服务器发送保存在缓冲区里面的写命令来进行同步。</li>
<li>部分重同步则用于处理断线后重复制情况:  当从服务器在断线后重新连接主服务器时,如果条件允许,主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器,从服务器只要接收并执行这些写命令,就可以将数据库更新至主服务器当前所处的状态。</li>
</ul>

<p>新版slaveof命令流程如下图所示：<br/>
<figure><img src="media/15945438416733/15947488155003.jpg" alt="" style="width:833px;"/></figure></p>

<p>部分重同步功能由以下三个部分构成: </p>

<ul>
<li>主服务器的复制偏移量( replication offset)和从服务器的复制偏移量。</li>
<li>主服务器的复制积压缓冲区( replication backlog) </li>
<li>服务器的运行ID( run ID)。</li>
</ul>

<h4 id="toc_3">1.2.1、复制偏移量</h4>

<p>执行复制的双方 主服务器和从服务器会分别维护一个复制偏移量:</p>

<ul>
<li>主服务器每次向从服务器传播N个字节的数据时,就将自己的复制偏移量的值加上N。</li>
<li>从服务器每次收到主服务器传播来的N 个字节的数据时,就将自已的复制偏移量的值加上N。</li>
</ul>

<p>通过对比主从服务器的复制偏移量,程序可以很容易地知道主从服务器是否处于一致状态:</p>

<ul>
<li>如果主从服务器处于一致状态,那么主从服务器两者的偏移量总是相同的。</li>
<li>相反,如果主从服务器两者的偏移量并不相同,那么说明主从服务器并未处于一致状态。</li>
</ul>

<p>问：如果主服务器向从服务器复制的时候，从服务器掉线后就立即重新连接主服务器,并且成功,那么接下来,从服务器将向主服务器发送 PSYNC命令,报告从服务器当前的复制偏移量为offset, 那么这时, 主服务器应该对从服务器执行完整重同步还是部分重同步呢? </p>

<p>答： 和复制缓冲区有关。</p>

<h4 id="toc_4">1.2.2、复制缓冲区</h4>

<p>复制缓冲区是有主服务器维护的一个固定长度的先进先出的队列。当主服务器进行命令传播的时候，它不仅会将写命令发送给所有的从服务器，还会将写命令入队复制缓冲区。因此主服务器的复制缓冲区会保存一部分最近传播的写命令，并且复制缓冲区会为队列中的每个字节记录相应的复制偏移量。</p>

<p>当从服务器重新连上主服务器时,从服务器会通过PSYC命令将自己的复制偏移量offset发送给主服务器,主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作:</p>

<ul>
<li>如果offset偏移量之后的数据(也即是偏移量。 offset+1开始的数据)仍然存在于复制积压缓冲区里面,那么主服务器将对从服务器执行部分重同步操作。</li>
<li>相反,如果 offset偏移量之后的数据已经不存在于复制积压缓冲区,那么主服务器将对从服务器执行完整重同步操作。</li>
</ul>

<p><strong>注意：</strong> 正确估算和设置复制缓冲区的大小非常重要。如果主服务器需要执行大量写命令，或者主从服务器断线很长时间后重新连接，复制缓冲区的大小不合理的话，可能导致psync命令的复制重同步模式不能正常发挥作用。</p>

<p>复制缓冲区的大小可根据 公式：断线到重连的平均时间秒数 * 主服务器每秒产生的写命令数据量，为了安全起见可以double 一下这个结果值。</p>

<h4 id="toc_5">1.2.3、 服务器的运行ID</h4>

<p>每台Redis服务器都有一个运行ID，从服务器每次发送psync请求同步数据时，会携带自己需要同步主服务器的运行ID。主服务器接收到psync命令时，需要判断命令参数运行ID与自己的运行ID是否相等，只有相等才有可能执行部分重同步。而当从服务器首次请求主服务器同步数据时，从服务器显然是不知道主服务器的运行ID，此时运行ID以“？”填充，同时复制偏移量初始化为-1。</p>

<h3 id="toc_6">1.3、新版复制同步机制的生产问题</h3>

<p>当在生产环境中，经常会发生如下情况</p>

<ul>
<li>从服务器重启，复制信息丢失</li>
<li>主服务器故障导致主从切换(从多台 从服务器中选举出一台作为主服务器，此时，主服务器的运行ID发生变化)<br/>
这时候显然是无法执行部分重同步的，而这两种情况又很常见，因此Redis 4.0针对主从复制又提出了psync2协议，使得主服务器故障导致主从切换后，依然有可能执行部分重同步。而这时候当主服务器接收到psync命令时，向客户端回复的是“+CONTINUE<new_repl_id>”。参数“psync2”表明从服务器支持psync2协议。。</li>
</ul>

<h4 id="toc_7">方案一： 持久化主从复制信息</h4>

<p>Redis服务器关闭时，将主从复制信息（复制的主服务器RUN_ID 与复制偏移量）作为辅助字段存储在RDB文件中；Redis服务器启动加载RDB文件时，恢复主从复制信息，重新同步主服务器时携带。</p>

<h4 id="toc_8">方案二： 存储上一个主服务器复制信息</h4>

<p>当主服务器发生故障的时候，从服务器成为新的主服务器时，便使用前一个主服务器的运行ID和复制偏移量。</p>

<p>代码如下所示:</p>

<pre><code class="language-c">char replid2[CONFIG_RUN_ID_SIZE+1];
long long second_replid_offset;
</code></pre>

<p>假设m为主服务器（运行ID为M_ID），A、B和C为三个从服务器；某一时刻主服务器m发生故障，从服务器A升级为主服务器（同时会记录replid2=M_ID），从服务器B和C重新向主服务器A发送“psync M_ID psync_offset”请求；显然根据上面条件，只要psync_offset满足条件，就可以执行部分重同步。</p>

<h3 id="toc_9">主从复制的其它问题</h3>

<ul>
<li>心跳检测<br/>
主服务器和从服务器之间是通过TCP长连接交互数据的，就必然需要周期性地发送心跳包来检测连接有效性，该字段表示发送心跳包的周期，主服务器以此周期向所有从服务器发送心跳包。可通过配置参数repl-ping-replica-period或者repl-ping- slave-period设置，默认为10。</li>
</ul>

<p>发送心跳检测从服务器是否有效，那么每次检测多长时间后判定从服务器失效呢？</p>

<p>主服务器会记录每个从服务器上次心跳检测成功的时间repl_ack_time，并且定时检测当前时间距离repl_ack_time是否超过一定超时门限，如果超过则认为从服务器处于失效状态。字段repl_min_slaves_max_lag存储的就是该超时门限，可通过配置参数min-slaves-max-lag或者min- replicas-max-lag设置该超时阈值，默认为10，单位秒。</p>

<p>repl_min_slaves_to_write表示当有效从服务器的数目小于该值时，主服务器会拒绝执行写命令。</p>

<p>当主服务器配置了“requirepass password”时，即表示从服务器必须通过密码认证才能同步主服务器数据。同样的需要在从服务器配置“masterauth<master-password>”，用于设置请求同步主服务器时的认证密码。</p>

<p>当主从服务器断开连接时，通过配置参数slave-serve-stale-data 或者replica-serve-stale-data设置，默认为1，设置从服务器是否继续处理命令请求。</p>

<p>可通过配置参数slave-read-only或者replica-read-only设置，默认为1，设置从服务器是否可以处理写命令请求，默认是从服务器是只读的，除非该命令是主服务器发送过来的。</p>

<p>复制缓冲区，用于缓存主服务器已执行且待发送给从服务器的命令请求；缓冲区大小由字段repl_backlog_size指定，其可通过配置参数repl-backlog-size设置，默认为1MB。</p>

<p>从服务器通过时间事件处理函数 serverCron，以一秒为周期执行主从复制操作。在时间事件处理是，从服务器想主服务器发起连接请求，成功连接之后，创建对应的文件事件。此外事件事件还用于检测主从连接是否超时，定时向服务器发送心跳包，定时报告自己的复制偏移量等。</p>

<p>用户可通过参数repl-timeout 配置，默认为60，单位秒，超过此时间则认为主从服务器之间的连接出现故障，从服务器会主动断开连接。</p>

<p>当从服务器接收到slaveof命令时，会主动连接主服务器请求同步数据，这并不是一蹴而就的，需要若干个步骤交互：</p>

<ul>
<li>设置主服务器的地址和端口号</li>
<li>连接Socket；</li>
<li>发送PING请求包确认连接是否正确；</li>
<li>发起密码认证（如果需要，通过 masterauth  <master-pwd>进行验证）；</li>
<li>信息同步；</li>
<li>发送PSYNC命令；</li>
<li>接收RDB文件并载入；</li>
<li>连接建立完成，等待主服务器同步命令请求。</li>
</ul>

<p>当从服务器支持eof 功能时 主服务器可以直接将数据库中数据以RDB协议格式通过socket发送给从服务器，免去了本地磁盘文件不必要的读写操作；</p>

<p>通过配置参数repl-diskless-sync进行设置完整同步是生成RDB文件持久化到磁盘发送还是直接通过socket进行发送，默认为0；即默认情况下，主服务器都是先持久化数据到本地文件，再将该文件发送给从服务器。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[九、Redis 持久化--AOF（二）]]></title>
    <link href="http://www.throne4j.com/15943917797824.html"/>
    <updated>2020-07-10T22:36:19+08:00</updated>
    <id>http://www.throne4j.com/15943917797824.html</id>
    <content type="html"><![CDATA[
<p>AOF是Redis的另外一种持久化方式。简单来说，AOF就是将Redis服务端执行过的每一条命令都保存到一个文件，这样当Redis重启时只要按顺序回放这些命令就会恢复到原始状态。</p>

<hr/>

<p><strong>问</strong>：既然已经有了RDB为什么还需要AOF呢？</p>

<p>答：RDB保存的是一个时间点的快照，那么如果Redis出现了故障，丢失的就是从最后一次RDB执行的时间点到故障发生的时间间隔之内产生的数据。如果Redis数据量很大，QPS很高，那么执行一次RDB需要的时间会相应增加，发生故障时丢失的数据也会增多。</p>

<p>而AOF保存的是一条条命令，理论上可以做到发生故障时只丢失一条命令。但由于操作系统中执行写文件操作代价很大，Redis提供了配置参数，通过对安全性和性能的折中，我们可以设置不同的策略。</p>

<hr/>

<p><strong>问</strong>：既然AOF数据安全性更高，是否可以只使用AOF呢？为什么Redis推荐RDB和AOF同时开启呢？</p>

<p>答：RDB保存的是最终的数据，是一个最终状态，而AOF保存的是达到这个最终状态的过程。很明显，如果Redis有大量的修改操作，RDB中一个数据的最终态可能会需要大量的命令才能达到，这会造成AOF文件过大并且加载时速度过慢（Redis提供了一种AOF重写的策略来解决上述问题，后文会详细描述其实现原理）。</p>

<p>再来考虑一下AOF和RDB文件的加载过程。RDB只需要把相应数据加载到内存并生成相应的数据结构（有些结构如intset、ziplist，保存时直接按字符串保存，所以加载时速度会更快），而AOF文件的加载需要先创建一个伪客户端，然后把命令一条条发送给Redis服务端，服务端再完整执行一遍相应的命令。根据Redis作者做的测试，RDB 10s～20s能加载1GB的文件，AOF的速度是RDB速度的一半（如果做了AOF重写会加快）。因为AOF和RDB各有优缺点，因此Redis一般会同时开启AOF和RDB。</p>

<hr/>

<p>但假设线上同时配置了RDB和AOF，那么会带来如下的两难选择：重启时如果优先加载RDB，加载速度更快，但是数据不是很全；如果优先加载AOF，加载速度会变慢，但是数据会比RDB中的要完整。</p>

<p>能不能结合这两者的优点呢？答案是AOF和RDB的混合持久化方案，</p>

<hr/>

<h2 id="toc_0">1、AOF的执行流程</h2>

<p>先介绍Redis服务端执行命令时如何同步到AOF文件以及AOF文件的格式，然后介绍Redis不同的配置对性能和安全性的影响。</p>

<h3 id="toc_1">1.1、AOF命令同步</h3>

<p>通过《<a href="15934396305281.html">三、redis命令处理生命周期</a> 》的执行流程，我们看到每一条命令的执行都会processCommand命令，processCommand命令的执行都会调用 call 函数，AOF命令的同步就是在 call命令中实现的。</p>

<p><figure><img src="media/15943917797824/15943937599696.jpg" alt="AOF命令同步"/><figcaption>AOF命令同步</figcaption></figure></p>

<p>如果开启了AOF，则每条命令执行完毕后都会同步写入aof_buf 中，aof_buf是个全局的SDS类型的缓冲区。</p>

<p>那么命令是按什么格式写入缓冲区中的呢？</p>

<p>Redis通过catAppendOnlyGenericCommand函数将命令转换为保存在缓冲区中的数据结构，</p>

<pre><code class="language-shell">127.0.0.1:6379&gt; SET redis-key value1
# 保存在缓冲区中的格式
*3\r\n$3\r\nSET\r\n$9\r\nredis-key\r\n$6\r\nvalue1\r\n
</code></pre>

<p><strong>Redis 使用自定义格式区分不同的命令，客户端会对命令请求转换为如下的协议格式，其中换行符 <code>\r\n</code> 用于区分命令请求的若干参数，<code>“*3”</code>表示该命令请求有3个参数，<code>“$3”</code>表示第一个参数长度为3，顺序读取三个字符SET ， <code>“$9”</code>表示第二个参数的长度，读取为redis-key ， <code>“$6”</code> 表示第三个参数长度为，读取为value1</strong></p>

<p>那么命令写入缓冲区后何时同步到文件中呢？</p>

<h3 id="toc_2">1.2、AOF文件写入</h3>

<p>为了提高文件的写入效率,在现代操作系中,当用户调用 write函数,将一些数据写入到文件的时候,操作系统通常会将写入数据暂时保存在一个内存冲区里面, 等到缓冲区的空间被填满、或者超过了指定的时限之后,才真正地将缓冲区中的数据写入到磁盘里面。</p>

<p>这种做法虽然提高了效率,但也为写入数据带来了安全问题,因为如果计算机发生停机,那么保存在内存缓冲区里面的写入数据将会丢失。<br/>
为此,系统提供了 fsync和 fdatasync两个同步函数,它们可以强制让操作系统立即将缓冲区中的数据写入到项盘里面,从而确保写入数据的安全性。</p>

<p>AOF持久化最终需要将缓冲区中的内容写入一个文件，写文件通过操作系统提供的write函数执行。但是write之后数据只是保存在kernel的缓冲区中，真正写入磁盘还需要调用 fsync 函数。fsync是一个阻塞并且缓慢的操作，所以Redis通过appendfsync配置控制执行fsync 的频次。具体有如下3种模式：</p>

<ul>
<li>no ：不执行fsync，将aof_buf 缓冲区中的所有内容写入到AOF文件，但不对AOF文件进行同步，由操作系统负责数据的刷盘。数据安全性最低但Redis性能最高。</li>
<li>always：每执行一次写入就会执行一次fsync。数据安全性最高但会导致Redis性能降低。</li>
<li>everysec： 每1秒执行一次fsync操作。属于折中方案，在数据安全性和性能之间达到一个平衡。</li>
</ul>

<p>生产环境一般配置为appendfsync everysec，即每秒执行一次fsync 操作。</p>

<h3 id="toc_3">1.3、AOF 重写</h3>

<p>随着Redis服务的运行，AOF文件会越来越大，并且当Redis服务有大量的修改操作时，对同一个键可能有成百上千条执行命令。AOF 重写通过fork出一个子进程来执行，重写不会对原有文件进行任何修改和读取，子进程对所有数据库中所有的键各自生成一条相应的执行命令，最后将重写开始后父进程继续执行的命令进行回放，生成一个新的AOF文件。</p>

<p>示例如下：</p>

<pre><code class="language-shell">127.0.0.1:6379&gt; rpush list 1 2 3         //list中增加1,2,3三个元素
(integer)3 
127.0.0.1:6379&gt; rpush list 4             //list中增加4 
(integer)4 
127.0.0.1:6379&gt; rpush list 5         //list中增加5
(integer)5 
127.0.0.1:6379&gt; lpop list            //弹出第一个元素
&quot;1&quot;
</code></pre>

<p>AOF重写就是直接按当前list中的内容写为“rpush list 2345”。4条命令变为了一条命令，既可以减小文件大小，又可以提高加载速度。</p>

<h3 id="toc_4">1.4、AOF重写触发方式</h3>

<p>AOF重写有两种触发方式：一种为通过配置自动触发，一种为手动执行bgrewriteaof命令显式触发。</p>

<ul>
<li><p>看自动触发方式，做如下配置：</p>
<pre><code class="language-text">auto-aof-rewrite-percentage 100 
auto-aof-rewrite-min-size 64mb
</code></pre>
<p>当AOF文件大于64MB时，并且AOF文件当前大小比基准大小增长了100%时会触发一次AOF重写。那么基准大小如何确定呢？起始的基准大小为Redis重启并加载完AOF文件之后，aof_buf的大小。当执行完一次AOF重写之后，基准大小相应更新为重写之后AOF文件的大小。当做了如上配置之后， Redis服务器会根据配置自动触发AOF重写。</p></li>
<li><p>手动触发AOF<br/>
下面我们看下手动触发AOF重写，即通过AOF客户端输入 bgrewriteaof 之后的执行流程。 </p></li>
</ul>

<p><figure><img src="media/15943917797824/15945412157461.jpg" alt="" style="width:1273px;"/></figure></p>

<p>子进程执行重写时可能会有成千上万条命令继续在父进程中执行，那么如何保证重写完成后的文件也包括这些命令呢？</p>

<p>首先需要在父进程中将重写过程中执行的命令进行保存，其次需要将这些命令在重写后的文件中进行回放。</p>

<p>Redis为了尽量减少主进程的阻塞时间，通过管道按批次将父进程累积的命令发送给子进程，由子进程重写完成后进行回放。</p>

<p>那么如何通过管道同步给子进程呢？分析下下图<br/>
<figure><img src="media/15943917797824/15945418134506.jpg" alt=""/></figure></p>

<p>父进程在fork之前会建立3对管道：fd0/fd1、fd2/fd3、fd4/fd5，它们各自配对执行。父进程通过fd1将执行aof重写时累积的命令发送给子进程，子进程通过fd0进行接收并保存。当子进程执行完重写之后，向fd3写入一个“！”号通知父进程不需要继续通过管道发送累积命令，父进程通过fd2接收到“！”号之后向fd5也写入一个“！”号进行确认。子进程通过fd4同步阻塞接收到“！”号后才可进行后续的退出操作。退出时首先会将接收到的累积命令进行回放，然后执行fsync。</p>

<h3 id="toc_5">1.5、混合持久化</h3>

<p>混合持久化指进行AOF重写时子进程将当前时间点的数据快照保存为RDB文件格式，而后将父进程累积命令保存为AOF格式。最终形成 RDB file和 AOF file共存的保存形式。</p>

<p>加载时，首先会识别AOF文件是否以REDIS字符串开头，如果是，就按RDB格式加载，加载完RDB后继续按AOF格式加载剩余部分。</p>

<p>是否开启混合持久化由如下配置设置</p>

<pre><code class="language-text">aof-use-rdb-preamble yes
</code></pre>

<h3 id="toc_6">总结</h3>

<ul>
<li>AOF文件通过保存所有修改数据库的写命令来记录服务器的数据库状态</li>
<li>AOF文件中的所有命令都以Redis命令请求协议的格式保存</li>
<li>命令请求会先保存到AOF缓冲区里面，之后再定期写入并同步到AOF文件</li>
<li>appendfsync选项的不同值对AOF持久化功能的安全性以及 Redis服务器的性能有很大的影响</li>
<li>服务器只要载入并重新执行保存在 AOF文件中的命令，就可以还原数据库本来的状态</li>
<li>AOF重写可以产生一个新的 AOF文件，这个新的 AOF文件和原有的AOF文件保存的数据库状态一样，但体积更小</li>
<li>AOF重写功能是通过读取数据库中的键值对来实现的，程序无需对现有的AOF文件进行任何读入、分析或者写入操作</li>
<li>执行 bgrewriteaof命令的时候，redis 服务器会维护一个AOF重写缓冲区,该缓冲区会在子进程创建新的 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件工作之后，服务器会将重写缓冲区中的所有内容追加到 新AOF文件的末尾，使新旧两个AOF文件所保存的数据库状态一致。最后，服务器使用新的 AOF 文件替换旧的AOF文件，来完成AOF文件的重写操作。</li>
</ul>

<hr/>

<h2 id="toc_7">2、RDB 与 AOF 相关配置指令</h2>

<table>
<thead>
<tr>
<th>配置项</th>
<th>可选值</th>
<th>功能</th>
<th>作用</th>
</tr>
</thead>

<tbody>
<tr>
<td>save</td>
<td><code>&lt;secondes&gt; &lt;changes&gt;</code> 默认：save 900 1、save 300 10、save 60 10000</td>
<td>RDB</td>
<td>自动触发配置</td>
</tr>
<tr>
<td>stop-writes-on-bgsave-error</td>
<td>yes/no(默认yes)</td>
<td>RBD</td>
<td>开启该参数后，如果开启了RDB 快照（即配置了save指令），并且最近一次快照执行失败，则Redis 将停止接收写相关的请求。</td>
</tr>
<tr>
<td>rdbcompression</td>
<td>yes/no(默认yes)</td>
<td>RDB</td>
<td>执行RDB快照时是否将 string类型的数据进行LZF压缩。</td>
</tr>
<tr>
<td>rdbchecksum</td>
<td>yes/no(默认yes)</td>
<td>RDB</td>
<td>是否开启RDB文件内容的校验</td>
</tr>
<tr>
<td>dbfilename</td>
<td>文件名称(默认 dump.rdb)</td>
<td>RDB</td>
<td>RDB文件名称</td>
</tr>
<tr>
<td>dir</td>
<td>文件路径(默认./)</td>
<td>RDB</td>
<td>RDB和AOF文件存放路径</td>
</tr>
<tr>
<td>rdb-save-incremental-fsync</td>
<td>yes/no(默认yes)</td>
<td>RDB</td>
<td>开启该参数后，生成RDB文件时每产生32MB数据就执行一次fsync。</td>
</tr>
<tr>
<td>appendonly</td>
<td>yes/no(默认no)</td>
<td>AOF</td>
<td>是否开启 AOF 功能</td>
</tr>
<tr>
<td>appendfilename</td>
<td>文件名称(默认 appendonly.aof)</td>
<td>AOF</td>
<td>AOF 文件名称</td>
</tr>
<tr>
<td>appendfsync</td>
<td>always/everysec/no (默认 everysec)</td>
<td>AOF</td>
<td>fsync执行频次,always：将aof_buf缓冲区中的所有内容写入并同步到AOF文件；everysec:每1秒执行一次fsync操作。属于折中方案，在数据安全性和性能之间达到一个平衡;no:  不执行fsync，由操作系统负责数据的刷盘。数据安全性最低但Redis性能最高。</td>
</tr>
<tr>
<td>no-appendfsync-on-rewrite</td>
<td>yes/no(默认no)</td>
<td>AOF</td>
<td>开启该参数后，如果后台正在执行一次RDB快照或者AOF重写，则主进程不再进行fsync操作（即使将appendfsync配置为always或者everysec）</td>
</tr>
<tr>
<td>auto-aof-rewrite-percentage</td>
<td>百分比(默认100)</td>
<td>AOF</td>
<td>自动重写配置项，当前AOF文件大于auto-aof-rewrite-min-size 配置的大小 并且比基准文件增长此百分比时触发AOF重写</td>
</tr>
<tr>
<td>auto-aof-rewrite-min-size</td>
<td>文件大小(默认64MB)</td>
<td>AOF</td>
<td>自动重写配置项，当前AOF文件大于此配置值，并且当前AOF文件 比基准文件增长auto-aof-rewrite-percentage配置的百分比时触发AOF重写</td>
</tr>
<tr>
<td>aof-load-truncated</td>
<td>yes/no(默认yes)</td>
<td>AOF</td>
<td>AOF文件以追加日志的方式生成，所以服务端发生故障时可能会有尾部命令不完整的情况。开启该参数后，在此种情况下，AOF文件会截断尾部不完整的命令然后继续加载，并且会在日志中进行提示。如果不开启该参数，则加载AOF文件时会打印错误日志，然后直接退出</td>
</tr>
<tr>
<td>aof-use-rdb-preamble</td>
<td>yes/no(默认yes)</td>
<td>AOF</td>
<td>是否开启混合持久化</td>
</tr>
<tr>
<td>aof-rewrite-incremental-fsync</td>
<td>yes/no(默认yes)</td>
<td>AOF</td>
<td>开启该参数后，AOF重写时没产生32MB数据执行一次fsync</td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[软件设计上的基本知识]]></title>
    <link href="http://www.throne4j.com/15943756601312.html"/>
    <updated>2020-07-10T18:07:40+08:00</updated>
    <id>http://www.throne4j.com/15943756601312.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">API与SPI分离</h2>

<p>框架或组件通常有两类客户，一个是使用者，一个是扩展者，API(Application Programming Interface)是给使用者用的，而SPI(Service Provide Interface)是给扩展者用的，在设计时，尽量把它们隔离开，而不要混在一起，也就是说，使用者是看不到扩展者写的实现的，比如：一个Web框架，它有一个API接口叫Action，里面有个execute()方法，是给使用者用来写业务逻辑的，然后，Web框架有一个SPI接口给扩展者控制输出方式，比如用velocity模板输出还是用json输出等，如果这个Web框架使用一个都继承Action的VelocityAction和一个JsonAction做为扩展方式，要用velocity模板输出的就继承VelocityAction，要用json输出的就继承JsonAction，这就是API和SPI没有分离的反面例子，SPI接口混在了API接口中，合理的方式是，有一个单独的Renderer接口，有VelocityRenderer和JsonRenderer实现，Web框架将Action的输出转交给Renderer接口做渲染输出。</p>

<pre><code class="language-text">![](media/15943756601312/15943757095695.jpg)

![](media/15943756601312/15943757185485.jpg)
</code></pre>

<h2 id="toc_1">服务域/实体域/会话域分离</h2>

<p>任何框架或组件，总会有核心领域模型，比如：<br/>
Spring的Bean，Struts的Action，Dubbo的Service，Napoli的Queue等等<br/>
这个核心领域模型及其组成部分称为实体域，它代表着我们要操作的目标本身，实体域通常是线程安全的，不管是通过不变类，同步状态，或复制的方式，服务域也就是行为域，它是组件的功能集，同时也负责实体域和会话域的生命周期管理，比如Spring的ApplicationContext，Dubbo的ServiceManager等，服务域的对象通常会比较重，而且是线程安全的，并以单一实例服务于所有调用，什么是会话？就是一次交互过程，会话中重要的概念是上下文，什么是上下文？</p>

<p>比如我们说：“老地方见”，这里的“老地方”就是上下文信息，为什么说“老地方”对方会知道，因为我们前面定义了“老地方”的具体内容，所以说，上下文通常持有交互过程中的状态变量等，会话对象通常较轻，每次请求都重新创建实例，请求结束后销毁。</p>

<p>简而言之：<br/>
把元信息交由实体域持有，把一次请求中的临时状态由会话域持有，由服务域贯穿整个过程。</p>

<p><figure><img src="media/15943756601312/15943757281530.jpg" alt=""/></figure>       <figure><img src="media/15943756601312/15943757329746.jpg" alt=""/></figure></p>

<h2 id="toc_2">在重要的过程上设置拦截接口</h2>

<p>如果你要写个远程调用框架，那远程调用的过程应该有一个统一的拦截接口，如果你要写一个ORM框架，那至少SQL的执行过程，Mapping过程要有拦截接口，如果你要写一个Web框架，那请求的执行过程应该要有拦截接口，等等，没有哪个公用的框架可以Cover住所有需求，允许外置行为，是框架的基本扩展方式，这样，如果有人想在远程调用前，验证下令牌，验证下黑白名单，统计下日志，如果有人想在SQL执行前加下分页包装，做下数据权限控制，统计下SQL执行时间，如果有人想在请求执行前检查下角色，包装下输入输出流，统计下请求量，等等，就可以自行完成，而不用侵入框架内部，拦截接口，通常是把过程本身用一个对象封装起来，传给拦截器链，</p>

<p>比如：远程调用主过程为invoke()，那拦截器接口通常invoke(Invocation)，Invocation对象封装了本来要执行过程的上下文，并且Invocation里有一个invoke()方法，由拦截器决定什么时候执行，同时，Invocation也代表拦截器行为本身，这样上一拦截器的Invocation其实是包装的下一拦截器的过程，直到最后一个拦截器的Invocation是包装的最终的invoke()过程，同理，SQL主过程为execute()，那拦截器接口通常为execute(Execution)，原理一样，当然，实现方式可以任意，上面只是举例。</p>

<p><figure><img src="media/15943756601312/15943757516458.jpg" alt=""/></figure></p>

<h2 id="toc_3">重要的状态的变更发送事件并留出监听接口</h2>

<p>这里先要讲一个事件和上面拦截器的区别，拦截器是干预过程的，它是过程的一部分，是基于过程行为的，而事件是基于状态数据的，任何行为改变的相同状态，对事件应该是一致的，事件通常是事后通知，是一个Callback接口，方法名通常是过去式的，比如onChanged()，比如远程调用框架，当网络断开或连上应该发出一个事件，当出现错误也可以考虑发出一个事件，这样外围应用就有可能观察到框架内部的变化，做相应适应。</p>

<p><figure><img src="media/15943756601312/15943757591172.jpg" alt=""/></figure></p>

<h2 id="toc_4">扩展接口职责尽可能单一，具有可组合性</h2>

<p>比如，远程调用框架它的协议是可以替换的，如果只提供一个总的扩展接口，当然可以做到切换协议，但协议支持是可以细分为底层通讯，序列化，动态代理方式等等，如果将接口拆细，正交分解，会更便于扩展者复用已有逻辑，而只是替换某部分实现策略，当然这个分解的粒度需要把握好。</p>

<h2 id="toc_5">微核插件式，平等对待第三方</h2>

<p>大凡发展的比较好的框架，都遵守微核的理念，Eclipse的微核是OSGi， Spring的微核是BeanFactory，Maven的微核是Plexus，通常核心是不应该带有功能性的，而是一个生命周期和集成容器，这样各功能可以通过相同的方式交互及扩展，并且任何功能都可以被替换，如果做不到微核，至少要平等对待第三方，即原作者能实现的功能，扩展者应该可以通过扩展的方式全部做到，原作者要把自己也当作扩展者，这样才能保证框架的可持续性及由内向外的稳定性。</p>

<h2 id="toc_6">不要控制外部对象的生命周期</h2>

<p>比如上面说的Action使用接口和Renderer扩展接口，框架如果让使用者或扩展者把Action或Renderer实现类的类名或类元信息报上来，然后在内部通过反射newInstance()创建一个实例，这样框架就控制了Action或Renderer实现类的生命周期，Action或Renderer的生老病死，框架都自己做了，外部扩展或集成都无能为力，好的办法是让使用者或扩展者把Action或Renderer实现类的实例报上来，框架只是使用这些实例，这些对象是怎么创建的，怎么销毁的，都和框架无关，框架最多提供工具类辅助管理，而不是绝对控制。</p>

<h2 id="toc_7">可配置一定可编程，并保持友好的CoC约定</h2>

<p>因为使用环境的不确定因素很多，框架总会有一些配置，一般都会到classpath直扫某个指定名称的配置，或者启动时允许指定配置路径，做为一个通用框架，应该做到凡是能配置文件做的一定要能通过编程方式进行，否则当使用者需要将你的框架与另一个框架集成时就会带来很多不必要的麻烦，另外，尽可能做一个标准约定，如果用户按某种约定做事时，就不需要该配置项。</p>

<p>比如：配置模板位置，你可以约定，如果放在templates目录下就不用配了，如果你想换个目录，就配置下。</p>

<h2 id="toc_8">区分命令与查询，明确前置条件与后置条件</h2>

<p>这个是契约式设计的一部分，尽量遵守有返回值的方法是查询方法，void返回的方法是命令，查询方法通常是幂等性的，无副作用的，也就是不改变任何状态，调n次结果都是一样的，比如get某个属性值，或查询一条数据库记录，命令是指有副作用的，也就是会修改状态，比如set某个值，或update某条数据库记录，如果你的方法即做了修改状态的操作，又做了查询返回，如果可能，将其拆成写读分离的两个方法，</p>

<p>比如：User deleteUser(id)，删除用户并返回被删除的用户，考虑改为getUser()和void的deleteUser()。另外，每个方法都尽量前置断言传入参数的合法性，后置断言返回结果的合法性，并文档化。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[八、Redis 持久化--RDB（一）]]></title>
    <link href="http://www.throne4j.com/15942163464303.html"/>
    <updated>2020-07-08T21:52:26+08:00</updated>
    <id>http://www.throne4j.com/15942163464303.html</id>
    <content type="html"><![CDATA[
<p>Redis 是一个内存数据库，为了保证数据不丢失，持久化就显得尤为重要了。Redis 有两种持久化方法:RDB方式，RDB保存某一个时间点之前的数据；另一种为AOF方式，AOF保存的是Redis服务器端执行的每一条命令。</p>

<p>通过info命令查看 redis服务端记录的相关持久化状态信息：</p>

<pre><code class="language-shell">127.0.0.1:6379&gt;info
# Persistence 
loading:0                               //是否正在加载RDB文件内容
rdb_changes_since_last_save:2           //最后一次保存之后改变的键的个数
rdb_bgsave_in_progress:0                //是否正在后台执行RDB保存任务
rdb_last_save_time:1540371552           //最后一次执行RDB保存任务的时间
rdb_last_bgsave_status:ok               //最后一次执行RDB保存任务的状态
rdb_last_bgsave_time_sec:0              //最后一次执行RDB保存任务消耗的时间
rdb_current_bgsave_time_sec:-1          //如果正在执行RDB保存任务，则为当前RDB任务已经消耗的时间，否则为-1 
rdb_last_cow_size:6631424               //最后一次执行RDB保存任务消耗的内存
aof_enabled:0                           //是否开启了AOF功能aof_rewrite_in_progress:0               //是否正在后台执行AOF重写任务
aof_rewrite_scheduled:0                 //是否等待调度一次AOF重写任务。如果触发了一次AOF重写，                                          但是后台正在执行RDB保存任务时会将该状态置为1 
aof_last_rewrite_time_sec:-1            //最后一次执行AOF重写任务消耗的时间
aof_current_rewrite_time_sec:-1         //如果正在执行AOF重写任务，则为当前该任务已经消耗的时间，否则为-1 
aof_last_bgrewrite_status:ok            //最后一次执行AOF重写任务的状态
aof_last_write_status:ok                //最后一次执行AOF缓冲区写入的状态（服务端执行命令时会开辟一段内存空间将命令放入其中，然后从该缓冲区中同步到文件。该状态标记最后一次同步到文件的状态
aof_last_cow_size:0                     //最后一次执行AOF重写任务消耗的内存

</code></pre>

<h2 id="toc_0">RDB 持久化方式</h2>

<p>RDB持久化方式是保存一个时间点的快照。</p>

<p>RDB快照有两种触发方式</p>

<ul>
<li>配置参数，在配置文件中写入 <code>save 60 1000</code>，则在60秒内如果有1000个key发生变化，就出发一次RDB快照执行。</li>
<li>通过客户端执行 bgsave 命令显式的触发一次RDB快照的执行。</li>
</ul>

<p>bgsave执行流程如下图所示：</p>

<p><figure><img src="media/15942163464303/15942173127342.jpg" alt="bgsave 执行流程"/><figcaption>bgsave 执行流程</figcaption></figure></p>

<p>在客户端输入 bgsave 命令后，Redis调用 bgsaveCommand 函数，该函数fork一个子进程执行 rdbSave 函数进行实际的快照存储工作，而父进程可以继续处理客户端请求。当子进程退出后，父进程调用相关回调函数进行后续处理。</p>

<h3 id="toc_1">RDB文件结构</h3>

<p>RDB 整体文件结构如下图所示：</p>

<p><figure><img src="media/15942163464303/15942232766455.jpg" alt=""/></figure></p>

<ul>
<li>头部5字节固定为“REDIS”字符串</li>
<li>4字节的RDB版本号（RDB_VERSION，注意不是Redis的版本号），当前RDB版本号为9，填充为4字节之后为0008。</li>
<li><p>辅助字段AUX_FIELD_KEY_VALUE_PAIRS，辅助字段可以标明以下信息</p>
<table>
<thead>
<tr>
<th>字段名称</th>
<th>字段值</th>
</tr>
</thead>
<tbody>
<tr>
<td>redis-ver</td>
<td>5.0.04</td>
</tr>
<tr>
<td>redis-bits</td>
<td>64/32</td>
</tr>
<tr>
<td>ctime</td>
<td>当前时间戳</td>
</tr>
<tr>
<td>used-mem</td>
<td>redis占用内存</td>
</tr>
<tr>
<td>aof-preamble</td>
<td>是否开启aof/rdb混合持久化</td>
</tr>
<tr>
<td>repl-stream-db</td>
<td>主从复制相关</td>
</tr>
<tr>
<td>repl-id</td>
<td>主从复制相关</td>
</tr>
<tr>
<td>repl-offset</td>
<td>主从复制相关</td>
</tr>
</tbody>
</table></li>
<li><p>数据库序号：指明数据需要存放到哪个数据库</p></li>
<li><p>当前数据库键值对散列表的大小，这样在加载时可以直接将散列表扩展到指定大小，提升加载速度。</p></li>
<li><p>当前数据库过期时间散列表的大小</p></li>
<li><p>Redis中具体键值对的存储</p></li>
<li><p>RDB文件结束标志</p></li>
<li><p>8字节校验码</p></li>
</ul>

<p>加载RDB文件的时候怎么区分加载的是辅助字段还是数据库序号或者是其他类型呢？其实在RDB每一部分之前都有一个类型字节，在Redis中称为opcodes，opcodes如下所示：</p>

<pre><code class="language-c">#define RDB_OPCODE_MODULE_AUX    247        //module相关辅助字段
#define RDB_OPCODE_IDLE          248        //lru空闲时间
#define RDB_OPCODE_FREQ          249        //lfu频率
#define RDB_OPCODE_AUX           250        //辅助字段类型
#define RDB_OPCODE_RESIZEDB      251        //RESIZEDB，即上文中介绍的5和6两项
#define RDB_OPCODE_EXPIRETIME_MS 252        //毫秒级别过期时间
#define RDB_OPCODE_EXPIRETIME    253        //秒级别过期时间
#define RDB_OPCODE_SELECTDB      254        //数据库序号，即第4项
#define RDB_OPCODE_EOF           255        //结束标志，即第8项
</code></pre>

<p>带opcodes 的RDB 结构表显形式</p>

<p><figure><img src="media/15942163464303/15942254144953.jpg" alt=""/></figure></p>

<p>下面我们看下 键值对的结构，如下图所示<br/>
<figure><img src="media/15942163464303/15942257282611.jpg" alt=""/></figure></p>

<ul>
<li>EXPIRE_TIME: 可选。根据具体的键是否有过期时间决定，该字段固定为8个字节。</li>
<li>LRU或者LFU：可选。根据配置的内存淘汰算法决定。LRU算法保存秒级别的时间戳，LFU算法只保存counter的计数（0～255，1 字节）</li>
<li><p>VALUE_TYPE：值类型。Redis数据类型和底层编码结构<br/>
<figure><img src="media/15942163464303/15942258850154.jpg" alt=""/></figure></p></li>
<li><p>KEY：键。键保存为字符串，下文会详细介绍字符串的保存形式。</p></li>
<li><p>VALUE：值。值根据数据类型和编码结构保存为不同的形式</p></li>
</ul>

<h3 id="toc_2">RDB键的保存形式</h3>

<p>redis中键都是字符串，比较常见的保存方法如下图所示：<br/>
<figure><img src="media/15942163464303/15943123637192.jpg" alt=""/></figure></p>

<p>前边LENGTH字段表示字符串长度，后边STRING即具体的字符串内容。</p>

<p>Redis中的LENGTH是个变长字段，通过首字节能够知道LENGTH字段有多长，然后读取LENGTH字段可以知道具体的STRING长度。LENGTH字段类型如下:</p>

<pre><code class="language-shell">00xxxxxx   #表示LENGTH字段占用1个字节，STRING的长度保存在后6个比特中，最长为63。
01xxxxxx xxxxxxxx  #表示LENGTH字段占用2个字节，而STRING的长度保存在后14个字节中，最长为16383 
10000000 xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx  表示LENGTH字段共占用5个字节，正好是一个无符号整型，STRING的长度最长为UINT32_MAX。 
10000001 xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx #如果STRING长度大于UINT32_MAX，则首字节表示为10000001，LENGTH字段共占用9个字节。后8字节表示实际长度，为一个LONG类型。
</code></pre>

<p>RDB中对字符串的保存还有两种优化形式：</p>

<ul>
<li><p>一种是尝试将字符串按整型保存<br/>
<figure><img src="media/15942163464303/15943127989186.jpg" alt="字符串按整型保存"/><figcaption>字符串按整型保存</figcaption></figure> </p>
<p>TYPE字段其实类似图20-5中的LENGTH字段，LENGTH字段首字节头两个比特取值为00、01、10这种类型，TYPE字段首字节头两个比特取值为11，后6个比特表明存储的整型类型，如下所示：</p>
<pre><code class="language-text">11000000 xxxxxxxx  INT8   取值范围[-128,127] 
11000001 xxxxxxxx xxxxxxxx INT16 取值范围[-32768,32767] <br/>
11000010 xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx  INT32 取值范围[-2147483648 ,  2147483647] 
</code></pre></li>
<li><p>一种是通过将字符串进行LZF压缩之后保存。<br/>
<figure><img src="media/15942163464303/15943130001731.jpg" alt="RDB LZF保存形式"/><figcaption>RDB LZF保存形式</figcaption></figure></p>
<p>TYPE首字节头两个比特仍然为11，后六个比特是000011。COMPRESS_LEN表明压缩之后的长度，该字段保存形式同图20-5中LENGTH字段的保存。LZF还保存了一个ORIGINAL_LEN字段，该字段记录压缩之前原始字符串的长度，保存形式也与图20-5中LENGTH字段的保存相同。最后一个DATA字段保存具体的LZF压缩之后的数据，数据长度从COMPRESS_LEN字段取得。</p></li>
</ul>

<h3 id="toc_3">RDB 值保存形式</h3>

<p>值类型有如下图所示：<br/>
<figure><img src="media/15942163464303/15943894568628.jpg" alt=""/></figure></p>

<p>其中字符串类型的保存于 上面的《键的保存形式》相同，其余几种值的保存形式各不相同</p>

<h4 id="toc_4">列表类型的保存</h4>

<p>列表在Redis中编码为 quicklist结构，从整体看是一个双向链表，但链表的每个节点在Redis中编码为zipList结构，ziplist结构在一块连续的内存中保存，并且保存时可以选择进行LZF压缩或者不压缩。据此，RDB 保存列表类型的结构如图所示：</p>

<p>ziplist未压缩<br/>
<figure><img src="media/15942163464303/15943897652665.jpg" alt=""/></figure></p>

<p>ziplist压缩：</p>

<p><figure><img src="media/15942163464303/15943898009527.jpg" alt=""/></figure></p>

<p>如果ziplist未压缩，每个ziplist按照字符串保存，如果ziplist进行了压缩，则按照下图方式进行保存<br/>
<figure><img src="media/15942163464303/15943899607716.jpg" alt="" style="width:544px;"/></figure></p>

<h4 id="toc_5">集合类型的保存</h4>

<p>集合类型在Redis中有两种编码方式：一种为intset，另一种为Hash。<br/>
intset在Redis中也是一块连续的内存，所以intset的保存比较简单，直接将intset按字符串保存。</p>

<p>如果编码为Hash，保存结构如下图所示：<br/>
<figure><img src="media/15942163464303/15943908892309.jpg" alt=""/></figure><br/>
第一个字段为字典的大小，接下来逐字段保存字典的键。为什么只保存键呢？其实集合类型使用散列表保存时只使用了键，所有的值都保存为NULL，所以此处只需要保存散列表的键。</p>

<h4 id="toc_6">有序集合类型的保存</h4>

<p>有序集合类型在Redis中也有两种编码方式：一种为ziplist，另一种为skiplist。如果编码为ziplist，即将ziplist整体作为一个字符串保存。所以我们重点看编码为skiplist的保存方式</p>

<p><figure><img src="media/15942163464303/15943913158909.jpg" alt=""/></figure><br/>
第一个字段为skiplist包含的元素个数，接着分别按元素和元素的分值依次保存。元素保存为字符串，元素分值保存为一个双精度浮点数类型（固定为8个字节）</p>

<h4 id="toc_7">散列类型的保存</h4>

<p>散列类型也有两种编码方式：一种为ziplist，一种为Hash。ziplist 编码方式的保存同有序集合。重点看散列类型按Hash编码时的保存方式。<br/>
<figure><img src="media/15942163464303/15943913962043.jpg" alt=""/></figure><br/>
第一个字段为散列表的大小，然后依次保存键值对，键值都保存为字符串类型。</p>

<h4 id="toc_8">Stream类型的保存</h4>

<p>Stream保存为RDB文件时整体格式如图所示：<br/>
<figure><img src="media/15942163464303/15943914536802.jpg" alt=""/></figure><br/>
其中具体的结构体介绍，如listpack，消费组等的介绍参考<a href="15938782048225.html">六、Redis 数据流 stream </a>。其中保存消费组的PEL时并没有保存相关消费者的信息，而是在加载完消费者之后，从消费者的PEL中查找并更新消费组PEL的相关信息。</p>

<h3 id="toc_9">RDB 实例</h3>

<p>我们查看一下空的 redis 库是怎样的</p>

<pre><code class="language-text">127.0.0.1:6379&gt;flushall
ok
127.0.0.1:6379&gt;bgsave
Background saving started
</code></pre>

<pre><code class="language-text">➜  redis xxd dump.rdb
00000000: 5245 4449 5330 3030 39fa 0972 6564 6973  REDIS0009..redis
00000010: 2d76 6572 0535 2e30 2e38 fa0a 7265 6469  -ver.5.0.8..redi
00000020: 732d 6269 7473 c040 fa05 6374 696d 65c2  s-bits.@..ctime.
00000030: 1a45 075f fa08 7573 6564 2d6d 656d c210  .E._..used-mem..
00000040: 0910 00fa 0c61 6f66 2d70 7265 616d 626c  .....aof-preambl
00000050: 65c0 00ff fe39 f4d9 2732 2a22            e....9..&#39;2*&quot;
➜  redis od -cx dump.rdb
0000000    R   E   D   I   S   0   0   0   9 372  \t   r   e   d   i   s
             4552    4944    3053    3030    fa39    7209    6465    7369
0000020    -   v   e   r 005   5   .   0   .   8 372  \n   r   e   d   i
             762d    7265    3505    302e    382e    0afa    6572    6964
0000040    s   -   b   i   t   s 300   @ 372 005   c   t   i   m   e 032
             2d73    6962    7374    40c0    05fa    7463    6d69    c265
0000060  032   E  \a   _ 372  \b   u   s   e   d   -   m   e   m 302 020
             451a    5f07    08fa    7375    6465    6d2d    6d65    10c2
0000100   \t 020  \0 372  \f   a   o   f   -   p   r   e   a   m   b   l
             1009    fa00    610c    666f    702d    6572    6d61    6c62
0000120    e 300  \0 377 376   9 364 331   &#39;   2   *   &quot;
             c065    ff00    39fe    d9f4    3227    222a
0000134
</code></pre>

<ul>
<li>RDB 文件用于保存和还原Redis服务器所有的数据库中的所有的键值对数据</li>
<li>save命令有服务器进行直接执行保存操作，但是会阻塞服务器</li>
<li>bgsave由紫禁城执行保存操作，不会阻塞服务器</li>
<li>服务器状态中会保存所有用save选项设置的保存条件，当人以一个保存条件被满足时，服务器会自动执行 bgsave 命令</li>
<li>RDB 文件是一个经过压缩的二进制文件，由多个部分组成</li>
<li>对于不同类型的键值对，RDB文件会使用不同的方式来保存它们。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[七、Redis 事务]]></title>
    <link href="http://www.throne4j.com/15940318259166.html"/>
    <updated>2020-07-06T18:37:05+08:00</updated>
    <id>http://www.throne4j.com/15940318259166.html</id>
    <content type="html"><![CDATA[
<p>Redis 中的事务能够保证一批命令的原子性操作，redis提供了 事务的命令有 watch、unwatch、multi、exec、discard 。<br/>
事务从开始到结束经历以下三个阶段：</p>

<ul>
<li><p>multi 开启事务<br/>
Redis 的事务 不能嵌套，即不能再一个开启的事务内再次调用multi命令开启新的事务。<br/>
multi命令源码：</p>
<pre><code class="language-redis">void multiCommand(client *c) {     
    //如果已经执行过multi命令，则不能再次执行<br/>
    if (c-&gt;flags &amp; CLIENT_MULTI) {        <br/>
        addReplyError(c,&quot;MULTI calls can not be nested&quot;);         <br/>
        return;     <br/>
    }     <br/>
    //client结构体置CLIENT_MULTI标志<br/>
    c-&gt;flags |= CLIENT_MULTI;                            <br/>
    addReply(c,shared.ok); <br/>
}
</code></pre></li>
<li><p>所有的命令会首先入队而不是直接执行</p>
<ul>
<li>当一个客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行。</li>
<li>当一个客户端处于事务状态后，服务器会根据客户端发来的不同命令执行不同的操作
<ul>
<li>发送命令 exec、discard、watch、unwatch，服务器会立即执行此命令</li>
<li>发送非exec、discard、watch、unwatch 命令，将这个命令放入一个事务队列里面，然后向客户端返回QUEUED回复。</li>
</ul></li>
</ul>
<pre><code class="language-text">int processCommand(client *c) {
    ...<br/>
        if (c-&gt;flags &amp; CLIENT_MULTI <br/>
            &amp;&amp; c-&gt;cmd-&gt;proc != execCommand <br/>
            &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand <br/>
            &amp;&amp;  c-&gt;cmd-&gt;proc != multiCommand <br/>
            &amp;&amp; c-&gt;cmd-&gt;proc != watchCommand) {<br/>
            //如果client有CLIENT_MULTI标志并且不是exec，discard，                                          multi和watch命令，则将该命令放入队列            <br/>
            queueMultiCommand(c);        //放入队列            <br/>
            addReply(c,shared.queued);         <br/>
        } else {                        <br/>
            //否则调用call命令            <br/>
            call(c,CMD_CALL_FULL);         <br/>
            ...<br/>
        } <br/>
 ...<br/>
}
</code></pre></li>
<li><p>exec提交并开始执行事务，exec命令执行所有入队命令，将命令返回值依次返回给客户端。</p></li>
</ul>

<p>watch命令提供了一种乐观锁机制。watch命令可以监听多个key，只有当被监听的key未修改时，事务才会执行。当一个事务发送exec或者discard命令后，所有watch的key会自动unwatch。</p>

<p>unwatch 命令其实就是删除相应client端和server端的监听状态。首先从client端的链表中取出key和对应的db，然后删除server端相应的监听信息，删除成功后再将client端的对应链表节点删除。执行完毕后，该连接所有被监听的key都会恢复到未监听状态。</p>

<p>discard命令放弃事务。放弃一个事务时首先会将所有入队命令清空，然后将client上事务相关的flags清空，最后将所有监听的keys取消监听。</p>

<p><strong><em>Redis 事务不支持事务回滚机制</em></strong>，即使事务队列中的某个命令在执行期间发生错误，整个事务也会继续执行下去，直到将事务队列中的所有命令都执行完毕为止。</p>

<h2 id="toc_0">事务队列</h2>

<p>每个redis 客户端都有自己的事务状态，这个事务状态保存在客户端状态的mstate属性中</p>

<pre><code class="language-c">typedef struct client {
    multiState mstate;   //命令队列，会将所有的命令按照顺序排列好并保存
} client;

typedef struct multiState {
    multiCmd *commands;//命令队列，FIFO顺序
    int count;// 已入队命令计数
}

typedef struct multiCmd {

    robj **argv;//参数
    int argc;//参数数量
    struct redisCommand *cmd;//命令指针
</code></pre>

<p>事务队列以先进先出(FIFO)的方式保存入队命令。</p>

<h2 id="toc_1">判断事务是否安全</h2>

<p>当客户端 执行 exec 提交事务的时候，服务器会根据这个客户端是否打开了 REDIS_DIRTY_CAS 标识来决定是否执行事务。</p>

<ul>
<li>如果客户端的REDIS_DIRTY_CAS (watch命令)标识已经被打开，那么说明客户端所监视的键当中，至少有一个键已经被修改过，这种情况，客户端提交的事务已经不再安全，这是服务器拒绝执行客户端提交的事务。</li>
<li>如果客户端的REDIS_DIRTY_CAS (watch命令)标识没有被打开，说明客户端监视的所有键都没有被修改过，事务仍然安全，服务器将执行客户端提交的事务。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[限流]]></title>
    <link href="http://www.throne4j.com/15938782054278.html"/>
    <updated>2020-07-04T23:56:45+08:00</updated>
    <id>http://www.throne4j.com/15938782054278.html</id>
    <content type="html"><![CDATA[
<p>保证系统能正常稳定的运行</p>

<ul>
<li>限制总并发数<br/>
数据库连接池、线程池</li>
<li>限制瞬时并发数<br/>
如nginx的limit_conn 模块，用来限制瞬时并发连接数</li>
<li>限制时间窗口内的平均速率<br/>
如guava的 RateLimiter、nginx的limit_req 模块，限制每秒平均速率</li>
<li>其它限制<br/>
如限制远程接口调用速率、限制mq的消费速率</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[六、Redis 数据流 stream]]></title>
    <link href="http://www.throne4j.com/15938782048225.html"/>
    <updated>2020-07-04T23:56:44+08:00</updated>
    <id>http://www.throne4j.com/15938782048225.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、stream 实现</h2>

<p>消息队列是分布式系统中不可缺少的组件之一，主要有异步处理、应用解耦、限流削峰的功能。目前应用较为广泛的消息队列有RabbitMQ、RocketMQ、Kafka等。Redis在最新的5.0.0版本中也加入了消息队列的功能，这就是Stream。</p>

<p>Redis Stream 它主要由消息、生产者、消费者、消费组4部分组成。可以通过如下指令创建一个消息流并项其中加入一条消息<br/>
<figure><img src="media/15938782048225/15939414214436.jpg" alt="" style="width:800px;"/></figure></p>

<pre><code class="language-text">xadd mystream * name zhangsan age 10
</code></pre>

<p>上面的命令中</p>

<ul>
<li>mystream 为 Stream 的名称；</li>
<li>* 代表由Redis自行生成消息ID；</li>
<li>name、age为该消息的field；hb、20则为对应的field的值。</li>
</ul>

<p>每个消息都由以下两部分组成:</p>

<ul>
<li>每个消息有唯一的消息ID，消息ID严格递增。</li>
<li>消息内容由多个field-value对组成。</li>
</ul>

<p>生产者负责向消息队列中生产消息，消费者消费某个消息流。消费者可以归属某个消费组，也可以不归属任何消费组。当消费者不归属于任何消费组时，该消费者可以消费消息队列中的任何消息。</p>

<p>消费组是Stream 具有如下特点</p>

<ul>
<li>每个消费组通过组名称唯一标识，每个消费组都可以消费该消息队列的全部消息，多个消费组之间相互独立。</li>
<li>每个消费组可以有多个消费者，消费者通过名称唯一标识，消费者之间的关系是竞争关系，也就是说一个消息只能由该组的一个成员消费。</li>
<li>组内成员消费消息后需要确认，每个消息组都有一个待确认消息队列（pending entry list，pel），用以维护该消费组已经消费但没有确认的消息。</li>
<li>消费组中的每个成员也有一个待确认消息队列，维护着该消费者已经消费尚未确认的消息。</li>
</ul>

<p>Redis Stream的底层实现主要使用了listpack以及Rax树</p>

<h3 id="toc_1">1.1、stream 底层结构 listpack</h3>

<p>listpack 是一个字符串列表的序列化格式，也就是将一个字符串列表进行序列化存储。Redis listpack可用于存储字符串或者整型。</p>

<p><figure><img src="media/15938782048225/15938831394252.jpg" alt="listpack结构图"/><figcaption>listpack结构图</figcaption></figure></p>

<p>listpack由4部分组成：</p>

<ul>
<li>Total Bytes：整个listpack的空间大小，占用4个字节，每个listpack最多占用4294967295Bytes。</li>
<li>Num Elem：listpack中的元素个数，即Entry的个数，占用2个字节<br/>
虽然占用2个字节，但是并不意味着listpack最多只能存放65535个Entry，当Entry个数大于等于65535时，Num Elem被设置为65535，此时如果需要获取元素个数，需要遍历整个listpack</li>
<li>End：listpack结束标志，占用1个字节，内容为0xFF。</li>
<li>Entry： 每个具体的元素，其内容可以为字符串或者整型。
<ul>
<li>encode： 该entry元素的编码，占用1个字节</li>
<li>content：entry元素内容</li>
<li>backlen： 记录了这个Entry的长度（Encode+content）</li>
</ul></li>
</ul>

<h3 id="toc_2">1.2、Stream底层结构Rax</h3>

<p>前缀树是字符串查找时，经常使用的一种数据结构，能够在一个字符串集合中快速查找到某个字符串, 但是由于前缀树中每个节点只存储字符串中的一个字符，故而有时会造成空间的浪费。Rax的出现就是为了解决这一问题，Rax中不仅可以存储字符串，同时还可以为这个字符串设置一个值，也就是key-value。</p>

<p><figure><img src="media/15938782048225/15939279706367.jpg" alt="含有两个压缩节点的rax"/><figcaption>含有两个压缩节点的rax</figcaption></figure></p>

<p><figure><img src="media/15938782048225/15939288033339.jpg" alt="含有foobar,footer两个key的Rax"/><figcaption>含有foobar,footer两个key的Rax</figcaption></figure></p>

<pre><code class="language-c">typedef struct rax {    
     raxNode *head;     //指向头节点的指针
     uint64_t numele;     //key的个数
     uint64_t numnodes; //节点个数
} rax;

typedef struct raxNode {     
    uint32_t iskey:1;   /* 当前节点是否包含一个key，占用1bit*/     
    uint32_t isnull:1;  /* 当前key对应的value是否为空，占用1bit */     
    uint32_t iscompr:1; /* 当前节点是否为压缩节点，占用1bit */     
    uint32_t size:29;   /* 压缩节点压缩的字符串长度或者非压缩节点的子节点个数，占用29bit */
    unsigned char data[];  /*包含填充字段，同时存储了当前节点包含的字符串以及子节点的指针、key对应的value指针。*/
} raxNode;
</code></pre>

<p>raxNode分为2类，压缩节点和非压缩节点</p>

<ul>
<li>压缩节点 。我们假设该节点存储的内容为字符串ABC
<figure><img src="media/15938782048225/15939314326955.jpg" alt=""/></figure>
<ul>
<li>·iskey为1且isnull为0时，value-ptr存在，否则value-ptr不存在；</li>
<li>·iscompr为1代表当前节点是压缩节点，size为3代表存储了3个字符；</li>
<li>紧随size的是该节点存储的字符串，根据字符串的长度确定是否需要填充字段（填充必要的字节，使得后面的指针地址放到合适的位置上）；</li>
<li>由于是压缩字段，故而只有最后一个字符有子节点。</li>
</ul></li>
<li>非压缩节点 。我们假设其内容为XY
<figure><img src="media/15938782048225/15939394205610.jpg" alt=""/></figure>
每个字符都有一个子节点，值得一提的是，字符个数小于2时，都是非压缩节点。</li>
</ul>

<h2 id="toc_3">2、stream 结构</h2>

<p>Redis Stream的实现依赖于Rax结构以及listpack结构，每个消息的具体信息存储在这个listpack中。Rax用于快速索引；listpack用于存储具体的消息</p>

<p>每个listpack都有一个master entry，该结构中存储了创建这个listpack时待插入消息的所有field，这主要是考虑同一个消息流，消息内容通常具有相似性，如果后续消息的field与master entry内容相同，则不需要再存储其field。</p>

<p>每个listpack中可能存储多条消息</p>

<p><figure><img src="media/15938782048225/15939395823945.jpg" alt="Stream结构"/><figcaption>Stream结构</figcaption></figure></p>

<p>Stream结构如下</p>

<pre><code class="language-c">/*
*每个Stream会有多个消费组，每个消费组通过组名称进行唯一标识，
*同时关联一个streamCG结构，
*/
typedef struct stream {     
   /*
   存储消息生产者生产的具体消息，每个消息有唯一的ID。
   以消息ID为键，消息内容为值存储在rax中，
   值得注意的是，rax中的一个节点可能存储多个消息， 
   */     
    rax *rax;             
    /*当前stream中的消息个数（不包括已经删除的消息）*/
    uint64_t length;     
    /*当前stream中最后插入的消息的ID，stream为空时，设置为0*/   
    streamID last_id;
    /*存储了当前stream相关的消费组，以消费组的组名为键，streamCG为值存储在rax中*/
    rax *cgroups;
} stream;

/*消费组结构定义*/
typedef struct streamCG {
    /*last_id为该消费组已经确认的最后一个消息的ID*/
    streamID last_id; 
    /*该消费组尚未确认的消息，并以消息ID为键，streamNACK（代表一个尚未确认的消息）为值*/
    rax *pel;
    /*为该消费组中所有的消费者，并以消费者的名称为键，streamConsumer（代表一个消费者）为值。*/
    rax *consumers; 
} streamCG;

/*消费者，每个消费者通过streamConsumer唯一标识*/
typedef struct streamConsumer {     
    mstime_t seen_time;     //该消费者最后一次活跃的时间
    sds name;     //消费者的名称
    rax *pel;   //该消费者尚未确认的消息，以消息ID为键，streamNACK 为值。
} streamConsumer;


/*未确认消息，维护了消费组或者消费者尚未确认的消息，
值得注意的是，消费组中的pel的元素与每个消费者的pel中的元素是共享的，
即该消费组消费了某个消息，这个消息会同时放到消费组以及该消费者的pel队列中，并且二者是同一个streamNACK结构。*/
typedef struct streamNACK {     
    mstime_t delivery_time;     //该消息最后发送给消费方的时间
    uint64_t delivery_count;     //该消息已经发送的次数
    streamConsumer *consumer;  //该消息当前归属的消费者。
} streamNACK;
</code></pre>

<hr/>

<h2 id="toc_4">3、Stream 命令</h2>

<h3 id="toc_5">xadd 命令</h3>

<p>将指定消息数据追加到指定的Stream队列中或裁减列中数据长度。</p>

<pre><code class="language-bash">xadd key [MAXLEN [~|=] &lt;count&gt;] &lt;ID or *&gt; [field value] [field value] ...
</code></pre>

<p>每条消息由一或多个阈值对组成，消息插入Stream队列中后会返回唯一的消息ID。xadd是唯一可以向Stream队列添加数据的命令</p>

<ul>
<li>MAXLEN<br/>
当Stream中数据量过大时，可通过此关键字来裁剪长度，删除stream中旧数据至指定的值；当数据量小于等于指定值时，不进行剪切。其中裁剪模式有两种。
<ul>
<li>~：模糊裁剪，优化精确裁剪，一般用此模式，效率更高。</li>
<li>=：精确裁剪，我们知道，在数据存储的listpack结构体中，裁剪长度的所有阈值是依照数据从老到新的方式，依次把listpack释放掉，但在此模式下，删除最后一个listpack中的数据比较费时，所以推荐用模糊裁剪。</li>
</ul></li>
<li>ID：添加消息可指定具体值或用 <code>*</code>代替，<strong>指定的值必须大于当前Stream队列中最大的消息ID</strong>，为<code>*</code>时则默认生成一个最新的ID，ID值取的是当前时间+序列号。</li>
</ul>

<pre><code class="language-shell"># 添加一条数据，使用系统生成的最新ID
&gt; xadd mystream * name doubi age 18
1593943429128-0
# 如果发现添加新元素后的Stream有超过100W+条消息，则删除旧消息，使长度大约缩减至100W个元素
&gt; xadd mystream MAXLEN ~ 1000000 * name tim age 29
</code></pre>

<h3 id="toc_6">xrange命令</h3>

<p>读取给定ID范围内的消息数据，并可以设置返回数据的条数。</p>

<pre><code class="language-shell">&gt; xrange key start end [COUNT count]
</code></pre>

<p>范围起始值分别由start和end字段指定，将返回两个ID之间（闭区间）的所有消息，消息排序为ID递增排序。</p>

<ul>
<li>start: 开始消息ID，指定具体值或通过“-”特殊符号来表示最小ID。</li>
<li>end：结束消息ID，指定具体值或通过“+”特殊符号来表示最大ID。</li>
<li>COUNT：设定返回的消息数量</li>
</ul>

<pre><code class="language-text">127.0.0.1:6379&gt; xrange mystream - + count 2
1) 1) &quot;1593943573938-0&quot;
   2) 1) &quot;name&quot;
      2) &quot;doubi&quot;
      3) &quot;age&quot;
      4) &quot;18&quot;
2) 1) &quot;1593957391373-0&quot;
   2) 1) &quot;name&quot;
      2) &quot;doubi1&quot;
      3) &quot;age&quot;
      4) &quot;19&quot;
</code></pre>

<h3 id="toc_7">xrevrange命令</h3>

<p>xrevrange命令与xrange用法完全一致，唯一区别是返回数据的顺序为消息ID的递减序，正好与xrange返回的数据顺序相反。</p>

<h3 id="toc_8">xdel 命令</h3>

<p>用于删除Stream队列中指定的一或多个消息ID对应的数据。</p>

<pre><code class="language-text">xdel key ID [ID ...]
</code></pre>

<p>key 类型必须为OBJ_STREAM，否则报错。</p>

<h3 id="toc_9">xgroup 命令</h3>

<p>用于队列的消费组管理，包含对消费组的创建、删除、修改等操作。</p>

<pre><code class="language-text">xgroup [CREATE key groupname id-or-$]  [SETID key id-or-$]        [DESTROY key groupname]  [DELCONSUMER key groupname consumername] [HELP]
</code></pre>

<ul>
<li>CREATE：创建一个新消费组。</li>
<li>SETID：修改某个消费组消费的消息last_id。</li>
<li>DESTROY：删除指定消费组。</li>
<li>DELCONSUMER：删除指定消费组中某个消费者。</li>
<li>HELP：查看使用帮助。</li>
</ul>

<pre><code class="language-shell"># 创建一个消费组mmp，从消息id为1593943573938-0的消息开始消费
127.0.0.1:6379&gt; xgroup CREATE mystream mmp 1593943573938-0
OK
</code></pre>

<p>最后一个参数是指定该消费组开始消费的消息ID，其中“0”或“0- 0”，表示从头开始消费，如果使用特殊符“$”，则表示队列中最后一项ID，只读取消息队列中新到的消息。</p>

<h3 id="toc_10">xreadgroup 命令</h3>

<p>用于从消费组中可靠地消费n条消息，如果指定的消费者不存在，则创建之。</p>

<pre><code class="language-text">XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] ID [ID ...]
</code></pre>

<ul>
<li>group：消费组名称</li>
<li>consumer：消费者名称。</li>
<li>COUNT：消费多少条数据。</li>
<li>BLOCK：是否为阻塞模式，milliseconds为阻塞多少毫秒</li>
<li>STREAMS：Stream队列名称，可指定多个。若指定多个，则ID 也要对应指定相同个数。</li>
<li>ID：读取只大于指定消息ID后未确认的消息；特殊符号“&gt;”，读取未传递给其他任何消费者的消息，也就是新消息。</li>
<li>NOACK：该消息不需要确认。</li>
</ul>

<p>客户端必须使用XACK确认消息处理，以便从待处理条目列表中删除待处理条目。可以使用XPENDING命令检查待处理条目列表。</p>

<h3 id="toc_11">xread 命令</h3>

<p>用于从Stream队列中读取N条消息，一般用作遍历队列中的消息。</p>

<p>从一个或者多个流中读取数据，仅返回ID大于调用者报告的最后接收ID的条目。此命令有一个阻塞选项，用于等待可用的项目，类似于BRPOP或者BZPOPMIN等等。</p>

<pre><code class="language-text">XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] ID [ID ...]
</code></pre>

<ul>
<li>COUNT: 读取多少条数据</li>
<li>BLOCK：是否为阻塞模式，milliseconds为阻塞多少毫秒</li>
<li>STREAMS：Stream队列名称</li>
<li>ID：指定从哪个消息ID开始读取，也就是消息ID大于指定的ID 的消息，可为“$”特殊符号，代表从最后一条开始读取。</li>
</ul>

<p>此命令读取消息后无须通过XACK确认，也不需要强制指定消费组名称与消费者名称</p>

<h3 id="toc_12">xacx 命令</h3>

<p>xack命令用于确认一或多个指定ID的消息，使其从待确认列表中删除。</p>

<pre><code class="language-text">xack key groupName ID [ID ...]
</code></pre>

<ul>
<li>group：消费组名称；</li>
<li>ID：确认的消息ID。</li>
</ul>

<pre><code class="language-shell">127.0.0.1:6379&gt; xack mystream mmp 1593957391373-0 1593943573938-0
(integer) 1
</code></pre>

<h3 id="toc_13">xpending 命令</h3>

<p>xpending命令用于读取某消费组或者某个消费者的未确认消息，返回未确认的消息ID、空闲时间、被读取次数。</p>

<pre><code class="language-text">xpending key group [start end count] [consumer]
</code></pre>

<p>group：指定的消费组；·start：范围开始ID，可以为特殊符“-”表示开始或指定ID；·end：范围结束ID，可以为特殊符“+”标识结尾或指定ID；·count：读取条数；·consumer：指定的消费者。</p>

<p>读取消费组cg1中消费者c1的所有待确认消息。</p>

<pre><code class="language-shell">127.0.0.1:6379&gt; xadd mystream * name doubi1 age 19
&quot;1593962280326-0&quot;
127.0.0.1:6379&gt; XREADGROUP GROUP mmp c1 COUNT 2 STREAMS mystream &gt;
1) 1) &quot;mystream&quot;
   2) 1) 1) &quot;1593962280326-0&quot;
         2) 1) &quot;name&quot;
            2) &quot;doubi1&quot;
            3) &quot;age&quot;
            4) &quot;19&quot;
127.0.0.1:6379&gt; xpending mystream mmp - + 2 c1
1) 1) &quot;1593962280326-0&quot;
   2) &quot;c1&quot;
   3) (integer) 3616  # 间隔多长时间没有确认
   4) (integer) 1
</code></pre>

<h3 id="toc_14">xinfo命令</h3>

<p>用于读取消息队列、消费组、消费者等的信息。</p>

<pre><code class="language-text">xinfo [CONSUMERS key groupname] [GROUPS key] [STREAM key] [HELP]
</code></pre>

<p>CONSUMERS：用于查看某个消费组下的消费者信息；·GROUPS：用于查看某个Stream队列下的消费组信息；·STREAM：用于查看某个Stream队列的整体组信息</p>

<pre><code class="language-shell"># 查看消费组c1中消费者消费信息：
127.0.0.1:6379&gt; xinfo consumers mystream mmp
1) 1) &quot;name&quot;
   2) &quot;c1&quot;
   3) &quot;pending&quot;
   4) (integer) 0
   5) &quot;idle&quot;
   6) (integer) 238485
   
   
   # 查看Stream队列信息
   127.0.0.1:6379&gt; xinfo stream mystream
 1) &quot;length&quot;
 2) (integer) 3
 3) &quot;radix-tree-keys&quot;
 4) (integer) 1
 5) &quot;radix-tree-nodes&quot;
 6) (integer) 2
 7) &quot;groups&quot;
 8) (integer) 1
 9) &quot;last-generated-id&quot;
10) &quot;1593962280326-0&quot;
11) &quot;first-entry&quot;
12) 1) &quot;1593961742431-0&quot;
    2) 1) &quot;name&quot;
       2) &quot;doubi&quot;
       3) &quot;age&quot;
       4) &quot;18&quot;
13) &quot;last-entry&quot;
14) 1) &quot;1593962280326-0&quot;
    2) 1) &quot;name&quot;
       2) &quot;doubi1&quot;
       3) &quot;age&quot;
       4) &quot;19&quot;
</code></pre>

<h3 id="toc_15">xlen 命令</h3>

<p>用于获取Stream队列的数据长度</p>

<pre><code class="language-text">xlen key ID [ID ...]
</code></pre>

<pre><code class="language-text">127.0.0.1:6379&gt; xlen mystream
(integer) 3
</code></pre>

<h3 id="toc_16">xtrim 命令</h3>

<p>缩减消息队列。</p>

<pre><code class="language-text">xtrim key MAXLEN [~] count
</code></pre>

<p>参照  xadd 命令</p>

<h3 id="toc_17">xclaim命令</h3>

<p>改变一或多个未确认消息的所有权，新的所有者是在命令参数中指定。</p>

<pre><code class="language-text">XCLAIM  key group consumer min-idle-time ID [ID ...] [IDLE ms] [TIME ms-unix-time] [RETRYCOUNT count] [FORCE] [JUSTID]
</code></pre>

<ul>
<li>consumer：指定新的消费者</li>
<li>min-idle-time：指定消息最小空闲数；</li>
<li>ID：指定消息ID；</li>
<li>IDLE <ms>: 设置消息的空闲时间（自最后一次交付到目前的时间）。如果没有指定IDLE，则假设IDLE值为0，即时间计数被重置，因为消息现在有新的所有者来尝试处理它。</li>
<li>TIME <ms-unix-time>: 这个命令与IDLE相同，但它不是设置相对的毫秒数，而是将空闲时间设置为一个指定的Unix时间（以毫秒为单位）。这对于重写生成XCLAIM命令的AOF文件很有用。</li>
<li>RETRYCOUNT <count>: 将重试计数器设置为指定的值。这个计数器在每一次消息被交付的时候递增。通常，XCLAIM不会更改这个计数器，它只在调用XPENDING命令时提供给客户端：这样客户端可以检测到异常，例如在大量传递尝试后由于某种原因从未处理过的消息。</li>
<li>FORCE: 在待处理条目列表（PEL）中创建待处理消息条目，即使某些指定的ID尚未在分配给不同客户端的待处理条目列表（PEL）中。但是消息必须存在于流中，否则不存在的消息ID将会被忽略。</li>
<li>JUSTID: 只返回成功认领的消息ID数组，不返回实际的消息。</li>
</ul>

<p>在流的消费者组上下文中，此命令改变待处理消息的所有权， 因此新的所有者是在命令参数中指定的消费者。通常是这样的：</p>

<ul>
<li>假设有一个具有关联消费者组的流。</li>
<li>某个消费者A在消费者组的上下文中通过XREADGROUP从流中读取一条消息。</li>
<li>作为读取消息的副作用，消费者组的待处理条目列表（PEL）中创建了一个待处理消息条目：这意味着这条消息已传递给给定的消费者，但是尚未通过XACK确认。</li>
<li>突然这个消费者出现故障，且永远无法恢复。</li>
<li>其他消费者可以使用XPENDING检查已经过时很长时间的待处理消息列表，为了继续处理这些消息，他们使用XCLAIM来获得消息的所有权，并继续处理。</li>
</ul>

]]></content>
  </entry>
  
</feed>
