<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大爷来玩儿啊~]]></title>
  <link href="http://www.throne4j.com/atom.xml" rel="self"/>
  <link href="http://www.throne4j.com/"/>
  <updated>2020-12-04T07:55:27+08:00</updated>
  <id>http://www.throne4j.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[todo]]></title>
    <link href="http://www.throne4j.com/16069200648740.html"/>
    <updated>2020-12-02T22:41:04+08:00</updated>
    <id>http://www.throne4j.com/16069200648740.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[原生 NIO 非阻塞通信]]></title>
    <link href="http://www.throne4j.com/16068260624844.html"/>
    <updated>2020-12-01T20:34:22+08:00</updated>
    <id>http://www.throne4j.com/16068260624844.html</id>
    <content type="html"><![CDATA[
<p>java.nio 包提供了非阻塞的通信能力</p>

<h2 id="toc_0">线程阻塞的概念</h2>

<p>所有处于阻塞状态的线程的共同特征是：放弃 CPU ,暂停运行，只有等到导致阻塞的原因消除，才能恢复运行；或者被其他线程中断，该线程退出阻塞状态，并且抛出 InterruptedException异常</p>

<h2 id="toc_1">线程阻塞的原因</h2>

<ul>
<li>线程执行了 Thread.sleep(int n) 方法，线程放弃 CPU ，睡眠 n 毫秒之后，恢复运行。</li>
<li>线程无法获取要执行代码的同步锁，进入阻塞状态</li>
<li>线程执行一个对象的 wait()方法，进入阻塞状态，直至其他线程唤醒该对象</li>
<li>线程执行 IO 操作或进行远程通信时，会因为等待相关资源进入阻塞状态</li>
<li>请求与服务器建立连接时会进入阻塞状态</li>
<li>线程从 socket 的输入流读取数据时，没有足够的数据，就会进入阻塞状态，直到读到了足够欧的数据，或者到达输入流的末尾，或出现异常，才会从输入流的 read()方法返回或者中断</li>
<li>线程向 socket 的输出流写数据时，肯能会进入阻塞状态</li>
<li>调用 socket 的 setSoLinger()方法设置了关闭 Socket 的延迟时间，那么线程执行 socket 的 close() 方法时，会进入阻塞状态</li>
</ul>

<p>服务器程序中线程遇到如下情况可能会进入阻塞状态</p>

<ul>
<li>线程执行 ServerSocket 的 accept()方法，等待客户的连接，直到接收到了客户的连接才从 accept()方法返回</li>
<li>线程从 socket 的输入流读入数据时，可能会进入阻塞状态</li>
<li>线程向 socket 的输出流写数据时，可能会进入阻塞状态</li>
</ul>

<h2 id="toc_2">服务器程序用多线程来处理阻塞通信的局限性</h2>

<p><figure><img src="media/16068260624844/16069196524116.jpg" alt="" style="width:733px;"/></figure></p>

<ul>
<li>JVM 会为每个线程分配独立的堆栈空间，工作线程数目越多，系统开销越大，而且增加了 JVM 调度线程的负担，增加了线程之间同步的复杂性，提高了线程死锁的可能性</li>
<li>工作线程的许多时间都浪费在阻塞IO操作上，JVM 需要频繁的转让 CPU 的使用权，使进入阻塞状态的线程放弃 CPU，再把 CPU 分配给处于可运行状态的线程。</li>
</ul>

<p>因此，工作线程并不是越多越好，适量的工作线程会提高服务器的并发能力，但是超出了系统的负荷时，反而降低并发性能。</p>

<h2 id="toc_3">和 BIO 的主要区别</h2>

<p>Java NIO 和 IO 之间第一个最大的区别是，IO 是面向流的，NIO 是面向缓冲区的。 Java IO 面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地 方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它 缓存到一个缓冲区。 Java NIO 的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓 冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查 是否该缓冲区中包含所有需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。</p>

<h2 id="toc_4">NIO 组件</h2>

<h3 id="toc_5">Channel</h3>

<p>通道 channel 用来连接缓冲区与数据源</p>

<p>java.nio.channels.Channel接口只声明了两个方法</p>

<ul>
<li>isOpen() 判断通道是否打开</li>
<li>close() 关闭通道</li>
</ul>

<h4 id="toc_6">SelectableChannel</h4>

<p>SelectableChannel 支持阻塞IO、非阻塞IO，他有两个子类：</p>

<ul>
<li>ServerSocketChannel: 相当于 ServerSocket 的替代类，支持阻塞通信和非阻塞通信,通过 ServerSocketChannel.open()创建</li>
<li>SocketChannel : 相当于 Socket 的替代类，支持阻塞通信和非阻塞通信，通过 SocketChannel.open()创建</li>
</ul>

<p>SelectableChannel可以向 Selector 注册读就绪和写就绪事件。<br/>
Selector负责监控这些事件，等到事件发生时，SelectableChannel就可以执行相应的操作，比如读事件或写事件。</p>

<p>主要方法：</p>

<ul>
<li>configureBlocking(boolean block) block 为 true表示 阻塞模式，false非阻塞模式，默认阻塞模式，isBlocking()方法返回它的阻塞模式</li>
<li>SelectionKey register(Selector sel, int ops)</li>
<li>SelectionKey register(Selector sel, int ops, Object attachment)<br/>
向Selector注册事件;ops: 感兴趣的事件，见 SelectionKey; attachment用于为SelectionKey关联一个附件，当被注册事件发生后，需要处理该事件时，可以从SelectionKey中获得这个附件，该附件可用来包含与处理这个事件相关的信息。</li>
</ul>

<pre><code class="language-text">MyHandler handler = new MyHandler();
SelectionKey key = socketChannel.register(selector, SelectionKey.OP_READ, handler);

之后 可以从SelectionKey中获取 handler,然后执行handler相关处理方法 ：

MyHandler handler =  (MyHandler) key.attachment()
</code></pre>

<h4 id="toc_7">ServerSocketChannel 只可能发生一种事件</h4>

<ul>
<li>SelectionKey.OP_ACCEPT: 接收连接就绪事件，表示至少有了一个客户连接，服务器可以接收这个连接</li>
</ul>

<h4 id="toc_8">SocketChannel 可能发生 3 中事件</h4>

<ul>
<li>SelectionKey.OP_CONNECT: 连接就绪事件，表示客户端与服务器的连接已经建立成功</li>
<li>SelectionKey.OP_READ: 度就绪事件，表示输入流中已经有了可读数据，可以执行读操作了</li>
<li>SelectionKey.OP_WRITE: 写就绪事件，表示已经可以向输出流写数据了。</li>
</ul>

<p>SocketChannel提供了 读和写数据的方法</p>

<ul>
<li>read(ByteBuffer buffer): 读数据，把他们放到参数指定的 ByteBuffer中</li>
<li>write(ByteBuffer buffer): 把参数指定的ByteBuffer中的数据发送出去</li>
</ul>

<h4 id="toc_9">服务端和客户端可以监听的事件表：</h4>

<table>
<thead>
<tr>
<th>CHANNEL</th>
<th>OP_READ</th>
<th>OP_WRITE</th>
<th>OP_CONNECT</th>
<th>OP_ACCEPT</th>
</tr>
</thead>

<tbody>
<tr>
<td>服务器ServerSocketChannel</td>
<td></td>
<td></td>
<td></td>
<td>Y</td>
</tr>
<tr>
<td>服务器SocketChannel</td>
<td>Y</td>
<td>Y</td>
<td></td>
<td></td>
</tr>
<tr>
<td>客户端SocketChannel</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
<td></td>
</tr>
</tbody>
</table>

<h3 id="toc_10">Selector</h3>

<p>Selector 的英文含义是“选择器”，也可以称为为“轮询代理器”、“事件订阅器”、“channel 容器管理机”都行。</p>

<p>为 ServerSocketChannel 监控接收连接就绪事件，为 SocketChannel 监控连接就绪、写就绪、读就绪事件。</p>

<p>一个Selector对象会包含 3中类型 SelectionKey集合：</p>

<ul>
<li>all-keys: 当前所有向 Selector 注册的 SelectionKey 的集合， Selector 的 keys() 方法返回该集合</li>
<li>selected-keys: 相关事件已经被 Selector 捕获的 SelectionKey 的集合，Selector的 selectedKeys()方法返回该集合</li>
<li>cancelled-keys: 已经被取消的 SelectionKey 集合，暂无访问该集合的方法。</li>
</ul>

<p>执行 Selector 的 select() 方法时，与 SelectionKey 相关的事件发生了，这个 SelectionKey 就被加入到 selected-keys 集合中。</p>

<p>主要方法：</p>

<ul>
<li>static Selector open() 创建 Selector对象</li>
<li>isOpen() 是否处于打开状态，创建 Selector 之后就处于打开状态，直到 执行close()方法</li>
<li>Set<SelectionKey> keys() 返回 all-keys集合</li>
<li>int selectNow() 返回相关事件已经发生的 SelectionKey 对象数目</li>
<li>int select() 或 int select(long timeout) 返回相关事件已经发生的SelectionKey对象的数目，如果一个都没有进入阻塞状态，直到出现以下情况之一：
<ul>
<li>至少有一个 SelectionKey 的相关事件已经发生</li>
<li>其他线程调用了 Selector 的 wakeup()方法，导致执行 select()方法的线程立即从 select()方法中返回</li>
<li>当执行 sselect()方法的线程被其他线程中断</li>
<li>超出了等待时间</li>
</ul></li>
<li>Selector wakeup() 唤醒执行 Selector 的 select()方法的线程</li>
<li>close() 关闭 Selector，使它占用的所有资源都被释放，所有与Selector 关联的 SelectionKey 都被取消</li>
</ul>

<h3 id="toc_11">SelectionKey</h3>

<p>代表 SocketChannel、ServerSocketChannel向 Selector 注册事件的句柄，包括接收连接就绪事件、连接就绪事件、读事件就绪、写事件就绪</p>

<ul>
<li>OP_READ : 当操作系统读缓冲区有数据可读时就绪。并非时刻都有数据可读，所 以一般需要注册该操作，仅当有就绪时才发起读操作，有的放矢，避免浪 费 CPU。</li>
<li>OP_WRITE : 当操作系统写缓冲区有空闲空间时就绪。一般情况下写缓冲区都有空 闲空间，小块数据直接写入即可，没必要注册该操作类型，否则该条件不 断就绪浪费 CPU;但如果是写密集型的任务，比如文件下载等，缓冲区很 可能满，注册该操作类型就很有必要，同时注意写完后取消注册。</li>
<li>OP_CONNECT : 当 SocketChannel.connect()请求连接成功后就绪。该操作只给客户端 使用。</li>
<li>OP_ACCEPT : 当接收到一个客户端连接请求时就绪。该操作只给服务器使用。</li>
</ul>

<p>以下情况下 SelectionKey 对象会失效：</p>

<ul>
<li>程序调用 SelectionKey 的 cancel() 方法</li>
<li>关闭 与 SelectionKey 关联的 Channel</li>
<li>与 SelectionKey 关联的 selector 被关闭</li>
</ul>

<p>主要方法：</p>

<ul>
<li>SelectableChannel channel() </li>
<li>Selector selector()</li>
<li>boolean isValid()</li>
<li>void cancel()</li>
<li>int interestOps()</li>
<li>SelectionKey interestOps(int ops)</li>
<li>boolean isReadable()</li>
<li>boolean isWritable()</li>
<li>boolean isConnectable()</li>
<li>boolean isAcceptable()</li>
<li>attach(Object obj)</li>
<li>Object attachment()</li>
</ul>

<h3 id="toc_12">缓冲区 buffer</h3>

<p>缓冲区从两个方面提高 IO 效能 ：</p>

<ul>
<li>减少实际的物理读写次数</li>
<li>缓冲区在创建的时候被分配内存，这块缓冲区一直被重用，减少了动态分配内存和回收内存的次数。</li>
</ul>

<p>以下是Buffer 类的层次结构</p>

<pre><code class="language-text">Buffer (java.nio)
|---IntBuffer (java.nio)
|---FloatBuffer (java.nio)
|---CharBuffer (java.nio)
|---DoubleBuffer (java.nio)
|---ShortBuffer (java.nio)
|---LongBuffer (java.nio)
|---ByteBuffer (java.nio)
</code></pre>

<p>所有的缓冲区都由以下属性</p>

<ul>
<li>容量 capacity: 表示该缓冲区可以保存多少数据</li>
<li>极限 limit: 表示缓冲区当前的终点，不能对缓冲区中超过极限的区域进行读写操作。极限是可以修改的，这有利于缓冲区的重用。</li>
<li>位置 position: 表示缓冲区中下一个读写单元的位置，每次读写缓冲区的数据时，都会改变该值，为下一次读写数据做准备</li>
</ul>

<p>以上三个属性的关系为 容量 &gt;= 极限 &gt;= 位置 &gt;= 0</p>

<p>Buffer 提供了用于改变以上 3 个属性的方法：</p>

<ul>
<li>clear()  把极限设为容量，再把位置设为 0</li>
<li>flip()  把极限设置为位置，再把位置设置为 0</li>
<li>rewind() 不改变极限，把位置设为 0</li>
</ul>

<p>Buffer类的其他方法：</p>

<ul>
<li>remaining()方法返回缓冲区的剩余容量 = 极限 - 位置</li>
<li>compact() 删除缓冲区内 从 0 到当前位置 position 的内容，然后把从当前位置 position 到极限 limit 的内容复制到 0 到 limit - position的区域内，当前位置 position 和 极限 limit 的取值也作相应的变化。</li>
<li>get() 相对读数据，从当前位置读取一个单元的数据，读完后位置 +1</li>
<li>get(index) 从指定位置 index 读取一个单元的数据</li>
<li>put()</li>
<li>put(index)</li>
</ul>

<p>由于 Buffer 是一个冲向类，不能直接实例化，通过如下方式获取</p>

<ul>
<li>allocate(int capacity) 返回一个 ByteBuffer 对象，参数 capacity 指定缓冲区的容量</li>
<li>directAllocate(int capacity) 返回ByteBuffer 对象，参数 capacity 指定缓冲区的容量，推荐缓冲区较大且长期存在或者需要重用的时候，使用这种缓冲区。</li>
</ul>

<h4 id="toc_13">直接内存</h4>

<p>HeapByteBuffer 与 DirectByteBuffer，在原理上，前者可以看出分配的 buffer 是在 heap 区域的，其实真正 flush 到远程的时候会先拷贝到直接内存，再做下一步操作;在 NIO 的框 架下，很多框架会采用 DirectByteBuffer 来操作，这样分配的内存不再是在 java heap 上，经 过性能测试，可以得到非常快速的网络交互，在大量的网络交互下，一般速度会比 HeapByteBuffer 要快速好几倍。</p>

<p>直接内存(Direct Memory)并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致 OutOfMemoryError 异常出现。</p>

<p>NIO 可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里面的 DirectByteBuffer 对象作为这块内存的引用进行操作。</p>

<p>DirectByteBuffer继承自 MappedByteBuffer 能把缓冲区和文件的某个区域直接映射。</p>

<p>这样能在一些场景中显著提高性能， 因为避免了在 Java 堆和 Native 堆中来回复制数据。</p>

<h5 id="toc_14">直接内存(堆外内存)与堆内存比较</h5>

<p>直接内存申请空间耗费更高的性能，当频繁申请到一定量时尤为明显<br/>
直接内存 IO 读写的性能要优于普通的堆内存，在多次读写操作的情况下差异明显</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux 文件描述符]]></title>
    <link href="http://www.throne4j.com/16064609884543.html"/>
    <updated>2020-11-27T15:09:48+08:00</updated>
    <id>http://www.throne4j.com/16064609884543.html</id>
    <content type="html"><![CDATA[
<p>Linux 系统中，把一切都看做是文件，当进程打开现有文件或创建新文件时，内核向进程返回一个文件描述符，文件描述符就是内核为了高效管理已被打开的文件所创建的索引，其是一个非负整数（通常是小整数），用于指代被打开的文件，所有执行I/O操作的系统调用都通过文件描述符。</p>

<p>程序刚刚启动的时候，0是标准输入，1是标准输出，2是标准错误。如果此时去打开一个新的文件，它的文件描述符会是3。</p>

<p>POSIX标准要求每次打开文件时（含socket）必须使用当前进程中最小可用的文件描述符号码，因此，在网络通信过程中稍不注意就有可能造成串话。</p>

<h2 id="toc_0">文件描述符的限制</h2>

<p>在编写文件操作的或者网络通信的软件时，初学者一般可能会遇到“Too many open files”的问题。</p>

<p>这主要是因为文件描述符是系统的一个重要资源，虽然说系统内存有多少就可以打开多少的文件描述符，但是在实际实现过程中内核是会做相应的处理的，一般最大打开文件数会是系统内存的10%（以KB来计算）（称之为系统级限制）。</p>

<p>查看系统级别的最大打开文件数可以使用</p>

<p><code>&gt; sysctl -a | grep fs.file-max</code>命令查看。</p>

<p>与此同时，内核为了不让某一个进程消耗掉所有的文件资源，其也会对单个进程最大打开文件数做默认值处理（称之为用户级限制），默认值一般是1024，使用 ulimit -n命令可以查看。在Web服务器中，通过更改系统默认值文件描述符的最大值来优化服务器是最常见的方式之一。</p>

<h2 id="toc_1">文件描述符合打开文件之间的关系</h2>

<p>每一个文件文件描述符会与一个打开文件相对应，同时，不同的文件描述符也会指向同一个文件。相同的文件可以被不同的进程打开，也可以在同一个进程中被打开多次。系统为每一个进程维护了一个文件描述符表，该表的值都是从 0 开始的，所以在不同的进程中你看到相同的文件描述符，这种情况下，相同文件描述符有可能指向同一个文件，也有可能指向不同的文件。</p>

<p>具体情况要具体分析，要理解具体概况如何，需要查看3个数据结构：</p>

<ul>
<li>进程级别的文件描述符表</li>
<li>系统级别的打开文件描述符表</li>
<li>文件系统的 i-node 表</li>
</ul>

<p>进程级别的文件描述符表的每一条目记录了单个文件描述符的相关信息：</p>

<ul>
<li>控制文件描述符从操作的一组标识（目前此类标志仅仅定义了一个：close-on-exec标志）</li>
<li>对打开文件句柄的引用</li>
</ul>

<p>内核对所有打开的文件的文件维护有一个系统级的描述符表格（open file description table）。有时，也称之为打开文件表（open file table），并将表格中各条目称为打开文件句柄（open file handle）。一个打开文件句柄存储了与一个打开文件相关的全部信息，如下所示：</p>

<ul>
<li>当前文件偏移量（调用read()和write()时更新，或使用lseek()直接修改）</li>
<li>打开文件时所使用的状态标识（即，open()的flags参数）</li>
<li>文件访问模式（如调用open()时所设置的只读模式、只写模式或读写模式）</li>
<li>与信号驱动相关的设置</li>
<li>对该文件i-node对象的引用</li>
<li>文件类型（例如：常规文件、套接字或FIFO）和访问权限</li>
<li>一个指针，指向该文件所持有的锁列表</li>
<li>文件的各种属性，包括文件大小以及与不同类型操作相关的时间戳</li>
</ul>

<p><figure><img src="media/16064609884543/16064916468169.jpg" alt=""/></figure></p>

<p>在进程A中，文件描述符1和30都指向了同一个打开的文件句柄（标号23）。这可能是通过调用dup()、dup2()、fcntl()或者对同一个文件多次调用了open()函数而形成的。</p>

<p>进程A的文件描述符2和进程B的文件描述符2都指向了同一个打开的文件句柄（标号73）。这种情形可能是在调用fork()后出现的（即，进程A、B是父子进程关系），或者当某进程通过UNIX域套接字将一个打开的文件描述符传递给另一个进程时，也会发生。再者是不同的进程独自去调用open函数打开了同一个文件，此时进程内部的描述符正好分配到与其他进程打开该文件的描述符一样。</p>

<p>此外，进程A的描述符0和进程B的描述符3分别指向不同的打开文件句柄，但这些句柄均指向i-node表的相同条目（1976），换言之，指向同一个文件。发生这种情况是因为每个进程各自对同一个文件发起了open()调用。同一个进程两次打开同一个文件，也会发生类似情况。</p>

<h2 id="toc_2">inode</h2>

<p>文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。</p>

<p>操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。</p>

<p>文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。</p>

<h3 id="toc_3">inode的内容</h3>

<p>inode包含文件的元信息，具体来说有以下内容：</p>

<ul>
<li>文件的字节数</li>
<li>文件拥有者的 user id</li>
<li>文件的 group id</li>
<li>文件的读、写、执行权限</li>
<li>文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。</li>
<li>链接数，即有多少文件名指向这个inode</li>
<li>文件数据block的位置</li>
</ul>

<p>可以用 stat 命令，查看某个文件的inode信息：</p>

<pre><code class="language-text">Documents stat MySql性能优化.itmz
16777221 20069263 -rw-r--r-- 1 qinshengke staff 0 56688 &quot;Nov 22 17:58:39 2020&quot; &quot;Oct  8 22:59:08 2020&quot; &quot;Nov 25 21:16:16 2020&quot; &quot;Oct  8 22:59:08 2020&quot; 4096 112 0x40 MySql性能优化.itmz
</code></pre>

<h3 id="toc_4">inode 大小</h3>

<p>inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。</p>

<p>每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。</p>

<p>查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。</p>

<pre><code class="language-text">Documents df -i
Filesystem     512-blocks      Used Available Capacity iused      ifree %iused  Mounted on
/dev/disk1s5s1  489620264  29178328 279123384    10%  563932 2447537388    0%   /
devfs                 689       689         0   100%    1192          0  100%   /dev
/dev/disk1s4    489620264   4194344 279123384     2%       2 2448101318    0%   /System/Volumes/VM
/dev/disk1s2    489620264    559648 279123384     1%     788 2448100532    0%   /System/Volumes/Preboot
/dev/disk1s6    489620264       512 279123384     1%      14 2448101306    0%   /System/Volumes/Update
/dev/disk1s1    489620264 175013440 279123384    39%  915827 2447185493    0%   /System/Volumes/Data
map auto_home           0         0         0   100%       0          0  100%   /System/Volumes/Data/home
/dev/disk2s2    976066560 760332288 215734272    78% 2970048     842712   78%   /Volumes/QSK
/dev/disk3s2      3366848   2497576    869272    75%    4547 4294962732    0%   /Volumes/VMware Fusion 12.1.0 for Mac
</code></pre>

<p>查看每个inode节点的大小，可以用如下命令：</p>

<p>sudo dumpe2fs -h /dev/hda | grep &quot;Inode size&quot;</p>

<p>由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。</p>

<h3 id="toc_5">inode 号码</h3>

<p>每个inode都有一个号码，操作系统用inode号码来识别不同的文件。</p>

<p>这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。</p>

<p>表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。</p>

<p>使用ls -i命令，可以看到文件名对应的inode号码</p>

<h3 id="toc_6">inode的特殊作用</h3>

<p>由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。</p>

<ul>
<li>有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。</li>
<li>移动文件或重命名文件，只是改变文件名，不影响inode号码。</li>
<li>打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Netty入门]]></title>
    <link href="http://www.throne4j.com/16063167790102.html"/>
    <updated>2020-11-25T23:06:19+08:00</updated>
    <id>http://www.throne4j.com/16063167790102.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Netty是什么？</h2>

<p>Netty 是JBOSS 提供的一个java开源框架，它提供异步的、事件驱动的网络应用程序和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。</p>

<h2 id="toc_1">为什么使用Netty</h2>

<p>有以下几点致使我们去使用 Netty：</p>

<ul>
<li>JAVA NIO 异步框架虽然提供了多路复用 IO 的支持，但是没有提供上层的 “信息格式” 的封装。例如JAVA NIO没有提供针对JSON、protocol这些信息的封装。</li>
<li>NIO的类库和API比较复杂，学习成本很高，需要熟练的掌握 Selector、ByteBuffer、ServerSocketChannel、SocketChannel等组件，要能正常使用 NIO 需要了解 NIO涉及到的 Reactor线程模型、多线程、网络编程等技能的支持。</li>
<li>要编写一个可靠的、已维护的、高可用的NIO服务器应用，除了框架本身要兼容实现各类操作系统之外，更重要的是它还要处理很多长层特有的服务，例如客户端权限、信息格式的封装、数据读取、断线重连、半包读写、心跳机制等，这些是 Netty 提供了相应的支持。</li>
<li>JAVA NIO 框架存在一个 poll/epoll 的bug： Selector 不能在 Selector.select(timeout) 上 阻塞，这也就意味着CPU资源占用率会达到 100%（linux内核上，JDK1.7 以及之前的版本会重现）</li>
</ul>

<h2 id="toc_2">Netty 为什么要使用 NIO 而不是 AIO</h2>

<p>Netty 不看重 Windows 上的使用，在 Linux 系统上，AIO 的底层实现仍使用 EPOLL，没有很好实现 AIO，因此在性能上没有明显的优势，而且被 JDK 封装了一层不容易深度优化。</p>

<p>AIO 还有个缺点是接收数据需要预先分配缓存, 而不是 NIO 那种需要接收时才需要分配缓存, 所以对连接数量非常大但流量小的情况, 内存浪费很多。</p>

<h2 id="toc_3">Netty核心组件初步了解</h2>

<ul>
<li>EventLoop、EventLoopGroup<br/>
EventLoop：可以看做是一个线程、EventLoopGroup可以看做是线程组。</li>
<li>Channel<br/>
Channel 是java NIO的一个基本组件，它代表一个实体(如硬件设备、文件、网络套接字等)的开放连接，可以将它看做是入站或出站的数据载体，可以被打开或者别关闭</li>
<li>事件和ChannelHandler、ChannelPipeline<br/>
事件: Netty事件可依据他们是入站还是出站的数据流进行划分<br/>
ChannelHandler: 处理或拦截 IO 事件，并将其转发到其ChannelPipeline下一个处理程序。<br/>
ChannelPipeline: ChannelHandler的链表容器，用于处理在该链上传播Channel入站和出站事件。</li>
<li>ChannelFuture、Promise<br/>
Netty 中所有的 I/O 操作都是异步的。这两个对象可以看作是一个异步操作的结果的占位符;它将在未来的某个时刻完成，并提供对其结果的访问</li>
</ul>

<h2 id="toc_4">EventLoop、EventLoopGroup、Channel之间的关系</h2>

<ul>
<li>EventLoopGroup包含一个或多个EventLoop</li>
<li>一个EventLoop在他的声明周期内只和一个Thread线程绑定</li>
<li>所有的EventLoop处理的 IO 事件都将在它专有的 Thread线程上被处理</li>
<li>一个Channel 在它的生命周期内只注册一个 EventLoop</li>
<li>一个EventLoop 可能被分配各个一个或多个Channel</li>
</ul>

<p>下面用图来说明他们之间的关系：<br/>
<figure><img src="media/16063167790102/16063195145545.jpg" alt=""/></figure></p>

<h3 id="toc_5">Channel 接口</h3>

<p>基本的 I/O 操作(bind()、connect()、read()和 write())依赖于底层网络传输所提供的原语。</p>

<p>在基于 Java 的网络编程中，其基本的构造是类 Socket。Netty 的 Channel 接口所提供 的 API，被用于所有的 I/O 操作。大大地降低了直接使用 Socket 类的复杂性。</p>

<h4 id="toc_6">Channel 生命周期</h4>

<ul>
<li>ChannelRegistered : Channel 已经被注册到了 EventLoop</li>
<li>ChannelActive : Channel 处于活动状态(已经连接到它的远程节点)。它现在可以接收和发送数据了</li>
<li>ChannelInactive : Channel 没有连接到远程节点</li>
<li>ChannelUnregistered : Channel 从 EventLoop 中取消注册</li>
</ul>

<h4 id="toc_7">Channel 接口中重要的方法</h4>

<ul>
<li>eventLoop: 返回分配给 Channel 的 EventLoop</li>
<li>pipeline: 返回分配给 Channel 的 ChannelPipeline</li>
<li>isActive: 如果 Channel 是活动的，则返回 true。活动的意义可能依赖于底层的传输。 例如，一个 Socket 传输一旦连接到了远程节点便是活动的，而一个 Datagram 传输一旦被打开便是活动的。</li>
<li>localAddress: 返回本地的 SocketAddress</li>
<li>remoteAddress: 返回远程的 SocketAddress</li>
<li>write: 将数据写到远程节点。这个数据将被传递给 ChannelPipeline，并且排队直到它被冲刷</li>
<li>flush: 将之前已写的数据冲刷到底层传输，如一个 Socket </li>
<li>writeAndFlush: 一个简便的方法，等同于调用 write()并接着调用 flush()</li>
</ul>

<h3 id="toc_8">EventLoop 和 EventLoopGroup</h3>

<p>EventLoop 定义了 Netty 的核心抽象，用于处理网络连接的生命周期中所发生的事件。<br/>
一个 EventLoop 将由一个永远都不会改变的 Thread 驱动，同时任务(Runnable 或者 Callable)可以直接提交给 EventLoop 实现，以立即执行或者调度执行。</p>

<p><figure><img src="media/16063167790102/EventLoop.jpg" alt="EventLoop"/><figcaption>EventLoop</figcaption></figure></p>

<p>根据配置和可用核心的不同，可能会创建多个 EventLoop 实例用以优化资源的使用，并 且单个 EventLoop 可能会被指派用于服务多个 Channel。</p>

<h4 id="toc_9">任务调度</h4>

<p>有时你将需要调度一个任务以便稍后(延迟)执行或者周期性地执行，常见的一个用例就是发送心跳消息到远程节点，以检查连接是否仍然还活着。如果没有响应，你便知道可以关闭该 Channel 了。</p>

<h4 id="toc_10">线程管理</h4>

<p>当提交任务到如果(当前)调用线程正是支撑 EventLoop 的线程，那么所提交 的代码块将会被(直接)执行。否则，EventLoop 将调度该任务以便稍后执行，并将它放入 到内部队列中。当 EventLoop 下次处理它的事件时，它会执行队列中的那些任务/事件。</p>

<p><figure><img src="media/16063167790102/16070090935626.jpg" alt=""/></figure></p>

<h4 id="toc_11">线程的分配</h4>

<p>服务于 Channel 的 IO 和事件的 EventLoop 则包含在 EventLoopGroup 中。</p>

<p>异步传输实现只使用了少量的 EventLoop(以及和它们相关联的 Thread)，而且在当前 的线程模型中，它们可能会被多个Channel 所共享。这使得可以通过尽可能少量的Thread 来 支撑大量的 Channel，而不是每个 Channel 分配一个 Thread。EventLoopGroup 负责为每个 新创建的 Channel 分配一个 EventLoop。</p>

<p><figure><img src="media/16063167790102/16070093180963.jpg" alt=""/></figure></p>

<p>一旦一个 Channel 被分配给一个 EventLoop，它将在它的整个生命周期中都使用这个 EventLoop(以及相关联的 Thread)。</p>

<p>这里就需要特别注意一个类了 ThreadLocal，因为一个 EventLoop 通 常会被用于支撑多个 Channel，所以对于所有相关联的 Channel 来说，ThreadLocal 都将是 一样的。这使得它对于实现状态追踪等功能来说是个糟糕的选择。然而，在一些无状态的上下文中，它仍然可以被用于在多个 Channel 之间共享一些重度的或者代价昂贵的对象，甚至是事件。</p>

<h2 id="toc_12">ChannelFuture 接口</h2>

<p>Netty 中所有的 I/O 操作都是异步的。因为一个操作可能不会立即返回，所以我们需要 一种用于在之后的某个时间点确定其结果的方法。为此，Netty 提供了 ChannelFuture 接口， 其 addListener()方法注册了一个 ChannelFutureListener，以便在某个操作完成时(无论是否 成功)得到通知。</p>

<h2 id="toc_13">ChannelHandler</h2>

<p>ChannelHandler 承担了所有处理入站和出站数据的处理。ChannelHandler 的方法是由网络事件触发的。</p>

<p>Netty 定义了下面两个重要的 ChannelHandler 子接口：</p>

<ul>
<li>ChannelInboundHandler——处理入站数据以及各种状态变化; </li>
<li>ChannelOutboundHandler——处理出站数据并且允许拦截所有的操作</li>
</ul>

<h3 id="toc_14">ChannelInboundHandler</h3>

<p>ChannelInboundHandler 会在数据被接收时或者与其对应的 Channel 状态发生改变时被调用。下面我们来看下它所定义的相关方法：</p>

<ul>
<li>channelRegistered : 当 Channel 已经注册到它的 EventLoop 并且能够处理 I/O 时被调用</li>
<li>channelUnregistered : 当 Channel 从它的 EventLoop 注销并且无法处理任何 I/O 时被调用</li>
<li>channelActive : 当 Channel 处于活动状态时被调用;Channel 已经连接/绑定并且已经就绪</li>
<li>channelInactive : 当 Channel 离开活动状态并且不再连接它的远程节点时被调用</li>
<li>channelReadComplete : 当 Channel 的一个读操作完成时被调用</li>
<li>channelRead : 当从 Channel 读取数据时被调用</li>
<li>channelWritabilityChanged : 当 Channel 的可写状态发生改变时被调用。可以通过调用 Channel 的 isWritable()方法 来检测 Channel 的可写性。与可写性相关的阈值可以通过Channel.config().setWriteHighWaterMark()和Channel.config().setWriteLowWaterMark()方法来设置</li>
<li>userEventTriggered : 当 ChannelnboundHandler.fireUserEventTriggered() 方法被调用时被 调用。</li>
</ul>

<h3 id="toc_15">ChannelOutboundHandler</h3>

<p>出站操作和数据将由 ChannelOutboundHandler 处理。它的方法将被 Channel、ChannelPipeline 以及 ChannelHandlerContext 调用</p>

<p>所有由 ChannelOutboundHandler 本身所定义的方法：</p>

<ul>
<li>bind(ChannelHandlerContext,SocketAddress,ChannelPromise)<br/>
当请求将 Channel 绑定到本地地址时被调用</li>
<li>connect(ChannelHandlerContext,SocketAddress,SocketAddress,ChannelPromise)<br/>
当请求将 Channel 连接到远程节点时被调用</li>
<li>disconnect(ChannelHandlerContext,ChannelPromise)<br/>
当请求将 Channel 从远程节点断开时被调用</li>
<li>close(ChannelHandlerContext,ChannelPromise) 当请求关闭 Channel 时被调用</li>
<li>deregister(ChannelHandlerContext,ChannelPromise)<br/>
当请求将 Channel 从它的 EventLoop 注销时被调用</li>
<li>read(ChannelHandlerContext)<br/>
当请求从 Channel 读取更多的数据时被调用</li>
<li>flush(ChannelHandlerContext)<br/>
当请求通过 Channel 将入队数据冲刷到远程节点时被调 用</li>
<li>write(ChannelHandlerContext,Object,ChannelPromise)<br/>
当请求通过 Channel 将数据写到 远程节点时被调用</li>
</ul>

<h3 id="toc_16">ChannelHandler 适配器</h3>

<p>有一些适配器类可以将编写自定义的 ChannelHandler 所需要的工作降到最低限度，因 为它们提供了定义在对应接口中的所有方法的默认实现。因为你有时会忽略那些不感兴趣的 事件，所以 Netty 提供了抽象基类 ChannelInboundHandlerAdapter 和 ChannelOutboundHandlerAdapter。</p>

<p>可以使用 ChannelInboundHandlerAdapter 和 ChannelOutboundHandlerAdapter 类作为 自己的 ChannelHandler 的起始点。这两个适配器分别提供了 ChannelInboundHandler 和 ChannelOutboundHandler 的基本实现。通过扩展抽象类 ChannelHandlerAdapter，它们获得 了它们共同的超接口 ChannelHandler 的方法。</p>

<p>ChannelHandlerAdapter 还提供了实用方法 isSharable()。如果其对应的实现被标注为 Sharable，那么这个方法将返回 true，表示它可以被添加到多个 ChannelPipeline。</p>

<p><figure><img src="media/16063167790102/16070173055991.jpg" alt=""/></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[redis rehash]]></title>
    <link href="http://www.throne4j.com/16027453677170.html"/>
    <updated>2020-10-15T15:02:47+08:00</updated>
    <id>http://www.throne4j.com/16027453677170.html</id>
    <content type="html"><![CDATA[
<p>作为一个内存数据库，redis内部采用了字典的数据结构实现了键值对的存储，字典也就是我们平时所说的哈希表。随着数据量的不断增加，数据必然会产生hash碰撞，而redis采用链地址法解决hash冲突。我们知道如果哈希表数据量达到了一个很大的量级，那么冲突的链的元素数量就会很大，这时查询效率就会变慢，因为取值的时候redis会遍历链表。而随着数据量的缩减，也会产生一定的内存浪费。redis在设计时充分考虑了字典的增加和缩减，为了优化数据量增加时的查询效率和缩减时的内存利用率，redis进行了一系列操作，而处理的这个过程被称作rehash。</p>

<h2 id="toc_0">redis 哈希表结构</h2>

<p><figure><img src="media/16027453677170/16027455213851.jpg" alt=""/></figure></p>

<pre><code class="language-c">// 哈希表定义

typedef struct dictht {

    dictEntry **table;

    unsigned long size;

    unsigned long sizemask;

    unsigned long used; 

} dictht;



// 字典定义

typedef struct dict {

    dictType *type;

    void *privdata;    dictht ht[2]; /* 两个hashtable */

    long rehashidx; /* rehashing 如果没有进行则 rehashidx == -1  否则 rehash则表示rehash进行到的索引位置 */ 

    unsigned long iterators; /* number of iterators currently running */

} dict;
</code></pre>

<p>从结构上看每个字典中都包含了两个hashtable。那么为什么一个字典会需要两个hashtable？首先redis在正常读写时会用到一个hashtable，而另一个hashtable的作用实际上是作为字典在进行rehash时的一个临时载体。我们可以这么理解，redis开始只会用一个hashtable去读写，如果这个hashtable的数据量增加或者缩减到某个值，到达了rehash的条件，redis便会开始根据数据量和链（bucket）的个数初始化那个备用的hashtable，来使这个hashtable从容量上满足后续的使用，并开始把之前的hashtable的数据迁移到这个新的hashtable上来，当然这种迁移是对每个节点值进行一次hash运算。等到数据全部迁移完成，再进行一次hashtable的地址更名，把这个备用的hashtable为正式的hashtable，同时清空另一个hashtable以供下一次rehash使用。</p>

<h2 id="toc_1">rehash 条件</h2>

<p>hashtable元素总个数 / 字典的链个数 = 每个链平均存储的元素个数(load_factor)</p>

<ul>
<li><p>服务器目前没有在执行BGSAVE命令或者BGREWRITEAOF命令，load_factor &gt;= 1，dict就会触发扩大操作rehash</p></li>
<li><p>服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令，load_factor &gt;= 5，dict就会触发扩大操作rehash</p></li>
<li><p>load_factor &lt; 0.1，dict就会触发缩减操作rehash</p></li>
</ul>

<h2 id="toc_2">rehash 过程</h2>

<p>我们假设 ht[0]为正在使用的hashtable，ht[1]为rehash之后的备用hashtable<br/>
步骤如下：</p>

<ul>
<li><p>为字典的备用哈希表分配空间：</p></li>
<li><p>如果执行的是扩展操作，那么备用哈希表的大小为第一个大于等于(已用节点个数)*2的2n（2的n次方幂）</p></li>
<li><p>如果执行的是收缩操作，那么备用哈希表的大小为第一个大于等于(已用节点个数)的2n</p></li>
<li><p>在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始（为-1时表示没有进行rehash）。</p></li>
<li><p>rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当一次rehash工作完成之后，程序将rehashidx属性的值+1。同时在serverCron中调用rehash相关函数，在1ms的时间内，进行rehash处理，每次仅处理少量的转移任务(100个元素)。</p></li>
<li><p>随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。</p></li>
</ul>

<h2 id="toc_3">rehash 总结</h2>

<p><strong><em>在Hash 表扩容或者收缩的时候，程序需要将现有的哈希表中的所有键值对rehash 到新的 Hash表里面，此rehash 过程不是一次性完成的，而是渐进式的完成。</em></strong></p>

<p>这种渐进式的 rehash 避免了集中式rehash带来的庞大计算量和内存操作，但是需要注意的是redis在进行rehash的时候，正常的访问请求可能需要做多要访问两次hashtable（ht[0]， ht[1]），例如键值被rehash到新ht[1]，则需要先访问ht[0]，如果ht[0]中找不到，则去ht[1]中找。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CPU缓存一致性协议MESI]]></title>
    <link href="http://www.throne4j.com/16026440050146.html"/>
    <updated>2020-10-14T10:53:25+08:00</updated>
    <id>http://www.throne4j.com/16026440050146.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">CPU高速缓存（Cache Memory）</h2>

<h3 id="toc_1">CPU为何要有高速缓存</h3>

<p>CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\O速度和CPU运算速度之间的不匹配问题。</p>

<p>在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。</p>

<p>时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。</p>

<p>比如循环、递归、方法的反复调用等。</p>

<p>空间局部性（Spatial Locality）：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。</p>

<p>比如顺序执行的代码、连续创建的两个对象、数组等。</p>

<h3 id="toc_2">带有高速缓存的CPU执行计算的流程</h3>

<p>程序以及数据被加载到主内存</p>

<p>指令和数据被加载到CPU的高速缓存</p>

<p>CPU执行指令，把结果写到高速缓存</p>

<p>高速缓存中的数据写回主内存</p>

<p><figure><img src="media/16026440050146/16026440570104.jpg" alt=""/></figure></p>

<h3 id="toc_3">目前流行的多级缓存结构</h3>

<p>由于CPU的运算速度超越了1级缓存的数据I\O能力，CPU厂商又引入了多级的缓存结构。</p>

<p>多级缓存结构<br/>
<figure><img src="media/16026440050146/16026440832590.jpg" alt=""/></figure></p>

<h2 id="toc_4">多核CPU多级缓存一致性协议MESI</h2>

<p>多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。</p>

<h3 id="toc_5">MESI协议缓存状态</h3>

<p>MESI 是指4中状态的首字母。每个 缓存行Cache line (缓存存储数据的单元)有4个状态，可用2个bit表示，它们分别是：</p>

<table>
<thead>
<tr>
<th>状态</th>
<th>描述</th>
<th>监听任务</th>
</tr>
</thead>

<tbody>
<tr>
<td>M 修改 (Modified)</td>
<td>该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。</td>
<td>缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。</td>
</tr>
<tr>
<td>E 独享、互斥 (Exclusive)</td>
<td>该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。</td>
<td>缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。</td>
</tr>
<tr>
<td>S 共享 (Shared)</td>
<td>该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。</td>
<td>缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。</td>
</tr>
<tr>
<td>I 无效 (Invalid)</td>
<td>该Cache line无效。</td>
<td>无</td>
</tr>
</tbody>
</table>

<p>注意：<br/>
<strong>对于M和E状态而言总是精确的，他们在和该缓存行的真正状态是一致的，而S状态可能是非一致的</strong>。如果一个缓存将处于S状态的缓存行作废了，而另一个缓存实际上可能已经独享了该缓存行，但是该缓存却不会将该缓存行升迁为E状态，这是因为其它缓存不会广播他们作废掉该缓存行的通知，同样由于缓存并没有保存该缓存行的copy的数量，因此（即使有这种通知）也没有办法确定自己是否已经独享了该缓存行。</p>

<p>从上面的意义看来E状态是一种投机性的优化：如果一个CPU想修改一个处于S状态的缓存行，总线事务需要将所有该缓存行的copy变成invalid状态，而修改E状态的缓存不需要使用总线事务。</p>

<h3 id="toc_6">MESI 状态转换</h3>

<p><figure><img src="media/16026440050146/16026444223626.jpg" alt=""/></figure></p>

<p>理解该图的前置说明：</p>

<h4 id="toc_7">触发事件</h4>

<table>
<thead>
<tr>
<th>触发事件</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>本地读取（Local read）</td>
<td>本地cache读取本地cache数据</td>
</tr>
<tr>
<td>本地写入（Local write）</td>
<td>本地cache写入本地cache数据</td>
</tr>
<tr>
<td>远端读取（Remote read）</td>
<td>其他cache读取本地cache数据</td>
</tr>
<tr>
<td>远端写入（Remote write）</td>
<td>其他cache写入本地cache数据</td>
</tr>
</tbody>
</table>

<h4 id="toc_8">cache分类</h4>

<p>前提：所有的cache共同缓存了主内存中的某一条数据。</p>

<p>本地cache:指当前cpu的cache。<br/>
触发cache:触发读写事件的cache。<br/>
其他cache:指既除了以上两种之外的cache。<br/>
注意：本地的事件触发 本地cache和触发cache为相同。</p>

<p><figure><img src="media/16026440050146/16026616087435.jpg" alt="" style="width:1121px;"/></figure></p>

<p>当一个cache line的调整的状态的时候，另外一个cache line 需要调整的状态。</p>

<p><figure><img src="media/16026440050146/16045611186544.jpg" alt="" style="width:1198px;"/></figure></p>

<p>举个栗子来说：<br/>
假设cache 1 中有一个变量x = 0的cache line 处于S状态(共享)。<br/>
那么其他拥有x变量的cache 2、cache 3等x的cache line调整为S状态（共享）或者调整为 I 状态（无效）。</p>

<p>假设有三个CPU A、B、C，对应三个缓存分别是cache a、b、 c。在主内存中定义了变量 x 的引用值为0。</p>

<ul>
<li><p>单核读取<br/>
执行流程是：<br/>
CPU A发出了一条指令，从主内存中读取x。从主内存通过bus读取到缓存中（远端读取Remote read）,这是该Cache line修改为E状态（独享）.</p></li>
<li><p>双核读取<br/>
执行流程是：<br/>
CPU A发出了一条指令，从主内存中读取x。<br/>
CPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。<br/>
CPU B发出了一条指令，从主内存中读取x。<br/>
CPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。</p></li>
<li><p>修改数据<br/>
执行流程是：<br/>
CPU A 计算完成后发指令需要修改x.<br/>
CPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无效)<br/>
CPU A 对x进行赋值。</p></li>
<li><p>同步数据<br/>
执行流程是：<br/>
CPU B 发出了要读取x的指令。<br/>
CPU B 通知CPU A, CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）<br/>
CPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[serversocketChannel]]></title>
    <link href="http://www.throne4j.com/16024819837796.html"/>
    <updated>2020-10-12T13:53:03+08:00</updated>
    <id>http://www.throne4j.com/16024819837796.html</id>
    <content type="html"><![CDATA[
<p>socketChannel， begin()</p>

<p>selector --&gt; selectorImpl 初始化两个集合，<br/>
EpollSelectorImpl</p>

<p><figure><img src="media/16024819837796/16065704639756.jpg" alt=""/></figure></p>

<p>publicKey 存放所有注册的selectionKey<br/>
publicSelectedKey  已经就绪的key</p>

<p><figure><img src="media/16024819837796/16065707769531.jpg" alt=""/></figure></p>

<p>fd0 管道的读端文件描述符<br/>
fd1 管道的写端文件描述符</p>

<p>线程中断的时候写入一个字节来唤醒线程。</p>

<p>管道本质上是一块内存</p>

<p>在两个进程之间如何进行通信，</p>

<p>selector.select()  --&gt; lockAndDoSelect(long timeout)</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TCP 与 HTTP]]></title>
    <link href="http://www.throne4j.com/16024149950927.html"/>
    <updated>2020-10-11T19:16:35+08:00</updated>
    <id>http://www.throne4j.com/16024149950927.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、TCP三次握手过程</h2>

<p><figure><img src="media/16024149950927/16066243723651.jpg" alt=""/></figure></p>

<h2 id="toc_1">2、为什么TCP需要3次握手</h2>

<p>TCP 是可靠的传输控制协议，而三次握手是保证数据可靠传输又能提高传输效率的最小次数。为什么?RFC793，也就是 TCP 的协议 RFC 中就谈到了原因，这是因为:</p>

<p>为了实现可靠数据传输， TCP 协议的通信双方，都必须维护一个序列号， 以标识发送出去的数据包中，哪些是已经被对方收到的。三次握手的过程即是通信双方相互告知序列号起始值，并确认对方已经收到了序列号 起始值的必经步骤。</p>

<h2 id="toc_2">3、TCP的四次挥手</h2>

<p><figure><img src="media/16024149950927/16066246987650.jpg" alt=""/></figure></p>

<ul>
<li>第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说&quot;我客户端没有数据要发给你了&quot;，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。</li>
<li>第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。</li>
<li>第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。</li>
<li>第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。</li>
</ul>

<h2 id="toc_3">4、为什么要有TIME_WAIT状态</h2>

<ul>
<li>可靠终止 TCP 连接。如果最后一个 ACK 报文因为网络原因被丢弃，此时 server 因为 没有收到ACK而超时重传FIN报文，处于TIME_WAIT状态的client可以继续对FIN报文做回 复，向 server 发送 ACK 报文。</li>
<li>保证让迟来的 TCP 报文段有足够的时间被识别和丢弃。连接结束了，网络中的延迟 报文也应该被丢弃掉，以免影响立刻建立的新连接。</li>
</ul>

<h2 id="toc_4">5、为什么 TCP 需要四次挥手</h2>

<p>TCP 是全双工的连接，必须两端同时关闭连接，连接才算真正关闭。如果一方已经准备关闭写，但是它还可以读另一方发送的数据。发送给 FIN 结束报文给 对方对方收到后，回复 ACK 报文。当这方也已经写完了准备关闭，发送 FIN 报文，对方回复 ACK。两端都关闭，TCP 连接正常关闭。</p>

<h2 id="toc_5">概述NIO</h2>

<p>NIO编程中涉及到如下几个</p>

<ul>
<li><p>Buffer:与 Channel 进行交互，数据是从 Channel 读入缓冲区，从缓冲区写入 Channel中的</p>
<ul>
<li>flip 方法 : 反转此缓冲区，将 position 给 limit，然后将 position 置为 0，其实就是切换 读写模式</li>
<li>clear 方法 :清除此缓冲区，将 position 置为 0，把 capacity 的值给 limit。</li>
<li>rewind 方法 : 重绕此缓冲区，将 position 置为 0<br/>
DirectByteBuffer 可减少一次系统空间到用户空间的拷贝。但 Buffer 创建和销毁的成本 更高，不可控，通常会用内存池来提高性能。直接缓冲区主要分配给那些易受基础系统的本 机 I/O 操作影响的大型、持久的缓冲区。如果数据量比较小的中小应用情况下，可以考虑使 用 heapBuffer，由 JVM 进行管理。</li>
</ul></li>
<li><p>Channel: 表示 IO 源与目标打开的连接，是双向的，但不能直接访问数据，只能与 Buffer 进行交互。通过源码可知，FileChannel 的 read 方法和 write 方法都导致数据复制了两次!</p></li>
<li><p>Selector 可使一个单独的线程管理多个 Channel</p>
<ul>
<li>open 方法: 创建 Selector</li>
<li>register 方法: 向多路复用器器注册通道，可以监听的事件类型:读、写、连接、accept。注册事件后会产生一个SelectionKey
<ul>
<li>SelectionKey: 它表示 SelectableChannel 和 Selector 之间的注册关系，</li>
</ul></li>
<li>wakeup 方法: 使尚未返回的第一个选择操作立即返回，唤醒的原因是:注册了新的 channel 或者事件; channel 关闭，取消注册;优先级更高的事件触发(如定时器事件)，希望及时处理</li>
</ul></li>
</ul>

<p>NIO 的服务端建立过程:Selector.open():打开一个 Selector;ServerSocketChannel.open(): 创建服务端的 Channel;bind():绑定到某个端口上。并配置非阻塞模式;register():注册 Channel 和关注的事件到 Selector 上;select()轮询拿到已经就绪的事件。</p>

<h2 id="toc_6">HTTP1.0 与HTTP1.1的区别</h2>

<p>HTTP1.0 最早在网页中使用是在 1996 年，那个时候只是使用一些较为简单的网页上和 网络请求上，而 HTTP1.1 则在 1999 年才开始广泛应用于现在的各大浏览器网络请求中，同时 HTTP1.1 也是当前使用最为广泛的 HTTP 协议。 </p>

<p>主要区别主要体现在如下几点：</p>

<ul>
<li>缓存处理，在HTTP1.0中主要使用header里的 if-Modified-Since，Expires来做缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略，如：Entity Tag、If-Unmodified-Since、If-Match、If-None-Match等更多可供选择的缓存头来控制缓存策略</li>
<li>带块优化以及网络连接的使用，HTTP1.0 中，存在一些浪费带宽的现象，例如客户端 只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能， HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206 (Partial Content)，这样就方便了开发者自由的选择以便于充分利用带宽和连接。</li>
<li>错误通知的管理，在 HTTP1.1 中新增了 24 个错误状态响应码，如 409(Conflict)表 示请求的资源与资源的当前状态发生冲突;410(Gone)表示服务器上的某个资源被永久性 的删除。</li>
<li>Host头处理，在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求 消息中的 URL 并没有传递主机名(hostname)。但随着虚拟主机技术的发展，在一台物理 服务器上可以存在多个虚拟主机(Multi-homed Web Servers)，并且它们共享一个 IP 地址。 HTTP1.1 的请求消息和响应消息都应支持 Host 头域，且请求消息中如果没有 Host 头域会报 告一个错误(400 Bad Request)。</li>
<li>长连接，HTTP 1.1 支持长连接(PersistentConnection)和请求的流水线(Pipelining) 处理，在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少了建立和关闭连接的消耗和延迟，在 HTTP1.1 中默认开启 Connection: keep-alive，一定程度上弥补了 HTTP1.0 每次请 求都要创建连接的缺点。</li>
</ul>

<h2 id="toc_7">HTTP2.0 和 HTTP1.X 相比的新特性</h2>

<p>新的二进制格式(Binary Format)，HTTP1.x 的解析是基于文本。基于文本协议的格式 解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制 则不同，只认 0 和 1 的组合。基于这种考虑 HTTP2.0 的协议解析决定采用二进制格式，实现方便且健壮。</p>

<p>多路复用(MultiPlexing)，即连接共享，即每一个 request 都是是用作连接共享机制的。 一个 request 对应一个 id，这样一个连接上可以有多个 request，每个连接的 request 可以随 机的混杂在一起，接收方可以根据 request 的 id 将 request 再归属到各自不同的服务端请求里面。</p>

<p>header 压缩，如上文中所言，对前面提到过 HTTP1.x 的 header 带有大量信息，而且每 次都要重复发送，HTTP2.0 使用 encoder 来减少需要传输的 header 大小，通讯双方各自 cache 一份 header fields 表，既避免了重复 header 的传输，又减小了需要传输的大小。</p>

<p>服务端推送(server push)，HTTP2.0 也具有 server push 功能。</p>

<h2 id="toc_8">HTTP2.0 的多路复用和 HTTP1.X 中的长连接复用有什么区别</h2>

<ul>
<li>HTTP/1.0 一次请求-响应，建立一个连接，用完关闭;每一个请求都要建立一个连接;</li>
<li>HTTP/1.1 Pipeling 解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法， 也就是人们常说的线头阻塞;</li>
<li>HTTP/2.0 多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行</li>
</ul>

<h2 id="toc_9">Http 与 Https 的区别</h2>

<p>HTTPS 协议(HyperText Transfer Protocol over Secure Socket Layer):一般理解为 HTTP+SSL/TLS，通过 SSL 证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。</p>

<ul>
<li><p>HTTP 的 URL 以 http:// 开头，而 HTTPS 的 URL 以 https:// 开头<br/>
HTTP 是不安全的，而 HTTPS 是安全的</p></li>
<li><p>HTTP 标准端口是 80 ，而 HTTPS 的标准端口是 443</p></li>
<li><p>在 OSI 网络模型中，HTTP 工作于应用层，而 HTTPS 的安全传输机制工作在传输层 </p></li>
<li><p>HTTP 无法加密，而 HTTPS 对传输的数据进行加密</p></li>
<li><p>HTTP 无需证书，而 HTTPS 需要 CA 机构颁发的 SSL 证书</p></li>
</ul>

<h2 id="toc_10">HTTPS 方式与 Web 服务器通信时的步骤</h2>

<ul>
<li>客户使用 https 的 URL 访问 Web 服务器，要求与 Web 服务器建立 SSL 连接。</li>
<li>Web 服务器收到客户端请求后，会将网站的证书信息(证书中包含服务器公 钥&lt;非对称加密&gt;)传送一份给客户端。(HTTPS 中，服务端将公钥发给数字证书认证机构进行安全认证并对公钥进行数字签名，完成后公钥和签名组合成数字证书。在和客户端通信时， 服务端将数字证书发给客户端，客户端通过第三方安全认证机构(一般会在浏览器开发时， 内置在浏览器中)对数字证书上的签名进行验证。)</li>
<li>客户端的浏览器与 Web 服务器开始协商 SSL 连接的安全等级，也就是信息加 密的等级。</li>
<li>客户端的浏览器根据双方同意的安全等级，建立会话密钥&lt;对称加密&gt;，然后 利用服务器公钥将会话密钥加密，并传送给网站。</li>
<li>Web 服务器利用自己的私钥解密出会话密钥。</li>
<li>Web 服务器利用会话密钥加密与客户端之间的通信。</li>
</ul>

<h2 id="toc_11">什么是 Http 协议无状态协议?怎么解决?</h2>

<p>无状态协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息,却无法获取到，也就是说，当客户端一次 HTTP 请求完成以后，客户端再发送一次 HTTP 请求，HTTP 并不知道当前客户端是一个”老用户“。</p>

<p>可以使用 Cookie 来解决无状态的问题，Cookie 就相当于一个通行证，第一次访问的时 候给客户端发送一个 Cookie，当客户端再次来的时候，拿着 Cookie(通行证)，那么服务器就 知道这个是”老用户“</p>

<h2 id="toc_12">一次完整的 HTTP 请求所经历的步骤</h2>

<ul>
<li><p>首先进行 DNS 域名解析(本地浏览器缓存、操作系统缓存或者 DNS 服务器)，首先会搜索浏览器自身的 DNS 缓存(缓存时间比较短，大概只有 1 分钟，且只能容纳 1000 条缓存)</p>
<ul>
<li>如果浏览器自身的缓存里面没有找到，那么浏览器会搜索系统自身的 DNS 缓存</li>
<li>如果还没有找到，那么尝试从 hosts 文件里面去找</li>
<li>在前面三个过程都没获取到的情况下，就去域名服务器去查找</li>
</ul></li>
<li><p>三次握手建立 TCP 连接<br/>
在 HTTP 工作开始之前，客户端首先要通过网络与服务器建立连接，HTTP 连接是通过 TCP 来完成的。HTTP 是比 TCP 更高层次的应用层协议，根据规则，只有低层协议建立之后，才能进行高层协议的连接，因此，首先要建立 TCP 连接，一般 TCP 连接的端口号是 80;</p></li>
<li><p>客户端发起 HTTP 请求</p></li>
<li><p>服务器响应 HTTP 请求</p></li>
<li><p>客户端解析 html 代码，并请求html代码中的资源。浏览器拿到 html 文件后，就开始解析其中的 html 代码，遇到 js/css/image 等静态资源 时，就向服务器端去请求下载</p></li>
<li><p>客户端渲染展示内容</p></li>
<li><p>关闭 TCP 连接</p></li>
</ul>

<p>一般情况下，一旦服务器向客户端返回了请求数据，它就要关闭 TCP 连接，然后如果 客户端或者服务器在其头信息加入了这行代码 Connection:keep-alive ，TCP 连接在发送后 将仍然保持打开状态，于是，客户端可以继续通过相同的连接发送请求，也就是说前面的 3 到 6，可以反复进行。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。</p>

<h2 id="toc_13">常见的 HTTP 相应状态码</h2>

<ul>
<li>200:请求被正常处理</li>
<li>204:请求被受理但没有资源可以返回 </li>
<li>206:客户端只是请求资源的一部分，服务器只对请求的部分资源执行 GET 方法，相应报文中通过 Content-Range 指定范围的资源。</li>
<li>301:永久性重定向</li>
<li>302:临时重定向</li>
<li>303:与 302 状态码有相似功能，只是它希望客户端在请求一个 URI 的时候，能通过 GET 方法重定向到另一个 URI 上</li>
<li>304:发送附带条件的请求时，条件不满足时返回，与重定向无关 </li>
<li>307:临时重定向，与 </li>
<li>302 类似，只是强制要求使用 POST 方法 </li>
<li>400:请求报文语法有误，服务器无法识别</li>
<li>401:请求需要认证</li>
<li>403:请求的对应资源禁止被访问 </li>
<li>404:服务器无法找到对应资源 </li>
<li>500:服务器内部错误 </li>
<li>503:服务器正忙</li>
</ul>

<h2 id="toc_14">常用的 HTTP 方法有哪些</h2>

<ul>
<li>GET: 用于请求访问已经被 URI(统一资源标识符)识别的资源，可以通过 URL 传参给服务器</li>
<li>POST:用于传输信息给服务器，主要功能与 GET 方法类似，但一般推荐使用 POST 方式。</li>
<li>PUT: 传输文件，报文主体中包含文件内容，保存到对应 URI 位置。</li>
<li>HEAD: 获得报文首部，与 GET 方法类似，只是不返回报文主体，一般用于验证 URI 是否有效。</li>
<li>DELETE:删除文件，与 PUT 方法相反，删除对应 URI 位置的文件。 OPTIONS:查询相应 URI 支持的 HTTP 方法</li>
</ul>

<h2 id="toc_15">HTTP 请求报文与响应报文格式</h2>

<p><a href="15955594725422.html">HTTP协议（二）-- HTTP 协议报文结构</a></p>

<h2 id="toc_16">URI 和 URL 的区别</h2>

<p>URI，是 uniform resource identifier，统一资源标识符，用来唯一的标识一个资源。</p>

<p>Web 上可用的每种资源如 HTML 文档、图像、视频片段、程序等都是一个来 URI 来定位 的</p>

<p>URI 一般由三部组成:</p>

<ul>
<li>访问资源的命名机制</li>
<li>存放资源的主机名</li>
<li>3资源自身的名称，由路径表示，着重强调于资源。</li>
</ul>

<p>URL 是 uniform resource locator，统一资源定位器，它是一种具体的 URI，即 URL 可以用 来标识一个资源，而且还指明了如何 locate 这个资源。</p>

<p>URL是Internet上用来描述信息资源的字符串，主要用在各种WWW客户程序和服务器 程序上，特别是著名的 Mosaic。</p>

<p>采用 URL 可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目 录等。</p>

<p>URL 一般由三部组成:</p>

<ul>
<li>协议(或称为服务方式)</li>
<li>存有该资源的主机 IP 地址(有时也包括端口号) </li>
<li>主机资源的具体地址。如目录和文件名等</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dubbo]]></title>
    <link href="http://www.throne4j.com/16024075158165.html"/>
    <updated>2020-10-11T17:11:55+08:00</updated>
    <id>http://www.throne4j.com/16024075158165.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Dubbo 简介</h2>

<p>在分布式服务架构下，各个服务间的相互 rpc 调用会越来越复杂。最终形成网状结构，此时服务的治理极为关键。</p>

<p>Dubbo 是一个带有服务治理功能的 RPC 框架，提供了一套较为完整的服务治理方案，其底层直接实现了 rpc 调用的全过程，并尽力做事 rpc 远程对 使用者透明。下图展示了 Dubbo 服务治理的功能。</p>

<p><figure><img src="media/16024075158165/16024075991851.jpg" alt="" style="width:751px;"/></figure></p>

<p>简单的说，Dubbo 就是个服务调用的框架，如果没有分布式的需求，其实是不需要用的，只有在分布式的时候，才有使用 Dubbo 这样的分布式服务框架的需求，并且本质上是个服务调用的东东。</p>

<p>其核心部分包括：</p>

<ul>
<li>远程通讯:提供对多种基于长连接的 NIO 框架抽象封装，包括多种线程 模型、序列化以及“请求-响应”模式的信息交换方式。</li>
<li>集群容错:提供基于接口方法的透明远程过程调用，包括多协议支持以 及软负载均衡，失败容错、地址路由、动态配置等集群支持。</li>
<li>自动发现:基于注册中心目录服务，使服务消费方能动态的查某服务的提供方，使地址透明，使服务提供方可以平滑增加或减少机器。</li>
</ul>

<h2 id="toc_1">dubbo 的架构</h2>

<p>dubbo 的整体结构如下图所示：</p>

<p><figure><img src="media/16024075158165/16024078552797.jpg" alt=""/></figure></p>

<ul>
<li>图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。</li>
<li>图中从下至上分为十层，各层均为单向依赖，右边的黑色箭头代表层之间的依赖关系，每一层都可以剥离上层被复用，其中，Service 和 Config 层为 API，其它各层均为 SPI。</li>
<li>图中绿色小块的为扩展接口，蓝色小块为实现类，图中只显示用于关联各层的实现类。</li>
<li>图中蓝色虚线为初始化过程，即启动时组装链，红色实线为方法调用过程，即运行时调时链，紫色三角箭头为继承，可以把子类看作父类的同一个节点，线上的文字为调用的方法。</li>
</ul>

<p>Dubbo总体架构设计一共划分了10层：</p>

<ul>
<li><p>服务接口层(Service)<br/>
该层是与实际业务逻辑相关的，根据服务提供方 和 服务消费方的业务设计对应的接口和实现。</p></li>
<li><p>配置层(Config)<br/>
对外配置接口，以 ServiceConfig 和 ReferenceConfig 为中 心，可以直接 new 配置类，也可以通过 Spring 解析配置生成配置类。</p></li>
<li><p>服务代理层(Proxy)<br/>
服务接口透明代理，生成服务的客户端 Stub 和服务 器端 Skeleton，以 ServiceProxy 为中心，扩展接口为 ProxyFactory。</p></li>
<li><p>服务注册层(Registry)<br/>
封装服务地址的注册与发现，以服务 URL 为中心， 扩展接口为RegistryFactory、Registry 和 RegistryService。可能没有服务注册中心，此时服务提供方直接暴露服务。</p></li>
<li><p>集群层(Cluster)<br/>
封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster、Directory、Router 和 LoadBalance。 将多个服务提供方组合为一个服务提供方，实现对服务消费方透明，只 需要与一个服务提供方进行交互。</p></li>
<li><p>监控层(Monitor)<br/>
RPC 调用次数和调用时间监控，以 Statistics 为中心， 扩展接口为 MonitorFactory、Monitor 和 MonitorService。</p></li>
<li><p>远程调用层(Protocol)<br/>
封将 RPC 调用，以 Invocation 和 Result 为中心， 扩展接口为 Protocol、Invoker 和 Exporter。Protocol 是服务域，它是 Invoker 暴露和引用的主功能入口，它负责 Invoker 的生命周期管理。Invoker 是 实体域，它是 Dubbo 的核心模型，其他模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起invoke 调用。它有可能是一个本地的实现，也可能是一个远程的实现，也可能是一个集群实现。</p></li>
<li><p>信息交换层(Exchange)<br/>
封装请求响应模式，同步转异步，以 Request 和 Response 为中心，扩展接口为 Exchanger、ExchangeChannel、ExchangeClient 和 ExchangeServer。</p></li>
<li><p>网络传输层(Transport)<br/>
抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel、Transporter、Client、Server 和 Codec。</p></li>
<li><p>数据序列化层(Serialize)<br/>
可复用的一些工具，扩展接口为 Serialization、ObjectInput、ObjectOutput 和 ThreadPool。</p></li>
</ul>

<p>各层之间的关系：</p>

<ul>
<li>在 RPC 中，Protocol 是核心层，也就是只要有 Protocol + Invoker + Exporter 就可以完成非透明的 RPC 调用，然后在 Invoker 的主过程上 Filter 拦截点。</li>
<li>图中的 Consumer 和 Provider 是抽象概念，只是想让看图者更直观的了解哪些类分属于客户端与服务器端，不用 Client 和 Server 的原因是 Dubbo 在很多场景下都使用 Provider, Consumer, Registry, Monitor 划分逻辑拓普节点，保持统一概念。</li>
<li>而 Cluster 是外围概念，所以 Cluster 的目的是将多个 Invoker 伪装成一个 Invoker，这样其它人只要关注 Protocol 层 Invoker 即可，加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响，因为只有一个提供者时，是不需要 Cluster 的。</li>
<li>Proxy 层封装了所有接口的透明化代理，而在其它层都以 Invoker 为中心，只有到了暴露给用户使用时，才用 Proxy 将 Invoker 转成接口，或将接口实现转成 Invoker，也就是去掉 Proxy 层 RPC 是可以 Run 的，只是不那么透明，不那么看起来像调本地服务一样调远程服务。</li>
<li>而 Remoting 实现是 Dubbo 协议的实现，如果你选择 RMI 协议，整个 Remoting 都不会用上，Remoting 内部再划为 Transport 传输层和 Exchange 信息交换层，Transport 层只负责单向消息传输，是对 Mina, Netty, Grizzly 的抽象，它也可以扩展 UDP 传输，而 Exchange 层是在传输层之上封装了 Request-Response 语义。</li>
<li>Registry 和 Monitor 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在一起。</li>
</ul>

<h2 id="toc_2">Dubbo 架构具有以下几个特点，分别是连通性、健壮性、伸缩性、以及向未来架构的升级性。</h2>

<h3 id="toc_3">连通性</h3>

<ul>
<li>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小</li>
<li>监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示</li>
<li>服务提供者向注册中心注册其提供的服务，并汇报调用时间到监控中心，此时间不包含网络开销</li>
<li>服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，同时汇报调用时间到监控中心，此时间包含网络开销</li>
<li>注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外</li>
<li>注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者</li>
<li>注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表</li>
<li>注册中心和监控中心都是可选的，服务消费者可以直连服务提供者</li>
</ul>

<h3 id="toc_4">健壮性</h3>

<ul>
<li>监控中心宕掉不影响使用，只是丢失部分采样数据</li>
<li>数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务</li>
<li>注册中心对等集群，任意一台宕掉后，将自动切换到另一台</li>
<li>注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯</li>
<li>服务提供者无状态，任意一台宕掉后，不影响使用</li>
<li>服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复</li>
</ul>

<h3 id="toc_5">伸缩性</h3>

<ul>
<li>注册中心为对等集群，可动态增加机器部署实例，所有客户端将自动发现新的注册中心</li>
<li>服务提供者无状态，可动态增加机器部署实例，注册中心将推送新的服务提供者信息给消费者</li>
</ul>

<h2 id="toc_6">Dubbo 服务的角色关系</h2>

<p>服务提供方 和 服务消费方 之间的调用关系，如下图所示：<br/>
<figure><img src="media/16024075158165/16024093724823.jpg" alt=""/></figure></p>

<h3 id="toc_7">节点角色说明：</h3>

<table>
<thead>
<tr>
<th>节点</th>
<th>角色说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>Provider</td>
<td>暴露服务的服务提供方</td>
</tr>
<tr>
<td>Consumer</td>
<td>调用远程服务的服务消费方</td>
</tr>
<tr>
<td>Registry</td>
<td>服务注册与发现的注册中心</td>
</tr>
<tr>
<td>Monitor</td>
<td>统计服务的调用次数和调用时间的监控中心</td>
</tr>
<tr>
<td>Container</td>
<td>服务运行容器</td>
</tr>
</tbody>
</table>

<h3 id="toc_8">调用关系说明</h3>

<ul>
<li>0：服务容器负责启动，加载，运行服务提供者。</li>
<li>1：服务提供者在启动时，向注册中心注册自己提供的服务。</li>
<li>2：服务消费者在启动时，向注册中心订阅自己所需的服务。</li>
<li>3：注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。</li>
<li>4：服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</li>
<li>5：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解答 Kafka]]></title>
    <link href="http://www.throne4j.com/16022540100685.html"/>
    <updated>2020-10-09T22:33:30+08:00</updated>
    <id>http://www.throne4j.com/16022540100685.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">kafka 中的 zookeeper 起到什么作用，可以不用zookeeper 么?(初级)</h2>

<p>zookeeper 是一个分布式的协调组件，早期版本的 kafka 用 zk 做 meta 信息存储， consumer 的消费状态，group 的管理以及 offset 的值。考虑到 zk 本身的一些因素以及整个 架构较大概率存在单点问题，新版本中逐渐弱化了 zookeeper 的作用。新的 consumer 使用 了 kafka 内部的 group coordination 协议，也减少了对 zookeeper 的依赖，但是 broker 依然依 赖于 ZK，zookeeper 在 kafka 中还用来选举和检测 broker 是否存活等等。</p>

<h2 id="toc_1">kafka 中 consumer group 是什么概念(初级)</h2>

<p>同样是逻辑上的概念，是 Kafka 实现单播和广播两种消息模型的手段。同一个 topic 的 数据，会广播给不同的 group;同一个 group 中的 worker，只有一个 worker 能拿到这个数 据。换句话说，对于同一个 topic，每个 group 都可以拿到同样的所有数据，但是数据进入 group 后只能被其中的一个 worker 消费。group 内的 worker 可以使用多线程或多进程来实 现，也可以将进程分散在多台机器上，worker 的数量通常不超过 partition 的数量，且二者 最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费(同 一 group 内)。</p>

<h2 id="toc_2">kafka 为什么那么快?(中级)</h2>

<p>系统缓存，页面缓存技术。<br/>
顺序写:由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机 写内存还要快。<br/>
Zero-copy 零拷技术减少拷贝次数。 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。 Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。</p>

<h2 id="toc_3">Kafka 中是怎么体现消息顺序性的?(中级) kafka 每个 partition 中的消息在写入时都是有序的，消费时，每个 partition 只能被每一</h2>

<p>个 group 中的一个消费者消费，保证了消费时也是有序的。<br/>
整个 topic 不保证有序。如果为了保证 topic 整个有序，那么将 partition 调整为 1.</p>

<h2 id="toc_4">kafka follower 如何与 leader 同步数据(高级)</h2>

<p>Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求 All Alive Follower 都复制完，这条消息才会被认为 commit，这种复制方式极大的影响了吞吐 率。而异步复制方式下，Follower 异步的从 Leader 复制数据，数据只要被 Leader 写入 log 就被认为已经 commit，这种情况下，如果 leader 挂掉，会丢失数据，kafka 使用 ISR 的方式 很好的均衡了确保数据不丢失以及吞吐率。</p>

<p>kafka producer 如何优化生产速度 增加线程<br/>
提高 batch.size<br/>
增加更多 producer 实例<br/>
增加 partition 数<br/>
设置 acks=-1 时，如果延迟增大:可以增大 num.replica.fetchers(follower 同步数据的<br/>
线程数)来调解;<br/>
跨数据中心的传输:增加 socket 缓冲区设置以及 OS tcp 缓冲区设置。</p>

<h2 id="toc_5">为什么 Kafka 不支持读写分离?(高级)</h2>

<p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，<br/>
从而实现的是一种主写主读的生产消费模型。<br/>
Kafka 并不支持主写从读，因为主写从读有 2 个很明显的缺点:<br/>
(1)数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时 间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值 都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读 取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。<br/>
(2)延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要 经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而 在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘 →网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能 并不太适用。</p>

<h2 id="toc_6">有几百万消息持续积压几小时怎么解决?(高级)</h2>

<p>发生了线上故障，几千万条数据在 MQ 里积压很久。是修复 consumer 的问题，让他恢 复消费速度，然后等待几个小时消费完毕?这是个解决方案。不过有时候我们还会进行临时 紧急扩容。</p>

<p>一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟是 18 万条。1000 多万 条，所以如果积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间 才能恢复过来。</p>

<p>一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下:</p>

<p>先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。<br/>
新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍或者 20 倍的 queue 数 量。然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消 费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。</p>

<p>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的 数据。</p>

<p>这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度 来消费数据。</p>

<p>等快速消费完积压数据之后，再恢复原先部署架构，重新用原先的 consumer 机器来消费消息。</p>

<h2 id="toc_7">Kafka 是如何实现高性能的?(高级)</h2>

<p>宏观架构层面利用 Partition 实现并行处理</p>

<p>Kafka 中每个 Topic 都包含一个或多个 Partition，不同 Partition 可位于不同节点。同时 Partition 在物理上对应一个本地文件夹，每个 Partition 包含一个或多个 Segment，每个 Segment 包含一个数据文件和一个与之对应的索引文件。在逻辑上，可以把一个 Partition 当 作一个非常长的数组，可通过这个“数组”的索引(offset)去访问其数据。</p>

<p>一方面，由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间 的并行处理。另一方面，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同 一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的 disk drive 上，从而实现 磁盘间的并行处理，充分发挥多磁盘的优势。</p>

<p>利用多磁盘的具体方法是，将不同磁盘mount到不同目录，然后server.properties中， 将 log.dirs 设置为多目录(用逗号分隔)。Kafka 会自动将所有Partition 尽可能均匀分配到不 同目录也即不同目录(也即不同 disk)上。</p>

<p>Partition 是最小并发粒度，Partition 个数决定了可能的最大并行度。。 </p>

<h3 id="toc_8">ISR 实现可用性与数据一致性的动态平衡</h3>

<p>常用数据复制及一致性方案</p>

<ul>
<li><p>Master-Slave</p>
<ul>
<li>RDBMS 的读写分离即为典型的 Master-Slave 方案</li>
<li>同步复制可保证强一致性但会影响可用性</li>
<li>异步复制可提供高可用性但会降低一致性</li>
</ul></li>
<li><p>WNR</p>
<ul>
<li>主要用于去中心化的分布式系统中。</li>
<li>N 代表总副本数，W 代表每次写操作要保证的最少写成功的副本数，R 代表每次读至少要读取的副本数</li>
<li>当 W+R&gt;N 时，可保证每次读取的数据至少有一个副本拥有最新的数据</li>
<li>多个写操作的顺序难以保证，可能导致多副本间的写操作顺序不一致。Dynamo 通过 向量时钟保证最终一致性</li>
</ul></li>
<li><p>Paxos 及其变种</p>
<ul>
<li>Google 的 Chubby，Zookeeper 的原子广播协议(Zab)，RAFT 等</li>
</ul></li>
</ul>

<h3 id="toc_9">基于 ISR 的数据复制方案</h3>

<p>Kafka 的数据复制是以 Partition 为单位的。而多个备份间的数据复制，通过 Follower 向 Leader 拉取数据完成。从一这点来讲，Kafka 的数据复制方案接近于上文所讲的 Master-Slave 方案。不同的是，Kafka 既不是完全的同步复制，也不是完全的异步复制，而是基于 ISR 的 动态复制方案。</p>

<p>ISR，也即 In-sync Replica。每个 Partition 的 Leader 都会维护这样一个列表，该列表中， 包含了所有与之同步的 Replica(包含 Leader 自己)。每次数据写入时，只有 ISR 中的所有 Replica 都复制完，Leader 才会将其置为 Commit，它才能被 Consumer 所消费。</p>

<p>这种方案，与同步复制非常接近。但不同的是，这个 ISR 是由 Leader 动态维护的。如果 Follower 不能紧“跟上”Leader，它将被 Leader 从 ISR 中移除，待它又重新“跟上”Leader 后，会被 Leader 再次加加 ISR 中。每次改变 ISR 后，Leader 都会将最新的 ISR 持久化到 Zookeeper 中。</p>

<p>由于 Leader 可移除不能及时与之同步的 Follower，故与同步复制相比可避免最慢的 Follower 拖慢整体速度，也即 ISR 提高了系统可用性。</p>

<p>ISR 中的所有 Follower 都包含了所有 Commit 过的消息，而只有 Commit 过的消息才会被 Consumer 消费，故从 Consumer 的角度而言，ISR 中的所有Replica 都始终处于同步状态，从 而与异步复制方案相比提高了数据一致性。</p>

<p>ISR 可动态调整，极限情况下，可以只包含 Leader，极大提高了可容忍的宕机的 Follower 的数量。与 Majority Quorum 方案相比，容忍相同个数的节点失败，所要求的总节点数少了 近一半。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySql 事务]]></title>
    <link href="http://www.throne4j.com/16022490047332.html"/>
    <updated>2020-10-09T21:10:04+08:00</updated>
    <id>http://www.throne4j.com/16022490047332.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">数据库事务具备ACID特性</h2>

<ul>
<li>原子性(A)：要执行的事务是一个独立的操作单元，要么全部执行，要么全部不执行</li>
<li>一致性(C)：事务的一致性是指事务的执行不能破坏数据库的一致性，一致性也称为完整性。一个事务在执行后，数据库必须从一个一致性状态转变为另一个一致性状态</li>
<li>隔离性(I)：多个事务并发执行时，一个事务的执行不应影响其他事务的执行</li>
<li>持久性(D)：是事务的保证，事务终结的标志(内存的数据持久到硬盘文件中)</li>
</ul>

<h2 id="toc_1">无隔离性会出现的问题：</h2>

<ul>
<li><p>丢失更新<br/>
A 事务撤销时，把已经提交的 B 事务的更新数据覆盖了。这种错误可能造成很严重的问 题，通过下面的账户取款转账就可以看出来，MySQL 通过三级封锁协议的第一级解决了丢 失更新，事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。</p></li>
<li><p>脏读<br/>
脏读主要是读取到了其他事务的数据，而其他事务随后发生回滚。MySQL 通过三级封锁 协议的第二级解决了脏读，在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上 释放 S 锁。</p></li>
<li><p>不可重复度<br/>
不可重复读是读取到数据后，随后其他事务对数据发生了修改，无法再次读取。MySQL 通过三级封锁协议的第三级解决了不可重复读。在二级的基础上，要求读取数据 A 时必须 加 S 锁，直到事务结束了才能释放 S 锁。</p></li>
<li><p>幻读 <br/>
幻读是读取到数据后，随后其他事务对数据发生了新增，无法再次读取。在 InnoDB 引擎 Repeatable Read 的隔离级别下，MySQL 通过 Next-Key Lock 以及 MVCC 解决了幻读，事务中 分为当前读以及快照读。</p></li>
</ul>

<h2 id="toc_2">事务隔离性</h2>

<p>SQL92规范中对隔离性定义了 4 种隔离级别（隔离性从上向下依次增强，但是导致的问题是并发能力的减弱）：</p>

<ul>
<li>读未提交(READ UNCOMMITED)
<ul>
<li>事物A和事物B，事物A未提交的数据，事物B可以读取到</li>
<li>这种隔离级别最低，这种级别一般是在理论上存在，数据库隔离级别一般都高于该级别</li>
<li>这里读取到的数据叫做“脏数据”</li>
</ul></li>
<li>读已提交(READ COMMITTED)
<ul>
<li>事物A和事物B，事物A提交的数据，事物B才能读取到</li>
<li>这种隔离级别高于读未提交</li>
<li>换句话说，对方事物提交之后的数据，我当前事物才能读取到</li>
<li>这种级别可以避免“脏数据”</li>
<li>这种隔离级别会导致“不可重复读取”</li>
</ul></li>
<li>可重复读(REPEATABLE READ)
<ul>
<li>事务A和事务B，事务A提交之后的数据，事务B读取不到</li>
<li>事务B是可重复读取数据</li>
<li>这种隔离级别高于读已提交</li>
<li>换句话说，对方提交之后的数据，我还是读取不到</li>
<li>这种隔离级别可以避免“不可重复读取”，达到可重复读取</li>
<li>比如1点和2点读到数据是同一个</li>
<li>MySQL默认级别</li>
<li>虽然可以达到可重复读取，但是会导致“幻读”</li>
</ul></li>
<li>序列化(SERIALIZABLE)。
<ul>
<li>事务A和事务B，事务A在操作数据库时，事务B只能排队等待</li>
<li>这种隔离级别很少使用，吞吐量太低，用户体验差</li>
<li>这种级别可以避免“幻像读”，每一次读取的都是数据库中真实存在数据，事务A与事务B串行，而不并发</li>
</ul></li>
</ul>

<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
<th>概念</th>
</tr>
</thead>

<tbody>
<tr>
<td>READ UNCOMMITED</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>事务能够看到其他事务没有提交的修改，当另一个事务又回滚了修改后的情况，又被称为脏读dirty read</td>
</tr>
<tr>
<td>READ COMMITTED</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>事务能够看到其他事务提交后的修改，这时会出现一个事务内两次读取数据可能因为其他事务提交的修改导致不一致的情况，称为不可重复读</td>
</tr>
<tr>
<td>REPEATABLE READ</td>
<td>×</td>
<td>×</td>
<td>√</td>
<td>事务在两次读取时读取到的数据的状态是一致的</td>
</tr>
<tr>
<td>SERIALIZABLE</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>可重复读中可能出现第二次读读到第一次没有读到的数据，也就是被其他事务插入的数据，这种情况称为幻读phantom read, 该级别中不能出现幻读</td>
</tr>
</tbody>
</table>

<p>大多数数据库系统的默认隔离级别都是READ COMMITTED（但MySQL不是)，InnoDB存储引擎默认隔离级别REPEATABLE READ，通过多版本并发控制（MVCC，Multiversion Concurrency Control）解决了幻读的问题。</p>

<h3 id="toc_3">隔离级别的实现原理</h3>

<p>为了解决更新丢失、脏读、不可重复读、幻读的问题，MySQL事务提出了4个不同的隔离级别，而这些隔离级别的实现本质上就是通过加锁，解锁来实现的。</p>

<p>那么我们该何时加锁，占锁多长时间，何时解锁呢？这就是我们今天的主题三级封锁协议。三级封锁协议顾名思义是3个不同级别的封锁协议，它们是以何时加锁，何时解锁来区分的。下面我们看一下具体的定义：</p>

<ul>
<li><p>一级封锁协议<br/>
事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。 一级封锁协议可以防止丢失修改，并保证事务T是可恢复的。使用一级封锁协议可以解决丢失修改问题。在一级封锁协议中，如果仅仅是读数据不对其进行修改，是不需要加锁的，它不能保证可重复读和不读“脏”数据。</p></li>
<li><p>二级封锁协议<br/>
在一级封锁协议之上，事务T在读取数据R之前必须先对其加S锁，读完后方可释放S锁。 二级封锁协议除防止了丢失修改，还可以进一步防止读“脏”数据。但在二级封锁协议中，由于读完数据后即可释放S锁，所以它不能保证可重复读。</p></li>
<li><p>三级封锁协议<br/>
在一级封锁协议之上，事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放。 三级封锁协议除防止了丢失修改和不读“脏”数据外，还进一步防止了不可重复读。</p></li>
</ul>

<p>在继续往下之前，我们需要先搞清楚什么是X锁，S锁。如果我们直接在网上搜索，我们能得到这样的一个关系：</p>

<p>排它锁 == 写锁 == X锁 ， 共享锁 == 读锁 == S锁</p>

<p>简单理解就是如果我对资源A加上了排它锁，那么我既可以读取资源A，也可以插入或更新资源A，而其他人都无法对资源A再加排它锁或共享锁。 如果我对资源A加上了共享锁，那么所有人都不能再对资源A加上排它锁 （包括我自己），而其他人也都可以对资源A再加共享锁。</p>

<p>关于X锁和S锁，我们需要了解，普通的select语句是不需要加锁的，而insert，update，delete，select ... for update 需要加X锁，select ... lock in share mode 这样的语句会加S锁。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解答RabbitMQ]]></title>
    <link href="http://www.throne4j.com/16022464930141.html"/>
    <updated>2020-10-09T20:28:13+08:00</updated>
    <id>http://www.throne4j.com/16022464930141.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">为什么使用消息队列</h2>

<p>首先 消息队列关注于数据的发送和接收，利用高效可靠的异步消息传递机制对分布式系统中的其余各个子系统进行集成。但是它拥有以下优点：</p>

<ul>
<li>高效:对于消息的处理处理速度快。 </li>
<li>可靠:一般消息中间件都会有消息持久化机制和其他的机制确保消息不丢失。 </li>
<li>异步:指发送完一个请求，不需要等待返回，随时可以再发送下一个请求，既不需要等待。</li>
</ul>

<p>使用消息队列可以实现应用之间的解耦、异步调用和削峰填谷。</p>

<p>但是引入消息队列也有如下一些问题：</p>

<ul>
<li>系统的可用性降低</li>
<li>系统的复杂度变高</li>
<li>一致性问题</li>
</ul>

<h2 id="toc_1">使用了消息中间件之后消息可能重复的原因，如何解决？</h2>

<h3 id="toc_2">重复的原因：</h3>

<ul>
<li><p>消息发送端应用重复发送</p>
<ul>
<li>消息发送端发送消息给消息中间件,消息中间件收到消息并成功存储,而这时消息中 间件出现了问题,导致应用端没有收到消息发送成功的返回因而进行重试产生了重 复。</li>
<li>消息中间件因为负载高响应变慢,成功把消息存储到消息存储中后,返回“成功”这 个结果时超时。</li>
<li>消息中间件将消息成功写入消息存储,在返回结果时网络出现问题,导致应用发送端 重试,而重试时网络恢复,由此导致重复。</li>
</ul></li>
<li><p>消息到达了消息存储，由消息中间件进行向外的投递时产生重复</p>
<ul>
<li>消息被投递到消息接收者进行处理，处理完毕后应用出现问题，消息中间件不知道消息的处理结果，会再次投递消息</li>
<li>消息被投递到消息接收者进行处理，处理完毕后网络出现问题，消息中间件不知道消息的处理结果，会再次投递消息</li>
<li>消息被投递到消息接收者进行处理，处理时间比较长，消息中间件因为消息超时会再次投递</li>
<li>消息被投递到消息接收者进行处理，处理完毕后消息中间件出现问题没能收到消息结果并处理，会再次投递消息</li>
<li>消息被投递到消息接收者进行处理，处理完毕消息中间件收到结果，但是遇到消息存储故障，没能更新投递状态，会再次投递消息</li>
</ul></li>
</ul>

<h3 id="toc_3">如何解决消息重复的问题？</h3>

<p>主要是要求消息接收者来处理这种重复的情况,也就是要 求消息接收者的消息处理是幂等操作。</p>

<h4 id="toc_4">什么是幂等性</h4>

<p>对于消息接收端的情况,幂等的含义是采用同样的输入多次调用处理函数,得到同样的结 果。</p>

<h4 id="toc_5">常见幂等的方法</h4>

<p>因此应对消息重复的办法是,使消息接收端的处理是一个幂等操作。这样的做法降低了 消息中间件的整体复杂性,不过也给使用消息中间件的消息接收端应用带来了一定的限制和门槛。</p>

<h5 id="toc_6">MVCC</h5>

<p>多版本并发控制，乐观锁的一种实现，在生产者发送消息时进行数据更新时需要带上数据的版本号，消费者去更新时需要去比较持有的数据版本号，版本号不一致的操作无法成功。</p>

<h5 id="toc_7">去重表</h5>

<p>利用数据库表单的特性来实现幂等，常用的一个思路是在表上构建唯一性索引，保证某<br/>
一类数据一旦执行完毕，后续同样的请求不再重复处理了</p>

<h2 id="toc_8">RabbitMQ中 channel、exchange、queue概念及作用</h2>

<p>Queue 就是消息队列，用于存储消息，具有自己的 erlang 进程。</p>

<p>exchange 内部实现为 保存 binding 关系的查找表;</p>

<p>channel 是实际进行路由工作的实体，即负责按照 routing_key 将 message 投递给 queue 。</p>

<p>在 RabbitMQ 中所有客户端与 RabbitMQ 之间的通讯都是在 channel 上，channel 是真实 TCP 连接之上的虚拟连接，所有 AMQP 命令都是通过 channel 发送的。</p>

<h2 id="toc_9">RabbitMQ 中的元数据有哪些？</h2>

<p>元数据主要分为 </p>

<ul>
<li>Queue 元数据(queue 名字和属性等)</li>
<li>Exchange 元数据(exchange 名字、类型和属性等)</li>
<li>Binding 元数据(存放路由关系的查找表)</li>
<li>Vhost 元数据(vhost 范围内针对前三者的名字空间约束和安全属性设置)，另外在集群中，元数据都是在一个 broker 中都是全局复制的。</li>
</ul>

<h2 id="toc_10">RabbitMQ中的vhost 是什么?起什么作用?</h2>

<p>vhost 可以理解为虚拟 broker ，即一个迷你版的 RabbitMQ server。其内部均含有独立 的 queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段。</p>

<h2 id="toc_11">RabbitMQ 上的一个 queue 中存放的 message 是 否有数量限制?</h2>

<p>默认情况下一般是无限制，因为限制取决于机器的内存，但是消息过多会导致处理效率 的下降。同时可以通过参数来限制， x-max-length :对队列中消息的条数进行限制 ， x-max-length-bytes :对队列中消息的总量进行限制。</p>

<h2 id="toc_12">为什么对所有的 message 都使用持久化机制?</h2>

<p>首先，必然导致性能的下降，因为写磁盘比写内存慢的多，Rabbit 的吞吐量有 10 倍的差距。</p>

<p>其次，message 的持久化机制用在 RabbitMQ 的集群时会出现“坑爹”问题。矛盾点 在于，要实现持久化的话，必须消息、消息队列、交换器三者持久化，如果集群中不同机器 中三者属性有差异，会发生不可预料的问题。</p>

<p>所以一般处理原则是:仅对关键消息作持久化 处理(根据业务重要程度)，且应该保证关键消息的量不会导致性能瓶颈。 </p>

<h2 id="toc_13">RAM node 和 Disk node 的区别？</h2>

<p>RAM node 就是内存节点，Rabbit 中的 queue、exchange 和 binding 等 RabbitMQ 基础 构件中相关元数据保存到内存中，</p>

<p>Disk node 是磁盘节点，上述数据会在内存和磁盘中均进 行存储。</p>

<p>一般在 RabbitMQ 集群中至少存在一个 Disk node.</p>

<h2 id="toc_14">RabbitMQ 如何确保消息的可靠性传输</h2>

<p>因为 MQ 中涉及到了 MQ 本身，生产者和消费，所以需要从三个角度来看</p>

<h3 id="toc_15">生产者</h3>

<p>生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络充斥着不稳定性，有以下几种方案：</p>

<h4 id="toc_16">选择RabbitMQ 提供的事务功能</h4>

<p>选择RabbitMQ的事务功能 就是生产者发送数据之前开启 RabbitMQ 事务(channel.txSelect)，然后发送消息，如果消息没有成功被 RabbitMQ 接收到， 那么生产者会收到异常报错，此时就可以回滚事务(channel.txRollback)，然后重试发送消 息;如果收到了消息，那么可以提交事务(channel.txCommit)。但是问题是，RabbitMQ 事 务机制一搞，基本上吞吐量会下来，因为太耗性能。</p>

<h4 id="toc_17">开启confirm 模式</h4>

<p>在生产者 那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。</p>

<p>如果 RabbitMQ 没能处理这个消息，会回调你一个 nack 接口，告诉你这个消息接收失败，你可以重试。而 且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收 到这个消息的回调，那么你可以重发。</p>

<p>事务机制和 cnofirm 机制最大的不同在于，事务机制是同步的，你提交一个事务之后会 阻塞在那儿，但是 confirm 机制是异步的，你发送个消息之后就可以发送下一个消息，然后 那个消息 RabbitMQ 接收了之后会异步回调你一个接口通知你这个消息接收到了。</p>

<p>所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。</p>

<h3 id="toc_18">RabbitMQ 自身</h3>

<p>RabbitMQ 自己丢数据，这个时候我们就必须开启 RabbitMQ 的持久化，结合confirm模式，等到消息持久化到磁盘之后才会通知生产者，就算这时RabbitMQ挂掉了，我们也可以自己重发。</p>

<h3 id="toc_19">消费端</h3>

<p>RabbitMQ 如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。</p>

<p>这个时候得用 RabbitMQ 提供的 ack 机制，简单来说，就是你关闭 RabbitMQ 自动 ack，进行手动确认，只有程序手动确认消息已消费才会在RabbitMQ中删除消息，这样消息就不会丢啦。</p>

<h2 id="toc_20">RabbitMQ 如何保证消息的顺序性</h2>

<p>从根本上说，异步消息是不应该有顺序依赖的。在 MQ 上估计是没法解决。要实现严格 的顺序消息，简单且可行的办法就是:保证生产者 - MQServer - 消费者是一对一对一的关系。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--队列]]></title>
    <link href="http://www.throne4j.com/16022443352683.html"/>
    <updated>2020-10-09T19:52:15+08:00</updated>
    <id>http://www.throne4j.com/16022443352683.html</id>
    <content type="html"><![CDATA[
<p>RabbitMQ 中消费行为主要跟队列有直接关系，那么我们接下来深入的分析队列。</p>

<h2 id="toc_0">临时队列</h2>

<p>临时队列对应的是没有持久化的队列，也就是如果 RabbitMQ 服务器重启，那么这些队列就不会存在，所以我们称之为临时队列。</p>

<h2 id="toc_1">自动删除队列</h2>

<p>自动删除队列和普通队列在使用上没有什么区别，唯一的区别是，当消费者断开连接时，队列将会被删除。</p>

<p>自动删除队列允许的消费者没有限制， 也就是说当这个队列上最后一个消费者断开连接才会执行删除。</p>

<p>自动删除队列只需要在声明队列时，设置属性 auto-delete 标识为 true 即可</p>

<h2 id="toc_2">单消费者队列</h2>

<p>普通队列允许的消费者没有限制，多个消费者绑定到多个队列时，RabbitMQ 会采用轮询进行投递。如果需要消费者独占队列，在队列创建的时候， 设定属性参数exclusive 为 true。</p>

<h2 id="toc_3">自动过期队列</h2>

<p>指队列在超过一定时间没使用，队列会从 RabbitMQ 中被删除。</p>

<p>什么是没使用?</p>

<ul>
<li>一定时间内没有 Get 操作发生。</li>
<li>没有 Consumer 连接在队列上</li>
</ul>

<p>就算一直有消息进入队列，也不算队列在被使用。 通过声明队列时，设定x-expires 参数即可，单位毫秒。</p>

<h2 id="toc_4">队列的持久性</h2>

<p>持久化队列和非持久化队列的区别是，持久化队列会被保存在磁盘中，固定并持久的存储，当 RabbitMQ 服务重启后，该队列会保持原来的状态在 RabbitMQ 中被管理，而非持久化队列不会被保存在磁盘中，RabbitMQ 服务重启后队列就会消失。</p>

<h2 id="toc_5">队列级别消息过期</h2>

<p>就是为每个队列设置消息的超时时间。只要给队列设置 x-message-ttl 参数，就设定了该队列所有消息的存活时间，时间单位是毫秒。如果声明队列时指定了死信交换器，则过期消息会成为死信消息。</p>

<h2 id="toc_6">队列参数列表</h2>

<table>
<thead>
<tr>
<th>参数</th>
<th>目的</th>
</tr>
</thead>

<tbody>
<tr>
<td>x-dead-letter-exchange</td>
<td>死信交换机</td>
</tr>
<tr>
<td>x-dead-letter-routing-key</td>
<td>死信消息的可选路由键</td>
</tr>
<tr>
<td>x-expires</td>
<td>队列在指定毫秒数后被删除</td>
</tr>
<tr>
<td>x-ha-policy</td>
<td>创建 HA 队列</td>
</tr>
<tr>
<td>x-ha-nodes</td>
<td>HA 队列的分布节点</td>
</tr>
<tr>
<td>x-max-length</td>
<td>队列的最大消息条数</td>
</tr>
<tr>
<td>x-max-length-bytes</td>
<td>消息的最大总量</td>
</tr>
<tr>
<td>x-message-ttl</td>
<td>毫秒为单位的消息过期时间，队列级别</td>
</tr>
<tr>
<td>x-max-prority</td>
<td>最大优先值为255的队列优先排序功能</td>
</tr>
</tbody>
</table>

<h2 id="toc_7">消息的属性</h2>

<p>按照 AMQP 的协议单个最大的消息大小为 16EB(2 的 64 次方)，但是 RabbitMQ 将消息大小限定为 2GB(2的31次方)。<br/>
<figure><img src="media/16022443352683/16022456945696.jpg" alt="" style="width:882px;"/></figure></p>

<p><figure><img src="media/16022443352683/16022457151235.jpg" alt=""/></figure></p>

<h3 id="toc_8">消息存活时间</h3>

<p>当队列消息的 TTL 和消息 TTL 都被设置，时间短的 TTL 设置生效。<br/>
如果将一个过期消息发送给 RabbitMQ，该消息不会路由到任何队列，而是直接丢弃。</p>

<p>为消息设置 TTL 有一个问题:RabbitMQ 只对处于队头的消息判断是否过期(即不会扫描队列)，所以，很可能队列中已存在死消息，但是队列并不 知情。这会影响队列统计数据的正确性，妨碍队列及时释放资源。</p>

<h3 id="toc_9">消息的持久化</h3>

<p>默认情况下，队列和交换器在服务器重启后都会消失，消息当然也是。将队列和交换器的 durable 属性设为 true，缺省为 false，但是消息要持久化还 不够，还需要将消息在发布前，将投递模式设置为 2。消息要持久化，必须要有持久化的队列、交换器和投递模式都为 2 。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--死信交换器 DLX]]></title>
    <link href="http://www.throne4j.com/16022411349774.html"/>
    <updated>2020-10-09T18:58:54+08:00</updated>
    <id>http://www.throne4j.com/16022411349774.html</id>
    <content type="html"><![CDATA[
<p><figure><img src="media/16022411349774/16022427035514.jpg" alt="" style="width:851px;"/></figure></p>

<p>如果使用消息拒绝机制，同时 requeue 参数设置为 false 时，消息丢失了，这点作为程序员我们不能忍。</p>

<p>所以 RabbitMQ 作为一个高级消息中间件，提出了死信交换器的概念，死信，意思就是死了的信息。这种交换器专门处理死了的信息(被拒绝可以重新投递的信息不能算死的)。</p>

<p>死信交换器是 RabbitMQ 对 AMQP 规范的一个扩展，往往用在对问题消息的诊断上(主要针对消费者)，还有延时队列的功能。</p>

<p>消息变成死信一般是以下三种情况:</p>

<ul>
<li>消息被拒绝，并且设置 requeue 参数为 false</li>
<li>消息过期(默认情况下 Rabbit 中的消息不过期，但是可以设置队列的过期时间和消息的过期时间以达到消息过期的效果) </li>
<li>队列达到最大长度(一般当设置了最大队列长度或大小并达到最大值时)</li>
</ul>

<p>死信交换器仍然只是一个普通的交换器，创建时并没有特别要求和操作。在创建队列的时候，声明该交换器将用作保存被拒绝的消息即可，即设置参数 x-dead-letter-exchange 指定哪个交换机为死信交换机。参数 x-dead-letter-routing-key 指定 死信routing-key。</p>

<p><figure><img src="media/16022411349774/16022418380839.jpg" alt=""/></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--消息的消费]]></title>
    <link href="http://www.throne4j.com/16022373268306.html"/>
    <updated>2020-10-09T17:55:26+08:00</updated>
    <id>http://www.throne4j.com/16022373268306.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">消息的获取方式</h2>

<h3 id="toc_1">拉取 Get</h3>

<p>属于一种轮询模型，发送一次 get 请求，获得一个消息。如果此时 RabbitMQ 中没有消息，会获得一个表示空的回复。总的来说，这种方式性能比较 差，很明显，每获得一条消息，都要和 RabbitMQ 进行网络通信发出请求。而且对 RabbitMQ 来说，RabbitMQ 无法进行任何优化，因为它永远不知道应用 程序何时会发出请求。对我们实现者来说，要在一个循环里，不断去服务器 get 消息。</p>

<h3 id="toc_2">推送 Consume</h3>

<p>属于一种推送模型。注册一个消费者后，RabbitMQ 会在消息可用时，自动将消息进行推送给消费者，这种模式我们已经使用过很多次。</p>

<h3 id="toc_3">消息的应答</h3>

<p>消费者收到的每一条消息都必须进行确认。消息确认后，RabbitMQ 才会从队列删除这条消息，RabbitMQ 不会为未确认的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么设计的原因是 RabbitMQ 允许消费者消费一条消 息的时间可以很久很久。</p>

<h3 id="toc_4">自动确认</h3>

<p>消费者在声明队列时，可以指定 autoAck 参数，当 autoAck=true 时，一旦消费者接收到了消息，就视为自动确认了消息。如果消费者在处理消息的过 程中，出了错，就没有什么办法重新处理这条消息，所以我们很多时候，需要在消息处理成功后，再确认消息，这就需要手动确认。</p>

<h3 id="toc_5">手动确认</h3>

<p>当 autoAck=false 时，RabbitMQ 会等待消费者显式发回 ack 信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息。否则，RabbitMQ 会在队列 中消息被消费后立即删除它。</p>

<p>采用消息确认机制后，只要令 autoAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题， 因为 RabbitMQ 会一直持有消息直到消费者显式调用 basicAck 为止。</p>

<p>当 autoAck=false 时，对于 RabbitMQ 服务器端而言，队列中的消息分成了两部分:一部分是等待投递给消费者的消息;一部分是已经投递给消费者， 但是还没有收到消费者 ack 信号的消息。如果服务器端一直没有收到消费者的 ack 信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消 息重新进入队列，等待投递给下一个消费者(也可能还是原来的那个消费者)</p>

<h3 id="toc_6">QoS 预取模式</h3>

<p>在确认消息被接收之前，消费者可以预先要求接收一定数量的消息，在处理完一定数量的消息后，批量进行确认。如果消费者应用程序在确认消息之前崩溃，则所有未确认的消息将被重新发送给其他消费者。所以这里存在着一定程度上的可靠性风险。</p>

<p>这种机制一方面可以实现限速(将消息暂存到 RabbitMQ 内存中)的作用，一方面可以保证消息确认质量(比如确认了但是处理有异常的情况)。</p>

<p><strong>注意</strong>: 消费确认模式必须是非自动 ACK 机制(这个是使用 baseQos 的前提条件，否则会 Qos 不生效)，然后设置 basicQos 的值;另外，还可以基于 consume 和 channel 的粒度进行设置(global)。</p>

<p>basicQos 方法参数详细解释:</p>

<ul>
<li>prefetchSize:最多传输的内容的大小的限制，0 为不限制，但据说 prefetchSize 参数，rabbitmq 没有实现。</li>
<li>prefetchCount:会告诉 RabbitMQ 不要同时给一个消费者推送多于 N 个消息，即一旦有 N 个消息还没有 ack，则该 consumer 将 block 掉，直到有消息 ack</li>
<li>global:true\false 是否将上面设置应用于 channel，简单点说，就是上面限制是 channel 级别的还是 consumer 级别。</li>
</ul>

<p>如果同时设置 channel 和消费者，会怎么样?AMQP 规范没有解释如果使用不同的全局值多次调用 basic.qos 会发生什么。 RabbitMQ 将此解释为意味着两个预取限制应该彼此独立地强制执行; 消费者只有在未达到未确认消息限制时才会收到新消息。 </p>

<h2 id="toc_7">消费者中的事务</h2>

<p>使用方法和生产者一致 假设消费者模式中使用了事务，并且在消息确认之后进行了事务回滚，会是什么样的结果? 结果分为两种情况:</p>

<ul>
<li>autoAck=false 手动应对的时候是支持事务的，也就是说即使你已经手动确认了消息已经收到了，但 RabbitMQ 对消息的确认会等事务的 返回结果，再做最终决定是确认消息还是重新放回队列，如果你手动确认之后，又回滚了事务，那么以事务回滚为准，此条消息会重新放回队列;</li>
<li>autoAck=true 如果自动确认为 true 的情况是不支持事务的，也就是说你即使在收到消息之后在回滚事务也是于事无补的，队列已经把 消息移除了。</li>
</ul>

<h2 id="toc_8">消息的拒绝</h2>

<h3 id="toc_9">Reject 和 Nack</h3>

<p>消息确认可以让 RabbitMQ 知道消费者已经接受并处理完消息。但是如果消息本身或者消息的处理过程出现问题怎么办?需要一种机制通知 RabbitMQ 这个消息我无法处理，请让别的消费者处理。</p>

<p>这里就有两种机制，Reject 和 Nack。</p>

<ul>
<li>Reject 在拒绝消息时，可以使用 requeue 标识，告诉 RabbitMQ 是否需要重新发送给别的消费者。如果是 false 则不重新发送，一般这个消息就会被RabbitMQ 丢弃。Reject 一次只能拒绝一条消息。如果是 true 则消息发生了重新投递。</li>
<li>Nack 跟 Reject 类似，只是它可以一次性拒绝多个消息。也可以使用 requeue 标识，这是 RabbitMQ 对 AMQP 规范的一个扩展。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--消息发布时的权衡]]></title>
    <link href="http://www.throne4j.com/16022331778802.html"/>
    <updated>2020-10-09T16:46:17+08:00</updated>
    <id>http://www.throne4j.com/16022331778802.html</id>
    <content type="html"><![CDATA[
<p>在 RabbitMQ 中，有不同的投递机制(生产者)，但是每一种机制都对性能有一定的影响。一般来讲速度快的可靠性低，可靠性好的性能差，具体怎 么使用需要根据你的应用程序来定，所以说没有最好的方式，只有最合适的方式。只有把你的项目和技术相结合，才能找到适合你的平衡。</p>

<p><figure><img src="media/16022331778802/16022332641946.jpg" alt=""/></figure></p>

<p>在 RabbitMQ 中实际项目中，生产者和消费者都是客户端，它们都可以完成申明交换器、申明队列和绑定关系，但是在我们的实战过程中，我们在生产者代码中申明交换器，在消费者代码中申明队列和绑定关系。</p>

<p>另外还要申明的就是，生产者发布消息时不一定非得需要消费者，对于 RabbitMQ 来说，如果是单纯的生产者你只需要生产者客户端、申明交换器、 申明队列、确定绑定关系，数据就能从生产者发送至 RabbitMQ。</p>

<h2 id="toc_0">无保障</h2>

<p>通过 basicPublish 发布你的消息并使用正确的交换器和路由信息，你的消息会被接收并发送到合适的队列中, 但是如果有网络问题，或者消息不可路由，或者RabbitMQ 自身有问题的话，这种方式就有风险。所以无保证的消息发送一般情况下不推荐。</p>

<h2 id="toc_1">失败确认</h2>

<p>在发送消息时设置 mandatory = true 标志，告诉 RabbitMQ，如果消息不可路由，应该将消息返回给发送者，并通知失败。可以这样认为，开启 mandatory 是开启故障检测模式。</p>

<p>注意:它只会让 RabbitMQ 向你通知失败，而不会通知成功。如果消息正确路由到队列，则发布者不会受到任何通知。带来的问题是无法确保发布消 息一定是成功的，因为通知失败的消息可能会丢失。</p>

<p>channel.addConfirmListener 则用来监听 RabbitMQ 发回的信息。</p>

<h2 id="toc_2">事务</h2>

<p>事务的实现主要是对信道(Channel)的设置，主要的方法有三个:</p>

<ul>
<li>channel.txSelect()声明启动事务模式;</li>
<li>channel.txComment()提交事务;</li>
<li>channel.txRollback()回滚事务;</li>
</ul>

<p>在发送消息之前，需要声明 channel 为事务模式，提交或者回滚事务即可。 开启事务后，客户端和 RabbitMQ 之间的通讯交互流程:</p>

<ul>
<li>客户端发送给服务器 Tx.Select(开启事务模式)</li>
<li>服务器端返回 Tx.Select-Ok(开启事务模式 ok)  推送消息</li>
<li>客户端发送给事务提交 Tx.Commit</li>
<li>服务器端返回 Tx.Commit-Ok</li>
</ul>

<p>以上就完成了事务的交互流程，如果其中任意一个环节出现问题，就会抛出 IoException，这样用户就可以拦截异常进行事务回滚，或决定要不要重<br/>
复消息。</p>

<p>既然已经有事务了，为何还要使用发送方确认模式呢，原因是因为事务的性能是非常差的。根据相关资料，事务会降低 2~10 倍的性能。</p>

<h2 id="toc_3">发送方确认模式</h2>

<p>基于事务的性能问题，RabbitMQ 团队为我们拿出了更好的方案，即采用发送方确认模式，该模式比事务更轻量，性能影响几乎可以忽略不计。</p>

<p>原理:生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式，所有在该信道上面发布的消息都将会被指派一个唯一的 ID(从 1 开始)，由这个 id 在生产者和 RabbitMQ 之间进行消息的确认。 </p>

<p>不可路由的消息，当交换器发现，消息不能路由到任何队列，会进行确认操作，表示收到了消息。如果发送方设置了 mandatory 模式,则会先调用 addReturnListener 监听器。</p>

<p>可路由的消息，要等到消息被投递到所有匹配的队列之后，broker 会发送一个确认给生产者(包含消息的唯一 ID)，这就使得生产者知道消息已经正确 到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker 回传给生产者的确认消息中 delivery-tag 域包含了 确认消息的序列号。</p>

<p>confirm 模式最大的好处在于它可以是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消息，生产者应用程序同样可以在回调方法中处理该 nack 消息决定下一步的处理。</p>

<p>Confirm 的三种实现方式:</p>

<ul>
<li>channel.waitForConfirms() 普通发送方确认模式，消息到达交换机，机会返回 true</li>
<li>channel.waitForConfirmsOrDie() 批量确认模式，使用同步方式等所有的消息发送之后才会执行后面代码，只要有一个小心未到达交换器就会抛出 IOException 异常</li>
<li>channel.addConfirmListener()一步监听发送方确认模式</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ--AMQP 概论]]></title>
    <link href="http://www.throne4j.com/16022252063226.html"/>
    <updated>2020-10-09T14:33:26+08:00</updated>
    <id>http://www.throne4j.com/16022252063226.html</id>
    <content type="html"><![CDATA[
<p>AMQP 是应用层协议的一个开放标准, 为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。目标是实现一种在全行业广泛使用的标准消息中间件技术，以便降低企业和系统集成的开销，并且向大众提供工业级的集成服务。 主要实现有 RabbitMQ。</p>

<h2 id="toc_0">客户端与 RabbitMQ 的通讯</h2>

<h3 id="toc_1">连接</h3>

<p>首先作为客户端(无论是生产者还是消费者)，如果要与 RabbitMQ 通讯的话，客户端与服务端之间必须创建一条 TCP 连接，当然同时建立连接后，客户端还必须发送一条“问候语”让彼此知道我们都是符合 AMQP 的语言的，比如你跟别人打招呼一般会说“你好!”，你跟国外的美女一般会说“hello!”一样。 你们确认好“语言”之后，就相当于客户端和 RabbitMQ 通过“认证”了。你们之间可以创建一条 AMQP 的信道。</p>

<p>连接在 RabbitMQ 原生客户端(5.0.0)版本中默认使用 java 的原生 socket，但是也支持 NIO，需要手动设置修改。</p>

<h3 id="toc_2">信道</h3>

<p>信道是生产者/消费者与 RabbitMQ 通信的渠道。信道是建立在 TCP 连接上的虚拟连接，什么意思呢? 就是说 rabbitmq 在一条 TCP 上建立成百上千个信道来达到多个线程处理，这个 TCP 被多个线程共享，每个线程对应一个信道，信道在RabbitMQ 都有唯一的 ID ,保证了信道私有性，对应上唯一的线程使用。</p>

<p>疑问: 为什么不建立多个 TCP 连接呢? </p>

<p>原因是 rabbit 保证性能，系统为每个线程开辟一个 TCP 是非常消耗性能，每秒成百上千的建立销毁 TCP 会严重消耗系统。</p>

<p>所以 rabbitmq 选择建立多个信道(建立在 tcp 的虚拟连接)连接到 rabbit 上。<br/>
从技术上讲，这被称之为“多路复用”，对于执行多个任务的多线程或者异步应用程序来说，好使的很。</p>

<h2 id="toc_3">RabbitMQ 中使用 AMQP</h2>

<h3 id="toc_4">包括的要素</h3>

<ul>
<li>生产者<br/>
消息的创建者，发送到RabbitMQ</li>
<li>消费者<br/>
连接到 RabbitMQ 订阅到队列上，消费消息，持续订阅(basicConsumer)和单条订阅(basicGet)</li>
<li>包含有效载荷和标签，有效载荷指要传输的数据，标签描述了有效载荷，并且 RabbitMQ用它来决定谁获得消息，消费者只能拿到有效载荷，病不知道生产者是谁。</li>
</ul>

<h3 id="toc_5">交换器、队列、绑定、路由键</h3>

<p>队列通过路由键(routing key，某种确定的规则)绑定到交换器，生产者将消息发布到交换器，交换器根据绑定的路由键将消息路由到特定队列， 然后由订阅这个队列的消费者进行接收。（routing_key和 丙丁见 binding_key 的最大长度是 255 个字节）</p>

<p><figure><img src="media/16022252063226/16022280502106.jpg" alt="" style="width:882px;"/></figure></p>

<h3 id="toc_6">消息的确认</h3>

<p>消费者收到的每一条消息都必须进行确认(自动确认和自行确认)。</p>

<p>消费者在声明队列时，可以指定 autoAck 参数，当 autoAck=false 时，RabbitMQ 会等待消费者显式发回 ack 信号后才从内存(和磁盘，如果是持久化消<br/>
息的话)中移去消息。否则，RabbitMQ 会在队列中消息被消费后立即删除它。</p>

<p>采用消息确认机制后，只要令 autoAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题， 因为 RabbitMQ 会一直持有消息直到消费者显式调用 basicAck 为止。</p>

<p>当 autoAck=false 时，对于 RabbitMQ 服务器端而言，队列中的消息分成了两部分:一部分是等待投递给消费者的消息;一部分是已经投递给消费者， 但是还没有收到消费者 ack 信号的消息。如果服务器端一直没有收到消费者的 ack 信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消 息重新进入队列，等待投递给下一个消费者(也可能还是原来的那个消费者)。</p>

<p>RabbitMQ 不会为未 ack 的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么 设计的原因是 RabbitMQ 允许消费者消费一条消息的时间可以很久很久</p>

<h2 id="toc_7">虚拟主机</h2>

<p>虚拟消息服务器，vhost，本质上就是一个 mini 版的 mq 服务器，有自己的队列、交换器和绑定，最重要的，自己的权限机制。Vhost 提供了逻辑上的 分离，可以将众多客户端进行区分，又可以避免队列和交换器的命名冲突。Vhost 必须在连接时指定，rabbitmq 包含缺省 vhost:“/”，通过缺省用户和 口令 guest 进行访问。</p>

<p>rabbitmq 里创建用户，必须要被指派给至少一个 vhost，并且只能访问被指派内的队列、交换器和绑定。Vhost 必须通过 rabbitmq 的管理控制工具创建。</p>

<h2 id="toc_8">交换器类型</h2>

<p>共有四种 direct、fanout、topic、headers，其中headers和 direct 可以忽略。</p>

<h3 id="toc_9">fanout</h3>

<p>消息广播到绑定的队列，不管队列绑定了什么路由键，消息经过交换器，每个队列都有一份</p>

<h3 id="toc_10">Topic</h3>

<p><code>通过使用 “*”和“#”通配符进行处理，使来自不同源头的消息到达同一个队列，”.”将路由键分为了几个标识符，“*” 匹配 1 个，“#”匹配一个或多个。</code></p>

<p><figure><img src="media/16022252063226/16022297347390.jpg" alt="" style="width:799px;"/></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[什么是消息中间件]]></title>
    <link href="http://www.throne4j.com/16021705401610.html"/>
    <updated>2020-10-08T23:22:20+08:00</updated>
    <id>http://www.throne4j.com/16021705401610.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">消息中间件(MQ)的定义</h2>

<p>其实并没有标准定义。一般认为，消息中间件属于分布式系统中一个子系统，关注于数据的发送和接收，利用高效可靠的异步消息传递机制对分布式系统中的其余各个子系统进行集成。</p>

<ul>
<li>高效:对于消息的处理处理速度快。 </li>
<li>可靠:一般消息中间件都会有消息持久化机制和其他的机制确保消息不丢失。 </li>
<li>异步:指发送完一个请求，不需要等待返回，随时可以再发送下一个请求，既不需要等待。 </li>
</ul>

<p>一句话总结，我们消息中间件不生产消息，只是消息的搬运工。</p>

<h2 id="toc_1">为什么要用消息中间件?</h2>

<p>所以消息中间件主要解决分布式系统之间消息的传递，同时为分布式系统中其他子系统提供了松耦合的架构，同时还有以下好处。</p>

<ul>
<li><p>低耦合<br/>
低耦合，不管是程序还是模块之间，使用消息中间件进行间接通信。</p></li>
<li><p>异步通信能力<br/>
异步通信能力，使得子系统之间得以充分执行自己的逻辑而无需等待。</p></li>
<li><p>缓冲能力<br/>
缓冲能力，消息中间件像是一个巨大的蓄水池，将高峰期大量的请求存储下来慢慢交给后台进行处理，对于秒杀业务来说尤为重要。</p></li>
<li><p>伸缩性<br/>
伸缩性，是指通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。就像弹簧一样挂东西一样，用 户多，伸一点，用户少，浅一点，啊，不对，缩一点。是伸缩，不是深浅。衡量架构是否高伸缩性的主要标准就是是否可用多台服务器构建集群，是否 容易向集群中添加新的服务器。加入新的服务器后是否可以提供和原来服务器无差别的服务。集群中可容纳的总的服务器数量是否有限制。</p></li>
<li><p>扩展性<br/>
扩展性，主要标准就是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。比如用户购买电影票的应用，现在我们要增加一个功能，用户买了铁血战士的票后，随机抽取用户送异形的限量周边。怎么做到不改动用户购票功能的基础上增加这个功能。熟悉设计模式的同学，应该很眼熟，这是设计模式中的开闭原则(对扩展开放，对修改关闭)在架构层面的一个原则。</p></li>
</ul>

<h2 id="toc_2">和 RPC 有何区别?</h2>

<p>RPC 和消息中间件的场景的差异很大程度上在于就是“依赖性”和“同步性”。</p>

<ul>
<li>依赖性:<br/>
比如短信通知服务并不是事交易环节必须的，并不影响下单流程，不是强依赖，所以交易系统不应该依赖短信服务。如果是 RPC 调用，短信通知服 务挂了，整个业务就挂了，这个就是依赖性导致的，而消息中间件则没有这个依赖性。</li>
</ul>

<p>消息中间件出现以后对于交易场景可能是调用库存中心等强依赖系统执行业务，之后发布一条消息(这条消息存储于消息中间件中)。像是短信通 知服务、数据统计服务等等都是依赖于消息中间件去消费这条消息来完成自己的业务逻辑。</p>

<ul>
<li>同步性:<br/>
RPC 方式是典型的同步方式，让远程调用像本地调用。消息中间件方式属于异步方式。</li>
</ul>

<h2 id="toc_3">消息中间件有些什么使用场景?</h2>

<h3 id="toc_4">异步处理</h3>

<p>场景说明: 用户注册后，需要发注册邮件和注册短信。</p>

<p>传统的做法有两种 </p>

<ul>
<li>串行的方式<br/>
将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。</li>
<li>并行方式<br/>
将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并 行的方式可以提高处理的时间。
<figure><img src="media/16021705401610/16021728568093.jpg" alt="串行"/><figcaption>串行</figcaption></figure></li>
</ul>

<p><figure><img src="media/16021705401610/16021728464187.jpg" alt="并行"/><figcaption>并行</figcaption></figure></p>

<p>上案例描述，传统的方式系统的性能(并发量，吞吐量，响应时间)会有瓶颈。如何解决这个问题呢? </p>

<p>引入消息队列，将不是必须的业务逻辑，异步处理。</p>

<p><figure><img src="media/16021705401610/16021712978489.jpg" alt="" style="width:560px;"/></figure></p>

<p>按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是 50 毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入 消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是 50 毫秒。因此架构改变后，系统的吞吐量提高到每秒 20 QPS。比串行提高了 3 倍，比 并行提高了两倍。</p>

<h3 id="toc_5">应用解耦</h3>

<p>场景说明:用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。</p>

<p>传统模式的缺点:</p>

<ul>
<li>1) 假如库存系统无法访问，则订单减库存将失败，从而导致订单失败;</li>
<li>2) 订单系统与库存系统耦合;</li>
</ul>

<p>如何解决以上问题呢?引入应用消息队列后的方案</p>

<p>订单系统:用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。 </p>

<p>库存系统:订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。</p>

<p>假如:在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与 库存系统的应用解耦。</p>

<h3 id="toc_6">流量削峰</h3>

<p>流量削峰也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。</p>

<p>应用场景:秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列:可以控制活动的人数;可以缓解短时间内高流量压垮应用。</p>

<h3 id="toc_7">日志处理</h3>

<p>日志处理是指将消息队列用在日志处理中，比如 Kafka 的应用，解决大量日志传输的问题。架构简化如下:<br/>
<figure><img src="media/16021705401610/16022199054947.jpg" alt="" style="width:623px;"/></figure></p>

<p>日志采集客户端，负责日志数据采集，定时写入 Kafka 队列:Kafka 消息队列，负责日志数据的接收，存储和转发;日志处理应用:订阅并消费 kafka 队列中的日志数据;</p>

<h3 id="toc_8">消息通讯</h3>

<p>消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。 点对点通讯:客户端 A 和客户端 B 使用同一队列，进行消息通讯。<br/>
聊天室通讯:客户端 A，客户端 B，客户端 N 订阅同一主题，进行消息发布和接收。实现类似聊天室效果。</p>

<h2 id="toc_9">常见的消息中间件比较</h2>

<p><figure><img src="media/16021705401610/16022199788204.jpg" alt="" style="width:1025px;"/></figure></p>

<p>如果一般的业务系统要引入 MQ，怎么选型:</p>

<p>用户访问量在 ActiveMQ 的可承受范围内，而且确实主要是基于解耦和异步来用的，可以考虑 ActiveMQ，也比较贴近 Java 工程师的使用习惯，但是<br/>
ActiveMQ 现在停止维护了，同时 ActiveMQ 并发不高，所以业务量一定的情况下可以考虑使用。</p>

<p>RabbitMQ 作为一个纯正血统的消息中间件，有着高级消息协议 AMQP 的完美结合，在消息中间件中地位无可取代，但是 erlang 语言阻止了我们去深入研究和掌控，对公司而言，底层技术无法控制，但是确实是开源的，有比较稳定的支持，活跃度也高。</p>

<p>对自己公司技术实力有绝对自信的，可以用 RocketMQ，但是 RocketMQ 诞生比较晚，并且更新迭代很快，这个意味着在使用过程中有可能会遇到很多坑，所以如果你们公司 Java 技术不是很强，不推荐使用。</p>

<p>如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，几乎是全世界这个领域的事实性规范。 </p>

<p>从性能上来看，使用文件系统的消息中间件(kafka、rokcetMq)性能是最好的，所以基于文件系统存储的消息中间件是发展趋势。(从存储方式和效率来看 文件系统&gt;KV存储&gt;关系型数据库)</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Collection 体系]]></title>
    <link href="http://www.throne4j.com/16020916538677.html"/>
    <updated>2020-10-08T01:27:33+08:00</updated>
    <id>http://www.throne4j.com/16020916538677.html</id>
    <content type="html"><![CDATA[
<p>Collection 集合体系是 List、 Set 和 Queue 的接口</p>

<p>List 特点： 存取有序，可以根据索引来直接取值<br/>
Set 特点： 存取无序，元素不可以重复<br/>
Queue特点： 存取有序，两端进出元素</p>

<h2 id="toc_0">List 系集合</h2>

<ul>
<li>ArrayList: 底层由数组实现，排列有序，元素可重复，线程不安全，按照 当前容量*1.5 + 1 进行扩容。</li>
<li>Vector ：</li>
<li>LinkedList</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[伪共享]]></title>
    <link href="http://www.throne4j.com/16020533928895.html"/>
    <updated>2020-10-07T14:49:52+08:00</updated>
    <id>http://www.throne4j.com/16020533928895.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">定义</h2>

<p>缓存系统中是以缓存行（cache line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。</p>

<h2 id="toc_1">缓存行</h2>

<p>CPU 缓存（Cache Memory）是位于 CPU 与内存之间的临时存储器，它的容量比内存小的多但是交换速度却比内存要快得多。</p>

<p>高速缓存的出现主要是为了解决 CPU 运算速度与内存读写速度不匹配的矛盾，因为 CPU 运算速度要比内存读写速度快很多，这样会使 CPU 花费很长时间等待数据到来或把数据写入内存。</p>

<p>在缓存中的数据是内存中的一小部分，但这一小部分是短时间内 CPU 即将访问的，当 CPU 调用大量数据时，就可避开内存直接从缓存中调用，从而加快读取速度。</p>

<p>因此为了 CPU 更快从内存中读取数据，设置了多级缓存机制，如下图所示：<br/>
<figure><img src="media/16020519457966/16020586138762.jpg" alt=""/></figure></p>

<p>当 CPU 运算时，首先会从 L1 缓存查找所需要的数据，如果没有找到，再去 L2 缓存中去找，以此类推，直到从内存中获取数据，这也就意味着，越长的调用链，所耗费的执行时间也越长。</p>

<p>那是不是可以从主内存拿数据的时候，顺便多拿一些呢？这样就可以避免频繁从主内存中获取数据了。聪明的计算机科学家已经想到了这个法子，这就是缓存行的由来。</p>

<p>缓存是由多个缓存行组成的，而<strong>每个缓存行大小通常来说，大小为 64 字节</strong>，并且每个缓存行有效地引用主内存中的一块儿地址，CPU 每次从主内存中获取数据时，会将相邻的数据也一同拉取到缓存行中，这样当 CPU 执行运算时，就大大减少了与主内存的交互。</p>

<pre><code class="language-java">public class CacheLineDemo {

    //一般缓存行大小是64字节，一个 long 类型占8字节
    static long[][] arr;

    public static void main(String[] args) {

        int size = 1024 * 1024;

        arr = new long[size][];
        for (int i = 0; i &lt; size; i++) {
            arr[i] = new long[8];
            for (int j = 0; j &lt; 8; j++) {
                arr[i][j] = 0L;
            }
        }
        long sum = 0L;
        long marked = System.currentTimeMillis();
        for (int i = 0; i &lt; size; i++) {
            for (int j = 0; j &lt; 8; j++) {
                sum = arr[i][j];
            }
        }
        System.out.println(&quot;[cache line]Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;);

        marked = System.currentTimeMillis();
        for (int i = 0; i &lt; 8; i += 1) {
            for (int j = 0; j &lt; size; j++) {
                sum = arr[j][i];
            }
        }
        System.out.println(&quot;[no cache line]Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;);
    }

}
</code></pre>

<h2 id="toc_2">伪共享问题</h2>

<p>当 CPU 执行完后，还需要将数据回写到内存上，以便于别的线程可以从主内存中获取最新的数据。假设两个线程都加载了相同的 Cache line 数据，会产生什么样的影响呢？下面我用一张图解释：</p>

<p><figure><img src="media/16020519457966/16020585354167.jpg" alt=""/></figure></p>

<p>数据 A、B、C 被加载到同一个 Cache line，假设线程 1 在 core1 中修改 A，线程 2 在 core2 中修改 B。</p>

<p>线程 1 首先对 A 进行修改，这时 core1 会告知其它 CPU 核，当前引用同一地址的 Cache line 已经无效，随后 core2 发起修改 B，会导致 core1 将数据回写到主内存中，core2 这时会重新从主内存中读取该 Cache line 数据。</p>

<p>可见，如果同一个 Cache line 的内容被多个线程读取，就会产生相互竞争，频繁回写主内存，降低了性能。</p>

<h2 id="toc_3">如何解决伪共享问题</h2>

<p>要解决伪共享这个问题最简单的做法就是将线程间共享元素分开到不同的 Cache line 中，这种做法叫用空间换取时间，具体做法如下：</p>

<pre><code class="language-java">public final static class ValuePadding {
  // 前置填充对象
  protected long p1, p2, p3, p4, p5, p6, p7;
  // value 值
  protected volatile long value = 0L;
  // 后置填充对象
  protected long p9, p10, p11, p12, p13, p14, p15;
}
</code></pre>

<p>JDK1.8 有专门的注解 @Contended 来避免伪共享，为了更加直观，我使用了对象填充的方法，其中 protected long p1, p2, p3, p4, p5, p6, p7 作为前置填充对象，protected long p9, p10, p11, p12, p13, p14, p15作为后置填充对象，这样任意线程访问 ValuePadding 时，value 都处于不同的 Cache line 中，不会产生伪共享问题。</p>

<p>下面的例子用来演示伪共享与解决伪共享后的性能差异：</p>

<pre><code class="language-java">public class FakeShareDemo {

    public static void main(String[] args) throws InterruptedException {
        for (int i = 1; i &lt; 10; i++) {
            System.gc();
            final long start = System.currentTimeMillis();
            runTest(Type.PADDING, i);
            System.out.println(&quot;[PADDING]Thread num &quot; + i + &quot; duration = &quot; + (System.currentTimeMillis() - start));
        }

        for (int i = 1; i &lt; 10; i++) {
            System.gc();
            final long start = System.currentTimeMillis();
            runTest(Type.NO_PADDING, i);
            System.out.println(&quot;[NO_PADDING] Thread num &quot; + i + &quot; duration = &quot; + (System.currentTimeMillis() - start));
        }
    }

    private static void runTest(Type type, int NUM_THREADS) throws InterruptedException {
        Thread[] threads = new Thread[NUM_THREADS];

        switch (type) {
            case PADDING:
                DataPadding.longs = new ValuePadding[NUM_THREADS];
                for (int i = 0; i &lt; DataPadding.longs.length; i++) {
                    DataPadding.longs[i] = new ValuePadding();
                }
                break;
            case NO_PADDING:
                Data.longs = new ValueNoPadding[NUM_THREADS];
                for (int i = 0; i &lt; Data.longs.length; i++) {
                    Data.longs[i] = new ValueNoPadding();
                }
                break;
        }


        for (int i = 0; i &lt; threads.length; i++) {
            threads[i] = new Thread(new FakeSharing(type, i));
        }
        for (Thread t : threads) {
            t.start();
        }
        for (Thread t : threads) {
            t.join();
        }
    }

    // 线程执行单元
    static class FakeSharing implements Runnable {
        public final static long ITERATIONS = 500L * 1000L * 100L;
        private int arrayIndex;
        private Type type;

        public FakeSharing(Type type, final int arrayIndex) {
            this.arrayIndex = arrayIndex;
            this.type = type;
        }

        public void run() {
            long i = ITERATIONS + 1;
            // 读取共享变量中指定的下标对象，并对其value变量不断修改
            // 由于每次读取数据都会写入缓存行，如果线程间有共享的缓存行数据，就会导致伪共享问题发生
            // 如果对象已填充，那么线程每次读取到缓存行中的对象就不会产生伪共享问题
            switch (type) {
                case NO_PADDING:
                    while (0 != --i) {
                        Data.longs[arrayIndex].value = 0L;
                    }
                    break;
                case PADDING:
                    while (0 != --i) {
                        DataPadding.longs[arrayIndex].value = 0L;
                    }
                    break;
            }
        }
    }

    // 线程间贡献的数据
    public final static class Data {
        public static ValueNoPadding[] longs;
    }

    public final static class DataPadding {
        public static ValuePadding[] longs;
    }

    // 使用填充对象
    public final static class ValuePadding {
        // 前置填充对象
        protected long p1, p2, p3, p4, p5, p6;
        // value 值
        protected volatile long value = 0L;
        // 后置填充对象
        protected long p9, p10, p11, p12, p13, p14, p15;
    }

    // 不填充对象
    //    @sun.misc.Contended
    public final static class ValueNoPadding {
        protected volatile long value = 0L;
    }

    enum Type {
        NO_PADDING,
        PADDING
    }
}
</code></pre>

]]></content>
  </entry>
  
</feed>
