<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大爷来玩儿啊~]]></title>
  <link href="http://www.throne4j.com/atom.xml" rel="self"/>
  <link href="http://www.throne4j.com/"/>
  <updated>2021-03-11T17:31:25+08:00</updated>
  <id>http://www.throne4j.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[锁在应用层的优化思路]]></title>
    <link href="http://www.throne4j.com/16149180511136.html"/>
    <updated>2021-03-05T12:20:51+08:00</updated>
    <id>http://www.throne4j.com/16149180511136.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">减少锁持有时间</h2>

<h2 id="toc_1">减少锁颗粒度</h2>

<h2 id="toc_2">锁分离 读写分离、condition</h2>

<h2 id="toc_3">锁粗化</h2>

<h2 id="toc_4">CAS 无锁操作</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux 性能监控工具]]></title>
    <link href="http://www.throne4j.com/16149089246443.html"/>
    <updated>2021-03-05T09:48:44+08:00</updated>
    <id>http://www.throne4j.com/16149089246443.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">监控内存和cpu----vmstat 命令</h2>

<p>vmstat 也是一款功能比较齐全的性能监测工具。它可以统计 cpu、内存使用情况、swap使用情况等信息</p>

<p>如下面样例，每秒采样一次，共计三次</p>

<pre><code class="language-text">[goddess@goddess ~]$ vmstat 1 3
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 2522180   2108 178404    0    0   398    31  234  645  3  4 93  0  0
 0  0      0 2522180   2108 178404    0    0     0     0   72   76  0  0 100  0  0
 0  0      0 2522180   2108 178404    0    0     0     0   65   72  0  0 100  0  0
</code></pre>

<p><figure><img src="media/16149089246443/16149092459844.jpg" alt="" style="width:1360px;"/></figure></p>

<h2 id="toc_1">监控 IO使用 ---- iostat命令</h2>

<p><figure><img src="media/16149089246443/16149094486626.jpg" alt="" style="width:821px;"/></figure></p>

<p>以上命令显示了 cpu的使用概况和磁盘IO信息</p>

<p>-d 表示输出磁盘使用情况，输出结果中各个列的含义如下</p>

<ul>
<li>tps 该设备每秒的传输次数</li>
<li>kB_read/s 每秒向设备读取的数据量</li>
<li>kB_wrtn/s 每秒向设备写入的数据量</li>
<li>kB_read 读取的总数据量</li>
<li>kB_wrtn 写入的总数据量</li>
</ul>

<p>磁盘IO很容易成为系统性能瓶颈，通过iostat 可以快速定位系统是否产生了大量的 IO 操作</p>

<h2 id="toc_2">多功能诊断器---pidstat 工具</h2>

<p>pidstat 的强大之处在于，它不仅可以监控进程的性能情况，也可以监控线程的性能情况</p>

<h3 id="toc_3">cpu使用率监控---cpu 100%的问题就定位</h3>

<p>通过 jps 获取到 java 程序的 PID,然后使用 pidstat 命令输出程序的 CPU 使用情况</p>

<p><figure><img src="media/16149089246443/16149102989293.jpg" alt="" style="width:1245px;"/></figure><br/>
<figure><img src="media/16149089246443/16149108660024.jpg" alt="" style="width:1352px;"/></figure></p>

<p>pidstat 的参数 -p 用于指定进程ID，-u表示对cpu使用率监控，1 3 表示每秒采样一次，总计3次<br/>
从图中可以看出 cpu使用率几乎100%</p>

<p>然后更进一步监控线程信息</p>

<p>使用命令</p>

<pre><code class="language-text">pidstat -p 1187 1 3 -u -t
</code></pre>

<p><figure><img src="media/16149089246443/16149110180994.jpg" alt="" style="width:1352px;"/></figure></p>

<p>参数 -t 将系统性能的监控细化到线程级别。从输出中可以知道，该java应用程序值所以占用如此高的 cpu，是因为 1204 线程的缘故</p>

<p>知道是java程序的哪个线程引起的 cpu 100% 之后，使用 jstack -l 1187 查看线程信息，需要注意的一点是 jstack 的线程ID使用的是 16进制，pidstat 显示的是10进制，需要做一下进制转换</p>

<pre><code class="language-text"># 查看 java 进程的线程信息
jstack -l 1187 
</code></pre>

<p><figure><img src="media/16149089246443/16149113584147.jpg" alt="" style="width:1349px;"/></figure></p>

<p>从结果图中看到 0x4b4 正是引起 cpu 100%的元凶，如此 造成 cpu 100%的问题就定位到了</p>

<h3 id="toc_4">IO 使用监控</h3>

<p><figure><img src="media/16149089246443/16149117818370.jpg" alt="" style="width:801px;"/></figure></p>

<p>进程PID ： 22796 ，程序中的线程 22813 疯狂写入磁盘，在使用 jstack -l 22796 查看程序的线程信息，定位到时哪个任务线程一直在写磁盘</p>

<h3 id="toc_5">内存监控</h3>

<p><figure><img src="media/16149089246443/16149119690277.jpg" alt="" style="width:802px;"/></figure><br/>
<figure><img src="media/16149089246443/16149119788091.jpg" alt="" style="width:808px;"/></figure></p>

<p>输出各列的含义如下：</p>

<ul>
<li>minflt/s 表示该进程每秒 minor faults(不需要从磁盘中调出内存页)的总数</li>
<li>majflt/s 表示该进程每秒major faults(需要从磁盘中调出内存页)的总数</li>
<li>VSZ: 表示该进程使用 虚拟内存大小，单位 kb</li>
<li>RSS: 表示该进程占用物理内存大小，单位 kb</li>
<li>%MEM: 表示占用内存比率</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[问题排查]]></title>
    <link href="http://www.throne4j.com/16148692234611.html"/>
    <updated>2021-03-04T22:47:03+08:00</updated>
    <id>http://www.throne4j.com/16148692234611.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">CPU占用过高排查</h2>

<h3 id="toc_1">TOP 工具</h3>

<p>使用top命令查看进程各种运行状况，请参考<a href="15983681960215.html">linux和macOS下top命令区别</a></p>

<p>1、先通过 top 命令找到消耗 cpu 很高的进程 PID<br/>
<figure><img src="media/15962980278783/15983692600595.jpg" alt="" style="width:1008px;"/></figure></p>

<p>2、执行 top -p PID 单独监控该进程<br/>
3、在第 2 步的监控界面输入 H，获取当前进程下的所有线程信息<br/>
4、找到消耗 cpu 特别高的线程编号，假设是 2734(要等待一阵)<br/>
5、执行 jstack PID 对当前的进程做 dump，输出所有的线程信息<br/>
6、将第 4 步得到的线程编号 PID 转成 16 进制是 0x???<br/>
7、根据第 6 步得到的 0x??? 在第 5 步的线程信息里面去找对应线程内容<br/>
8、解读线程信息，定位具体代码位置，此处可能并不是代码问题引起的cpu占用过高，可能由于 GC 引起频繁的垃圾回收，可使用jstat -gc 250 10查看gc统计情况<a href="%5B%E5%9B%9B%E3%80%81JVM%E8%87%AA%E5%8A%A8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86--%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%EF%BC%8C%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%5D(15773440983590.html)"></a></p>

<h3 id="toc_2">pidstat 工具</h3>

<p>pidstat 的强大之处在于，它不仅可以监控进程的性能情况，也可以监控线程的性能情况</p>

<p>通过 jps 获取到 java 程序的 PID,然后使用 pidstat 命令输出程序的 CPU 使用情况</p>

<p><figure><img src="media/16149089246443/16149102989293.jpg" alt="" style="width:1245px;"/></figure><br/>
<figure><img src="media/16149089246443/16149108660024.jpg" alt="" style="width:1352px;"/></figure></p>

<p>pidstat 的参数 -p 用于指定进程ID，-u表示对cpu使用率监控，1 3 表示每秒采样一次，总计3次<br/>
从图中可以看出 cpu使用率几乎100%</p>

<p>然后更进一步监控线程信息</p>

<p>使用命令</p>

<pre><code class="language-text">pidstat -p 1187 1 3 -u -t
</code></pre>

<p><figure><img src="media/16149089246443/16149110180994.jpg" alt="" style="width:1352px;"/></figure></p>

<p>参数 -t 将系统性能的监控细化到线程级别。从输出中可以知道，该java应用程序值所以占用如此高的 cpu，是因为 1204 线程的缘故</p>

<p>知道是java程序的哪个线程引起的 cpu 100% 之后，使用 jstack -l 1187 查看线程信息，需要注意的一点是 jstack 的线程ID使用的是 16进制，pidstat 显示的是10进制，需要做一下进制转换</p>

<pre><code class="language-text"># 查看 java 进程的线程信息
jstack -l 1187 
</code></pre>

<p><figure><img src="media/16149089246443/16149113584147.jpg" alt="" style="width:1349px;"/></figure></p>

<p>从结果图中看到 0x4b4 正是引起 cpu 100%的元凶，如此 造成 cpu 100%的问题就定位到了</p>

<h2 id="toc_3">内存占用过高</h2>

<p>可以使用jmap命令来查看堆空间信息<br/>
打印出排名前20的对象<br/>
jmap –histo JVM_ID | head -20</p>

<p><figure><img src="media/15962980278783/15983702156050.jpg" alt=""/></figure></p>

<p>从此命令的返回结果中可以看出排名前几的可能就是引发内存占用过高的对象，进而找出那部分代码出了问题</p>

<h2 id="toc_4">总结</h2>

<p>在 JVM 出现性能问题的时候。(表现上是 CPU100%，内存一直占用)<br/>
1、 如果 CPU 的 100%，要从两个角度出发，一个有可能是业务线程疯狂运行，比如说想很多死循环。还有一种可能性，就是 GC 线程在疯狂的回收，因<br/>
为 JVM 中垃圾回收器主流也是多线程的，所以很容易导致 CPU 的 100%<br/>
2、 在遇到内存溢出的问题的时候，一般情况下我们要查看系统中哪些对象占用得比较多，我的是一个很简单的代码，在实际的业务代码中，找到对应的<br/>
对象，分析对应的类，找到为什么这些对象不能回收的原因，就是我们前面讲过的可达性分析算法，JVM 的内存区域，还有垃圾回收器的基础，当然， 如果遇到更加复杂的情况，你要掌握的理论基础远远不止这些(JVM 很多理论都是排查问题的关键)</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[九、Arthas]]></title>
    <link href="http://www.throne4j.com/15978529329852.html"/>
    <updated>2020-08-20T00:02:12+08:00</updated>
    <id>http://www.throne4j.com/15978529329852.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">简介</h2>

<p>Arthas 是 Alibaba 开源的 Java 诊断工具,在线排查问题，无需重启；动态跟踪Java代码；实时监控JVM状态。</p>

<p><a href="https://alibaba.github.io/arthas/">官方文档参考</a><br/>
<a href="https://arthas.aliyun.com/doc/quick-start.html">快速入门</a></p>

<p>当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决：</p>

<p>这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？<br/>
我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？<br/>
遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？<br/>
线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！<br/>
是否有一个全局视角来查看系统的运行状况？<br/>
有什么办法可以监控到JVM的实时运行状态？<br/>
怎么快速定位应用的热点，生成火焰图？</p>

<h2 id="toc_1">下载和安装</h2>

<p>不需要安装，就是一个 jar 包</p>

<pre><code class="language-text">curl -O https://alibaba.github.io/arthas/arthas-boot.jar 

java -jar arthas-boot.jar
</code></pre>

<p>启动 arthas 的 jar 包是 arthas-boot.jar</p>

<p>直接 java -jar arthas-boot.jar。选择 attach 的进程绑定<br/>
<figure><img src="media/15773440983590/15976833500370.jpg" alt=""/></figure></p>

<h2 id="toc_2">arthas 命令</h2>

<p>输入help查看 arthas 支持的命令</p>

<pre><code class="language-shell">[arthas@29087]$ help
 NAME         DESCRIPTION
 help         Display Arthas Help
 keymap       Display all the available keymap for the specified connection.
 sc           Search all the classes loaded by JVM
 sm           Search the method of classes loaded by JVM
 classloader  Show classloader info
 jad          Decompile class
 getstatic    Show the static field of a class
 monitor      Monitor method execution statistics, e.g. total/success/failure count, average rt, fail rate, etc.
 stack        Display the stack trace for the specified class and method
 thread       Display thread info, thread stack
 trace        Trace the execution time of specified method invocation.
 watch        Display the input/output parameter, return object, and thrown exception of specified method invocation
 tt           Time Tunnel
 jvm          Display the target JVM information
 perfcounter  Display the perf counter infornation.
 ognl         Execute ognl expression.
 mc           Memory compiler, compiles java files into bytecode and class files in memory.
 redefine     Redefine classes. @see Instrumentation#redefineClasses(ClassDefinition...)
 dashboard    Overview of target jvm&#39;s thread, memory, gc, vm, tomcat info.
 dump         Dump class byte array from JVM
 heapdump     Heap dump
 options      View and change various Arthas options
 cls          Clear the screen
 reset        Reset all the enhanced classes
 version      Display Arthas version
 session      Display current session information
 sysprop      Display, and change the system properties.
 sysenv       Display the system env.
 vmoption     Display, and update the vm diagnostic options.
 logger       Print logger info, and update the logger level
 history      Display command history
 cat          Concatenate and print files
 echo         write arguments to the standard output
 pwd          Return working directory name
 mbean        Display the mbean information
 grep         grep command for pipes.
 tee          tee command for pipes.
 profiler     Async Profiler. https://github.com/jvm-profiling-tools/async-profiler
 stop         Stop/Shutdown Arthas server and exit the console.
</code></pre>

<h3 id="toc_3">dashboard</h3>

<p><figure><img src="media/15773440983590/15976836704891.jpg" alt="" style="width:1891px;"/></figure></p>

<h3 id="toc_4">thread</h3>

<p>这个命令和 jstack 很相似，但是功能更加强大，主要是查看当前 JVM 的线程堆栈信息 同时可以结合使用 thread –b 来进行死锁的排查死锁。</p>

<p>参数说明:</p>

<pre><code class="language-text">-n 指定最忙的前 n 个线程并打印堆栈
-b 找出阻塞当前线程的线程
-i 指定 cpu 占比统计的采样间隔，单位为毫秒
</code></pre>

<pre><code class="language-text">[arthas@29087]$ thread -b
&quot;Thread-0&quot; Id=11 BLOCKED on java.lang.Object@602bace6 owned by &quot;Thread-1&quot; Id=12
    at com.goddess.base.concurrent.SynchronizedObjDeadLock.lambda$deadLock$0(SynchronizedObjDeadLock.java:27)
    -  blocked on java.lang.Object@602bace6
    -  locked java.lang.Object@12487489 &lt;---- but blocks 1 other threads!
    at com.goddess.base.concurrent.SynchronizedObjDeadLock$$Lambda$1/122883338.run(Unknown Source)
    at java.lang.Thread.run(Thread.java:745)
</code></pre>

<p>thread -i 1000 -n 3 每过 1000 毫秒进行采样，显示最占 CPU 时间的前 3 个线程</p>

<p>thread --state WAITING 查看处于等待状态的线程</p>

<h3 id="toc_5">jvm</h3>

<p>查看jvm信息<br/>
<figure><img src="media/15773440983590/15976840064874.jpg" alt=""/></figure></p>

<h3 id="toc_6">jad 反编译指定已加载类的源码</h3>

<p><figure><img src="media/15773440983590/15976841522972.jpg" alt="" style="width:1293px;"/></figure></p>

<h3 id="toc_7">trace</h3>

<p>使用 trace 命令可以跟踪统计方法耗时。</p>

<p>例如：trace com.goddess.base.controller.UserController get</p>

<h3 id="toc_8">monitor 方法监控</h3>

<p>监控的维度说明：</p>

<table>
<thead>
<tr>
<th>监控项</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>timestamp</td>
<td>时间戳</td>
</tr>
<tr>
<td>class</td>
<td>Java类</td>
</tr>
<tr>
<td>method</td>
<td>方法（构造方法、普通方法）</td>
</tr>
<tr>
<td>total</td>
<td>调用次数</td>
</tr>
<tr>
<td>success</td>
<td>成功次数</td>
</tr>
<tr>
<td>fail</td>
<td>失败次数</td>
</tr>
<tr>
<td>rt</td>
<td>平均RT</td>
</tr>
<tr>
<td>fail-rate</td>
<td>失败率</td>
</tr>
</tbody>
</table>

<p>每 5 秒统计一次 com.goddess.base.controller.UserController 类的 get 方法执行情况</p>

<pre><code class="language-text">&gt; monitor -c 5 com.goddess.base.controller.UserController get
timestamp            class          method        total  success  fail  avg-rt(ms)  fail-rate
-----------------------------------------------------------------------------------------------
 2018-12-03 19:06:38  demo.MathGame  primeFactors  5      1        4     1.15        80.00%
</code></pre>

<h3 id="toc_9">watch</h3>

<p>让你能方便的观察到指定方法的调用情况。能观察到的范围为：返回值、抛出异常、入参，通过编写 OGNL 表达式进行对应变量的查看。</p>

<p>参数说明：</p>

<ul>
<li>class-pattern 类名表达式</li>
<li>method-pattern 方法名表达式匹配</li>
<li>express 观察表达式</li>
<li>condition-express 条件表达式</li>
<li>b 在方法调用之前观察</li>
<li>e 在方法调用之后观察,异常抛出时才触发</li>
<li>s 在方法返回之后观察</li>
<li>f 在方法结束之后观察</li>
<li>E 开启正则表达式匹配，默认为通配符匹配</li>
<li>[x:] 指定输出结果的属性遍历深度，默认为1</li>
</ul>

<p>特别说明：</p>

<ul>
<li><p>watch 命令定义了4个观察事件点，即 -b 方法调用前，-e 方法异常后，-s 方法返回后，-f 方法结束后</p></li>
<li><p>4个观察事件点 -b、-e、-s 默认关闭，-f 默认打开，当指定观察点被打开后，在相应事件点会对观察表达式进行求值并输出</p></li>
<li><p>这里要注意方法入参和方法出参的区别，有可能在中间被修改导致前后不一致，除了 -b 事件点 params 代表方法入参外，其余事件都代表方法出参</p></li>
<li><p>当使用 -b 时，由于观察事件点是在方法调用前，此时返回值或异常均不存在</p></li>
</ul>

<p>变量说明：</p>

<table>
<thead>
<tr>
<th>变量名</th>
<th>变量解释</th>
</tr>
</thead>

<tbody>
<tr>
<td>loader</td>
<td>本次调用类所在的 ClassLoader</td>
</tr>
<tr>
<td>clazz</td>
<td>本次调用类的 Class 引用</td>
</tr>
<tr>
<td>method</td>
<td>本次调用方法反射引用</td>
</tr>
<tr>
<td>target</td>
<td>本次调用类的实例</td>
</tr>
<tr>
<td>params</td>
<td>本次调用参数列表，这是一个数组，如果方法是无参方法则为空数组</td>
</tr>
<tr>
<td>returnObj</td>
<td><code>本次调用返回的对象。当且仅当 isReturn==true 成立时候有效，表明方法调用是以正常返回的方式结束。如果当前方法无返回值 void，则值为 null</code></td>
</tr>
<tr>
<td>throwExp</td>
<td><code>本次调用抛出的异常。当且仅当 isThrow==true 成立时有效，表明方法调用是以抛出异常的方式结束。</code></td>
</tr>
<tr>
<td>isBefore</td>
<td><code>辅助判断标记，当前的通知节点有可能是在方法一开始就通知，此时 isBefore==true 成立，同时 isThrow==false 和 isReturn==false，因为在方法刚开始时，还无法确定方法调用将会如何结束。</code></td>
</tr>
<tr>
<td>isThrow</td>
<td>辅助判断标记，当前的方法调用以抛异常的形式结束。</td>
</tr>
<tr>
<td>isReturn</td>
<td>辅助判断标记，当前的方法调用以正常返回的形式结束。</td>
</tr>
</tbody>
</table>

<pre><code class="language-shell"># 查看get方法的入参和出参
&gt; watch com.goddess.base.controller.UserController get &#39;{params[0],returnObj}&#39; -x 2

# 按照耗时进行过滤,#cost&gt;200(单位是ms)表示只有当耗时大于200ms时才会输出，过滤掉执行时间小于200ms的调用
&gt; watch com.goddess.base.controller.UserController get &#39;{params[0],returnObj}&#39; &#39;#cost&gt;200&#39; -x 2
&gt; 
</code></pre>

<h3 id="toc_10">stack 输出当前方法被调用的调用路径</h3>

<p>参数说明：</p>

<ul>
<li>class-pattern 类名表达式匹配</li>
<li>method-pattern 方法名表达式匹配</li>
<li>condition-express 条件表达式</li>
<li>[n:] 执行次数限制</li>
<li>[E] 开启正则表达式匹配，默认为通配符匹配</li>
</ul>

<p>据执行时间来过滤：<br/>
stack demo.MathGame primeFactors &#39;#cost&gt;5&#39;</p>

<h3 id="toc_11">tt</h3>

<p>方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测</p>

<h3 id="toc_12">vmoption 查看，更新JVM 诊断相关参数</h3>

<p>查看JVM诊断相关参数：</p>

<pre><code class="language-shell">[arthas@56963]$ vmoption
 KEY                    VALUE                   ORIGIN                 WRITEABLE
---------------------------------------------------------------------------------------------
 HeapDumpBeforeFullGC   false                   DEFAULT                true
 HeapDumpAfterFullGC    false                   DEFAULT                true
 HeapDumpOnOutOfMemory  false                   DEFAULT                true
 Error
 HeapDumpPath                                   DEFAULT                true
 CMSAbortablePrecleanW  100                     DEFAULT                true
 aitMillis
 CMSWaitDuration        2000                    DEFAULT                true
 CMSTriggerInterval     -1                      DEFAULT                true
 PrintGC                false                   DEFAULT                true
 PrintGCDetails         true                    MANAGEMENT             true
 PrintGCDateStamps      false                   DEFAULT                true
 PrintGCTimeStamps      false                   DEFAULT                true
 PrintGCID              false                   DEFAULT                true
 PrintClassHistogramBe  false                   DEFAULT                true
 foreFullGC
 PrintClassHistogramAf  false                   DEFAULT                true
 terFullGC
 PrintClassHistogram    false                   DEFAULT                true
 MinHeapFreeRatio       0                       DEFAULT                true
 MaxHeapFreeRatio       100                     DEFAULT                true
 PrintConcurrentLocks   false                   DEFAULT                true
</code></pre>

<p>查看指定option</p>

<pre><code class="language-shell">[arthas@56963]$ vmoption PrintGCDetails
 KEY                    VALUE                   ORIGIN                 WRITEABLE
---------------------------------------------------------------------------------------------
 PrintGCDetails         false                   MANAGEMENT             true

</code></pre>

<p>更新指定option：</p>

<pre><code class="language-shell">[arthas@56963]$ vmoption PrintGCDetails true
Successfully updated the vm option.
PrintGCDetails=true
</code></pre>

<h3 id="toc_13">sc 查看jvm已加载的类信息</h3>

<p>参数说明：<br/>
<figure><img src="media/15773440983590/15978503405145.jpg" alt=""/></figure></p>

<pre><code class="language-text">#模糊搜索
$ sc demo.*
demo.MathGame
Affect(row-cnt:1) cost in 55 ms.

</code></pre>

<h3 id="toc_14">sm 查看已加载类的方法信息</h3>

<h3 id="toc_15">classloader 查看 classloader的继承树，urls，类加载信息</h3>

<h3 id="toc_16">heapdum 类似jmap命令的heap dump功能</h3>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[八、jdk8 新增的功能特性]]></title>
    <link href="http://www.throne4j.com/16020424526444.html"/>
    <updated>2020-10-07T11:47:32+08:00</updated>
    <id>http://www.throne4j.com/16020424526444.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">原子操作 CAS</h2>

<p>JDK1.8 时，java.util.concurrent.atomic 包中提供了一个新的原子类:LongAdder。</p>

<p>LongAdder 在高并发的场景下会比它的前辈 --- AtomicLong 具有更好的性能，代价是消耗更多的内存空间。</p>

<p>AtomicLong 是利用了底层的 CAS 操作来提供并发性的，调用了 Unsafe 类的 getAndAddLong 方法，该方法是个 native 方法，它的逻辑是采用自旋的方式不断 更新目标值，直到更新成功。</p>

<p>在并发量较低的环境下，线程冲突的概率比较小，自旋的次数不会很多。但 是，高并发环境下，N 个线程同时进行自旋操作，会出现大量失败并不断自旋的 情况，此时 AtomicLong 的自旋会成为瓶颈。</p>

<p>AtomicLong 中有个内部变量 value 保存着实际的 long 值，所有的操作都是 针对该变量进行。也就是说，高并发环境下，value 变量其实是一个热点，也就 是 N 个线程竞争一个热点。</p>

<p>LongAdder 的基本思路就是分散热点，将 value 值分散到一个数组中，不同 线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行 CAS 操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的 long 值，只有将各个槽中的变量值累加返回，这个值也仅仅是个近似值，这也是他不能完全代替LongAtomic 的原因之一。</p>

<p>除了引入 LongAdder外，还有引入了其它三个类：LongAccumulator、DoubleAdder、DoubleAccumulator。</p>

<p>通过 LongBinaryOperator，可以自定义对入参的任意操作，并返回结果 (LongBinaryOperator 接收 2 个 long 作为参数，并返回 1 个 long)。<br/>
LongAccumulator 内部原理和 LongAdder 几乎完全一样。 DoubleAdder 和 DoubleAccumulator 用于操作 double 原始类型。</p>

<h2 id="toc_1">StampedLock</h2>

<p>StampedLock 是 Java8 引入的一种新的锁机制,简单的理解,可以认为它是读写锁的一个改进版本。</p>

<p>读写锁虽然分离了读和写的功能,使得读与读之间可以完全并发,但是读和写之间依然是冲突的,读锁会完全阻塞写锁,它使用的依然是悲观的锁策略.如果有大量的读线程,他也有可能引起写线程的饥饿。</p>

<p>而 StampedLock 则提供了一种乐观的读策略,这种乐观策略的锁非常类似于 无锁的操作,使得乐观锁完全不会阻塞写线程。它的思想是读写锁中读不仅不阻塞读，同时也不应该阻塞写。</p>

<p>读不阻塞写的实现思路:<br/>
在读的时候如果发生了写，则应当重读而不是在读的时候直接阻塞写!即读写之间不会阻塞对方，但是写和写之间还是阻塞的! StampedLock 的内部实现是基于 CLH 的。</p>

<h2 id="toc_2">CompleteableFuture</h2>

<p>JDK1.8 才新加入的一个实现类 CompletableFuture，实现了 Future<T>，CompletionStage<T>两个接口。详情见 ： <a href="15882235745444.html">CompletableFuture</a></p>

<h2 id="toc_3">lambada 表达式</h2>

<p>在语法上，Lambda 表达式包含三个部分，参数列表，箭头，主体，比如:</p>

<pre><code class="language-text">(parameters) -&gt; expression 

(parameters) -&gt; {statements;}
</code></pre>

<p>Lambda 表达式用在函数式接口上，所谓函数式接口，是只定义了一个抽象方法的接口(Interface)，接口中是否有默认方法，不影响。</p>

<p>注解@FunctionalInterface 可以帮助我们在设计函数式接口时防止出错。</p>

<p>我们常用的 Runnable,Callable 都是函数式接口，JDK8 中新增了几个函数式接 口:</p>

<ul>
<li><p>Predicate<T> :<br/>
包含 test 方法，接受泛型的 T，返回 boolean，可以视为断言(检查)接口 </p></li>
<li><p>Consumer<T> :<br/>
包含 accept 方法，接受泛型的 T，无返回，可以视为数据消费接口 </p></li>
<li><p>Function<T，R> :<br/>
包含 apply 方法，接受泛型的 T，返回 R，可以视为映射转换接口 Supplier<T><br/>
包含 get 方法，无输入，返回 T，可以视为创建一个新对象接口 </p></li>
<li><p>UnaryOperator<T></p></li>
</ul>

<p>扩展至 Function<T，T>，所以这个本质上也是一个映射转换接口，只不过映 射转换后的类型保持不变</p>

<ul>
<li><p>BiFunction<T, U, R><br/>
包含 apply 方法，接受泛型的 T、U，返回 R，可以视为复合型映射转换接口</p></li>
<li><p>BinaryOperator<T><br/>
扩展至Function BiFunction<T,T,T>，所以这个本质上也是一个复合型映射转 换接口，只不过映射转换后的类型保持不变</p></li>
<li><p>BiPredicate <T, U><br/>
包含 test 方法，接受泛型的 T，U，返回 boolean，可以视为复合型断言(检 查)接口</p></li>
<li><p>BiConsumer<T，U>:<br/>
包含 accept 方法，接受泛型的 T，U，无返回，可以视为复合型数据消费接<br/>
口</p></li>
</ul>

<h3 id="toc_4">函数描述符</h3>

<p>函数式接口的抽象方法的签名基本上就是 Lambda 表达式的签名。我们将这 种抽象方法叫作函数描述符</p>

<p>Runnable 接口可以看作一个什么也不接受什么也不返回(void)的函数的签 名，因为它只有一个叫作 run 的抽象方法，这个方法什么也不接受，什么也不返 回(void)。</p>

<p>我们可以用 () -&gt; void 代表参数列表为空，且返回 void 的函数。这正是 Runnable 接口所代表的。我们于是可以称() -&gt; void 是 Runnable 接口的函数描述符。</p>

<h2 id="toc_5">新增类库的新特性</h2>

<h3 id="toc_6">Optional</h3>

<p>Optional实际上是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。</p>

<pre><code class="language-java">Optional&lt; String &gt; fullName = Optional.ofNullable( null );
System.out.println( &quot;Full Name is set? &quot; + fullName.isPresent() );        
System.out.println( &quot;Full Name: &quot; + fullName.orElseGet( () -&gt; &quot;[none]&quot; ) ); 
System.out.println( fullName.map( s -&gt; &quot;Hey &quot; + s + &quot;!&quot; ).orElse( &quot;Hey Stranger!&quot; ) );
</code></pre>

<h3 id="toc_7">Stream</h3>

<p>最新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中,Stream API极大简化了集合框架的处理</p>

<h3 id="toc_8">Date/Time API (JSR 310)</h3>

<p>当前北京时间：  2020-10-07 23:41:45</p>

<ul>
<li>第一个是Clock类<br/>
它通过指定一个时区，然后就可以获取到当前的时刻，日期与时间。Clock可以替换System.currentTimeMillis()与TimeZone.getDefault()。</li>
</ul>

<pre><code class="language-java">// Get the system clock as UTC offset 
final Clock clock = Clock.systemUTC();
System.out.println( clock.instant() );
System.out.println( clock.millis() );

2020-10-07T15:46:53.818Z
1602085613878
</code></pre>

<ul>
<li>LocaleDateTime、LocalDate、LocalTime</li>
</ul>

<p>LocaleDate只持有ISO-8601格式且无时区信息的日期部分。相应的，LocaleTime只持有ISO-8601格式且无时区信息的时间部分。LocaleDate与LocalTime都可以从Clock中得到</p>

<pre><code class="language-java">// Get the local date and local time
final LocalDate date = LocalDate.now();
final LocalDate dateFromClock = LocalDate.now( clock );
         
System.out.println( date );
System.out.println( dateFromClock );
         
// Get the local date and local time
final LocalTime time = LocalTime.now();
final LocalTime timeFromClock = LocalTime.now( clock );
         
System.out.println( time );
System.out.println( timeFromClock );

2020-10-07
2020-10-07
23:47:33.925
15:47:33.925
</code></pre>

<p>LocalDateTime</p>

<pre><code class="language-java">// Get the local date/time
final LocalDateTime datetime = LocalDateTime.now();
final LocalDateTime datetimeFromClock = LocalDateTime.now( clock );
         
System.out.println( datetime );
System.out.println( datetimeFromClock );

2020-10-07T23:50:34.974
2020-10-07T15:50:34.974
</code></pre>

<p>如果你需要特定时区的日期/时间，那么ZonedDateTime是你的选择。它持有ISO-8601格式具具有时区信息的日期与时间</p>

<pre><code class="language-java">// Get the zoned date/time
final ZonedDateTime zonedDatetime = ZonedDateTime.now();
final ZonedDateTime zonedDatetimeFromClock = ZonedDateTime.now( clock );
final ZonedDateTime zonedDatetimeFromZone = ZonedDateTime.now( ZoneId.of( &quot;Asia/Shanghai&quot; ) );
         
System.out.println( zonedDatetime );
System.out.println( zonedDatetimeFromClock );
System.out.println( zonedDatetimeFromZone );

2020-10-07T23:56:49.792+08:00[Asia/Shanghai]
2020-10-07T15:56:49.792Z
2020-10-07T23:56:49.792+08:00[Asia/Shanghai]
</code></pre>

<h2 id="toc_9">JavaScript 引擎 Nashorn</h2>

<p>Nashorn，一个新的JavaScript引擎随着Java 8一起公诸于世，它允许在JVM上开发运行某些JavaScript应用。Nashorn就是javax.script.ScriptEngine的另一种实现，并且它们俩遵循相同的规则，允许Java与JavaScript相互调用。下面看一个例子：</p>

<pre><code class="language-java">ScriptEngineManager manager = new ScriptEngineManager();
ScriptEngine engine = manager.getEngineByName( &quot;JavaScript&quot; );
         
System.out.println( engine.getClass().getName() );
System.out.println( &quot;Result:&quot; + engine.eval( &quot;function f() { return 1; }; f() + 1;&quot; ) );
</code></pre>

<h2 id="toc_10">Base64</h2>

<p>在Java 8中，Base64编码已经成为Java类库的标准。</p>

<pre><code class="language-java">import java.nio.charset.StandardCharsets;
import java.util.Base64;
 
public class Base64s {
    public static void main(String[] args) {
        final String text = &quot;Base64 finally in Java 8!&quot;;
         
        final String encoded = Base64
            .getEncoder()
            .encodeToString( text.getBytes( StandardCharsets.UTF_8 ) );
        System.out.println( encoded );
         
        final String decoded = new String( 
            Base64.getDecoder().decode( encoded ),
            StandardCharsets.UTF_8 );
        System.out.println( decoded );
    }
}
</code></pre>

<p>Base64类同时还提供了对URL、MIME友好的编码器与解码器（Base64.getUrlEncoder() / Base64.getUrlDecoder(), Base64.getMimeEncoder() / Base64.getMimeDecoder()）。</p>

<h2 id="toc_11">并行（parallel）数组</h2>

<p>Java 8增加了大量的新方法来对数组进行并行处理。可以说，最重要的是parallelSort()方法，因为它可以在多核机器上极大提高数组排序的速度。</p>

<pre><code class="language-java">import java.util.Arrays;
import java.util.concurrent.ThreadLocalRandom;

public class ParallelArrays {
    public static void main( String[] args ) {
        long[] arrayOfLong = new long [ 20000 ];        
        
        Arrays.parallelSetAll( arrayOfLong, 
            index -&gt; ThreadLocalRandom.current().nextInt( 1000000 ) );
        Arrays.stream( arrayOfLong ).limit( 10 ).forEach( 
            i -&gt; System.out.print( i + &quot; &quot; ) );
        System.out.println();
         
        Arrays.parallelSort( arrayOfLong );     
        Arrays.stream( arrayOfLong ).limit( 10 ).forEach( 
            i -&gt; System.out.print( i + &quot; &quot; ) );
        System.out.println();
    }
}
</code></pre>

<h2 id="toc_12">Java虚拟机（JVM）的新特性</h2>

<p>PermGen空间被移除了，取而代之的是Metaspace（JEP 122）。JVM选项-XX:PermSize与-XX:MaxPermSize分别被-XX:MetaSpaceSize与-XX:MaxMetaspaceSize所代替</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[七、 JVM 性能调优]]></title>
    <link href="http://www.throne4j.com/15962980278783.html"/>
    <updated>2020-08-02T00:07:07+08:00</updated>
    <id>http://www.throne4j.com/15962980278783.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、调优步骤</h2>

<p>调优步骤：衡量系统现状、设定调优目标、寻找性能瓶颈、性能调优、衡量是否到达目标(如果未到达目标，需重新寻找性能瓶颈）、性能调优结束。</p>

<h3 id="toc_1">寻找性能瓶颈</h3>

<p>性能瓶颈的表象：资源消耗过多、外部处理系统的性能不足、资源消耗不多但程序的响应速度却仍达不到要求。</p>

<h3 id="toc_2">资源消耗：CPU、文件IO、网络IO、内存。</h3>

<p>外部处理系统的性能不足：所调用的其他系统提供的功能或数据库操作的响应速度不够。<br/>
资源消耗不多但程序的响应速度却仍达不到要求：程序代码运行效率不够高、未充分使用资源、程序结构不合理。</p>

<h4 id="toc_3">CPU消耗分析</h4>

<p>CPU主要用于中断、内核、用户进程的任务处理，优先级为中断&gt;内核&gt;用户进程。</p>

<h5 id="toc_4">上下文切换：</h5>

<p>每个线程分配一定的执行时间，当到达执行时间、线程中有IO阻塞或高优先级线程要执行时，将切换执行的线程。在切换时要存储目前线程的执行状态，并恢复要执行的线程的状态。<br/>
对于Java应用，典型的是在进行文件IO操作、网络IO操作、锁等待、线程Sleep时，当前线程会进入阻塞或休眠状态，从而触发上下文切换，上下文切换过多会造成内核占据较多的CPU的使用。</p>

<h5 id="toc_5">运行队列：</h5>

<p>每个CPU核都维护一个可运行的线程队列。系统的load主要由CPU的运行队列来决定。<br/>
运行队列值越大，就意味着线程会要消耗越长的时间才能执行完成。</p>

<h5 id="toc_6">利用率：</h5>

<p>CPU在用户进程、内核、中断处理、IO等待、空闲，这五个部分使用百分比。</p>

<h4 id="toc_7">文件IO消耗分析</h4>

<p>Linux在操作文件时，将数据放入文件缓存区，直到内存不够或系统要释放内存给用户进程使用。所以通常情况下只有写文件和第一次读取文件时会产生真正的文件IO。<br/>
对于Java应用，造成文件IO消耗高主要是多个线程需要进行大量内容写入（例如频繁的日志写入）的动作、磁盘设备本身的处理速度慢、文件系统慢、操作的文件本身已经很大。</p>

<h4 id="toc_8">网络IO消耗分析</h4>

<p>对于分布式Java应用，网卡中断是不是均衡分配到各CPU(cat/proc/interrupts查看)。</p>

<h4 id="toc_9">内存消耗分析（-Xms和-Xmx设为相同的值，避免运行期JVM堆内存要不断申请内存）</h4>

<p>对于Java应用，内存的消耗主要在Java堆内存上，只有创建线程和使用Direct ByteBuffer才会操作JVM堆外的内存。<br/>
JVM内存消耗过多会导致GC执行频繁，CPU消耗增加，应用线程的执行速度严重下降，甚至造成OutOfMemoryError，最终导致Java进程退出。</p>

<h4 id="toc_10">JVM堆外的内存</h4>

<p>swap的消耗、物理内存的消耗、JVM内存的消耗。</p>

<h3 id="toc_11">程序执行慢原因分析</h3>

<p>锁竞争激烈：很多线程竞争互斥资源，但资源有限， 造成其他线程都处于等待状态。</p>

<p>未充分使用硬件资源：线程操作被串行化。</p>

<p>数据量增长：单表数据量太大（如1个亿）造成数据库读写速度大幅下降（操作此表）。</p>

<h2 id="toc_12">2、apache bench 压测工具进行接口优化</h2>

<p>ab -c 10 -n 100 url<br/>
其中－n表示请求数，－c表示并发数</p>

<pre><code class="language-shell">&gt; ab -c 10 -n 100 https://www.baidu.com

....

Server Software:        BWS/1.1
Server Hostname:        www.baidu.com
Server Port:            443
SSL/TLS Protocol:       TLSv1.2,ECDHE-RSA-AES128-GCM-SHA256,2048,128
Server Temp Key:        ECDH P-256 256 bits
TLS Server Name:        www.baidu.com

Document Path:          /
Document Length:        227 bytes

# 并发请求数
Concurrency Level:      100
# 整个测试持续的时间
Time taken for tests:   0.849 seconds
# 完成的请求数
Complete requests:      100
# 失败的请求数
Failed requests:        0
# 整个场景中的网络传输量
Total transferred:      108197 bytes
# 整个场景中的HTML内容传输量
HTML transferred:       22700 bytes
# 吞吐率
Requests per second:    117.76 [#/sec] (mean)
# 用户平均请求等待时间
Time per request:       849.153 [ms] (mean)
# 服务器平均请求处理时间
Time per request:       8.492 [ms] (mean, across all concurrent requests)
# 平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题
Transfer rate:          124.43 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:       62  541 150.3    662     666
Processing:    15  148 120.4     61     295
Waiting:       11  146 118.8     61     291
Total:         76  689  66.5    704     773

Percentage of the requests served within a certain time (ms)
  50%    704
  66%    710
  75%    714
  80%    716
  90%    723
  95%    725
  98%    731
  99%    773
 100%    773 (longest request)
</code></pre>

<p>性能指标：</p>

<ul>
<li><p>吞吐率（Requests per second）<br/>
概念：服务器并发处理能力的量化描述，单位是reqs/s，指的是某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。<br/>
计算公式：总请求数 / 处理完成这些请求数所花费的时间，即<br/>
Request per second = Complete requests / Time taken for tests</p></li>
<li><p>用户平均请求等待时间（Time per request）<br/>
计算公式：处理完成所有请求数所花费的时间/ （总请求数 / 并发用户数），即<br/>
Time per request = Time taken for tests /（ Complete requests / Concurrency Level）</p></li>
<li><p>服务器平均请求等待时间（Time per request: across all concurrent requests）<br/>
计算公式：处理完成所有请求数所花费的时间 / 总请求数，即<br/>
Time taken for / testsComplete requests<br/>
可以看到，它是吞吐率的倒数。<br/>
同时，它也=用户平均请求等待时间/并发用户数，即<br/>
Time per request / Concurrency Level</p></li>
</ul>

<h2 id="toc_13">3、gc优化</h2>

<h3 id="toc_14">3.1、gc性能指标</h3>

<h4 id="toc_15">3.1.1吞吐量</h4>

<p>这里衡量的吞吐量是指 应用程序所花费的时间和系统总运行时间的比值。</p>

<p>我们可以按照这个公式来计算 GC 的吞吐量: 系统总运行时间 = 应用程序耗时 +GC 耗时。如果系统运行了 100 分钟，GC 耗时 1 分钟，则系统吞吐量为 99%。GC 的吞吐量一般不能低于 95%。</p>

<h4 id="toc_16">3.1.2延迟，由gc 引起的停顿时间</h4>

<p>停顿时间：指垃圾回收器正在运行时，应用程序的暂停时间。</p>

<p>对于串行回收器而言，停顿时间可能会比较长;而使用并发回收器，由于垃圾收集器和应用程序交替 运行，程序的停顿时间就会变短，但其效率很可能不如独占垃圾收集器，系统的吞吐量也很可能会降低。</p>

<p>垃圾回收频率: 通常垃圾回收的频率越低越好，增大堆内存空间可以有效降低垃圾回收发生的频率，但同时也意味着堆积的回收对象越多，最终也会增加回收时的停顿 时间。所以我们需要适当地增大堆内存空间，保证正常的垃圾回收频率即可。</p>

<h4 id="toc_17">3.1.3 内存占用</h4>

<p>gc 正常时占用的内存量</p>

<h3 id="toc_18">3.2、GC 调优策略</h3>

<h4 id="toc_19">3.2.1、降低 Minor GC 频率</h4>

<p>由于新生代空间较小，Eden 区很快被填满，就会导致频繁 Minor GC，因此我们可以通过增大新生代空间来降低 Minor GC 的频率。 单次 Minor GC 时间是由两部分组成:T1(扫描新生代)和 T2(复制存活对象)。</p>

<p>情况 1: 假设一个对象在 Eden 区的存活时间为 500ms，Minor GC 的时间间隔是 300ms，因为这个对象存活时间 &gt; 间隔时间，那么正常情况下，Minor GC 的时间为 :T1+T2。</p>

<p>情况 2:当我们增大新生代空间，Minor GC 的时间间隔可能会扩大到 600ms，此时一个存活 500ms 的对象就会在 Eden 区中被回收掉，此时就不存在复制存活对象了，所以再发生 Minor GC 的时间为:即 <code>T1*2(空间大了)+T2*0</code><br/>
可见，扩容后，Minor GC 时增加了 T1，但省去了 T2 的时间。</p>

<p>在 JVM 中，复制对象的成本要远高于扫描成本。如果在堆内存中存在较多的长期存活的对象，此时增加年轻代空间，反而会增加 Minor GC 的时间。如 果堆中的短期对象很多，那么扩容新生代，单次 Minor GC 时间不会显著增加。因此，单次 Minor GC 时间更多取决于 GC 后存活对象的数量，而非 Eden 区的大小。</p>

<h4 id="toc_20">3.2.2、降低 Full GC 的频率</h4>

<p>由于堆内存空间不足或老年代对象太多，会触发 Full GC，频繁的 Full GC 会带来上下文切换，增加系统的性能开销。 </p>

<p>减少创建大对象: 在平常的业务场景中，我们一次性从数据库中查询出一个大对象用于 web 端显示。比如，一次性查询出 60 个字段的业务操作，这种大对象如果超过年轻代最大对象阈值，会被直接创建在老年代; 即使被创建在了年轻代，由于年轻代的内存空间有限，通过 Minor GC 之后也会进入到老年代。</p>

<p>这种大对象很容易产生较多的 Full GC。 增大堆内存空间:在堆内存不足的情况下，增大堆内存空间，且设置初始化堆内存为最大堆内存，也可以降低 Full GC 的频率。</p>

<h4 id="toc_21">gc 调优策略总结</h4>

<ul>
<li><p>新生代大小选择</p>
<ul>
<li>响应时间优先的应用:尽可能设大,直到接近系统的最低响应时间限制(根据实际情况选择)。在此种情况下,新生代收集发生的频率也是最小的。同时,减少到达老年代的对象。</li>
<li>吞吐量优先的应用:尽可能的设置大,可能到达 Gbit 的程度.因为对响应时间没有要求,垃圾收集可以并行进行,一般适合 8CPU 以上的应用。</li>
<li>避免设置过小.当新生代设置过小时会导致:1.MinorGC 次数更加频繁 2.可能导致 MinorGC 对象直接进入老年代,如果此时老年代满了,会触发FullGC. </li>
</ul></li>
<li><p>老年代大小选择</p>
<ul>
<li>响应时间优先的应用:老年代使用并发收集器,所以其大小需要小心设置,一般要考虑并发会话率和会话持续时间等一些参数.如果堆设置小了,可能会造成内存碎片,高回收频率以及应用暂停而使用传统的标记清除方式; 如果堆大了,则需要较长的收集时间。最优化的方案,一般需要参考以下数据获得: 并发垃圾收集信息、持久代并发收集次数、传统 GC 信息、花在新生代和老年代回收上的时间比例。</li>
<li>吞吐量优先的应用:一般吞吐量优先的应用都有一个很大的新生代和一个较小的老年代.原因是,这样可以尽可能回收掉大部分短期对象,减少中期的对象,而 老年代尽存放长期存活对象。</li>
</ul></li>
<li><p>较小堆引起的碎片问题<br/>
因为年老代的并发收集器使用标记,清除算法,所以不会对堆进行压缩.当收集器回收时,他会把相邻的空间进行合并,这样可以分配给较大的对象.但是,当堆空间较小时,运行一段时间以后,就会出现&quot;碎片&quot;,如果并发收集器找不到足够的空间,那么并发收集器将会停止,然后使用传统的标记,清除方式进行回收.如果出现&quot;碎片&quot;,可能需要进行如下配置:<br/>
-XX:+UseCMSCompactAtFullCollection:使用并发收集器时,开启对年老代的压缩.<br/>
-XX:CMSFullGCsBeforeCompaction=0:上面配置开启的情况下,这里设置多少次Full GC后,对年老代进行压缩</p></li>
<li><p>用64位操作系统，Linux下64位的jdk比32位jdk要慢一些，但是吃得内存更多，吞吐量更大</p></li>
<li><p>XMX和XMS设置一样大，MaxPermSize和MinPermSize设置一样大，这样可以减轻伸缩堆大小带来的压力</p></li>
<li><p>系统停顿的时候可能是GC的问题也可能是程序的问题，多用jmap和jstack查看，或者killall -3 java，然后查看java控制台日志，能看出很多问题。</p></li>
<li><p>仔细了解自己的应用，如果用了缓存，那么年老代应该大一些，缓存的HashMap不应该无限制长，建议采用LRU算法的Map做缓存，LRUMap的最大长度也要根据实际情况设定。</p></li>
<li><p>采用并发回收时，年轻代小一点，年老代要大，因为年老大用的是并发回收，即使时间长点也不会影响其他程序继续运行，网站不会停顿</p></li>
</ul>

<h2 id="toc_22">4、常见问题</h2>

<h3 id="toc_23">4.1、超大对象</h3>

<p>代码中创建了很多大对象 , 且一直因为被引用不能被回收，这些大对象会进入老年代，导致内存一直被占用，很容易引发 GC 甚至是 OOM</p>

<h3 id="toc_24">4.2、内存泄漏</h3>

<p>大量对象引用没有释放，JVM 无法对其自动回收。</p>

<p>内存泄漏和内存溢出辨析：<br/>
内存溢出:实实在在的内存空间不足导致; 内存泄漏:该释放的对象没有释放，常见于使用容器保存元素的情况下。 </p>

<p>如何避免:<br/>
内存溢出:检查代码以及设置足够的空间 内存泄漏:一定是代码有问题 往往很多情况下，内存溢出往往是内存泄漏造成的。</p>

<h3 id="toc_25">4.3、长生命周期的对象持有短生命周期对象的引用</h3>

<p>例如将 HashMap 设置为静态变量，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏</p>

<h3 id="toc_26">4.4、连接未关闭</h3>

<p>如数据库连接、网络连接和 IO 连接等，只有连接被关闭后，垃圾回收器才会回收对应的对象。</p>

<h3 id="toc_27">4.5、变量作用域不合理</h3>

<p>例如，1.一个变量的定义的作用范围大于其使用范围，2.如果没有及时地把对象设置为 null</p>

<h2 id="toc_28">5、MAT Analyzer(TODO)</h2>

<p>MAT(Memory Analyzer Tool)工具是eclipse的一个插件(MAT也可以单独使用)，使用起来非常方便，尤其是在分析大内存的dump文件时，可以非常直观的看到各个对象在堆空间中所占用的内存大小、类实例数量、对象引用关系、利用OQL对象查询，以及可以很方便的找出对象GC Roots的相关信息，当然最吸引人的还是能够快速为开发人员生成内存泄露报表，方便定位问题和分析问题。</p>

<h3 id="toc_29">OQL</h3>

<p>在MAT 中 select 子句的格式与 SQL 基本一致，用于指定要显示的列，也可以使用 * 号，查看结果对象的引用示例(相当于 outgoing references)</p>

<pre><code class="language-text">select OBJECTS v.elementData from java.util.vector v

select * from OBJECTS &quot;com\.goddess\.java\..*&quot;

select * from char[] s where s.@length&gt;10

select * from java.lang.String s where toString(s) like &quot;.*java.*&quot;

select * from java.lang.String s where s.value!=null and 
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[六、java 虚拟机执行子系统---字节码执行引擎]]></title>
    <link href="http://www.throne4j.com/15760522223546.html"/>
    <updated>2019-12-11T16:17:02+08:00</updated>
    <id>http://www.throne4j.com/15760522223546.html</id>
    <content type="html"><![CDATA[
<p>执行引擎是Java虚拟机核心的组成部分之一。</p>

<p>“虚拟机”是一个相对于“物理机”的概念，这两种机器都有代码执行能力，其区别是物理机的执行引擎是直接建立在处理器、缓存、指令集和操作系统层面上的，而虚拟机的执行引擎则是由软件自行实现的，因此可以不受物理条件制约地定制指令集与执行引擎的结构体系，能够执行那些不被硬件直接支持的指令集格式。</p>

<p>Java虚拟机的解释执行引擎被称为“基于栈的执行引擎”，里面的“栈”就是操作数栈。</p>

<p>这里需要对java虚拟机栈有一个了解 <a href="15865981620428.html">二、JVM自动内存管理--java内存区域与内存溢出异常</a></p>

<h2 id="toc_0">1、方法调用</h2>

<h3 id="toc_1">1.1、解析调用</h3>

<p>方法调用并不等同于方法中的代码被执行，方法调用阶段唯一的任务就是确定被调用方法的版本（即调用哪一个方法），暂时还未涉及方法内部的具体运行过程。</p>

<p>调用不同类型的方法，字节码指令集里面设计了不同的指令。java虚拟机支持一下5条方法调用字节码指令：</p>

<ul>
<li>invokestatic 用于调用静态方法</li>
<li>invokespecial 用于调用实例构造器<init>()方法，私有方法和父类中的方法。</li>
<li>invokevirtual 用于调用所有的虚方法</li>
<li>invokeinterface 用于调用接口方法，会在运行时在确定一个实现该接口的对象</li>
<li>invokedynamic 现在运行时动态解析出调用点限定符所引用的方法，然后再执行该方法。</li>
</ul>

<p>些方法统称为“非虚方法”（Non-Virtual Method）： 要能被 invokestatic 和 invokespecial 指令调用的方法，都可以在解析阶段中确定唯一的调用版本，Java语言里符合这个条件的方法共有静态方法、私有方法、实例构造器、父类方法4种，再加上被final 修饰的方法（尽管它使用invokevirtual指令调用），这5种方法调用会在类加载的时候就可以把符号引用解析为该方法的直接引用。</p>

<p>解析调用一定是个静态的过程，在编译期间就完全确定，在类加载的解析阶段就会把涉及的符号引用全部转变为明确的直接引用，不必延迟到运行期再去完成。</p>

<h3 id="toc_2">1.2、分派</h3>

<p>而另一种主要的方法调用形式：分派（Dispatch）调用则要复杂许多，它可能是静态的也可能是动态的，按照分派依据的宗量数可分为单分派和多分派。这两类分派方式两两组合就构成了静态单分派、静态多分派、动态单分派、动态多分派4种分派组合情况。</p>

<p>因为Java具备面向对象的3个基本特征：继承、封装和多态。本节讲解的分派调用过程将会揭示多态性特征的一些最基本的体现，如“重载”和“重写”在Java虚拟机之中是如何实现的，这里的实现当然不是语法上该如何写，我们关心的依然是虚拟机如何确定正确的目标方法。</p>

<h4 id="toc_3">1.2.1、静态分派</h4>

<p>所有依赖静态类型来决定方法执行版本的分派动作，都称为静态分派。静态分派解决了方法的重载问题。</p>

<p>从定义中我们需要了解什么事静态类型，首先先看一段如下代码：</p>

<pre><code class="language-java">public class StaticDispatch {

    static abstract class Human {
    }

    static class Man extends Human {
    }

    static class Woman extends Human {
    }

    public void sayHello(Human human) {
        System.out.println(&quot;Hello human&quot;);
    }

    public void sayHello(Man man) {
        System.out.println(&quot;Hello man&quot;);
    }

    public void sayHello(Woman woman) {
        System.out.println(&quot;Hello woman&quot;);
    }

    public static void main(String[] args) {
        // 这里Human 被称为静态类型，man被称为实际类型
        Human man = new Man();
        Human woman = new Woman();

        StaticDispatch staticDispatch = new StaticDispatch();
        staticDispatch.sayHello(man);
        staticDispatch.sayHello(woman);
    }
}
</code></pre>

<p>上例中 Human 被称为变量的 ”静态类型“ 后面的Man 被称为变量的“实际类型”。</p>

<p>静态类型和实际类型在程序中都可能会发生变化，区别是静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且最终的静态类型是在编译期可知的；而实际类型变化的结果在运行期才可确定，编译器在编译程序的时候并不知道一个对象的实际类型是什么。</p>

<p>编译期间选择静态分派目标的过程，这个过程也是Java语言实现方法重载的本质。</p>

<h4 id="toc_4">1.2.2、动态分派</h4>

<p>动态分派的实现过程与java语言多态性的另一个重要体现---重写 有着密切关系。</p>

<pre><code class="language-java">public class DynamicDispatch {

    abstract static class Human {
        public abstract void sayHello();
    }

    static class Man extends Human {
        public void sayHello() {
            System.out.println(&quot;Hello man&quot;);
        }
    }

    static class Woman extends Human {
        public void sayHello() {
            System.out.println(&quot;Hello woman&quot;);
        }
    }

    public static void main(String[] args) {
        Human man = new Man();
        Human woman = new Woman();
        man.sayHello();
        woman.sayHello();
    }
}

----------------------

Hello man
Hello woman

</code></pre>

<p>关于方法的重写，java虚拟机是怎么判断应该调用哪个方法的呢？</p>

<p>我们看下上面方法的字节码</p>

<pre><code class="language-java">  public static void main(java.lang.String[]);
    descriptor: ([Ljava/lang/String;)V
    flags: ACC_PUBLIC, ACC_STATIC
    Code:
      stack=2, locals=3, args_size=1
         0: new           #2                  // class com/goddess/base/classloader/DynamicDispatch$Man
         3: dup
         4: invokespecial #3                  // Method com/goddess/base/classloader/DynamicDispatch$Man.&quot;&lt;init&gt;&quot;:()V
         7: astore_1
         8: new           #4                  // class com/goddess/base/classloader/DynamicDispatch$Woman
        11: dup
        12: invokespecial #5                  // Method com/goddess/base/classloader/DynamicDispatch$Woman.&quot;&lt;init&gt;&quot;:()V
        15: astore_2
        16: aload_1
        17: invokevirtual #6                  // Method com/goddess/base/classloader/DynamicDispatch$Human.sayHello:()V
        20: aload_2
        21: invokevirtual #6                  // Method com/goddess/base/classloader/DynamicDispatch$Human.sayHello:()V
        24: return
      LineNumberTable:
        line 29: 0
        line 30: 8
        line 31: 16
        line 32: 20
        line 33: 24
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0      25     0  args   [Ljava/lang/String;
            8      17     1   man   Lcom/goddess/base/classloader/DynamicDispatch$Human;
           16       9     2 woman   Lcom/goddess/base/classloader/DynamicDispatch$Human;
}

</code></pre>

<p>0～15行的字节码是准备动作，作用是建立man和woman的内存空间、调用Man和Woman类型的实例构造器，将这两个实例的引用存放在第1、2个局部变量表的变量槽中。</p>

<p>16～21行是关键部分，16和20行的aload指令分别把刚刚创建的两个对象的引用压到栈顶，这两个对象是将要执行的sayHello()方法的所有者，称为接收者（Receiver）；17和21行是方法调用指令，这两条调用指令单从字节码角度来看，无论是指令（都是invokevirtual）还是参数（都是常量池中第22项的常量，注释显示了这个常量是Human.sayHello()的符号引用）都完全一样，但是这两句指令最终执行的目标方法并不相同。</p>

<p>那看来解决问题的关键还必须从invokevirtual指令本身入手，要弄清楚它是如何确定调用方法版本、如何实现多态查找来着手分析才行。</p>

<p>invokevirtual指令的运行时解析过程：</p>

<ul>
<li>找到操作数栈顶的第一个元素所指向的对象的实际类型，记做 C</li>
<li>如果在类型 C 中找到与常量 中的描述符和简单名称都有相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；不通过则返回java.lang.IllegalAccessError异常。</li>
<li>否则，按照继承关系从下往上依次对 C 的各个父类进行第二步的搜索和验证过程。</li>
<li>如果始终没有找到合适的方式，则抛出 java.lang.AbstractMethodError异常。</li>
</ul>

<p>正是因为 invokevirtual 指令执行的第一步就是在运行期确定接受者的实际类型，所以两次调用中的 invokevirtual 指令并不是把常量池中方法的符号引用解析到直接引用上就结束了，还会根据方法接受者的实际类型来选择方法版本，这个过程就是java 语言中方法重写的本质。</p>

<p>我们把这种在运行期根据实际类型确定方法执行版本的过程称为动态分派。</p>

<p>这种多台行的根源在于虚方法调用指令 invokevirtual 的执行逻辑，那自然得出的结论就只对方法有效，对字段无效，因为字段不适用这条指令。</p>

<p>使用如下代码说明动态派生中的虚方法与字段的区别：</p>

<pre><code class="language-java">public class FieldHasNoPolymorphic {
    static class BigBrother {
        public int money = 1;

        public BigBrother() {
            money = 2;
            showMeTheMoney();
        }

        public void showMeTheMoney() {
            System.out.println(&quot;BigBrother had ￥&quot; + money);
        }
    }


    static class LittleBrother extends BigBrother {
        public int money = 3;

        public LittleBrother() {
            money = 4;
            showMeTheMoney();
        }

        public void showMeTheMoney() {
            System.out.println(&quot;LittleBrother had ￥&quot; + money);
        }
    }

    public static void main(String[] args) {
        BigBrother brother = new LittleBrother();
        System.out.println(&quot;brother had ￥&quot; + brother.money);
    }
}

------ 

LittleBrother had ￥0
LittleBrother had ￥4
brother had ￥2
</code></pre>

<p>两句输出都是 “LittleBrother,” 这是因为 LittleBrother 类在创建的时候回隐式的调用 BigBrother 的构造函数，而 BigBrother 构造函数中的对showMetheMoney 的调用是一次虚方法调用，实际执行的版本是 LittleBrother::showMetheModey()方法，而这时虽然父类的money字段别初始化为了2，但是子类 LittleBrother 中的money 还未被程序初始化，因为，子类中的money要等到子类的构造函数执行时才会被初始化，所以此main函数打印出来的结果才会如上例所示。</p>

<h4 id="toc_5">1.2.3、单分派和多分派</h4>

<p>方法的接受者与方法的参数统称为方法的宗量，根据分派给予多少种宗量，可以将分派划分为单分派和多分派两种。单分派是根据一个宗量对目标方法进行选择，多分派则是根据多于一个宗量对目标方法进行选择。</p>

<p>如今的Java语言是一门静态多分派、动态单分派的语言。</p>

<h3 id="toc_6">2、虚拟机的动态分派实现</h3>

<p>动态分派是执行非常频繁的动作，而且动态分派的方法版本选择过程需要运行时在接收者类型的方法元数据中搜索合适的目标方法，因此，Java虚拟机实现基于执行性能的考虑，真正运行时一般不会如此频繁地去反复搜索类型元数据。面对这种情况，一种基础而且常见的优化手段是为类型在方法区中建立一个虚方法表（Virtual Method Table，也称为vtable，与此对应的，在invokeinterface执行时也会用到接口方法表——Interface Method Table，简称itable），使用虚方法表索引来代替元数据查找以提高性能。</p>

<p><figure><img src="media/15760522223546/15969817696559.jpg" alt=""/></figure></p>

<p>虚方法表中存放着各个方法的实际入口地址。如果某个方法在子类中没有被重写，那子类的虚方法表中的地址入口和父类相同方法的地址入口是一致的，都指向父类的实现入口。如果子类中重写了这个方法，子类虚方法表中的地址也会被替换为指向子类实现版本的入口地址。</p>

<p>虚方法表一般在类加载的连接阶段进行初始化，准备了类的变量初始值后，虚拟机会把该类的虚方法表也一同初始化完毕。</p>

<p>虚拟机除了使用虚方法表之外，为了进一步提高性能，还会使用类型继承关系分析（Class Hierarchy Analysis，CHA）、守护内联（Guarded Inlining）、内联缓存（Inline Cache）等多种非稳定的激进优化来争取更大的性能空间。</p>

<h4 id="toc_7">2.1、java.lang.invoke包</h4>

<p>JDK7 新加入到饿java.lang.invoke包 是JSR292 的一个重要组成部分,这个包的主要目的是在之前单纯靠符号引用来确定调用的目标方法这条路之外,提供一种新的动态确定目标方法的机制,成为 &quot;方法句柄&quot;。</p>

<p>方法句柄使 java语言也可以拥有类似于函数指针或者委托的方法别名这样的工具了。如下例所示的方法句柄的基本用法:</p>

<pre><code class="language-java">/**
 * MethodHandle基础用法演示
 */
public class MethodHandleTest {
    static class ClassA {
        public void println(String s) {

            System.out.println(&quot;ClassA: &quot;+s);
        }
    }

    private static MethodHandle getPrintlnMH(Object reveiver) throws Throwable {
        // MethodType：代表“方法类型”，包含了方法的返回值（methodType()的第一个参数）和具体参数（methodType()第二个及以后的参数）。
        MethodType mt = MethodType.methodType(void.class, String.class);
        // lookup()方法来自于MethodHandles.lookup，这句的作用是在指定类中查找符合给定的方法名称、方法类型，并且符合调用权限的方法句柄。
        // 因为这里调用的是一个虚方法，按照Java语言的规则，方法第一个参数是隐式的，代表该方法的接
        // 收者，也即this指向的对象，这个参数以前是放在参数列表中进行传递，现在提供了bindTo() 方法来完成这件事情。
        return lookup().findVirtual(reveiver.getClass(), &quot;println&quot;, mt).bindTo(reveiver);
    }

    public static void main(String[] args) throws Throwable {
        Object obj = System.currentTimeMillis() % 2 == 0 ? System.out : new ClassA();
        // 无论obj最终是哪个实现类，下面这句都能正确调用到println方法。
        getPrintlnMH(obj).invokeExact(&quot;icyfenix&quot;);
    }
}
</code></pre>

<p>方法getPrintlnMH()中实际上是模拟了invokevirtual指令的执行过程，只不过它的分派逻辑并非固化在Class文件的字节码上，而是通过一个由用户设计的Java方法来实现。而这个方法本身的返回值（MethodHandle对象），可以视为对最终调用方法的一个“引用”。</p>

<p>通过代码我们发现这样的事情通过反射也可以很容易的实现，但是他们有一下一些区别：</p>

<ul>
<li><p>Reflection和MethodHandle机制本质上都是在模拟方法调用，但是Reflection是在模拟Java代码层次的方法调用，而MethodHandle是在模拟字节码层次的方法调用。<br/>
在MethodHandles.Lookup上的3个方法findStatic()、findVirtual()、findSpecial()正是为了对应于invokestatic、invokevirtual（以及invokeinterface）和invokespecial这几条字节码指令的执行权限校验行为，而这些底层细节在使用Reflection API时是不需要关心的。</p></li>
<li><p>Reflection中的java.lang.reflect.Method对象远比MethodHandle机制中的java.lang.invoke.MethodHandle对象所包含的信息来得多。前者是方法在Java端的全面映像，包含了方法的签名、描述符以及方法属性表中各种属性的Java端表示方式，还包含执行权限等的运行期信息。而后者仅包含执行该方法的相关信息。用开发人员通俗的话来讲，Reflection 是重量级，而 MethodHandle 是轻量级。</p></li>
<li><p>由于MethodHandle是对字节码的方法指令调用的模拟，那理论上虚拟机在这方面做的各种优化（如方法内联），在MethodHandle上也应当可以采用类似思路去支持（但目前实现还在继续完善中），而通过反射去调用方法则几乎不可能直接去实施各类调用点优化措施。</p></li>
<li><p>Reflection API的设计目标是只为Java语言服务的，而MethodHandle 则设计为可服务于所有Java虚拟机之上的语言。</p></li>
</ul>

<h4 id="toc_8">2.2、invokedynamic 指令</h4>

<p>JDK 7为了更好地支持动态类型语言，引入了第五条方法调用的字节码指令invokedynamic，那么invokedynamic到底有什么应用呢？</p>

<p>某种意义上可以说invokedynamic指令与MethodHandle机制的作用是一样的，都是为了解决原有4 条“invoke*”指令方法分派规则完全固化在虚拟机之中的问题，把如何查找目标方法的决定权从虚拟机转嫁到具体用户代码之中，让用户（广义的用户，包含其他程序语言的设计者）有更高的自由度。而且，它们两者的思路也是可类比的，都是为了达成同一个目的，只是一个用上层代码和API来实现，另一个用字节码和Class中其他属性、常量来完成。</p>

<p>每一处含有invokedynamic指令的位置都被称作“动态调用点（Dynamically-Computed Call Site）”，这条指令的第一个参数不再是代表方法符号引用的CONSTANT_Methodref_info常量，而是变为JDK 7 时新加入的CONSTANT_InvokeDynamic_info常量，从这个新常量中可以得到3项信息：引导方法（Bootstrap Method，该方法存放在新增的BootstrapMethods属性中）、方法类型（MethodType）和名称。引导方法是有固定的参数，并且返回值规定是java.lang.invoke.CallSite对象，这个对象代表了真正要执行的目标方法调用。根据CONSTANT_InvokeDynamic_info常量中提供的信息，虚拟机可以找到并且执行引导方法，从而获得一个CallSite对象，最终调用到要执行的目标方法上。</p>

<p>JDK8 引入了Lambda表达式和接口默认方法后，Java语言使用到了invokedynamic指令。</p>

<pre><code class="language-java">import java.lang.invoke.MethodHandle;
import java.lang.invoke.MethodHandles;
import java.lang.invoke.MethodType;
import java.lang.reflect.Field;

public class GrandFather {
    void thinking() {
        System.out.println(&quot;i am grandfather&quot;);
    }

    public static void main(String[] args) {
        Son son = new Son();
        son.thinking();
    }
}

class Father extends GrandFather {
    void thinking() {
        System.out.println(&quot;i am father&quot;);
    }
}

class Son extends Father {
    void thinking() {
        try {
            // 请读者在这里填入适当的代码（不能修改其他地方的代码）
            // 实现调用祖父类的thinking()方法，打印&quot;i am grandfather&quot;
            MethodType methodType = MethodType.methodType(void.class);
            Field lookupImpl = MethodHandles.Lookup.class.getDeclaredField(&quot;IMPL_LOOKUP&quot;);
            lookupImpl.setAccessible(true);
            MethodHandle thinking = ((MethodHandles.Lookup) lookupImpl.get(null)).findSpecial(GrandFather.class, &quot;thinking&quot;, methodType, GrandFather.class);
            thinking.invoke(this);
        } catch (Throwable throwable) {
            throwable.printStackTrace();
        }
    }
}
</code></pre>

<h3 id="toc_9">3、基于栈的字节码解释执行引擎</h3>

<p>javac 编译器输出的字节码指令流基本上是一种基于栈的指令集架构(Instruction Set Architecture，ISA)字节码指令流里面的指令大部分是零地址指令，他们一来操作数栈进行工作。</p>

<p>现在我们主流PC机中物理硬件直接支持的指令集架构，这些指令依赖寄存器进行工作，这些指令流是基于寄存器的指令集。</p>

<p>举个例子来看下基于栈的指令集与基于寄存器的指令集有什么不同</p>

<pre><code class="language-text">iconst_1
iconst_1
iadd 
istore_0
</code></pre>

<p>两条iconst_1指令连续把两个常量 1 压入栈， iadd 指令吧站定的两个值出栈、相加，然后把结果放回栈顶，最后istore_0 把栈顶的值放到局部变量表的第 0 个变量槽。</p>

<p>这种指令流中的指令通常是不带参数的，使用操作数栈中的数据作为指令的运算输入，指令的运算结果也存储在操作数栈中。</p>

<p>基于寄存器的指令集，程序可能是这样的：</p>

<pre><code class="language-text">mov eax, 1
add eax, 1
</code></pre>

<p>mov指令吧EAX寄存器的值设置为 1，然后add指令再把这个值加 1，结果就保存在EAX寄存器里面。</p>

<p>基于栈的指令集及主要优点是可移植，而基于寄存器的指令集则依赖于硬件寄存器，不可避免的受到硬件的约束；如果使用栈架构的指令集，用户程序不会直接用到这些寄存器，那就可以由虚拟机实现来自行决定把一些访问最频繁的数据（程序计数器、栈顶缓存等）放到寄存器中以获取尽量好的性能，这样实现起来也更简单一些；代码相对更加紧凑（字节码中每个字节就对应一条指令，而多地址指令集中还需要存放参数）、编译器实现更加简单（不需要考虑空间分配的问题，所需空间都在栈上操作）等。</p>

<p>栈架构指令集的主要缺点是理论上执行速度相对来说会稍慢一些，不过这里的执行速度是要局限在解释执行的状态下，如果经过即时编译器输出成物理机上的汇编指令流，那就与虚拟机采用哪种指令集架构没有什么关系了。</p>

<h3 id="toc_10">基于栈的解释器执行过程</h3>

<p>准备了一段Java代码，以便向读者实际展示在虚拟机里字节码是如何执行的。</p>

<pre><code class="language-java">public int calc(){
    int a = 100;     
    int b = 200;     
    int c = 300;     
    return (a + b) * c; 
}
</code></pre>

<p>使用javap 查看他的字节码指令：</p>

<pre><code class="language-java">public int calc();     
    Code:         
        Stack=2, Locals=4, Args_size=1   // 这段代码需要深度为2的操作数栈和4个变量槽的局部变量空间。        
        0:   bipush  100   // 将单字节的整型常量值（-128～127）推入操作数栈顶，跟随有一个参数，指明推送的常量值，这里是100。       
        2:   istore_1       // 将操作数栈顶的整型值出栈并存放到第1个局部变量槽中。
        3:   sipush  200    //将200推入栈顶   
        6:   istore_2       // 将操作数栈顶的整型值出栈并保存在第2个局部变量槽中。
        7:   sipush  300    //将300推入栈顶 
        10:  istore_3       // 将操作数栈顶的整型值出栈并保存在第3个局部变量槽中。 
        11:  iload_1        // 将局部变量表第1个变量槽中的整型值复制到操作数栈顶。
        12:  iload_2        // 把第2个变量槽的整型值入栈。
        13:  iadd           // 将操作数栈中头两个栈顶元素出栈，做整型加法，然后把结果重新入栈。在iadd指令执行完毕后，栈中原有的100和200被出栈，它们相加的和300被重新入栈。
        14:  iload_3        // 把存放在第3个局部变量槽中的300入栈到操作数栈中
        15:  imul           // 将操作数栈中头两个栈顶元素出栈，做整型乘法，然后把结果重新入栈
        16:  ireturn       // 方法返回指令之一，它将结束方法执行并将操作数栈顶的整型值返回给该方法的调用者
}
``

虚拟机最终会对执行过程做出一系列优化来提高性能，实际的运作过程并不会完全符合概念模型的描述。
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[五、java虚拟机执行子系统---类加载机制]]></title>
    <link href="http://www.throne4j.com/15922073766854.html"/>
    <updated>2020-06-15T15:49:36+08:00</updated>
    <id>http://www.throne4j.com/15922073766854.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、类的生命周期</h2>

<p>从类被加载到虚拟机内存中开始，到卸载出内存为止，类的生命周期包括加载(Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unloading)7个阶段，其中验证、准备和解析三部分称为连接。类的加载、连接、初始化过程都是在程序运行期间进行的</p>

<p>在如下几种情况下，Java虚拟机将结束生命周期<br/>
– 执行了System.exit()方法<br/>
– 程序正常执行结束<br/>
– 程序在执行过程中遇到了异常或错误而异常终止<br/>
– 由于操作系统出现错误而导致Java虚拟机进程终止</p>

<p>JVM 类加载机制分为五个部分<br/>
<figure><img src="media/15922073766854/15922110200798.jpg" alt=""/></figure></p>

<p>虚拟机把描述类的数据从Class文件加载到内存， 并对数据进行校验、转换解析和初始化， 最终形成可以被虚拟机直接使用的Java类型， 这就是虚拟机的类加载机制。</p>

<h3 id="toc_1">1.1、加载</h3>

<p>在内存中生成一个代表这个类的java.lang.Class对象，作为方法去这个类的各种数据的入口。<br/>
此阶段完成三件事。</p>

<ul>
<li>通过一个类的全限定名来获取定义此类的二进制字节流(可以来自zip、war等压缩包，网络，动态生成，数据库等)。</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构</li>
<li>在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。</li>
</ul>

<p>加载阶段既可以使用Java虚拟机里内置的引导类加载器来完成，也可以由用户自定义的类加载器去完成。</p>

<p>对于数组类而言，情况就有所不同，数组类本身不通过类加载器创建，它是由Java虚拟机直接在 内存中动态构造出来的。但是数组的元素类型还是需要通过类加载器来完成加载。</p>

<ul>
<li>如果数组的组件类型是引用类型，那就递归采用本节中定义的加载过程去加载这个组件类型，数组C将被标 识在加载该组件类型的类加载器的类名称空间上(一个类型必须与类加 载器一起确定唯一性)</li>
<li>如果数组的组件类型不是引用类型(例如int[]数组的组件类型为int)，Java虚拟机将会把数组C标记为与引导类加载器关联。</li>
<li>数组类的可访问性与它的组件类型的可访问性一致，如果组件类型不是引用类型，它的数组类的可访问性将默认为public，可被所有的类和接口访问到。</li>
</ul>

<h3 id="toc_2">1.2、验证</h3>

<p>确保Class文件的字节流中包含的信息是否符合当前虚拟机要求.</p>

<ul>
<li>class文件格式验证</li>
<li><p>元数据验证</p>
<ul>
<li>这个类是否有父类(除了java.lang.Object之外，所有的类都应当有父类)。</li>
<li>这个类的父类是否继承了不允许被继承的类(被final修饰的类)。</li>
<li>如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法。</li>
<li>类中的字段、方法是否与父类产生矛盾(例如覆盖了父类的final字段，或者出现不符合规则的方 法重载，例如方法参数都一致，但返回值类型却不同等)。</li>
</ul></li>
<li><p>字节码验证<br/>
主要目的是通过数据流分析和控制流分析，确定 程序语义是合法的、符合逻辑的</p></li>
<li><p>符号引用验证</p>
<ul>
<li>符号引用中通过字符串描述的全限定名是否能找到对应的类。</li>
<li>在指定类中是否存在符合方法的字段描述符及简单名称所描述的方法和字段。</li>
<li>符号引用中的类、字段、方法的可访问性(private、protected、public、<package>)是否可被当 前类访问。<br/>
阶段的校验行为发生在虚拟机将符号引用转化为直接引用[3]的时候，这个转化动作将在 连接的第三阶段——解析阶段中发生,此阶段的目的是保证解析能够正常执行。</li>
</ul></li>
</ul>

<h3 id="toc_3">1.3、准备</h3>

<p>准备阶段是正式为类中定义的<strong>变量(即静态变量，被static修饰的变量)分配内存并设置类变量初始值</strong>的阶段。</p>

<p><strong><em>注意</em></strong> ： 关于准备阶段，还有两个容易产生混淆的概念需要着重强调，首先是这时候进行内存分配的 仅包括类变量，而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次是这里所说的初始值“通常情况”下是数据类型的零值，</p>

<h3 id="toc_4">1.4、 解析</h3>

<p>虚拟机将常量池中的符号引用替换为直接引用的过程</p>

<ul>
<li>符号引用<br/>
符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可，符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。</li>
</ul>

<p>各种虚拟机实现的内存布局可以各不相同，但是他们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在java虚拟机规范的Class文件格式中</p>

<ul>
<li>直接引用：可以是执行目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那么引用的目标必定已经存在于内存中。</li>
</ul>

<p>解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符这7 类符号引用进行，分别对应于常量池的CONSTANT_Class_info、CON-STANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info、CONSTANT_MethodType_info、CONSTANT_MethodHandle_info、CONSTANT_Dyna-mic_info和CONSTANT_InvokeDynamic_info 8种常量类型。</p>

<h3 id="toc_5">1.5、 初始化</h3>

<p>初始化是指执行<strong><em>静态代码块，静态变量</em></strong>的初始化操作，它是类加载阶段的最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都有jvm主导，到了初始化阶段，才开始真正执行类中定义的java程序代码。</p>

<p>初始化阶段是执行类构造器<client>方法的过程。<client>方法是由编译器自动收集类中的类变 量的赋值操作和静态语句块中的语句合并而成的。<strong>虚拟机会保证子<client>方法执行之前，父类 的<client>方法已经执行完毕</strong></p>

<p>有且只有以下<strong>六种对类型进行主动引用的情况需要立即对类进行初始化</strong>：</p>

<ul>
<li><p>遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果类型没有进行过初始化，则需要先出法器初始化阶段。</p>
<ul>
<li>使用new关键字实例化对象的时候</li>
<li>读取或设置一个类型的静态字段(被final修饰、已在编译器把结果放入常量池的静态字段除外)的时候</li>
<li><strong>调用一个类型的静态方法的时候</strong></li>
</ul></li>
<li><p>使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发器初始化。</p></li>
<li><p>当初始化类的时候，如果发现其父类没有进行过初始化，则需要先触发其父类的初始化。</p></li>
<li><p>当虚拟机启动时，用户需要制定一个要执行的主类(包含main()方法的哪个类)，虚拟机会先初始化这个主类</p></li>
<li><p>当使用 jdk7 新加入的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic、REF_p utStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，需要先触发其初始化</p></li>
<li><p>当一个接口中定义了jdk8新加入的默认方法(被default关键字修饰的接口方法)时，如果有这个接口的实现类发生了初始化，那该接口在其之前被初始化。</p></li>
</ul>

<hr/>

<p>以下几种 对类型的被动引用情况不会执行类初始化：</p>

<ul>
<li>通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化</li>
<li>通过对象数组，不会触发该类的初始化</li>
<li>常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类</li>
<li>通过类名获取Class对象，不会触发类的初始化</li>
<li>通过Class.forName加载指定类是，如果指定参数 initialize 为 false 时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化</li>
<li>通过ClassLoader 默认的 loadClass 方法，也不会触发初始化动作。</li>
</ul>

<p><strong><em>静态变量、静态代码块的初始化是按照上到下的顺序执行的</em></strong></p>

<p><strong><em>类与接口的初始化不同，如果一个类被初始化，则其父类或父接口也会被初始化，但如果一个接口初始化，则不会引起其父接口的初始化。</em></strong></p>

<p><strong><em>被static final限定的常量叫做编译时常量，对于这种常量，不需要初始化就可以读取。在编译阶段这个常量被放入被调用这个方法所在的类的常量池当中。当一个常量的值并非在编译期间可以确定的情况，那么其值就不会别放到调用类的常量池中，这时在程序运行时会导致主动使用这个常量所在的类，这时就会触发别调用类的初始化</em></strong></p>

<h3 id="toc_6">1.6、类的卸载</h3>

<p>当类A被加载、连接、初始胡之后、它的生命周期就开始了，当代表类A的Class对象不再被引用，即类不可达的时候，Class对象就会结束生命周期，类A在方法区内的数据就会被卸载，从而结束类A的生命周期。 <br/>
一个类何时结束生命周期，取决于代表它的class对象何时结束生命周期。</p>

<p>有java虚拟机自带的类加载器加载的类，在虚拟机的生命周期中，始终不会被卸载。而又用户自定义的类加载器所加载的类是可以被卸载的。</p>

<h2 id="toc_7">2、类加载器</h2>

<p>把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需的类。实现这个动作的代码被称为“类加载器”（Class Loader）。</p>

<h3 id="toc_8">2.1、 java虚拟机自带的加载器</h3>

<ul>
<li>启动类加载器 (Bootstrap Classloader)<br/>
此加载器没有父加载器，它的实现依赖于操作系统地城服务，是java虚拟机实现的一部分，负责加载虚拟机的核心类库。</li>
<li>扩展类加载器 (Extension Classloader)<br/>
扩展加载器负责加载系统属性java.ext.dirs指定位置的类库、加载jdk安装目录下面的$JAVA_HOME/lib/ext目录下的类库，父类是java.lang.ClassLoader</li>
<li>应用程序类加载器 (application Classloader)<br/>
应用类加载器负责加载classpath或者系统属性java.class.path所指位置的类库。</li>
</ul>

<h3 id="toc_9">2.2、 用户自定义的类加载器</h3>

<p>继承java.lang.ClassLoader，通过重写方法findClass/loadClass方法来实现自定义的委派机制/破坏委派机制的类加载器</p>

<p>加载器的加载阶段主要完成3件事：</p>

<ul>
<li>通过类的全限定名来获取定义此类的二进制字节流</li>
<li>将这个类字节流代表的静态存储结构转为 方法区的运行时数据结构</li>
<li>在堆中生成一个代表此类的java.lang.Class对象，作为访问方法区这些数据结构的入口。</li>
</ul>

<p>JVM 规范允许加载器预测到某个类将要被使用就会预先加载这个类，在加载这个类的时候，如果发现这个class类有缺失或存在错误，类加载器必须在<strong><em>这个类被首次被使用的时候才会抛出错误信息</em></strong>。如果这类一直没有被程序主动使用，则加载器不会跑抛出错误。</p>

<p><strong>获取ClassLoader的方式</strong>：</p>

<ul>
<li>clazz.getClassLoader() 获取当前类的加载器</li>
<li>Thread.currentThread().getContextClassLoader() 获取当前线程的加载器</li>
<li>ClassLoader.getSystemClassLoader() 获取系统的加载器</li>
<li>DriverManager.getCallerClassLoader 获取调用者的ClassLoader。</li>
</ul>

<h3 id="toc_10">2.3、类与类加载器</h3>

<p>比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。</p>

<p>这里的 “相等” 包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance() 方法的返回结果，也包括了使用instanceof关键字做对象所属关系判定等各种情况。</p>

<p>类加载有三种方式：</p>

<ul>
<li>命令行启动应用时候由JVM初始化加载</li>
<li>通过Class.forName()方法动态加载</li>
<li>通过ClassLoader.loadClass()方法动态加载</li>
</ul>

<p>对于数组类而言， 情况就有所不同， 数组类本身不通过类加载器创建， 它是由 Java 虚拟机直接创建的。 但数组类与类加载器仍然有很密切的关系， 因为数组类的元素类型 (Element一个数组类（下面简Type, 指的是数组去掉所有维度的类型）最终是要靠类加载器去创建，一个数组类（简称为C)创建过程就遵循以下规则：</p>

<ul>
<li><p>如果数组的组件类型（Component Type, 指的是数组去掉一个维度的类型）是引用类型， 那就递归采用本节中定义的加载过程去加载这个组件类型， 数组C将在加载该组件类型的类加载器的类名称空间上被标识（ 一个类必须与类加载器一起确定唯一性）．</p></li>
<li><p>如果数组的组件类型不是引用类型（假如是int[] 数组）， 数组是没有加载器的。</p></li>
<li><p>数组类的可见性与它的组件类型的可见性一致， 如果组件类型不是引用类型， 那数组类的可见性将默认为public 。</p></li>
</ul>

<p>类加载器对要加载的类的加载过程：</p>

<p>全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载；</p>

<p>先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类；</p>

<p>缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效</p>

<h2 id="toc_11">3、 双亲委派模型</h2>

<p><figure><img src="media/15922073766854/15966230750220.jpg" alt="双亲委派模型"/><figcaption>双亲委派模型</figcaption></figure></p>

<p>JVM的类加载器的实现方式采用双亲委派机制，所谓双亲委派机制是加载器在收到加载某个类的请求时，首先，它自己不会尝试去加载这个类，而是将请求委派给父加载器去完成，最终会委派给启动加载器(bootstrap classloader)去完成，如果父加载器无法完成加载请求，则在将请求委派给子加载器去完成。</p>

<p>双亲委派模型意义：</p>

<ul>
<li>可以确保java核心类库所提供的类不会被自定义的类所代替</li>
<li>不同的类加载器可以为相同名称的类创建额外的命名空间。相同名称的类可以并存在java虚拟机中，但需要不同的类加载器来加载他们</li>
<li>不同类加载器所加载的类之间是不兼容的，这就相当于在java虚拟机内部创建了多个相互隔离的java类空间</li>
</ul>

<p>通过重写方法findClass/loadClass方法可以实现自定义的委派机制/破坏委派机制的类加载器</p>

<p><strong>子加载器能访问到父加载器加载的类，但是反过来父加载器无法访问到子加载器所加载的类</strong></p>

<p>每个加载器都有属于它自己的命名空间</p>

<p>在运行期，一个java类的唯一性是由该类的完全限定名称(二进制名),和用于加载该类的定义类加载器所共同决定的。</p>

<p>父ClassLoader可以使用当前线程Thread.currentThread().getContextClassLoader()所制定的ClassLoader加载的类，这就改变了父classLoader不能使用子classLoader或其他没有直接父子关系的ClassLoader加载的类的情况.</p>

<p>如果没有通过setContextClassLoader(ClassLoader cl)进行设置的话，线程将继承其父线程的上下文加载器(在Laucher启动类中设置的)。java应用运行时的初始线程的上下文加载器是系统类加载器。在线程中运行的代码可以通过该类的加载器来加载类与资源。</p>

<h3 id="toc_12"><strong>SPI(service provider interface)</strong></h3>

<p>在双亲委托模型下，类加载是由下至上的，即下层的类加载器会委托上层加载器进行加载。但对于SPI来说，有些接口是Java核心类库所提供的，而java核心库是由启动类加载器来加载的，而这些接口的实现却来自于不同的jar包，java的启动类加载器是不会加载其他来源的jar包，这样传统的双亲委托模型就无法满足 SPI 要求。</p>

<p>通过给当前线程设置上下文类加载器，就可以由设置的上下文类加载器来实现对接口实现类的加载,在SPI开发中经常使用到。</p>

<h3 id="toc_13">关于线程上下文类加载器的使用模式</h3>

<p>如果一个类由加载器A加载，那么这个类的依赖类也是由相同的类加载器A加载的。ContextClassLoader 的作用就是为了破坏java的类加载机制。</p>

<p>当高层提供了统一的接口让低层去实现，同时又要在高层加载低层的类，就必须通过线程上下文类加载器来帮助高层ClassLoader找到并加载类。</p>

<p>ServiceLoader类在jvm中是很重要的类,一个简单的服务提供者加载工具。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[四、JVM自动内存管理--虚拟机性能监控，故障处理工具]]></title>
    <link href="http://www.throne4j.com/15773440983590.html"/>
    <updated>2019-12-26T15:08:18+08:00</updated>
    <id>http://www.throne4j.com/15773440983590.html</id>
    <content type="html"><![CDATA[
<ul>
<li><p>GC 频率： 高频的 FullGC 会给系统带来非常大的性能消耗，虽然 MinorGC 相对 FullGC 来说好了许多，但过多的 MinorGC 仍会给系统带来压力</p></li>
<li><p>内存： 这里的内存指的是堆内存大小，堆内存又分为年轻代内存和老年代内存。堆内存不足，会增加 MinorGC ，影响系统性能。</p></li>
<li><p>吞吐量： 频繁的 GC 将会引起线程的上下文切换，增加系统的性能开销，从而影响每次处理的线程请求，最终导致系统的吞吐量下降。</p></li>
<li><p>延迟： JVM 的 GC 持续时间也会影响到每次请求的响应时间</p></li>
</ul>

<h2 id="toc_0">jvm参数一览</h2>

<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
</tr>
</thead>

<tbody>
<tr>
<td>-XX:+PrintVMOptions</td>
<td>打印虚拟机接受到的命令行显式参数</td>
</tr>
<tr>
<td>-XX:+PrintCommandLineFlags</td>
<td>打印虚拟机接受到的命令行显式参数</td>
</tr>
<tr>
<td>-XX:+PrintFlagsFinal</td>
<td>打印所有系统参数</td>
</tr>
</tbody>
</table>

<h3 id="toc_1">生产服务器推荐开启</h3>

<p>-XX:-HeapDumpOnOutOfMemoryError 默认关闭，建议开启，在 java.lang.OutOfMemoryError 异常出现时，输出一个 dump 文件，记录当时的堆内存快照。<br/>
-XX:HeapDumpPath=./java_pid<pid>.hprof 用来设置堆内存快照的存储文件路径，默认是 java 进程启动位置。</p>

<h3 id="toc_2">jvm堆配置参数</h3>

<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
</tr>
</thead>

<tbody>
<tr>
<td>-Xms</td>
<td>初始堆大小，默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制</td>
</tr>
<tr>
<td>-Xmx</td>
<td>最大堆空间k、m为单位，默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制</td>
</tr>
<tr>
<td>-Xmn</td>
<td>设置新生代大小</td>
</tr>
<tr>
<td>-XX:NewRatio</td>
<td>设置老年代与新生代的比例，比如值为 4，表示新生代与老年代所占比例为1:4,新生代占整个堆大小的五分之一，如果设置了-Xmn参数，此参数不需要再设置</td>
</tr>
<tr>
<td>-XX:SurvivorRatio</td>
<td>设置新生代eden空间和from/to空间的比例关系，例如8，新生代:from:to = 8:1:1</td>
</tr>
<tr>
<td>-XX:PermSize</td>
<td>方法区初始大小，默认是物理内存的六十四分之一</td>
</tr>
<tr>
<td>-XX:MaxPermSize</td>
<td>方法区最大空间值，默认是物理内存的四分之一</td>
</tr>
<tr>
<td>-XX:MaxTenuringThreshold</td>
<td>新生代中对象存活次数，默认15</td>
</tr>
<tr>
<td>-XX:MetaspaceSize</td>
<td>元空间GC阈值（JDK1.8）</td>
</tr>
<tr>
<td>-XX:MaxMetaspaceSize</td>
<td>最大元空间大小（JDK1.8）</td>
</tr>
<tr>
<td>-Xss</td>
<td>栈大小，在jdk5之后的版本每个线程栈大小为 1m，之前的版本每个线程栈大小为 256k</td>
</tr>
<tr>
<td>-XX:MaxDirectMemorySize</td>
<td>直接内存大小，默认为最大堆空间</td>
</tr>
</tbody>
</table>

<p>说明: <br/>
整个堆大小的计算公式: JVM 堆大小 ＝ 年轻代大小＋年老代大小＋持久代大小。</p>

<p>增大新生代大小就会减少对应的年老代大小，设置-Xmn值对系统性能影响较大，所以如果设置新生代大小的调整，则需要严格的测试调整。而新生代是用来存放新创建的对象，大小是随着堆大小增大和减少而有相应的变化，默认值是保持堆大小的十五分之一，-Xmn参数就是设置新生代的大小，也可以通过-XX:NewRatio来设置新生代与年老代的比例，java 官方推荐配置为3:8。</p>

<p>新生代的特点就是内存中的对象更新速度快，在短时间内容易产生大量的无用对象，如果在这个参数时就需要考虑垃圾回收器设置参数也需要调整。推荐使用: 复制清除算法和并行收集器进行垃圾回收，而新生代的垃圾回收叫做初级回收。</p>

<h3 id="toc_3">jvm 追踪类信息</h3>

<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
</tr>
</thead>

<tbody>
<tr>
<td>-verbose:class</td>
<td>跟踪类的加载和卸载</td>
</tr>
<tr>
<td>-XX:+TraceClassLoading</td>
<td>跟踪类的加载</td>
</tr>
<tr>
<td>-XX:+TraceClassUnloading</td>
<td>跟踪类的卸载</td>
</tr>
<tr>
<td>-XX:+PrintClassHistogram</td>
<td>表示遇到 Ctrl-Break 后打印类实例的柱状信息，与 jmap -histo 功能相同。</td>
</tr>
</tbody>
</table>

<h3 id="toc_4">jvm 垃圾回收器参数</h3>

<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
</tr>
</thead>

<tbody>
<tr>
<td>-XX:+UseSerialGC</td>
<td>串行垃圾回收，已很少使用</td>
</tr>
<tr>
<td>-XX:+UseParallelGC</td>
<td></td>
</tr>
<tr>
<td>-XX:+UseParNewGC</td>
<td>新生代使用并行，老年代使用串行</td>
</tr>
<tr>
<td>-XX:+UseConcMarkSweepGC</td>
<td>新生代使用并行，老年代使用 CMS</td>
</tr>
<tr>
<td>-XX:+UseG1GC</td>
<td>使用G1垃圾收集器</td>
</tr>
<tr>
<td>-XX:ParallelGCThreads</td>
<td>指定并行的垃圾手机线程的数量，最好等于CPU数量</td>
</tr>
<tr>
<td>-XX:+UseParallelOldGC</td>
<td>年老代垃圾收集方式为并行收集(Parallel Compacting)</td>
</tr>
<tr>
<td>-XX:GCTimeRatio</td>
<td>设置垃圾回收时间占程序运行时间的百分比</td>
</tr>
<tr>
<td>-XX:+DisableExplicitGC</td>
<td>禁用System.gc(),因为它会触发 Full GC</td>
</tr>
<tr>
<td>-XX:CMSFullGCsBeforeCompaction</td>
<td>在多次 GC 后进行内存压缩，这个是因为并行收集器不对内存空间进行压缩，所以运行一段时间之后，会产生很多内存碎片，是的运行效率降低</td>
</tr>
<tr>
<td>-XX:+CMSParallelRemarkEnabled</td>
<td>降低标记停顿</td>
</tr>
<tr>
<td>-XX:+UseCMSCompactAtFullCollection</td>
<td>在每次Full GC时，对老年代区域进行碎片整理</td>
</tr>
<tr>
<td>-XX:CMSInitiatingOccupancyFraction</td>
<td>使用CMS作为垃圾回收，使用70%后开始CMS收集</td>
</tr>
<tr>
<td>-XX:+CMSIncrementalMode</td>
<td>设置增量模式</td>
</tr>
</tbody>
</table>

<h3 id="toc_5">jvm gc日志配置参数</h3>

<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
</tr>
</thead>

<tbody>
<tr>
<td>-XX:PrintGC</td>
<td>打印gc日志</td>
</tr>
<tr>
<td>-Xlogger:logpath</td>
<td>设置 gc 的日志路，如: -Xlogger:log/gc.log</td>
</tr>
<tr>
<td>-XX:+PrintGCDetails</td>
<td>打印详细gc日志</td>
</tr>
<tr>
<td>-XX:+PrintHeapAtGC</td>
<td>GC前后打印堆信息</td>
</tr>
<tr>
<td>-XX:+PrintGCTimeStamps</td>
<td>打印GC发生的时间</td>
</tr>
<tr>
<td>-XX:+PrintGCApplicationConcurrentTime</td>
<td>打印应用程序的执行时间</td>
</tr>
<tr>
<td>-XX:+PrintGCApplicationStoppedTime</td>
<td>打印应用由于GC而产生的停顿时间</td>
</tr>
<tr>
<td>-Xloggc</td>
<td>保存gc日志，-Xloggc:../logs/gc.log</td>
</tr>
<tr>
<td>verbose:gc</td>
<td>显式gc事件</td>
</tr>
<tr>
<td>-XX:-TraceClassLoading</td>
<td>跟踪类的加载</td>
</tr>
<tr>
<td>-Xloggc:filename</td>
<td>把相关日志信息记录到文件以便分析.</td>
</tr>
<tr>
<td>与上面几个配合使用</td>
<td></td>
</tr>
</tbody>
</table>

<h2 id="toc_6">jps （虚拟机进程状况工具）</h2>

<p>列出当前机器上正在运行的虚拟机进程，并显示虚拟机执行主类名称与虚拟机的唯一进程ID，jps 从操作系统的临时目录上去找(所以有一些信息可能显示不全)。</p>

<p>参数说明 <br/>
-q :仅仅显示进程，<br/>
-m:输出主函数传入的参数. 下的 hello 就是在执行程序时从命令行输入的参数 -l: 输出应用程序主类完整 package 名称或 jar 完整名称.<br/>
-v: 列出 jvm 参数, -Xms20m -Xmx50m 是启动程序指定的 jvm 参数</p>

<pre><code class="language-text">➜ jps
1249 org.jetbrains.idea.maven.server.RemoteMavenServer36
4468 org.jetbrains.jps.cmdline.Launcher
1208
4490 sun.tools.jps.Jps
</code></pre>

<h2 id="toc_7">jstat（虚拟机统计信息监视工具）</h2>

<p>jstat（JVM Statistics Monitoring Tool）是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据。</p>

<p>jstat -<option> [-t] [-h<lines>] vmid [interval[s|ms] [count]]</p>

<p>option主要分为三类：类加载、垃圾收集、运行期编译状况。<br/>
-t 参数可以在输出信息前加上一个 timestamp 列，显示程序的运行时间<br/>
-h 参数可以在周期性数据输出时，输出多少行数据后，跟着输出一个表头信息<br/>
interval和count代表查询间隔和次数,例如间隔250毫秒查看运行状态10次，</p>

<p><figure><img src="media/15773440983590/15975893994393.jpg" alt=""/></figure></p>

<pre><code class="language-shell">&gt; jstat -gc 4468 250 10
S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
10752.0 10752.0  0.0   4205.5 65536.0  27588.7   175104.0    144.0    16256.0 15720.1 1920.0 1802.4      1    0.004   0      0.000    0.004
</code></pre>

<ul>
<li>S0C:第一个幸存区(From 区)的大小 </li>
<li>S1C:第二个幸存区(To 区)的大小 </li>
<li>S0U:第一个幸存区的使用大小 </li>
<li>S1U:第二个幸存区的使用大小 </li>
<li>EC:伊甸园(Eden)区的大小 </li>
<li>EU:伊甸园(Eden)区的使用大小 </li>
<li>OC:老年代大小 </li>
<li>OU:老年代使用大小 </li>
<li>MC:方法区大小 </li>
<li>MU:方法区使用大小 </li>
<li>CCSC:压缩类空间大小 </li>
<li>CCSU:压缩类空间使用大小 </li>
<li>YGC:年轻代垃圾回收次数 </li>
<li>YGCT:年轻代垃圾回收消耗时间 </li>
<li>FGC:老年代垃圾回收次数 </li>
<li>FGCT:老年代垃圾回收消耗时间 </li>
<li>GCT:垃圾回收消耗总时间</li>
</ul>

<pre><code class="language-text">➜  ~ jstat -gc 51926 5000 5 |awk &#39;{print $13,$14,$15,$16,$17}&#39;
YGC YGCT FGC FGCT GCT
2 0.037 102 4.110 4.147
2 0.037 102 4.110 4.147
2 0.037 102 4.110 4.147
2 0.037 102 4.110 4.147
2 0.037 102 4.110 4.147
</code></pre>

<h2 id="toc_8">jinfo：Java配置信息工具</h2>

<p>jinfo（Configuration Info for Java）的作用是实时查看和调整虚拟机各项参数。jinfo 还可以使用-sysprops选项把虚拟机进程的System.getProperties()的内容打印出来</p>

<p>jinfo -sysprops VID 把虚拟机进程的System.getProperties()的内容打印出来<br/>
java -XX:+PrintFlagsFinal -version  查看所有高级参数的当前情况</p>

<p>在运行期修改部分参数值（可以使用-flag[+|-]name或者-flag name=value在运行期修改一部分运行期可写的虚拟机参数值）。</p>

<p>jinfo -flag PrintGC 7825 查看PrintGC 是否开启<br/>
jinfo -flag +PrintGC 7825 开启PrintGC<br/>
jinfo -flag -PrintGC 7825 关闭PrintGC</p>

<h3 id="toc_9">VM 参数分类</h3>

<p><a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html">JVM 的命令行参数参考</a></p>

<p><a href="https://www.oracle.com/java/technologies/javase/vmoptions-jsp.html">HotSpot VM Options参数选项</a></p>

<h4 id="toc_10">堆配置</h4>

<p>我们使用 -Xms 设置堆的初始空间大小，使用 -Xmx 设置堆的最大空间大小</p>

<pre><code class="language-shell"># 在上面的命令中，我们设置 JVM 的初始堆大小为 20M，最大堆空间为 30M。
&gt; java -Xms20m -Xmx30m Demo
</code></pre>

<p>在 JDK1.8 中，堆分为年轻代和老年代。</p>

<p>JVM 提供了参数 -Xmn 来设置年轻代内存的大小，但没有提供参数设置老年代的大小。但其实老年代的大小就等于堆大小减去年轻代大小。</p>

<pre><code class="language-shell">#设置 JVM 堆初始大小为20M。其中年轻代的大小为 10M，那么剩下的就是老年代的大小，有 10M了。
&gt; java -Xms20m -Xmn10M Demo
</code></pre>

<h5 id="toc_11">Eden区</h5>

<p>在年轻代中，分为三个区域，分别是：eden 空间、from 空间、to 空间。如果要设置这部分的大小，那么就使用 -XX:SurvivorRatio 这个参数，该参数设置 eden / from 空间的比例关系，该参数的公式如下：</p>

<pre><code class="language-text">-XX:SurvivorRatio = eden/from = eden/to
</code></pre>

<p>例如我们的年轻代有 10 M，而我们设置 -XX:SurvivorRatio 参数为 2。也就是说 eden/from = eden/to = 2。</p>

<p>这里教一个快速计算的方法，我们假设 eden = 2，那么 from = 1，to = 1，那么 eden + from + to = 10M。这样就可以算出每一份大小是 10/4 = 2.5M。所以 Eden 区 = 2.5 * 2 = 5M，from 区是 2.5M，to 区是 2.5M。</p>

<h5 id="toc_12">永久代/元空间</h5>

<p>在 JDK 1.8 之前，所加载的类信息都放在永久代中。我们用 -XX:PermSize 设置永久代初始大小，用 -XX:MaxPermSize 设置永久代最大大小。</p>

<pre><code class="language-text">&gt; java -XX:PermSize10m -XX:MaxPermSize50m -XX:+PrintGCDetails Demo
</code></pre>

<p>但在 JDK1.8 之时，永久代被移除，取而代之的是元空间（Metaspace）。在元空间这块内存中，有两个参数很相似，它们是： -XX:MetaspaceSize 和 -XX:MaxMetaspaceSize。</p>

<pre><code class="language-shell">&gt; java -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=50m -XX:+PrintGCDetails Demo
</code></pre>

<h5 id="toc_13">栈空间</h5>

<p>栈空间是每个线程各自有的一块区域，如果栈空间太小，也会导致 StackOverFlow 异常。而要设置栈空间大小，只需要使用 -Xss 参数就可以。</p>

<pre><code class="language-shell"># 设置最大栈空间为 2M
&gt; java -Xss2m Demo
</code></pre>

<h5 id="toc_14">直接内存</h5>

<p>在 JVM 中还有一块内存，它独立于 JVM 的堆内存，它就是：直接内存。我们可以使用 -XX:MaxDirectMemorySize 设置最大直接内存。如果不设置，默认为最大堆空间，即 -Xmx。</p>

<pre><code class="language-shell">&gt; java -XX:MaxDirectMemorySize=50m Demo
</code></pre>

<h2 id="toc_15">jmap：Java内存映像工具</h2>

<p><figure><img src="media/15773440983590/15976757860737.jpg" alt=""/></figure></p>

<pre><code class="language-shell">➜  ~ jmap -heap 20488
Attaching to process ID 20488, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 25.121-b13

using thread-local object allocation.
Parallel GC with 10 thread(s)

#堆配置情况，也就是 JVM 参数配置的结果[平常说的 tomcat 配置 JVM 参数，就是在配置这些]
Heap Configuration:  
   #最小堆使用比例
   MinHeapFreeRatio         = 0 
   #最大堆可用比例
   MaxHeapFreeRatio         = 100
   #最大堆空间大小
   MaxHeapSize              = 4294967296 (4096.0MB)
   #新生代分配大小
   NewSize                  = 89128960 (85.0MB)
   #最大可新生代分配大小
   MaxNewSize               = 1431306240 (1365.0MB)
   #老年代大小
   OldSize                  = 179306496 (171.0MB)
   #新生代比例
   NewRatio                 = 2
   #新生代与 suvivor 的比例
   SurvivorRatio            = 8
   #MetaspaceSize 元数据区大小
   MetaspaceSize            = 21807104 (20.796875MB)
   # 压缩类空间大小
   CompressedClassSpaceSize = 1073741824 (1024.0MB)
   # 最大可分配元数据区大小
   MaxMetaspaceSize         = 17592186044415 MB
   G1HeapRegionSize         = 0 (0.0MB)
#堆使用情况【堆内存实际的使用情况】
Heap Usage:
# 新生代
PS Young Generation 
# 伊甸区
Eden Space:
   # 伊甸区容量
   capacity = 67108864 (64.0MB)
   # 伊甸区已使用
   used     = 8067512 (7.693778991699219MB)
   # 伊甸区当前剩余
   free     = 59041352 (56.30622100830078MB)
   ## 伊甸区使用情况
   12.02152967453003% used
# s1 区
From Space:
   capacity = 11010048 (10.5MB)
   used     = 0 (0.0MB)
   free     = 11010048 (10.5MB)
   0.0% used
# s2 区
To Space:
   capacity = 11010048 (10.5MB)
   used     = 0 (0.0MB)
   free     = 11010048 (10.5MB)
   0.0% used
# 老年代使用情况
PS Old Generation
   capacity = 179306496 (171.0MB)
   used     = 0 (0.0MB)
   free     = 179306496 (171.0MB)
   0.0% used

2295 interned Strings occupying 161832 bytes.
</code></pre>

<p>jmap –histo <pid> 显示对象统计信息<br/>
jmap –histo:live <pid> 如果 live 子参数加上后,只统计活的对象数量</p>

<p>jmap -histo 20488  按照数量排名对象<br/>
jmap -histo:live 20488  按照数量排名存活的对象<br/>
jmap -histo:live  20488 | head -10 前十行</p>

<pre><code class="language-text">➜  ~ jmap -histo 20488

 num     #instances         #bytes  class name
----------------------------------------------
   1:           711        5225088  [I
   2:          2151        1535568  [B
   3:          6572         796664  [C
   4:          5022         120528  java.lang.String
   5:           727          82720  java.lang.Class
   6:          1328          60912  [Ljava.lang.Object;
   7:           661          26440  java.util.LinkedHashMap$Entry
   8:           326          16624  [Ljava.lang.String;
   9:           391          12512  java.util.HashMap$Node
  10:            43          12432  [Ljava.util.HashMap$Node;
  11:           152          10944  java.lang.reflect.Field
  12:           328          10496  java.io.File
  13:           405           9720  java.lang.StringBuilder
  14:           138           8832  java.net.URL
  15:           266           8512  java.util.Hashtable$Entry
  16:           135           5400  java.lang.ref.Finalizer
  17:           120           4800  java.lang.ref.SoftReference
  18:           179           4296  java.lang.StringBuffer
  19:            31           4224  [Ljava.util.Hashtable$Entry;
  20:           258           4128  java.lang.Integer
</code></pre>

<p>jmap -dump:format=b,file=/heap.hprof pid 导出堆快照文件</p>

<h2 id="toc_16">jhat: 虚拟机对转储快照分析工具</h2>

<p>JDK提供jhat（JVM Heap Analysis Tool）命令与jmap搭配使用，来分析jmap生成的堆转储快照。jhat内置了一个微型的HTTP/Web服务器，生成堆转储快照的分析结果后，可以在浏览器中查看。但是尽量不要在实际工作中使用这个命令工具，因为这个命令比较简陋，也因为分析工作一般都不会再服务器上进行，把jmap dump下来的文件转储到其它机器上可以使用更加友好的工具进行分析。</p>

<p>jhat /heap.hprof 分析快照文件<br/>
<figure><img src="media/15773440983590/16149130702351.jpg" alt="" style="width:757px;"/></figure></p>

<p>在浏览器中访问 <a href="http://127.0.0.1:7000">http://127.0.0.1:7000</a> 查看分析结果</p>

<p>OQL查询对象路径</p>

<pre><code class="language-text">select file.path.value.toString() from java.io.File file
</code></pre>

<h2 id="toc_17">jstack：Java堆栈跟踪工具</h2>

<p>jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。</p>

<p>线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的目的通常是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间挂起等，都是导致线程长时间停顿的常见原因。</p>

<p>一般来说 jstack 主要是用来排查是否有死锁的情况，</p>

<p>线程出现停顿时通过jstack来查看各个线程的调用堆栈，就可以获知没有响应的线程到底在后台做些什么事情，或者等待着什么资源。</p>

<p><figure><img src="media/15773440983590/15976799292165.jpg" alt=""/></figure></p>

<pre><code class="language-java">public class SynchronizedObjDeadLock {
    public static void main(String[] args) {
        new SynchronizedObjDeadLock().deadLock();
    }
    private static final Object objectA = new Object();
    private static final Object objectB = new Object();

    private void deadLock() {

        new Thread(()-&gt;{
            synchronized (objectA) {
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(&quot;dA&quot;);
                synchronized (objectB) {
                    System.out.println(&quot;dB&quot;);
                }
            }
        }).start();

        new Thread(()-&gt;{
            synchronized (objectB) {
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(&quot;B&quot;);
                synchronized (objectA) {
                    System.out.println(&quot;A&quot;);
                }
            }
        }).start();

    }
}
</code></pre>

<pre><code class="language-shell">&gt; jstack -l 29087
Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.121-b13 mixed mode):
省略好多东西.....

Found one Java-level deadlock:
=============================
&quot;Thread-1&quot;:
  waiting to lock monitor 0x00007ffbfd81e978 (object 0x000000076ac8e828, a java.lang.Object),
  which is held by &quot;Thread-0&quot;
&quot;Thread-0&quot;:
  waiting to lock monitor 0x00007ffbfd8210a8 (object 0x000000076ac8e838, a java.lang.Object),
  which is held by &quot;Thread-1&quot;

Java stack information for the threads listed above:
===================================================
&quot;Thread-1&quot;:
    at com.goddess.base.concurrent.SynchronizedObjDeadLock.lambda$deadLock$1(SynchronizedObjDeadLock.java:41)
    - waiting to lock &lt;0x000000076ac8e828&gt; (a java.lang.Object)
    - locked &lt;0x000000076ac8e838&gt; (a java.lang.Object)
    at com.goddess.base.concurrent.SynchronizedObjDeadLock$$Lambda$2/1349393271.run(Unknown Source)
    at java.lang.Thread.run(Thread.java:745)
&quot;Thread-0&quot;:
    at com.goddess.base.concurrent.SynchronizedObjDeadLock.lambda$deadLock$0(SynchronizedObjDeadLock.java:27)
    - waiting to lock &lt;0x000000076ac8e838&gt; (a java.lang.Object)
    - locked &lt;0x000000076ac8e828&gt; (a java.lang.Object)
    at com.goddess.base.concurrent.SynchronizedObjDeadLock$$Lambda$1/122883338.run(Unknown Source)
    at java.lang.Thread.run(Thread.java:745)

Found 1 deadlock.
</code></pre>

<h3 id="toc_18">性能统计工具-----hprof</h3>

<p>java -agentlib:hprof=help 查看hprof的帮助文档<br/>
<figure><img src="media/15773440983590/16149136296528.jpg" alt="" style="width:2134px;"/></figure></p>

<h3 id="toc_19">jhsdb 基于服务性代理的调试工具</h3>

<p>JDK9及以上版本中提供了JCMD和JHSDB两个集成式的多功能工具箱，它们不仅整合了上一节介绍到的所有基础工具所能提供的专项功能，而且由于有着“后发优势”，能够做得往往比之前的老工具们更好、更强大</p>

<p><figure><img src="media/15773440983590/15976856213870.jpg" alt="JCMD、JHSDB和基础工具的对比"/><figcaption>JCMD、JHSDB和基础工具的对比</figcaption></figure></p>

<p>使用以下命令进入JHSDB的图形化模式:<br/>
jhsdb hsdb --pid 29087</p>

<h2 id="toc_20">可视化工具</h2>

<h3 id="toc_21">JMX(Java Management Extensions，即 Java 管理扩展)</h3>

<p>JMX 是一个为应用程序、设备、系统等植入管理功能的框架。</p>

<p>JMX 可以跨越一系列异构操作系统平台、 系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。<br/>
管理远程进程需要在远程程序的启动参数中增加:</p>

<pre><code class="language-text">-Djava.rmi.server.hostname=.....
-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8888 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false
</code></pre>

<h3 id="toc_22">Jconsole</h3>

<p><figure><img src="media/15773440983590/15976826355683.jpg" alt=""/></figure><br/>
<figure><img src="media/15773440983590/15976826842222.jpg" alt=""/></figure><br/>
<figure><img src="media/15773440983590/15976827010008.jpg" alt=""/></figure><br/>
<figure><img src="media/15773440983590/15976827131457.jpg" alt=""/></figure><br/>
<figure><img src="media/15773440983590/15976827354222.jpg" alt=""/></figure></p>

<h3 id="toc_23">visualvm</h3>

<p><figure><img src="media/15773440983590/15976829051342.jpg" alt=""/></figure></p>

<p><figure><img src="media/15773440983590/15976828332220.jpg" alt=""/></figure></p>

<p><figure><img src="media/15773440983590/15976828463285.jpg" alt=""/></figure></p>

<p><figure><img src="media/15773440983590/15976828688260.jpg" alt=""/></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[软引用（SoftReference）实现内存敏感的高速缓存]]></title>
    <link href="http://www.throne4j.com/15866239860150.html"/>
    <updated>2020-04-12T00:53:06+08:00</updated>
    <id>http://www.throne4j.com/15866239860150.html</id>
    <content type="html"><![CDATA[
<p>软引用可用来实现内存敏感的高速缓存。</p>

<h2 id="toc_0">软引用（SoftReference）</h2>

<p>如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。</p>

<p>SoftReference的特点是它的一个实例保存对一个Java对象的软引用，该软引用的存在不妨碍垃圾收集线程对该Java对象的回收。也就是说，一旦SoftReference保存了对一个Java对象的软引用后，在垃圾线程对这个Java对象回收前，SoftReference类所提供的get()方法返回Java对象的强引用。另外，一旦垃圾线程回收该Java对象之后，get()方法将返回null。</p>

<pre><code class="language-java">MyObject aRef = new MyObject();
SoftReference  aSoftRef=new SoftReference(aRef);
</code></pre>

<p>此时，对于这个MyObject对象，有两个引用路径，一个是来自SoftReference对象的软引用，一个来自变量aReference的强引用，所以这个MyObject对象是强可及对象。<br/>
随即，我们可以结束aReference对这个MyObject实例的强引用: aRef = null;</p>

<p>此后，这个MyObject对象成为了软可及对象。如果垃圾收集线程进行内存垃圾收集，并不会因为有一个SoftReference对该对象的引用而始终保留该对象。Java虚拟机的垃圾收集线程对软可及对象和其他一般Java对象进行了区别对待:软可及对象的清理是由垃圾收集线程根据其特定算法按照内存需求决定的。也就是说，垃圾收集线程会在虚拟机抛出OutOfMemoryError之前回收软可及对象，而且虚拟机会尽可能优先回收长时间闲置不用的软可及对象，对那些刚刚构建的或刚刚使用过的“新”软可反对象会被虚拟机尽可能保留。在回收这些对象之前，我们可以通过:</p>

<pre><code class="language-java">MyObject anotherRef=(MyObject)aSoftRef.get();
</code></pre>

<p>重新获得对该实例的强引用。而回收之后，调用get()方法就只能得到null了。</p>

<h2 id="toc_1">ReferenceQueue工作机制</h2>

<p>软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。使用ReferenceQueue清除失去了软引用对象的SoftReference。</p>

<p>作为一个Java对象，SoftReference对象除了具有保存软引用的特殊性之外，也具有Java对象的一般性。所以，当软可及对象被回收之后，虽然这个SoftReference对象的get()方法返回null,但这个SoftReference对象已经不再具有存在的价值，需要一个适当的清除机制，避免大量SoftReference对象带来的内存泄漏。在java.lang.ref包里还提供了ReferenceQueue。如果在创建SoftReference对象的时候，使用了一个ReferenceQueue对象作为参数提供给SoftReference的构造方法，如:</p>

<pre><code class="language-java">ReferenceQueue queue = new ReferenceQueue();
SoftReference ref=new SoftReference(aMyObject, queue);
</code></pre>

<p>那么当这个SoftReference所软引用的aMyOhject被垃圾收集器回收的同时，ref所强引用的SoftReference对象被列入ReferenceQueue。也就是说，ReferenceQueue中保存的对象是Reference对象，而且是已经失去了它所软引用的对象的Reference对象。另外从ReferenceQueue这个名字也可以看出，它是一个队列，当我们调用它的poll()方法的时候，如果这个队列中不是空队列，那么将返回队列前面的那个Reference对象。<br/>
在任何时候，我们都可以调用ReferenceQueue的poll()方法来检查是否有它所关心的非强可及对象被回收。如果队列为空，将返回一个null,否则该方法返回队列中前面的一个Reference对象。利用这个方法，我们可以检查哪个SoftReference所软引用的对象已经被回收。于是我们可以把这些失去所软引用的对象的SoftReference对象清除掉。常用的方式为:</p>

<pre><code class="language-java">SoftReference ref = null;
while ((ref = (EmployeeRef) q.poll()) != null) {
    // 清除ref
}
</code></pre>

<h2 id="toc_2">使用软引用构建敏感数据的缓存</h2>

<h3 id="toc_3">为什么需要使用软引用</h3>

<p>首先，我们看一个雇员信息查询系统的实例。我们将使用一个Java语言实现的雇员信息查询系统查询存储在磁盘文件或者数据库中的雇员人事档案信息。作为一个用户，我们完全有可能需要回头去查看几分钟甚至几秒钟前查看过的雇员档案信息(同样，我们在浏览WEB页面的时候也经常会使用“后退”按钮)。这时我们通常会有两种程序实现方式:一种是把过去查看过的雇员信息保存在内存中，每一个存储了雇员档案信息的Java对象的生命周期贯穿整个应用程序始终;另一种是当用户开始查看其他雇员的档案信息的时候，把存储了当前所查看的雇员档案信息的Java对象结束引用，使得垃圾收集线程可以回收其所占用的内存空间，当用户再次需要浏览该雇员的档案信息的时候，重新构建该雇员的信息。很显然，第一种实现方法将造成大量的内存浪费，而第二种实现的缺陷在于即使垃圾收集线程还没有进行垃圾收集，包含雇员档案信息的对象仍然完好地保存在内存中，应用程序也要重新构建一个对象。我们知道，访问磁盘文件、访问网络资源、查询数据库等操作都是影响应用程序执行性能的重要因素，如果能重新获取那些尚未被回收的Java对象的引用，必将减少不必要的访问，大大提高程序的运行速度。</p>

<h2 id="toc_4">通过软可及对象重获方法实现Java对象的高速缓存</h2>

<p>利用Java平台垃圾收集机制的特性以及前述的垃圾对象重获方法，我们通过一个雇员信息查询系统的小例子来说明如何构建一种高速缓存器来避免重复构建同一个对象带来的性能损失。我们将一个雇员的档案信息定义为一个Employee类:</p>

<pre><code class="language-java">@Data
public class Employee {
    private String id;// 雇员的标识号码
    private String name;// 雇员姓名
    private String department;// 该雇员所在部门
    private String Phone;// 该雇员联系电话
    private int salary;// 该雇员薪资
    private String origin;// 该雇员信息的来源
}
</code></pre>

<p>这个Employee类的构造方法中我们可以预见，如果每次需要查询一个雇员的信息。哪怕是几秒中之前刚刚查询过的，都要重新构建一个实例，这是需要消耗很多时间的。下面是一个对Employee对象进行缓存的缓存器的定义:</p>

<pre><code class="language-java">import java.lang.ref.ReferenceQueue;
import java.lang.ref.SoftReference;
import java.util.HashTable;

public class EmployeeCache {
    // 一个Cache实例
    private static EmployeeCache cache;
    // 用于Chche内容的存储
    private HashTable&lt;String,EmployeeRef&gt; employeeRefs;
    private ReferenceQueue&lt;Employee&gt; q;// 垃圾Reference的队列
    // 继承SoftReference，使得每一个实例都具有可识别的标识。并且该标识与其在HashMap内的key相同。
    private class EmployeeRef extends SoftReference&lt;Employee&gt; {
        private String _key = &quot;&quot;;
        public EmployeeRef(Employee em, ReferenceQueue&lt;Employee&gt; q) {
            super(em, q);
            _key = em.getID();
        }
    }
    // 构建一个缓存器实例
    private EmployeeCache() {
        employeeRefs = new HashTable&lt;String,EmployeeRef&gt;();
        q = new ReferenceQueue&lt;Employee&gt;();
    }
    // 取得缓存器实例
    public static EmployeeCache getInstance() {
        if (cache == null) {
            cache = new EmployeeCache();
        }
        return cache;
    }
    // 以软引用的方式对一个Employee对象的实例进行引用并保存该引用
    private void cacheEmployee(Employee em) {
        cleanCache();// 清除垃圾引用
        EmployeeRef ref = new EmployeeRef(em, q);
        employeeRefs.put(em.getID(), ref);
    }
    // 依据所指定的ID号，重新获取相应Employee对象的实例
    public Employee getEmployee(String ID) {
        Employee em = null;
        // 缓存中是否有该Employee实例的软引用，如果有，从软引用中取得。
        if (employeeRefs.containsKey(ID)) {
            EmployeeRef ref = (EmployeeRef) employeeRefs.get(ID);
            em = (Employee) ref.get();
        }
        // 如果没有软引用，或者从软引用中得到的实例是null，重新构建一个实例，
        // 并保存对这个新建实例的软引用
        if (em == null) {
            em = new Employee(ID);
            System.out.println(&quot;Retrieve From EmployeeInfoCenter. ID=&quot; + ID);
            this.cacheEmployee(em);
        }
        return em;
    }
    // 清除那些所软引用的Employee对象已经被回收的EmployeeRef对象
    private void cleanCache() {
        EmployeeRef ref = null;
        while ((ref = (EmployeeRef) q.poll()) != null) {
            employeeRefs.remove(ref._key);
        }
    }
    // 清除Cache内的全部内容
    public void clearCache() {
        cleanCache();
        employeeRefs.clear();
        System.gc();
        System.runFinalization();
    }
}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[三、JVM自动内存管理--垃圾收集]]></title>
    <link href="http://www.throne4j.com/15866079598905.html"/>
    <updated>2020-04-11T20:25:59+08:00</updated>
    <id>http://www.throne4j.com/15866079598905.html</id>
    <content type="html"><![CDATA[
<p>GC- Garbage Collection 垃圾回收，在 JVM 中是自动化的垃圾回收机制，我们一般不用去关注，在 JVM 中 GC 的重要区域是堆空间。</p>

<p>我们也可以通过一些额外方式主动发起它，比如 System.gc(),主动发起,但是项目中切记不要使用 System.gc()。</p>

<h2 id="toc_0">1、如何识别垃圾对象</h2>

<p>既然是要回收内存中的垃圾，那么怎么判断一个对象变成垃圾了呢？</p>

<ul>
<li>引用计数算法</li>
<li>可达性分析算法</li>
</ul>

<h3 id="toc_1">1.1、引用计数算法</h3>

<p>给对象添加一个引用计数器，当一个地方引用它，则计数器加1，引用失效，计数器减1，任何时候 计数器为0 的对象就是不可在此使用的对象。<br/>
它很难解决对象直减的相互循环引用的问题。  </p>

<pre><code class="language-java">/**
 * 这个示例展示两个对象相互引用，程序计数器不会为0的，
 * 如果gc采用引用计数算法，这两个对象将不会得到回收。
 * 但实际情况是，这两个对象得到了回收，hospital jvm采用的不是引用计数垃圾回收算法。
 * -XX:+PrintGCDetails -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8
 *
 */
public class ReferenceCountingGC {

    public Object instance = null;

    private static final int _1MB = 1024 * 1024;

    private byte[] bigSize = new byte[2 * _1MB];

    public static void testGC() {
        ReferenceCountingGC objA = new ReferenceCountingGC();
        ReferenceCountingGC objB = new ReferenceCountingGC();
        objA.instance = objB;
        objB.instance = objA;

        objA = null;
        objB = null;

        System.gc();
    }

    public static void main(String[] args) {
        testGC();
    }
}
垃圾回收结果
[GC (System.gc()) [PSYoungGen: 8028K-&gt;624K(76288K)] 8028K-&gt;632K(251392K), 0.0016257 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[Full GC (System.gc()) [PSYoungGen: 624K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;418K(175104K)] 632K-&gt;418K(251392K), [Metaspace: 3153K-&gt;3153K(1056768K)], 0.0134161 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
Heap
 PSYoungGen      total 76288K, used 1966K [0x000000076ab00000, 0x0000000770000000, 0x00000007c0000000)
  eden space 65536K, 3% used [0x000000076ab00000,0x000000076aceb9e0,0x000000076eb00000)
  from space 10752K, 0% used [0x000000076eb00000,0x000000076eb00000,0x000000076f580000)
  to   space 10752K, 0% used [0x000000076f580000,0x000000076f580000,0x0000000770000000)
 ParOldGen       total 175104K, used 418K [0x00000006c0000000, 0x00000006cab00000, 0x000000076ab00000)
  object space 175104K, 0% used [0x00000006c0000000,0x00000006c0068b30,0x00000006cab00000)
 Metaspace       used 3173K, capacity 4496K, committed 4864K, reserved 1056768K
  class space    used 356K, capacity 388K, committed 512K, reserved 1048576K
</code></pre>

<h3 id="toc_2">1.2、可达性算法（✨）</h3>

<p>可达性算法是通过一系列被称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”（Reference Chain），如果某个对象到GC Roots间没有任何引用链相连，或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此对象是不可能再被使用的。</p>

<p>可作为GC Roots的对象包括下面几种：</p>

<ul>
<li>在虚拟机栈（栈帧中的本地变量表）中引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等。</li>
<li>在方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量</li>
<li>在方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用。</li>
<li>在本地方法栈中JNI（即通常所说的Native方法）引用的对象。</li>
<li>Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象（比如NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器。</li>
<li>所有被同步锁（synchronized关键字）持有的对象。</li>
<li>反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。</li>
</ul>

<p>重点是前面4种GC Roots对象，除了这些固定的GC Roots集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GC Roots集合。</p>

<p>类回收需要满足如下3个条件：</p>

<ul>
<li>该类所有的实例都已经被GC,也就是JVM中不存在该Class的任何实例</li>
<li>加载该类的ClassLoader已经被GC</li>
<li>该类对应的java.lang.Class对象没有在任何地方被引用，不能在任何地方通过反射访问该类的方法。</li>
<li>能让我等滚蛋的参数控制 -Xnoclassgc：禁用类的垃圾收集(GC)。</li>
</ul>

<p>可达性分析算法理论上要求全过程都基于一个能保障一致性的快照中才能够进行分析，这意味着必须全程冻结用户线程的运行。</p>

<h4 id="toc_3">1.2.1、并发的可达性分析（三色标记）</h4>

<p>可达性分析中，通过 GC Roots再继续往下遍历对象图，这一步骤的停顿时间就必定会与Java堆容量直接成正比例关系了：堆越大，存储的对象越多，对象图结构越复杂，要标记更多对象而产生的停顿时间自然就更长，这听起来是理所当然的事情。</p>

<p>想解决或者降低用户线程的停顿，就要先搞清楚为什么必须在一个能保障一致性的快照上才能进行对象图的遍历？</p>

<p>为了能解释清楚这个问题，我们引入三色标记（Tri-color Marking）作为工具来辅助推导，把遍历对象图过程中遇到的对象，按照“是否访问过”这个条件标记成以下三种颜色：</p>

<ul>
<li><p>白色：表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达。</p></li>
<li><p>灰色：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过。</p></li>
<li><p>黑色：表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色的对象代表已经扫描过，它是安全存活的，如果有其他对象引用指向了黑色对象，无须重新扫描一遍。黑色对象不可能直接（不经过灰色对象）指向某个白色对象。</p></li>
</ul>

<p><figure><img src="media/15866079598905/15964699168785.jpg" alt=""/></figure></p>

<p>当且仅当以下两个条件同时满足时，会产生“对象消失”的问题，即原本应该是黑色的对象被误标为白色：</p>

<ul>
<li>赋值器插入了一条或多条从黑色对象到白色对象的新引用；</li>
<li>赋值器删除了全部从灰色对象到该白色对象的直接或间接引用</li>
</ul>

<p>我们要解决并发扫描时的对象消失问题，只需破坏这两个条件的任意一个即可。由此分别产生了两种解决方案：增量更新（Incremental Update）和原始快照（Snapshot At The Beginning，SATB）。</p>

<p>增量更新要破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象为根，重新扫描一次。这可以简化理解为，黑色对象一旦新插入了指向白色对象的引用之后，它就变回灰色对象了。</p>

<p>原始快照要破坏的是第二个条件，当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。这也可以简化理解为，无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索。</p>

<p>CMS是基于增量更新来做并发标记的，G1、Shenandoah则是用原始快照来实现。</p>

<h2 id="toc_4">2、JVM 对象的四大引用</h2>

<p>java引用分为强引用、软引用、弱引用，虚引用四种。</p>

<ul>
<li>强引用是程序代码中最普遍一种引用，只要强引用关系存在，垃圾收集器永远不会回收调被引用的对象。</li>
<li>软引用（SoftReference）描述的是一些还有用，但非必须的对象，只被软引用关联着的对象，在系统发生内存溢出异常前，会把这些对象列进回收范围进行回收。 <a href="15866239860150.html">软引用（SoftReference）实现内存敏感的高速缓存</a></li>
</ul>

<pre><code class="language-java">public class TestSoftRef {
    @Data
    @AllArgsConstructor
    @ToString
    public static class User {
        public int id = 0;
        public String name = &quot;&quot;;
    
    }
    
    //
    public static void main(String[] args) {
        User u = new User(1, &quot;通天道人&quot;); //new是强引用
        SoftReference&lt;User&gt; userSoft = new SoftReference&lt;User&gt;(u);//软引用
        u = null;//干掉强引用，确保这个实例只有userSoft的软引用
        System.out.println(userSoft.get()); //看一下这个对象是否还在
        System.gc();//进行一次GC垃圾回收  千万不要写在业务代码中。
        System.out.println(&quot;After gc&quot;);
        System.out.println(userSoft.get());
        //往堆中填充数据，导致OOM
        List&lt;byte[]&gt; list = new LinkedList&lt;&gt;();
        try {
            for (int i = 0; i &lt; 100; i++) {
                //System.out.println(&quot;*************&quot;+userSoft.get());
                list.add(new byte[1024 * 1024 * 1]); //1M的对象 100m
            }
        } catch (Throwable e) {
            //抛出了OOM异常时打印软引用对象
            System.out.println(&quot;Exception*************&quot; + userSoft.get());
        }
    
    }
}
</code></pre>

<ul>
<li>弱引用（WeakReference）描述非必须对象，对象的重要性比软引用更加低，被弱引用关联的对象，下一次垃圾收集发生的时候，就会被回收掉。</li>
</ul>

<pre><code class="language-java">/**
 * 弱引用示例
 * -XX:+PrintGCDetails -XX:+PrintGC -Xms20m -Xmx20m
 **/
public class TestWeakRef {
    @Data
    public static class User {
        public int id = 0;
        public String name = &quot;&quot;;
    
        public User(int id, String name) {
            super();
            this.id = id;
            this.name = name;
        }
    
        @Override
        public String toString() {
            return &quot;User [id=&quot; + id + &quot;, name=&quot; + name + &quot;]&quot;;
        }
    
    }
    
    public static void main(String[] args) {
        User u = new User(1, &quot;通天道人&quot;);
        WeakReference&lt;User&gt; userWeak = new WeakReference&lt;User&gt;(u);
        u = null;//干掉强引用，确保这个实例只有userWeak的弱引用
        System.out.println(userWeak.get());
        System.gc();//进行一次GC垃圾回收,千万不要写在业务代码中。
        System.out.println(&quot;After gc&quot;);
        System.out.println(userWeak.get());
    }
}
</code></pre>

<ul>
<li>虚引用（PhantomReference）基本没什么用，一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知。</li>
</ul>

<h2 id="toc_5">3、方法区的回收</h2>

<p>方法区并不是垃圾回收的主要区域，但是方法区也可以回收以下两部分的内容： 废弃常量和无用类。</p>

<h2 id="toc_6">4、垃圾收集算法</h2>

<h3 id="toc_7">分代回收理论</h3>

<p>当前商业虚拟机的垃圾回收器，大多遵循“分代收集”的理论来进行设计，这个理论大体上是这么描述的：</p>

<ul>
<li>绝大部分的对象都是朝生夕死。</li>
<li>熬过多次垃圾回收的对象就越难回收。</li>
<li>跨代引用相对于同代引用来说仅占极少数。<br/>
根据以上理论，朝生夕死的对象放一个区域，难回收的对象放另外一个区域，这个就构成了新生代和老年代</li>
</ul>

<p>常见的垃圾收集算法有</p>

<ul>
<li>标记-清除算法 mark-sweep</li>
<li>标记整理算法 mark-compact</li>
<li>复制算法 copying</li>
<li>分代算法 generational</li>
<li>分区算法</li>
</ul>

<h3 id="toc_8">4.1、 标记清除算法</h3>

<p>算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，统一回收所有未被标记的对象。</p>

<p>过程:</p>

<ul>
<li>首先标记所有需要回收的对象</li>
<li>统一回收被标记的对象<br/>
缺点:<br/>
1.效率问题，标记和清除效率都不高 2.标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不 提前触发另一次垃圾收集动作。</li>
</ul>

<p><figure><img src="media/15866079598905/15961870545090.jpg" alt="标记清除算法示意图"/><figcaption>标记清除算法示意图</figcaption></figure></p>

<h3 id="toc_9">4.2、标记整理算法</h3>

<p>首先标记出所有需要回收的对象，在标记完成后，后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端<br/>
边界以外的内存</p>

<p><figure><img src="media/15866079598905/15961895612170.jpg" alt=""/></figure></p>

<h3 id="toc_10">4.3、复制算法</h3>

<p>复制算法将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。</p>

<p>在大部分对象需要回收的情况下这种方式的效率非常高，但是对于大部分对象存活的情况，效率就大打折扣了，另外内存空间浪费严重。</p>

<p><figure><img src="media/15866079598905/15961872702735.jpg" alt="复制算法示意图"/><figcaption>复制算法示意图</figcaption></figure></p>

<h3 id="toc_11">4.4、JVM 堆内存采用的垃圾收集算法</h3>

<h4 id="toc_12">4.4.1、新生代采用算法</h4>

<ul>
<li>新生成的对象都放在新生代，<strong>新生代用复制算法进行gc</strong>(理论上，年轻代对象的生命周期非常短，是复制算法)</li>
<li>年轻代分为3个区域，Eden区、from survivor、 to survivor，Eden区满的时候，还存活的对象将被复制到一个from survivor，当from survivor区域满了之后，依然存活的对象被移动到to survivor 区域，to survivor区域满了之后，依然存活的对象会被复制到老年代。</li>
<li>Eden和两个survivor的缺省比例是8:1:1</li>
</ul>

<p>新生代的垃圾回收被称为 minor gc 或者 young gc ，发生的频率高、执行速度快。</p>

<p>新生代中的对象 90% 是“朝生夕死”的，所以一般来说回收占据 10%的空间够用了，所以并不需要按照 1:1 的比例来划分内存空间，而是 将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor[1]。当回收时，将 Eden 和 Survivor 中还存活着的对象一 次性地复制到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才用过的 Survivor 空间。</p>

<h4 id="toc_13">4.4.2、老年代采用算法</h4>

<ul>
<li>一般采用Mark-Sweep或者Mark-Compact算法进行GC</li>
<li>存放了经过一个或多次GC还存活的对象</li>
<li>有多种垃圾收集器可以选择。每种垃圾收集器可以看做一个GC算法的具体实现。</li>
</ul>

<p>可以根据具体应用的需求选用何时的垃圾收集器(追求吞吐量还是追求最短的湘阴那个时间?)</p>

<h4 id="toc_14">4.4.3、根节点枚举</h4>

<p>所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的，因此毫无疑问根节点枚举与之前提及的整理内存碎片一样会面临相似的“Stop The World”的困扰。</p>

<h3 id="toc_15">4.5、分代算法、分区算法</h3>

<p>分代算法基于如下思想：jvm 把内存划分为不同的块，根据每块内存区间的特点，使用适合的算法回收<br/>
分区算法是将整个堆空间划分为联系的不同的小区间，每个小区间都独立使用，独立回收，这种算法的好处是可以控制一次回收多个小区间。</p>

<h2 id="toc_16">5、垃圾收集器</h2>

<h3 id="toc_17">5.1、GC的时机</h3>

<ul>
<li>在分代模型的基础上，GC从时机上分为两种: Scavenge GC 和 Full GC</li>
<li>Scavenge GC(Minor GC)
<ul>
<li>触发时机: 新对象生成时，Eden空间满了</li>
<li>理论上Eden区域大多数对象会在Scavenge GC 回收，复制算法的执行效率会非常高，Scavenge GC时间比较短。</li>
</ul></li>
<li>Full GC 
<ul>
<li>对整个JVM进行整理吗，包括Young、old和Perm/MetaSpace</li>
<li>主要的触发时机: <br/>
a) Old满了 <br/>
b) Perm/MetaSpace满了<br/>
c) System.gc()</li>
<li>效率低，尽量减少Full GC。</li>
</ul></li>
</ul>

<h4 id="toc_18">5.1.1、安全点</h4>

<p>程序的代码指令流并不是在任意位置都能停顿下来开始垃圾收集，而是强制要求必须执行到达指定的位置才能够暂停下来进行垃圾回收，这个指定位置被称为 安全点。</p>

<p>安全点的选定既不能太少以至于让收集器等待时间过长，也不能太过频繁以至于过分增大运行时的内存负荷。例如方法调用、循环跳转、异常跳转等都属于指令序列复用，所以只有具有这些功能的指令才会产生安全点。</p>

<p>另外一个需要考虑的问题是，如何在垃圾收集发生时让所有线程（这里其实不包括执行JNI调用的线程）都跑到最近的安全点，然后停顿下来。</p>

<p>这里有两种方案可供选择：抢先式中断（Preemptive Suspension）和主动式中断（Voluntary Suspension），抢先式中断不需要线程的执行代码主动去配合，在垃圾收集发生时，系统首先把所有用户线程全部中断，如果发现有用户线程中断的地方不在安全点上，就恢复这条线程执行，让它一会再重新中断，直到跑到安全点上。现在几乎没有虚拟机实现采用抢先式中断来暂停线程响应GC事件。</p>

<p>而主动式中断的思想是当垃圾收集需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志位，各个线程执行过程时会不停地主动去轮询这个标志，一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起。轮询标志的地方和安全点是重合的，另外还要加上所有创建对象和其他需要在Java堆上分配内存的地方，这是为了检查是否即将要发生垃圾收集，避免没有足够内存分配新对象。</p>

<h4 id="toc_19">5.1.2、安全区域</h4>

<p>安全点机制保证了程序执行时，在不太长的时间内就会遇到可进入垃圾收集过程的安全点。但是，程序“不执行”的时候呢？所谓的程序不执行就是没有分配处理器时间，典型的场景便是用户线程处于Sleep状态或者Blocked状态，这时候线程无法响应虚拟机的中断请求，不能再走到安全的地方去中断挂起自己，虚拟机也显然不可能持续等待线程重新被激活分配处理器时间。对于这种情况，就必须引入安全区域（Safe Region）来解决。</p>

<p>安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化，因此，在这个区域中任意地方开始垃圾收集都是安全的。我们也可以把安全区域看作被扩展拉伸了的安全点。</p>

<p><figure><img src="media/15866079598905/15965556823120.jpg" alt=""/></figure></p>

<h4 id="toc_20">5.1.3、记忆集与卡表</h4>

<p>为解决对象跨代引用所带来的问题，垃圾收集器在新生代中建立了名为记忆集（Remembered Set）的数据结构，用以避免把整个老年代加进GC Roots扫描范围。</p>

<p>所有涉及部分区域收集（Partial GC）行为的垃圾收集器，典型的如G1、ZGC和Shenandoah收集器，都会面临对象跨代引用所带来的问题。</p>

<p>记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构。</p>

<p>在垃圾收集的场景中，收集器只需要通过记忆集判断出某一块非收集区域是否存在有指向了收集区域的指针就可以了，并不需要了解这些跨代指针的全部细节，下面列举了一些可供选择的记录精度</p>

<ul>
<li>字长精度 ： 每个记录精确到一个机器字长，该字长包含跨代指针。</li>
<li>对象精度 ： 每个记录精确到一个对象，该对象里包含跨带指针。</li>
<li>卡精度 ： 每个记录精确到一块内存区域，该区域内有对象含有跨代指针。</li>
</ul>

<p>第三种“卡精度” 所指的是用一种称为“卡表”（Card Table）的方式去实现记忆集，卡表就是记忆集的一种具体实现，它定义了记忆集的记录精度、与堆内存的映射关系等。</p>

<p>卡表最简单的形式可以只是一个字节数组，数组每个元素都对应着其标识内存区域中的一块特定大小的内存块，这个内存块被称作 “卡页”</p>

<p>一个卡页的内存中通常包含不止一个对象，只要卡页内有一个（或更多）对象的字段存在着跨代指针，那就将对应卡表的数组元素的值标识为1，称为这个元素变脏（Dirty），没有则标识为0。</p>

<p>一般来说，卡页大小都是以2的N次幂的字节数，通过上面代码可以看出HotSpot中使用的卡页是2的9次幂，即512字节（地址右移9位，相当于用地址除以512）。</p>

<h4 id="toc_21">5.1.4、写屏障</h4>

<p>卡表元素如何维护的问题，例如它们何时变脏、谁来把它们变脏呢？</p>

<p>卡表元素何时变脏的答案是很明确的——有其他分代区域中对象引用了本区域对象时，其对应的卡表元素就应该变脏，变脏时间点原则上应该发生在引用类型字段赋值的那一刻。</p>

<p>写屏障可以看作在虚拟机层面对“引用类型字段赋值”这个动作的AOP切面，在引用对象赋值时会产生一个环形（Around）通知，供程序执行额外的动作，也就是说赋值的前后都在写屏障的覆盖范畴内。在赋值前的部分的写屏障叫作写前屏障（Pre-Write Barrier），在赋值后的则叫作写后屏障（Post-Write Barrier）。</p>

<p>应用写屏障后，虚拟机就会为所有赋值操作生成相应的指令，一旦收集器在写屏障中增加了更新卡表操作，无论更新的是不是老年代对新生代对象的引用，每次只要对引用进行更新，就会产生额外的开销，不过这个开销与Minor GC时扫描整个老年代的代价相比还是低得多的。</p>

<h4 id="toc_22">5.1.5、伪共享</h4>

<p>卡表在高并发场景下还面临着“伪共享”（False Sharing）问题。</p>

<p>伪共享是处理并发底层细节时一种经常需要考虑的问题，现代中央处理器的缓存系统中是以缓存行（Cache Line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量恰好共享同一个缓存行，就会彼此影响（写回、无效化或者同步）而导致性能降低，这就是伪共享问题。</p>

<p>为了避免伪共享问题，一种简单的解决方案是不采用无条件的写屏障，而是先检查卡表标记，只有当该卡表元素未被标记过时才将其标记为变脏。</p>

<p>在JDK 7之后，HotSpot虚拟机增加了一个新的参数-XX：+UseCondCardMark，用来决定是否开启卡表更新的条件判断。开启会增加一次额外判断的开销，但能够避免伪共享问题，两者各有性能损耗，是否打开要根据应用实际运行情况来进行测试权衡。</p>

<h3 id="toc_23">5.2、垃圾回收器</h3>

<p>垃圾回收器三项指标：</p>

<ul>
<li>内存占用（Footprint）</li>
<li>吞吐量（Throughput）</li>
<li>延迟（Latency）</li>
</ul>

<p>三者共同构成了一个“不可能三角”。</p>

<p><figure><img src="media/15866079598905/15964733477079.jpg" alt=""/></figure></p>

<p>年轻代的垃圾收集算法有 Serial、ParNew、Parallel Scavenge<br/>
老年代的垃圾收集算法有 CMS、Serial Old(MSC)、Parallel Old</p>

<p>下图是各款收集器的并发情况，浅颜色需要暂停用户线程，深颜色是gc与用户线程是并发工作的：<br/>
<figure><img src="media/15866079598905/15965544967402.jpg" alt=""/></figure></p>

<h4 id="toc_24">5.2.1、Serial</h4>

<p>-XX:+UseSerialGC 新生代和老年代都用串行收集器</p>

<p>单线程收集器，收集时会暂停所有的工作线程(STW)</p>

<ul>
<li>最早的收集器，单线程执行</li>
<li>New和Old Generation都可以使用</li>
<li>在新生代采用复式算法；在老年代使用Mark-Compact算法</li>
<li>虚拟机运行在client模式时的默认新生代垃圾收集器。</li>
</ul>

<p><figure><img src="media/15866079598905/15964726443598.jpg" alt=""/></figure></p>

<h4 id="toc_25">5.2.2、ParNew收集器</h4>

<p>-XX:+UseParNewGC 新生代使用 ParNew，老年代使用 Serial Old</p>

<p>Serial收集器的多线程版本，与 CMS 进行配合，对于 CMS(CMS 只回收老年代)，新生代垃圾回收器只有 Serial 与 ParNew 可以选。</p>

<p>通过-XX:ParallelGCThreads来控制GC线程数的多少</p>

<p><figure><img src="media/15866079598905/15964732844452.jpg" alt=""/></figure></p>

<h4 id="toc_26">5.2.3、ParallelGC 收集器</h4>

<p>XX:+UseParallelGC 新生代使用 ParallerGC，老年代使用 Parallel Old，JDK1.8 默认就是这个组合。</p>

<ul>
<li>多线程收集器</li>
<li>采用复制算法</li>
<li>实现以吞吐量最大化为目标(允许较长时间内的STOP THE WORLD)</li>
</ul>

<p>高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。</p>

<p>所谓吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了 100 分钟，其中垃圾收集花掉 1 分钟，那吞吐量就是 99%。</p>

<p>-XX:+UseParallelGC 新生代使用 Parallel Scavenge，老年代使用 Parallel Old</p>

<p>-XX：MaxGCPauseMillis 参数允许的值是一个大于0的毫秒数，收集器将尽力保证内存回收花费的时间不超过用户设定值（不容乐观）</p>

<p>-XX：GCTimeRatio 参数的值则应当是一个大于0小于100的整数，也就是垃圾收集时间占总时间的比率，相当于吞吐量的倒数</p>

<p>-XX:+UseAdaptiveSizePolicy （默认开启）。这是一个开关参数， 当这个参数被激活之后，就不需要人工指定新生代的大小(-Xmn)、Eden 与 Survivor 区的比例(-XX:SurvivorRatio)、 晋升老年代对象大小(-XX:PretenureSizeThreshold)等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。</p>

<h4 id="toc_27">5.2.4、CMS (Concurrent mark sweep)</h4>

<p>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。<br/>
<figure><img src="media/15866079598905/16148730320393.jpg" alt=""/></figure></p>

<p>从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于标记-清除算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为四个步骤，包括：</p>

<ul>
<li>初始标记（CMS initial mark）<br/>
短暂，仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快。</li>
<li>并发标记（CMS concurrent mark）<br/>
耗时比较长，和用户的应用程序同时进行，进行 GC Roots 追踪的过程，标记从 GCRoots 开始关联的所有对象开始遍历整个可达分析路径的对象。</li>
<li>重新标记（CMS remark）<br/>
短暂，为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。</li>
<li>并发清除（CMS concurrent sweep）</li>
</ul>

<p>其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。由于在整个过程中耗时最长的并发标记和并发清除阶段中，垃圾收集器线程都可以与用户线程一起工作，所以从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。</p>

<p>主要的优点在名字上已经体现出来：并发收集、低停顿</p>

<p>三个明显的缺点：</p>

<ul>
<li>CMS收集器对处理器资源非常敏感。<br/>
采用了并发的收集，CMS默认启动的回收线程数是（处理器核心数量+3）/4，当处理核心数不足 4 个时，CMS 对用户的影响较大。</li>
<li><p>CMS收集器无法处理“浮动垃圾”（Floating Garbage），有可能出现“Concurrent Mode Failure”失败进而导致另一次完全“Stop The World”的Full GC的产生。使用串行收集器进行垃圾回收。</p></li>
<li><p>会有大量空间碎片产生。可能会频繁触发Full GC。<br/>
当碎片较多时，给大对象的分配带来很大的麻烦，为了解决这个问题，CMS 提供一个参数：-XX:+UseCMSCompactAtFullCollection，一般是开启的，如果分配不了大对象，就进行内存碎片的整理过程。</p></li>
</ul>

<p>浮动垃圾： 在CMS的并发标记和并发清理阶段，用户线程是还在继续运行的，程序在运行自然就还会伴随有新的垃圾对象不断产生，但这一部分垃圾对象是出现在标记过程结束以后，CMS无法在当次收集中处理掉它们，只好留待下一次垃圾收集时再清理掉。</p>

<p>-XX:+UseConcMarkSweepGC ，表示新生代使用 ParNew，老年代的用 CMS<br/>
该垃圾回收器适合回收堆空间几个 G~ 20G 左右。</p>

<p>-XX:ConcGCThreads 设置并发线程数量，默认并发线程数是(parallelGCThread+3)/4，其中parallelGCThread 表示 GC并行时使用的线程数量</p>

<p>-XX:CMSInitiatingOccupancyFraction 可以指定当老年代空间使用率达到多少时进行一次 CMS 垃圾回收。</p>

<p>-XX:+UseCMSCompactAtFullCollection 开关可以使CMS在垃圾收集完成后，进行一次内存碎片整理，内存碎片整理不是并发进行的。</p>

<p>-XX:CMSFullGCsbeforeCompaction 多少次 CMS 后进行一次内存压缩。</p>

<h4 id="toc_28">5.2.5、Serial Old(MSC)</h4>

<ul>
<li>采用Mark-compact算法</li>
</ul>

<p><figure><img src="media/15866079598905/15964737309982.jpg" alt=""/></figure></p>

<h4 id="toc_29">5.2.6、Parallel Old</h4>

<ul>
<li>Parallel Scavenge 在老年代的实现</li>
<li>采用Mark-compact算法</li>
<li>更注重吞吐量</li>
</ul>

<p><figure><img src="media/15866079598905/15964738440764.jpg" alt=""/></figure></p>

<h4 id="toc_30">5.2.7、Garbage First 收集器</h4>

<p>-XX:+UseG1GC 开启G1垃圾收集器。</p>

<h5 id="toc_31">G1 介绍</h5>

<p>一般建议逐渐增大该值，随着 size 增加，垃圾的存活时间更长，GC 间隔更长，但每次 GC 的时间也会更长。</p>

<p>G1 将堆内存“化整为零”，将堆内存划分成多个大小相等独立区域（Region），每一个 Region 都可以根据需要，扮演新生代的 Eden 空间、Survivor 空间，或者老年代空间。新生代和老年代不再物理进行隔离。</p>

<p>G1 跟踪各个 Region 里面的垃圾堆 积的价值大小(回收所获得的空间大小以及回收所需时间的经验值)，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region (这也就是 Garbage-First 名称的来由)。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。</p>

<p>算法：标记—整理 （old，humongous） 和复制回收算法(survivor)。</p>

<p><figure><img src="media/15866079598905/15964751147238.jpg" alt=""/></figure></p>

<p><figure><img src="media/15866079598905/15965495989846.jpg" alt="G1收集器运行示意图"/><figcaption>G1收集器运行示意图</figcaption></figure></p>

<h5 id="toc_32">G1 GC 主要的参数</h5>

<table>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
</tr>
</thead>

<tbody>
<tr>
<td>-XX:+UseG1GC</td>
<td>开启G1</td>
</tr>
<tr>
<td>-XX:G1HeapRegionSize=n</td>
<td>设置 Region 大小，并非最终值</td>
</tr>
<tr>
<td>-XX:MaxGCPauseMillis</td>
<td>设置 G1 收集过程目标时间，搜集过程中的最大停顿时间，默认值 200ms，不是硬性条件</td>
</tr>
<tr>
<td>-XX:G1NewSizePercent</td>
<td>新生代最小值，默认值 5%</td>
</tr>
<tr>
<td>-XX:G1MaxNewSizePercent</td>
<td>新生代最大值，默认值 60%</td>
</tr>
<tr>
<td>-XX:ParallelGCThreads</td>
<td>STW 期间，并行 GC 线程数</td>
</tr>
<tr>
<td>-XX:ConcGCThreads=n</td>
<td>并发标记阶段，并行执行的线程数</td>
</tr>
<tr>
<td>-XX:InitiatingHeapOccupancyPercent</td>
<td>设置触发标记周期的 Java 堆占用率阈值。默认值是 45%。这里的 java 堆占比指的是 non_young_capacity_bytes，包括 old+humongous</td>
</tr>
</tbody>
</table>

<h5 id="toc_33">全局并发标记(global concurrent marking)</h5>

<ul>
<li><p>初始标记:仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改TAMS(Nest Top Mark Start)的值，让下一阶段用户程序并发运行时，能在正确可以的 Region 中创建对象，此阶段需要停顿线程(STW)，但耗时很短。</p></li>
<li><p>并发标记:从 GC Root 开始对堆中对象进行可达性分析，找到存活对象，此阶段耗时较长，但可与用户程序并发执行。</p></li>
<li><p>最终标记:为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到Remembered Set 中。这阶段需要停顿线程(STW)，但是可并行执行。</p></li>
<li><p>筛选回收:首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起 并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。</p></li>
</ul>

<h5 id="toc_34">G1垃圾收集器特点：</h5>

<ul>
<li>并行与并发：G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿的时间，部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 Java 程序继续执行。</li>
<li>分代收集：与其他收集器一样，分代概念在 G1 中依然得以保留。虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次 GC 的旧对象以获取更好的收集效果。</li>
<li>空间整理：与 CMS 的“标记—清理”算法不同，G1 从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着 G1 运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 GC。</li>
<li>追求停顿时间：-XX:MaxGCPauseMillis 指定目标的最大停顿时间，G1 尝试调整新生代和老年代的比例，堆大小，晋升年龄来达到这个目标时间。</li>
</ul>

<h3 id="toc_35">5.3、GC日志</h3>

<pre><code class="language-text">-XX:+PrintGC 输出简要GC日志 
-XX:+PrintGCDetails 输出详细GC日志 
-Xloggc:gc.log  输出GC日志到文件
-XX:+PrintGCTimeStamps 输出GC的时间戳（以JVM启动到当期的总时长的时间戳形式） 
-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800） 
-XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息
-verbose:gc 开启GC日志
-XX:+PrintReferenceGC 打印年轻代各个引用的数量以及时长

</code></pre>

<p><figure><img src="media/15866079598905/15973070472442.jpg" alt=""/></figure></p>

<p><figure><img src="media/15866079598905/15973132054448.jpg" alt=""/></figure></p>

<p>·user：进程执行用户态代码所耗费的处理器时间。<br/>
·sys：进程执行核心态代码所耗费的处理器时间。<br/>
·real：执行动作从开始到结束耗费的时钟时间</p>

<p>前面两个是处理器时间，而最后一个是时钟时间，它们的区别是处理器时间代表的是线程占用处理器一个核心的耗时计数，而时钟时间就是现实世界中的时间计数。</p>

<p>如果是单核单线程的场景下，这两者可以认为是等价的，但如果是多核环境下，同一个时钟时间内有多少处理器核心正在工作，就会有多少倍的处理器时间被消耗和记录下来。</p>

<p>在垃圾收集调优时，我们主要依据real时间为目标来优化程序，因为最终用户只关心发出请求到得到响应所花费的时间，也就是响应速度，而不太关心程序到底使用了多少个线程或者处理器来完成任务。</p>

<h3 id="toc_36">5.4、垃圾收集器总结</h3>

<table>
<thead>
<tr>
<th>收集器</th>
<th>收集对象和算法</th>
<th>收集器类型</th>
<th>说明</th>
<th>适用场景</th>
</tr>
</thead>

<tbody>
<tr>
<td>Serial</td>
<td>新生代，复制算法</td>
<td>单线程</td>
<td></td>
<td>简单高效；适合内存不大的情况；</td>
</tr>
<tr>
<td>ParNew</td>
<td>新生代，复制算法</td>
<td>并行的多线程收集器</td>
<td>ParNew 垃圾收集器是Serial 收集器的多线程版本</td>
<td>搭配 CMS 垃圾回收器的首选</td>
</tr>
<tr>
<td>Parallel Scavenge吞吐量优先收集器</td>
<td>新生代，复制算法</td>
<td>并行的多线程收集器</td>
<td>类似 ParNew，更加关注吞吐量，达到一个可控制的吞吐量；</td>
<td>本身是 Server 级别多 CPU 机器上的默认 GC 方式，主要适合后台运算不需要太多交互的任务；</td>
</tr>
<tr>
<td>Serial Old</td>
<td>老年代，标记整理算法</td>
<td>单线程</td>
<td></td>
<td>Client 模式下虚拟机使用</td>
</tr>
<tr>
<td>Parallel Old</td>
<td>老年代，标记整理算法</td>
<td>并行的多线程收集器</td>
<td>Parallel Scavenge 收集器的老年代版本，为了配合 Parallel Scavenge 的面向吞吐量的特性而开发的对应组合；</td>
<td>在注重吞吐量以及 CPU 资源敏感的场合采用</td>
</tr>
<tr>
<td>CMS</td>
<td>老年代，标记清除算法</td>
<td>并行与并发收集器</td>
<td>尽可能的缩短垃圾收集时用户线程停止时间；缺点在于：1.内存碎片2.需要更多 cpu 资源3.浮动垃圾问题，需要更大的堆空间</td>
<td>重视服务的响应速度、 系统停顿时间和用户体验的互联网网站或者 B/S 系统。互联网后端目前 cms 是主流的垃圾回收器；</td>
</tr>
<tr>
<td>G1</td>
<td>跨新生代和老年代； 标记整理 + 化整为零</td>
<td>并行与并发收集器</td>
<td>JDK1.7 才正式引入，采用分区回收的思维，基本不牺牲吞吐量的前提下完成低停顿的内存回收；可预测的停顿是其最大的优势；</td>
<td>面向服务端应用的垃圾回收器，目标为取代 CMS</td>
</tr>
</tbody>
</table>

<h2 id="toc_37">6、垃圾收集器的重要参数 （使用-XX:+/- 开启/关闭）</h2>

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>UseSerialGC</td>
<td>虚拟机运行在 Client 模式下的默认值，打开此开关后，使用 Serial+Serial Old 的收集器组合进行内存回收</td>
</tr>
<tr>
<td>UseParNewGC</td>
<td>打开此开关后，使用 ParNew + Serial Old 的收集器组合进行内存回收</td>
</tr>
<tr>
<td>UseConcMarkSweepGC</td>
<td>打开此开关后，使用 ParNew + CMS + Serial Old 的收集器组合进行内存回收。Serial Old 收集器将作为 CMS 收集 器出现 Concurrent Mode Failure 失败后的后备收集器使用</td>
</tr>
<tr>
<td>UseParallelGC</td>
<td>虚拟机运行在 Server 模式下的默认值，打开此开关后，使用 Parallel Scavenge + Serial Old(PS MarkSweep) 的收集 器组合进行内存回收</td>
</tr>
<tr>
<td>UseParallelOldGC</td>
<td>打开此开关后，使用 Parallel Scavenge + Parallel Old 的收集器组合进行内存回收</td>
</tr>
<tr>
<td>SurvivorRatio</td>
<td>新生代中 Eden 区域与 Survivor 区域的容量比值，默认为 8，代表 Eden : Survivor = 8 : 1</td>
</tr>
<tr>
<td>PretenureSizeThreshold</td>
<td>直接晋升到老年代的对象大小，设置这个参数后，大于这个参数的对象将直接在老年代分配</td>
</tr>
<tr>
<td>MaxTenuringThreshold</td>
<td>晋升到老年代的对象年龄，每个对象在坚持过一次 Minor GC 之后，年龄就增加 1，当超过这个参数值时就进入 老年代</td>
</tr>
<tr>
<td>UseAdaptiveSizePolicy</td>
<td>动态调整 Java 堆中各个区域的大小以及进入老年代的年龄</td>
</tr>
<tr>
<td>HandlePromotionFailure</td>
<td>是否允许分配担保失败，即老年代的剩余空间不足以应付新生代的整个 Eden 和 Survivor 区的所有对象都存活 的极端情况</td>
</tr>
<tr>
<td>ParallelGCThreads</td>
<td>设置并行 GC 时进行内存回收的线程数</td>
</tr>
<tr>
<td>GCTimeRatio</td>
<td>GC 时间占总时间的比率，默认值为 99，即允许 1% 的 GC 时间，仅在使用 Parallel Scavenge 收集器生效</td>
</tr>
<tr>
<td>MaxGCPauseMillis</td>
<td>设置 GC 的最大停顿时间，仅在使用 Parallel Scavenge 收集器时生效</td>
</tr>
<tr>
<td>CMSInitiatingOccupancyFraction</td>
<td>设置 CMS 收集器在老年代空间被使用多少后触发垃圾收集，默认值为 68%，仅在使用 CMS 收集器时生效</td>
</tr>
<tr>
<td>UseCMSCompactAtFullCollection</td>
<td>设置 CMS 收集器在完成垃圾收集后是否要进行一次内存碎片整理，仅在使用 CMS 收集器时生效</td>
</tr>
<tr>
<td>CMSFullGCsBeforeCompaction</td>
<td>设置 CMS 收集器在进行若干次垃圾收集后再启动一次内存碎片整理，仅在使用 CMS 收集器时生效</td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[二、JVM自动内存管理--java内存区域与内存溢出异常]]></title>
    <link href="http://www.throne4j.com/15865981620428.html"/>
    <updated>2020-04-11T17:42:42+08:00</updated>
    <id>http://www.throne4j.com/15865981620428.html</id>
    <content type="html"><![CDATA[
<p>java 技术体系的自动内存管理的最根本的目标就是要自动化的解决两个问题：</p>

<ul>
<li>自动给对象分配内存</li>
<li>自动回收分配给对象的内存</li>
</ul>

<p>我们在进行java开发的过程中，我们根本不用去为每一个对象申请以及释放内存空间，这是是由于JVM帮我们完成了对象的内存管理，如果我们不了解JVM是怎么使用内存的，一旦发生内存泄漏或者溢出方面的问题，那只能火急火燎的找大牛过来帮忙处理了。</p>

<h2 id="toc_0">运行时数据区域</h2>

<p>JVM在运行过程中，会把内存分为多个不同的数据区，他们各有各的用途，我们通过下图看下JVM是如何对内存结构进行划分的：<br/>
<figure><img src="media/15866079598905/15866802670837.jpg" alt="" style="width:1082px;"/></figure></p>

<h3 id="toc_1">1、程序计数器</h3>

<p>程序计数器是一块较小的内存空间，它可以看做是当前线程所执行字节码的行号指示器。</p>

<p>字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制流的指示器(分支、循环、跳转、异常处理、线程回复等基础功能都需要程序计数器)。</p>

<p>由于 jvm 虚拟机的多线程是通过线程轮流切、分配处理器执行时间(cpu时间片轮转机制)来实现，因此为了线程在切换后能恢复到正确的执行位置，每条线程需要一个独立的程序计数器，各条线程的程序计数器互不影响，独立存储，因此<strong>程序计数器是线程私有的</strong>。此块区域也是唯一一个没有OOM的内存区。</p>

<h3 id="toc_2">2、java虚拟机栈</h3>

<p>java虚拟机栈也是线程私有的，它的生命周期与线程相同，虚拟机栈描述的是java方法执行的线程内存模型：每个方法被执行的时候，JVM都会同步创建一个栈帧（Stack Frame）用于存储 局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。</p>

<p>Java虚拟机以方法作为最基本的执行单元，“栈帧”（Stack Frame）则是用于支持虚拟机进行方法调用和方法执行背后的数据结构，它也是虚拟机运行时数据区中的虚拟机栈（Virtual Machine Stack）的栈元素。</p>

<p>虚拟机栈的大小缺省为 1M，可用参数 –Xss 调整大小，例如-Xss256k。</p>

<h4 id="toc_3">2.1、栈帧</h4>

<p>每一个方法从调用开始至执行结束的过程，都对应着一个栈帧在虚拟机栈里面从入栈到出栈的过程。</p>

<p>一个栈帧需要分配多少内存，并不会受到程序运行期变量数据的影响，而仅仅取决于程序源码和具体的虚拟机实现的栈内存布局形式。</p>

<p>我们看下栈帧的结构，如下图所示：<br/>
<figure><img src="media/15865981620428/15960979383450.jpg" alt=""/></figure></p>

<h5 id="toc_4">2.1.1、局部变量表</h5>

<p>局部变量表是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量。存放如下数据：</p>

<ul>
<li>编译期可知的各种 java 虚拟机基本数据类型（boolean、byte、char、short、int、float、long、double）,其内存分配在栈上，变量出了作用域就会自动释放；</li>
<li><p>对象引用 <br/>
reference类型:一是从根据引用直接或间接地查找到对象在Java堆中的数据存放的起始地址或索引，二是根据引用直接或间接地查找到对象所属数据类型在方法区中的存储的类型信息, 无论是成员变量，局部变量，还是类变量，它们指向的对象都存储在堆内存中；</p></li>
<li><p>returnAddress类型(指向了一条字节码指令的地址)<br/>
目前已经很少见了，它是为字节码指令jsr、jsr_w和ret服务的，指向了一条字节码指令的地址，某些很古老的Java虚拟机曾经使用这几条指令来实现异常处理时的跳转，但现在也已经全部改为采用异常表来代替了。</p></li>
</ul>

<p>这些数据类型在局部变量表中的存储空间以局部变量槽（Slot）来表示。</p>

<p>局部变量表的容量以变量槽（Variable Slot）为最小单位。其中64位的double和long类型的数据会占用2个局部变量空间(slot), 其他基本数据类型只占用1个。局部变量空间所需的内存空间在编译期间完成分配。</p>

<p>Java虚拟机通过索引定位的方式使用局部变量表，索引值的范围是从0开始至局部变量表最大的变量槽数量。如果访问的是32位数据类型的变量，索引N就代表了使用第N个变量槽，如果访问的是64位数据类型的变量，则会同时使用第N和N+1两个变量槽。对于两个相邻的共同存放一个64位数据的两个变量槽，虚拟机不允许采用任何方式单独访问其中的某一个。</p>

<p>当一个方法被调用时，Java虚拟机会使用局部变量表来完成参数值到参数变量列表的传递过程，即实参到形参的传递。如果执行的是实例方法（没有被static修饰的方法），那局部变量表中第0位索引的变量槽默认是用于传递方法所属对象实例的引用，在方法中可以通过关键字“this”来访问到这个隐含的参数。其余参数则按照参数表顺序排列，占用从1开始的局部变量槽，参数表分配完毕后，再根据方法体内部定义的变量顺序和作用域分配其余的变量槽。</p>

<p>为了尽可能节省栈帧耗用的内存空间，局部变量表中的变量槽是可以重用的，方法体中定义的变量，其作用域并不一定会覆盖整个方法体，如果当前字节码PC计数器的值已经超出了某个变量的作用域，那这个变量对应的变量槽就可以交给其他变量来重用。</p>

<p>不过，这样的设计除了节省栈帧空间以外，还会伴随有少量额外的副作用，例如在某些情况下变量槽的复用会直接影响到系统的垃圾收集行为,例如：</p>

<pre><code class="language-java">public static void main(String[] args) {
    byte[] bytes = new byte[1024 * 1024 * 64];
    System.gc();
}

[0.003s][warning][gc] -XX:+PrintGC is deprecated. Will use -Xlog:gc instead.
[0.015s][info   ][gc] Using G1
[0.036s][info   ][gc] Periodic GC disabled
[0.186s][info   ][gc] GC(0) Pause Full (System.gc()) 68M-&gt;66M(234M) 3.159ms
</code></pre>

<p>上例中 bytes所使用内存并没有被垃圾回收期所回收，因为gc的时候 bytes数组 仍然处于作用域内。</p>

<p>代码调整如下:</p>

<pre><code class="language-java">public static void main(String[] args) {
    {
       byte[] bytes = new byte[1024 * 1024 * 64];
    }
    System.gc();
}

[0.003s][warning][gc] -XX:+PrintGC is deprecated. Will use -Xlog:gc instead.
[0.011s][info   ][gc] Using G1
[0.031s][info   ][gc] Periodic GC disabled
[0.168s][info   ][gc] GC(0) Pause Full (System.gc()) 68M-&gt;66M(234M) 3.055ms
</code></pre>

<p>从gc日志看出，bytes数组依然没有被垃圾会后期所回收。</p>

<p>接着修改程序代码如下：</p>

<pre><code class="language-java">public static void main(String[] args) {
    {
       byte[] bytes = new byte[1024 * 1024 * 64];
    }
    int xx = 0;
    System.gc();
}

[0.003s][warning][gc] -XX:+PrintGC is deprecated. Will use -Xlog:gc instead.
[0.013s][info   ][gc] Using G1
[0.033s][info   ][gc] Periodic GC disabled
[0.185s][info   ][gc] GC(0) Pause Full (System.gc()) 68M-&gt;1M(17M) 5.387ms
</code></pre>

<p>此时我们看到bytes数组正常被垃圾回收器回收了，但是这是问什么呢？</p>

<p>产生这种问题的根本原因就是：局部变量表中的变量槽是否还存有关于 bytes 数组对象的引用，第一次修改后，gc虽然已经离开了bytes数组的作用域，但在此之后，在没有发生过任何对局部变量表的读写操作，bytes数组原本所占用的变量槽还没有被其它变量所复用，所以作为GC Roots 一部分的局部变量表仍然保持着对它的引用。</p>

<p>第二次修改后，加了int xx = 0, 由于局部变量表中变量槽是可以被复用的，之前存储变量 bytes 数组的槽现在改为了存储变量 xx，然后再进行GC是，bytes数组所占用的内存就可以正常被垃圾回收器回收了。</p>

<p>这种操作(或者手动将变量值设置为null，把变量对应的局部变量槽清空)可以作为一种在极特殊情形（对象占用内存大、此方法的栈帧长时间不能被回收、方法调用次数达不到即时编译器的编译条件）下的“奇技”来使用。</p>

<p>另外需要注意的是: 局部变量在声明之后必须进行赋值操作。</p>

<h5 id="toc_5">2.2、操作数栈</h5>

<p>操作数栈是一个后进先出的栈，同局部变量表一样，操作数栈的最大深度也在编译的时候被写入到Code属性的max_stacks数据项之中。操作数栈的深度都不会超过在max_stacks数据项中设定的最大值。</p>

<p>当一个方法刚刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈和入栈操作。</p>

<p>两个不同栈帧作为不同方法的虚拟机栈的元素，是完全相互独立的。但是在大多虚拟机的实现里都会进行一些优化处理，令两个栈帧出现一部分重叠。</p>

<p><figure><img src="media/15865981620428/15966856928254.jpg" alt=""/></figure></p>

<h5 id="toc_6">2.3、动态连接</h5>

<p>每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接（Dynamic Linking）。</p>

<p>Class文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池里指向方法的符号引用作为参数。这些符号引用一部分会在类加载阶段或者第一次使用的时候就被转化为直接引用，这种转化被称为静态解析。<br/>
另外一部分将在每一次运行期间都转化为直接引用，这部分就称为动态连接。</p>

<h5 id="toc_7">2.4、方法返回地址</h5>

<p>当一个方法开始执行后，只有两种方式退出这个方法。</p>

<ul>
<li><p>第一种方式是执行引擎遇到任意一个方法返回的字节码指令，这时候可能会有返回值传递给上层的方法调用者（调用当前方法的方法称为调用者或者主调方法），方法是否有返回值以及返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法的方式称为“正常调用完成”。</p></li>
<li><p>另外一种退出方式是在方法执行的过程中遇到了异常，并且这个异常没有在方法体内得到妥善处理。无论是Java虚拟机内部产生的异常，还是代码中使用athrow字节码指令产生的异常，只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种退出方法的方式称为“异常调用完成”。</p></li>
</ul>

<p>无论采用何种退出方式，在方法退出之后，都必须返回到最初方法被调用时的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层主调方法的执行状态。</p>

<p>方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令等。</p>

<h3 id="toc_8">3、本地方法栈</h3>

<p>与java虚拟机栈的作用相似，不同的是此块区域是为本地方法(native)服务的。</p>

<h3 id="toc_9">4、java堆内存</h3>

<p>对于Java应用程序来说，Java堆（Java Heap）是虚拟机所管理的内存中最大的一块。</p>

<p>Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，Java 世界里“几乎”所有的对象实例都在这里分配内存。</p>

<p>但是随着即时编译技术的进步，尤其是逃逸分析技术的日渐强大，出现了栈上分配、标量替换优化手段，因此要说所有对象实例都分配在堆上就没那么严谨了。</p>

<p>逃逸分析的原理：分析对象动态作用域，当一个对象在方法中定义后，它可能被外部方法所引用。比如：调用参数传递到其他方法中，这种称之为方法逃逸。甚至还有可能被外部线程访问到，例如：赋值给其他线程中访问的变量，这个称之为线程逃逸。从不逃逸到方法逃逸到线程逃逸，称之为对象由低到高的不同逃逸程度。</p>

<pre><code class="language-java">/**
 * -XX:-DoEscapeAnalysis 关闭逃逸分析，jvm 默认是开启逃逸分析的。
 */
public class EscapeAnalysisMock {

    public static void main(String[] args) throws Exception {
        long start = System.currentTimeMillis();
        for (int i = 0; i &lt; 5000000; i++) {
            allocate();
        }
        System.out.println(System.currentTimeMillis() - start + &quot; ms&quot;);
        Thread.sleep(600000);
    }

    static void allocate() {
        MyObject myObject = new MyObject(2000, 2000.6);
    }

    static class MyObject {
        int a;
        double b;

        public MyObject(int a, double b) {
            this.a = a;
            this.b = b;
        }
    }
}

-------------------------
开启时本地执行 4ms 
关闭逃逸分析本执行 45ms
</code></pre>

<p>如果是逃逸分析出来的对象可以在栈上分配的话，那么该对象的生命周期就跟随线程了，就不需要垃圾回收，如果是频繁的调用此方法则可以得到很大的性能提高。采用了逃逸分析后，满足逃逸的对象在栈上分配。</p>

<p>在JVM启动的时候创建。Java堆空间只是在逻辑上是连续的，在物理上并不一定是连续的内存空间。堆所占内存的大小由-Xmx指令和-Xms指令来调节。</p>

<p>在《Java虚拟机规范》中对Java堆的描述是: 所有的对象实例以及数组都应当在堆上分配。</p>

<p>如果从分配内存的角度看，所有线程共享的Java堆中可以划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB），以提升对象分配时的效率。不过无论从什么角度，无论如何划分，都不会改变Java堆中存储内容的共性，无论是哪个区域，存储的都只能是对象的实例，将Java 堆细分的目的只是为了更好地回收内存，或者更快地分配内存。</p>

<p>Java堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的，这点就像我们用磁盘空间去存储文件一样，并不要求每个文件都连续存放。但对于大对象（典型的如数组对象），多数虚拟机实现出于实现简单、存储高效的考虑，很可能会要求连续的内存空间。</p>

<p>Java堆既可以被实现成固定大小的，也可以是可扩展的，不过当前主流的Java虚拟机都是按照可扩展来实现的（通过参数 -Xmx 和 -Xms 设定）。如果在Java堆中没有内存完成实例分配，并且堆也无法再扩展时，Java虚拟机将会抛出OutOfMemoryError异常。</p>

<p>由上面分析可得出如下的java堆特征：</p>

<ul>
<li>线程共享区域</li>
<li>用于存放对象实例和数组</li>
<li>堆是java虚拟机管理的内存中最大的一块。</li>
<li>垃圾收集器的管理的主要区域,为了现在垃圾收集收集器都是采用分代收集算法，所以把堆细分为多个子区域：
<ul>
<li>新生代 <br/>
默认情况下，新生代中Eden空间与Survivor空间的比例是8:1,可以使用参数-XX:SurvivorRatio进行设置
<ul>
<li>伊甸区(eden)</li>
<li>from survivor</li>
<li>to survivor</li>
</ul></li>
<li>老年代  主要存放应用程序中生命周期长的内存对象</li>
</ul></li>
</ul>

<p>堆大小参数：-Xms：堆的最小值；-Xmx：堆的最大值；-Xmn：新生代的大小；-XX:NewSize；新生代最小值；-XX:MaxNewSize：新生代最大值；</p>

<h3 id="toc_10">5、方法区</h3>

<p>方法区（Method Area）与Java堆一样，是所有线程共享的一块内存区域，用于存储被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。</p>

<p>jdk7之前采用永久代来实现，占用jvm的堆内存不说，还可能会OOM: PermGen space,</p>

<p>jdk8之后移除永久代而采用了元数据区（本地内存）来实现方法区，理论上来说，只要物理条件允许，这个区域要多大有多大。</p>

<h4 id="toc_11">5.1、常量池</h4>

<h5 id="toc_12">5.1.1、Class 常量池(静态常量池)</h5>

<p>在 class 文件中除了有类的版本、字段、方法和接口等描述信息外，还有一项信息是常量池 (Constant Pool Table)，用于存放编译期间生成的各种字面量和符号引用</p>

<h5 id="toc_13">5.1.2、运行时常量池</h5>

<p>运行时常量池（Runtime Constant Pool）是方法区的一部分，是每一个类或接口的常量池（Constant_Pool）的运行时表示形式，它包括了若干种不同的常量：从编译期可知的数值字面量到必须运行期解析后才能获得的方法或字段引用。</p>

<p>运行时常量池是在类加载完成之后，将 Class 常量池中的符号引用值转存到运行时常量池中，类在解析之后，将符号引用替换成直接引用。</p>

<p>运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性。java语言并不要求常量一定只在编译器产生。</p>

<p>例如 String类的intern()方法就是在JVM运行期间将新的常量放入到常量池中。</p>

<p><strong>注意：</strong> jdk6之前字符串常量池是放在永久区中的，第一次创建字符串实例的时候讲字符串复制到常量池中，intern()返回常量池中的引用地址，而jdk6之后字符串常量池被移动到了java堆内存中,所以直接将字符串首次出现的引用地址记录到常量池就可以了，这是intern()方法返回的和堆中字符串实例是同一个引用地址。</p>

<p>既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。</p>

<h5 id="toc_14">5.1.3、字符串常量池</h5>

<p>字符串常量池这个概念是最有争议的，翻阅了虚拟机规范等很多正式文档，发现没有这个概念的官方定义，所以与运行时常量池的关系不去抬杠，我们从它的作用和 JVM 设计它用于解决什么问题的点来分析它。<br/>
以 JDK1.8 为例，字符串常量池是存放在堆中，并且与 java.lang.String 类有很大关系。设计这块内存区域的原因在于：String 对象作为 Java 语言中重要的数据类型，是内存中占据空间最大的一个对象。高效地使用字符串，可以提升系统的整体性能。<br/>
所以要彻底弄懂，我们的重心其实在于深入理解 String 字符串</p>

<ul>
<li>String str = &quot;sb&quot;<br/>
当代码中使用这种方式创建字符串对象时，JVM 首先会检查该对象是否在字符串常量池中，如果在，就返回该对象引用，否则新的字符串将在常量池中被创建。这种方式可以减少同一个值的字符串对象的重复创建，节约内存。</li>
<li><p>String str = new String(“sb”)<br/>
首先在编译类文件时， &quot;sb&quot;常量字符串将会放入到常量结构中， 在类加载时， “sb&quot;将会在常量池中创建； 其次， 在调用 new 时， JVM 命令将会调用 String 的构造函数，同时引用常量池中的&quot;sb” 字符串，在堆内存中创建一个 String 对象；最后，str 将引用 String 对象。</p></li>
<li><p>使用 new，对象会创建在堆中，同时赋值的话，会在常量池中创建一个字符串对象，复制到堆中。<br/>
具体的复制过程是先将常量池中的字符串压入栈中，在使用 String 的构造方法时，会拿到栈中的字符串作为构方法的参数。<br/>
这个构造函数是一个 char 数组的赋值过程，而不是 new 出来的，所以是引用了常量池中的字符串对象。</p></li>
</ul>

<pre><code class="language-java">@Data
public class Stu {
    private String name;
    
    public static void main(String[] args)  {
        Stu stu = new Stu();
        //字符串sb会在堆中也会存在于字符串常量池中
        stu.setName(&quot;sb&quot;);
    }
}
</code></pre>

<ul>
<li><p>String str2= &quot;ab&quot;+ &quot;cd&quot;+ &quot;ef&quot;;<br/>
编程过程中，字符串的拼接很常见。前面我讲过 String 对象是不可变的，如果我们使用 String 对象相加，拼接我们想要的字符串，是不是就会产生多个对象呢？例如以下代码：分析代码可知：首先会生成 ab 对象，再生成 abcd 对象，最后生成 abcdef 对象，从理论上来说，这段代码是低效的。<br/>
编译器自动优化了这行代码，编译后的代码，你会发现编译器自动优化了这行代码，如下String str= &quot;abcdef&quot;;</p></li>
<li><p>string.intern()方法： </p>
<pre><code class="language-java">String a =new String(&quot;sb&quot;).intern();
String b=new String(&quot;sb&quot;).intern();<br/>
if(a==b) { <br/>
    System.out.print(&quot;a==b&quot;); <br/>
} else {<br/>
    System.out.print(&quot;a!=b&quot;);<br/>
}
</code></pre>
<ul>
<li><p>new Sting(“sb”) 会在堆内存中创建一个 a 的 String 对象，&quot;sb&quot;将会在常量池中创建。</p></li>
<li><p>在调用 intern() 方法之后，会去常量池中查找是否有等于该字符串对象的引用，有就返回引用。</p></li>
<li><p>调用 String b = new Sting(&quot;sb&quot;) 会在堆内存中创建一个 b 的 String 对象。</p></li>
<li><p>在调用 intern() 方法之后，会去常量池中查找是否有等于该字符串对象的引用，有就返回引用。</p></li>
</ul>
<p>所以 a 和 b 引用的是同一个对象。</p></li>
</ul>

<h4 id="toc_15">5.2、元数据区</h4>

<p>元数据区是自jdk8才出现的一个新的内存区域用来取代之前的永久区，用本地内存来存储类元数据信息</p>

<h3 id="toc_16">6、直接内存</h3>

<p><strong>直接内存不是虚拟机运行时数据区的一部分</strong><br/>
NIO 使用区域，基于管道(channel)与缓冲区(buffer)的IO方式，它可以使用native函数库直接分配堆外内存，然后通过一个存储在java堆里面的 DirectByteBuffer 作为这块直接内存的引用进行操作。使用直接内存避免了java堆与Native堆来回复制数据，一些场景下，能显著提高运行性能。</p>

<p>jdk中直接内存的回收就用到虚引用，由于jvm自动内存管理的范围是堆内存，而直接内存是在堆内存之外（其实是内存映射文件，自行去理解虚拟内存空间的相关概念），所以直接内存的分配和回收都是有Unsafe类去操作，java在申请一块直接内存之后，会在堆内存分配一个对象保存这个堆外内存的引用，这个对象被垃圾收集器管理，一旦这个对象被回收，相应的用户线程会收到通知并对直接内存进行清理工作。见 sun.misc.Cleaner类</p>

<h4 id="toc_17">为什么要使用直接内存</h4>

<p>直接内存就是不受 JVM 控制的内存。相比于堆内存有几个优势:</p>

<ul>
<li>减少了垃圾回收的工作，因为垃圾回收会暂停其他的工作。</li>
<li>加快了复制的速度。因为堆内在 flush 到远程时，会先复制到直接内存(非堆内存)，然后再发送，而堆外内存相当于省略掉了这个工作。 </li>
<li>3、可以在进程间共享，减少 JVM 间的对象复制，使得 JVM 的分割部署更容易实现。</li>
<li>可以扩展至更大的内存空间。比如超过 1TB 甚至比主存还大的空间。</li>
</ul>

<h4 id="toc_18">直接内存的缺点</h4>

<ul>
<li>堆外内存难以控制，如果内存泄漏，那么很难排查</li>
<li>堆外内存相对来说，不适合存储很复杂的对象。一般简单的对象比较适合</li>
</ul>

<h2 id="toc_19">揭开 java 虚拟机对象的面纱</h2>

<p>通过上面对java 虚拟机内存区域的介绍，我们进一步思考，内存中存储什么东西、它们是如何创建、如何布局、如何访问的呢？接下来我们探讨一下HotSpot虚拟机在Java堆中对象分配、布局和访问的全过程。</p>

<h3 id="toc_20">1、对象的创建</h3>

<h4 id="toc_21">1.1、创建对象的方式</h4>

<p>Java程序运行过程中无时无刻都有对象被创建出来。在 Java 中有如下5种</p>

<table>
<thead>
<tr>
<th>创建方式</th>
<th>是否调用构造函数</th>
</tr>
</thead>

<tbody>
<tr>
<td>new关键字</td>
<td>调用构造函数进行初始化</td>
</tr>
<tr>
<td>Class.forName().instance()、Object.class.newInstance()</td>
<td>Class.forName加载并连接类，newInstance()调用构造函数进行初始化</td>
</tr>
<tr>
<td>Constructor类的NewInstance()</td>
<td>调用构造函数进行初始化</td>
</tr>
<tr>
<td>Clone()</td>
<td>没有调用构造函数</td>
</tr>
<tr>
<td>反序列化</td>
<td>没有调用构造函数</td>
</tr>
</tbody>
</table>

<h4 id="toc_22">1.2、对象内存分配</h4>

<p>这里我们只对new关键字进行分析，当JVM遇到new关键字创建普通的java对象(不包括数组和Class对象等)时，<strong><em>首先</em></strong> 检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过，如果没有那么必须执行相应的加载过程()。</p>

<p>在类加载检查通过后，接下来虚拟机为新生对象分配内存(类加载完成后即可知其大小)，jvm将一块确定大小的内存块从java堆中划拨出来。在划拨堆内存出来的时候，会涉及到如何分配的问题，下面有两种分配方式：</p>

<ul>
<li><p>指针碰撞 <br/>
定义： 假设堆内存是规整的，所有使用过的堆内存放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就是把这个指针向空闲空间方向移动一段与对象大小相等的的距离。<br/>
<figure><img src="media/15866239860150/15869624345720.jpg" alt="" style="width:869px;"/></figure></p></li>
<li><p>空闲列表<br/>
如果堆内存是不规整的，已使用和未被使用的内存是交错在一起的，那就没办法简简单单地进行“指针碰撞”了，虚拟机就必须维护一个用来记录那些内存块是可用的列表，在分配对象的时候找一个内存大小适中的内存空间划分给对象，并更新列表上的记录，这种分配方式被称为空闲列表<br/>
<figure><img src="media/15866239860150/15869639142729.jpg" alt="" style="width:877px;"/></figure></p></li>
</ul>

<p>选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有空间压缩整理（Compact）的能力决定。因此，当使用Serial、ParNew等带压缩整理过程的收集器时，系统采用的分配算法是指针碰撞，既简单又高效；而当使用CMS这种基于清除（Sweep）算法的收集器时，理论上就只能采用较为复杂的空闲列表来分配内存。</p>

<p>因此采用复制算法、标记整理算法的收集器时，系统采用“指针碰撞“，而采用CMS这种基于清除算法的收集器时，采用”空闲列表“来分配。</p>

<p>内存分配完成之后， JVM必须将分配到的内存空间(不包括对象头)都进行初始化为零值，这样保证了在代码中可以不赋初值就可以直接使用。</p>

<p>接下来JVM还要对对象进行必要的设置，例如对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。</p>

<p>在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了。但是从Java程序的视角看来，对象创建才刚刚开始---构造函数，即Class文件中的<init>()方法还没执行，所有的对象字段还是初始的默认值，执行完<init>()之后对象才会想我们程序中所希望的那样赋予相应的变量值。</p>

<h4 id="toc_23">1.3、内存分配的并发安全问题</h4>

<p>但是在并发情况下，即使是”指针碰撞“这种仅仅是移动指针所指向位置的操作，<strong>也并不是线程安全的</strong>，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。</p>

<p>解决上面所说的问题有两种可选方案</p>

<ul>
<li><p>分配内存空间的动作进行同步处理（JVM是采用 CAS 配上失败重试的方式保证更新操作的原子性）</p></li>
<li><p>另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在 Java 堆中预先分配一小块私有内存，也就是本地线程分配缓冲（Thread Local Allocation Buffer,TLAB），JVM 在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个 Buffer，如果需要分配内存，就在自己的 Buffer 上分配，这样就不存在竞争的情况，可以大大提升分配效率，当 Buffer 容量不够的时候，再重新从 Eden 区域申请一块继续使用。可以通过-XX：+/-UseTLAB参数来设定。</p></li>
</ul>

<h4 id="toc_24">1.4、堆内存分配策略</h4>

<ul>
<li><p>对象优先在 Eden 区分配</p></li>
<li><p>大对象直接进入老年代<br/>
参数-XX:PretenureSizeThreshold=4m -XX:+UseSerialGC 超过多少大小的对象直接进入老年代</p></li>
<li><p>长期存活对象进入老年区<br/>
如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1，对象在 Survivor区中每熬过一次 Minor GC，年龄就增加 1，当它的年龄增加到一定程度(默认为 15)_时，就会被晋升到老年代中。</p></li>
<li><p>对象年龄动态判定<br/>
为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。</p></li>
<li><p>空间分配担保<br/>
在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。如果不成立，则虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历 次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC，尽管这次 Minor GC 是有风险的，如果担保失败则会进行一次 Full GC;如果小 于，或者 HandlePromotionFailure 设置不允许冒险，那这时也要改为进行一次 Full GC。</p></li>
</ul>

<h3 id="toc_25">2、 对象的内存布局</h3>

<p>对象在堆内存中存储布局可以划分为三部分：对象头(Object Header)、实例数据(Instance Data)、对齐填充(Padding)。<br/>
<figure><img src="media/15865981620428/15962978615532.jpg" alt=""/></figure></p>

<p>通过hotspot虚拟机源码查看可查看<br/>
<figure><img src="media/15865981620428/15962989936134.jpg" alt="" style="width:1594px;"/></figure></p>

<h4 id="toc_26">2.1、 对象头</h4>

<p>对象头部分包含两类信息：</p>

<ul>
<li>Mark Word<br/>
用于存储对象自身的运行时数据，如哈希码，GC分代年龄，锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等，这部分数据被称为 </li>
<li>class pointer(类型指针)<br/>
类型指针即对象指向它的类元数据的指针。并不是所有的虚拟机实现都必须在对象数据上保留类型指针（用句柄实现）。</li>
</ul>

<h5 id="toc_27">2.1.1、指针压缩</h5>

<p>对象占用的内存大小受到 vm参数 UseCompressedOops 的影响</p>

<p>1）CompressedOops原理：</p>

<p>64位地址分为堆的基地址+偏移量，当堆内存 &lt;32GB 时候，在压缩过程中，把偏移量 /8后保存到32位地址。在解压再把32位地址放大8倍，所以启用CompressedOops的条件是堆内存要在4GB*8=32GB以内。</p>

<p>CompressedOops，可以让跑在64位平台下的JVM，不需要因为更宽的寻址，而付出Heap容量损失的代价。 不过它的实现方式是在机器码中植入压缩与解压指令，可能会给JVM增加额外的开销。</p>

<p>2）零基压缩优化(Zero Based Compressd Oops)</p>

<p>零基压缩是针对压解压动作的进一步优化。 它通过改变正常指针的随机地址分配特性，强制堆地址从零开始分配（需要OS支持），进一步提高了压解压效率。要启用零基压缩，你分配给JVM的内存大小必须控制在4G以上，32G以下。</p>

<p>总的来说就是下面的规则：</p>

<ul>
<li>如果GC堆大小在4G以下，直接砍掉高32位，避免了编码解码过程；</li>
<li>如果GC堆大小在4G以上32G以下，则启用UseCompressedOop；</li>
<li>如果GC堆大小大于32G，压指失效，使用原来的64位（所以说服务器内存太大不好......）。</li>
</ul>

<h5 id="toc_28">2.1.2、Mark Word 的组成以及布局情况</h5>

<p>下图是在64位虚拟机上的对象头的堆内存布局：<br/>
<figure><img src="media/15866239860150/15889568831679.jpg" alt=""/></figure></p>

<p>开启指针压缩(-XX:+UseCompressedOops)，对象头大小为 12 bytes，64位机器 不开启指针压缩(-XX:-UseCompressedOops)，对象头大小为16字节。</p>

<p>通过Jol工具可以查看对象信息,通过maven仓库导入JOL包</p>

<pre><code class="language-text">&lt;dependency&gt;
    &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;
    &lt;artifactId&gt;jol-core&lt;/artifactId&gt;
    &lt;version&gt;0.9&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<p>查看Object对象的信息如下：</p>

<pre><code class="language-text">public static void main(String[] args) {
    Object a = new Object();
    System.out.println(ClassLayout.parseInstance(a).toPrintable());
}

-----------------------------------------------------------------------
java.lang.Object object internals:
 OFFSET  SIZE   TYPE DESCRIPTION                               VALUE
      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)
      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)
      8     4        (object header)                           e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)
     12     4        (loss due to the next object alignment)
Instance size: 16 bytes
Space losses: 0 bytes internal + 4 bytes external = 4 bytes total
</code></pre>

<h5 id="toc_29">Lock Record  锁记录</h5>

<p>1、数据结构及其openjdk实现<br/>
lock record的数据结构</p>

<pre><code class="language-text">// A BasicObjectLock associates a specific Java object with a BasicLock.
// It is currently embedded in an interpreter frame.
class BasicObjectLock VALUE_OBJ_CLASS_SPEC {
 private:
  BasicLock _lock;                        // the lock, must be double word aligned
  oop       _obj;                         // object holds the lock;
};
class BasicLock VALUE_OBJ_CLASS_SPEC {
 private:
  volatile markOop _displaced_header;
};
</code></pre>

<p>2、什么时候被创建？在哪里创建？</p>

<p>当字节码解释器执行monitorenter字节码轻度锁住一个对象时，就会在获取锁的线程的栈上显式或者隐式分配一个lock record。</p>

<p>3、lock record的创建位置</p>

<p>lock record在线程的Interpretered Frame上(解释帧)分配</p>

<p>4、有什么作用？</p>

<p>持有displaced word和锁住对象的元数据；<br/>
解释器使用lock record来检测非法的锁状态；<br/>
隐式地充当锁重入机制的计数器；</p>

<h4 id="toc_30">2.2、 实例数据</h4>

<p>用来存储真正的有效信息，即我们在程序代码里面所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的字段都必须记录起来。</p>

<p>这部分的存储顺序会受到虚拟机分配策略参数（-XX：FieldsAllocationStyle参数）和字段在Java源码中定义顺序的影响。</p>

<p>HotSpot虚拟机默认的分配顺序为longs/doubles、ints、shorts/chars、bytes/booleans、oops（Ordinary Object Pointers，OOPs），从以上默认的分配策略中可以看到，相同宽度的字段总是被分配到一起存放，在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前。如果HotSpot虚拟机的+XX：CompactFields参数值为true（默认就为true），那子类之中较窄的变量也允许插入父类变量的空隙之中，以节省出一点点空间。</p>

<h4 id="toc_31">2.3、 对齐填充</h4>

<p>这部分仅仅是起到占位符的作用。由于jvm的自动内存管理系统要求任何对象的大小必须是8字节的整数倍，如果对象实例数据没有对齐的话，则通过对齐填充来进行补全，使其大小是8字节的整数倍(对象头已经被设计成正好是8字节的整数倍的结构了)</p>

<h3 id="toc_32">3、对象访问定位</h3>

<p>创建完对象之后，就到了使用对象的时候了。JVM会通过虚拟机栈上的reference（指向对象的引用）数据来操作堆上的具体对象。</p>

<p>jvm主要有两种访问对象的方式：</p>

<ul>
<li><p>使用句柄访问<br/>
java堆内存中将可能划分出一块内存作为句柄池，reference中存储的就是对象的句柄地址，句柄中包含了对象的实例数据与类型数据各自具体的地址信息。<br/>
当对象改变之后，只需要改变句柄中的实例数据的指针地址，而句柄本身的地址这不会改变，那么reference的引用也不会改变。<br/>
<figure><img src="media/15866239860150/15953360466927.jpg" alt=""/></figure></p></li>
<li><p>使用直接指针访问<br/>
reference中存储的直接就是对象的地址，直接访问对象的话，一步到位，访问速度会更加迅速。<br/>
<figure><img src="media/15866239860150/15953360587854.jpg" alt=""/></figure></p></li>
</ul>

<h2 id="toc_33">JAVA堆栈内存溢出异常</h2>

<p>java虚拟机规范允许虚拟机自行选择是否支持栈的动态扩容，但Hotspot选择不支持扩容。所以除非在创建线程申请内存时，因无法获取足够内存而出现OOM异常。</p>

<p>如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。</p>

<p>如果虚拟机的栈内存允许动态扩展，当扩展栈容量无法申请到足够的内存时，将抛出OutOfMemoryError异常。</p>

<h3 id="toc_34">1、java堆可引起OutOfMemoryError异常</h3>

<pre><code class="language-java">
/**
 * OOM 异常 -Xms5m -Xmx5m -XX:+HeapDumpOnOutOfMemoryError
 */
public class HeapOomMock {
    public static void main(String[] args) {
        List&lt;byte[]&gt; list = new ArrayList&lt;byte[]&gt;();
        int i = 0;
        boolean flag = true;
        while (flag) {
            try {
                i++;
                list.add(new byte[1024 * 1024]);//每次增加一个1M大小的数组对象
            } catch (Throwable e) {
                e.printStackTrace();
                flag = false;
                System.out.println(&quot;count=&quot; + i);//记录运行的次数
            }
        }
    }
}
</code></pre>

<h3 id="toc_35">2、java虚拟机栈OutOfMemoryError、StackOverFlowError</h3>

<p>OutOfMemoryError：</p>

<pre><code class="language-java">/**
 * jvm栈OOM(此操作可能拖垮cpu，请谨慎执行)
 * -Xss256k
 **/
public class StackOOMErrorMock {
    public static void main(String[] args) {
        for (int i = 0; ; i++) {
            new Thread(()-&gt;{
                while (true) {

                }
            }).start();
        }
    }
}
</code></pre>

<p>StackOverFlowError：</p>

<pre><code class="language-java">/**
 * StackOverFlowError
 * -Xss256k 栈大小
 */
public class StackOverFlowMock {
    private static int index = 1;

    public void call() {
        index++;
        call();
    }

    public static void main(String[] args) {
        StackOverFlowMock mock = new StackOverFlowMock();
        try {
            mock.call();
        } catch (Throwable e) {
            System.out.println(&quot;Stack deep : &quot; + index);
            e.printStackTrace();
        }
    }
}
</code></pre>

<p>还有一种是占用了过多的局部变量表空间，比如说声明了非常多的局部变量</p>

<h3 id="toc_36">3、方法区运行时常量池引起的OutOfMemoryError异常：</h3>

<pre><code class="language-java">/**
 * jdk1.8之前 -XX:PermSize=6M -XX:MaxPermSize=6M
 * jdk1.8之后 -Xmx6M
 **/
public class ConstantPoolOOMMock {

    public static void main(String[] args) {
        Set&lt;String&gt; stringSet = new HashSet&lt;&gt;();
        int i = 0;
        while (true) {
            stringSet.add(String.valueOf(i++).intern());
        }
    }
}
</code></pre>

<h3 id="toc_37">4、元数据区可引起OutOfMemoryError异常：</h3>

<pre><code class="language-java">import net.sf.cglib.proxy.Enhancer;
import net.sf.cglib.proxy.MethodInterceptor;

/**
 * jdk8之前： -XX:PermSize=10M -XX:MaxPermSize=10M
 * jdk8及之后： -XX:MaxMetaspaceSize=20m
 *
 */
public class MetaSpaceMemory {
    public static void main(String[] args) {
        for (; ; ) {
            Enhancer enhancer = new Enhancer();
            enhancer.setSuperclass(MetaSpaceMemory.class);
            enhancer.setUseCache(false);
            enhancer.setCallback((MethodInterceptor) (obj, method, args1, proxy) -&gt; proxy.invokeSuper(obj, args1));
            System.out.println(&quot;metaspace oom&quot;);
            enhancer.create();
        }
    }

    private Object person;

    public Object getPerson() {
        return person;
    }

    public void setPerson(Object person) {
        this.person = person;
    }

}
</code></pre>

<h3 id="toc_38">5、直接内存OOM异常</h3>

<pre><code class="language-java">/**
 * -XX:MaxDirectMemorySize=5M -Xmx20M
 **/
public class DirectMemoryOOMMock {
    private static final int _1MB = 1024*1024*10;
    public static void main(String[] args) throws IllegalAccessException {
        Field declaredField = Unsafe.class.getDeclaredFields()[0];
        declaredField.setAccessible(true);
        Unsafe unsafe = (Unsafe)declaredField.get(null);
        while (true)
            unsafe.allocateMemory(_1MB);
    }
}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一、openJDK的源码，那么该去哪下载呢?]]></title>
    <link href="http://www.throne4j.com/15870470229137.html"/>
    <updated>2020-04-16T22:23:42+08:00</updated>
    <id>http://www.throne4j.com/15870470229137.html</id>
    <content type="html"><![CDATA[
<p>1.openJDK的项目<br/>
    链接：<a href="http://hg.openjdk.java.net/%EF%BC%8C%E5%A6%82%E4%B8%8B%E5%9B%BE1%E6%89%80%E7%A4%BA">http://hg.openjdk.java.net/，如下图1所示</a><br/>
    <figure><img src="media/15870470229137/15870471369545.jpg" alt=""/></figure></p>

<p>例如我我们需要下载jdk8u，就在上图中找到jdk8u，点击进去<br/>
如下图所示：<br/>
<figure><img src="media/15870470229137/15870475497348.jpg" alt=""/></figure><br/>
这里可以选择相应的版本点击jdk进去，可以browser查看文件目录：<br/>
<figure><img src="media/15870470229137/15870477802419.jpg" alt=""/></figure></p>

<p>看到点击zip下载openjdk源码文件</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[]]></title>
    <link href="http://www.throne4j.com/16144462023580.html"/>
    <updated>2021-02-28T01:16:42+08:00</updated>
    <id>http://www.throne4j.com/16144462023580.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[从团队自研的百万并发中间件系统的内核设计看Java并发性能优化]]></title>
    <link href="http://www.throne4j.com/16144392642134.html"/>
    <updated>2021-02-27T23:21:04+08:00</updated>
    <id>http://www.throne4j.com/16144392642134.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、大部分人对Java并发仍停留在理论阶段</h2>

<p>很多同学对Java并发编程的知识，可能看了很多的书，也通过不少视频课程进行了学习。</p>

<p>但是，大部分人可能还是停留在理论的底层，主要是了解理论，基本对并发相关的技术很少实践和使用，更很少做过复杂的中间件系统。</p>

<p>实际上，真正把这些技术落地到中间件系统开发中去实践的时候，是会遇到大量的问题，需要对并发相关技术的底层有深入的理解和掌握。</p>

<p>然后，结合自己实际的业务场景来进行对应的技术优化、机制优化，才能实现最好的效果。</p>

<p>因此，本文将从笔者曾经带过的一个高并发中间件项目的内核机制出发，来看看一个实际的场景中遇到的并发相关的问题。</p>

<p>同时，我们也将一步步通过对应的伪代码演进，来分析其背后涉及到的并发的性能优化思想和实践，最后来看看优化之后的效果。</p>

<p>2、中间件系统的内核机制：双缓冲机制</p>

<p>这个中间件项目整体就不做阐述了，因为涉及核心项目问题。我们仅仅拿其中涉及到的一个内核机制以及对应的场景来给大家做一下说明。</p>

<p>其实这个例子是大量的开源中间件系统、大数据系统中都有涉及到的一个场景，就是：核心数据写磁盘文件。</p>

<p>比如，大数据领域里的hadoop、hbase、elasitcsearch，Java中间件领域里的redis、mq，这些都会涉及到核心数据写磁盘文件的问题。</p>

<p>而很多大型互联网公司自研的中年间系统，同样也会有这个场景。只不过不同的中间件系统，他的作用和目标是不一样的，所以在核心数据写磁盘文件的机制设计上，是有一些区别的。</p>

<p>那么我们公司自研的中间件项目，简单来说，需要实现的一个效果是：开辟两块内存空间，也就是经典的内存双缓冲机制。</p>

<p>然后核心数据进来全部写第一块缓冲区，写满了之后，由一个线程进行那块缓冲区的数据批量刷到磁盘文件的工作，其他线程同时可以继续写另外一块缓冲区。</p>

<p>我们想要实现的就是这样的一个效果。这样的话，一块缓冲区刷磁盘的同时，另外一块缓冲区可以接受其他线程的写入，两不耽误。核心数据写入是不会断的，可以持续不断的写入这个中间件系统中。</p>

<p>我们来看看下面的那张图，也来了解一下这个场景。</p>

<p><figure><img src="media/16144392642134/16144454253734.jpg" alt=""/></figure></p>

<p>如上图，首先是很多线程需要写缓冲区1，然后是缓冲区1写满之后，就会由写满的那个线程把缓冲区1的数据刷入磁盘文件，其他线程继续写缓冲区2。</p>

<p>这样，数据批量刷磁盘和持续写内存缓冲，两个事儿就不会耽误了，这是中间件系统设计中极为常用的一个机制，大家看下面的图。</p>

<p><figure><img src="media/16144392642134/16144454375211.jpg" alt=""/></figure></p>

<h2 id="toc_1">3、百万并发的技术挑战</h2>

<p>先给大家说一下这个中间件系统的背景：这是一个服务某个特殊场景下的中间件系统，整体是集群部署。</p>

<p>然后每个实例部署的都是高配置机器，<strong>定位是单机承载并发达到万级甚至十万级，整体集群足以支撑百万级并发</strong>，因此对单机的写入性能和吞吐要求极为高。</p>

<p>在超高并发的要求之下，上图中的那个内核机制的设计就显得尤为重要了。弄的不好，就容易导致写入并发性能过差，达不到上述的要求。</p>

<p>此外在这里多提一句，类似的这种机制在很多其他的系统里都有涉及。比如之前一篇文章：【高并发优化实践】10倍请求压力来袭，你的系统会被击垮吗？，那里面讲的一个系统也有类似机制。</p>

<p>只不过不同的是，那篇文章是用这个机制来做MQ集群整体故障时的容灾降级机制，跟本文的高并发中间件系统还有点不太一样，所以在设计上考虑的一些细节也是不同的。</p>

<p>而且，之前那篇文章的主题是讲这种内存双缓冲机制的一个线上问题：瞬时超高并发下的系统卡死问题。</p>

<h2 id="toc_2">4、内存数据写入的锁机制以及串行化问题</h2>

<p>首先我们先考虑第一个问题，你多个线程会并发写同一块内存缓冲，这个肯定有问题啊！</p>

<p>因为内存共享数据并发写入的时候，必须是要加锁的，否则必然会有并发安全问题，导致内存数据错乱。</p>

<p>所以在这里，我们写了下面的伪代码，先考虑一下线程如何写入内存缓冲。</p>

<p><figure><img src="media/16144392642134/16144456345419.jpg" alt=""/></figure></p>

<p>好了，这行代码弄好之后，对应着下面的这幅图，大家看一下。</p>

<p><figure><img src="media/16144392642134/16144456759616.jpg" alt=""/></figure></p>

<p>看到这里，就遇到了Java并发的第一个性能问题了，你要知道高并发场景下，大量线程会并发写内存的，你要是直接这样加一个锁，必然会导致所有线程都是串行化。</p>

<p>即一个线程加锁，写数据，然后释放锁。接着下一个线程干同样的事情。这种串行化必然导致系统整体的并发性能和吞吐量会大幅度降低的。</p>

<h2 id="toc_3">5、内存缓冲分片机制+分段枷锁机制</h2>

<p>因此在这里必须要对内存双缓冲机制引入分段加锁机制，也就是将内存缓冲切分为多个分片，每个内存缓冲分片就对应一个锁。</p>

<p>这样的话，你完全可以根据自己的系统压测结果，调整内存分片数量，提升锁的数量，进而允许大量线程高并发写入内存。</p>

<p>我们看下面的伪代码，对这块就实现了内存缓冲分片机制：</p>

<p><figure><img src="media/16144392642134/16144458264541.jpg" alt=""/></figure></p>

<p>好！我们再来看看，目前为止的图是什么样子的：</p>

<p><figure><img src="media/16144392642134/16144458207073.jpg" alt=""/></figure></p>

<p>这里因为每个线程仅仅就是加锁，写内存，然后释放锁。</p>

<p>所以，每个线程持有锁的时间是很短很短的，单个内存分片的并发写入经过压测，达到每秒几百甚至上千是没问题的，因此线上系统我们是单机开辟几十个到上百个内存缓冲分片的。</p>

<p>经过压测，这足以支撑每秒数万的并发写入，如果将机器资源使用的极限，每秒十万并发也是可以支持的。</p>

<h2 id="toc_4">6、缓冲区写满时的双缓冲交换</h2>

<p>那么当一块缓冲区写满的时候，是不是就必须要交换两块缓冲区？接着需要有一个线程来将写满的缓冲区数据刷写到磁盘文件中？</p>

<p>此时的伪代码，大家考虑一下，是不是如下所示：<br/>
<figure><img src="media/16144392642134/16144458729849.jpg" alt=""/></figure></p>

<p>同样，我们通过下面的图来看看这个机制的实现：<br/>
<figure><img src="media/16144392642134/16144459675347.jpg" alt=""/></figure></p>

<h2 id="toc_5">7、且慢！刷写磁盘不是会导致锁持有时间过长吗？</h2>

<p>且慢，各位同学，如果按照上面的伪代码思路，一定会有一个问题：要是一个线程，他获取了锁，开始写内存数据。</p>

<p>然后，发现内存满了，接着直接在持有锁的过程中，还去执行数据刷磁盘的操作，这样是有问题的。</p>

<p>要知道，数据刷磁盘是很慢的，根据数据的多少，搞不好要几十毫秒，甚至几百毫秒。</p>

<p>这样的话，岂不是一个线程会持有锁长达几十毫秒，甚至几百毫秒？</p>

<p>这当然不行了，后面的线程此时都在等待获取锁然后写缓冲区2，你怎么能一直占有锁呢？</p>

<p>一旦你按照这个思路来写代码，必然导致高并发场景下，一个线程持有锁上百毫秒。刷数据到磁盘的时候，后续上百个工作线程全部卡在等待锁的那个环节，啥都干不了，严重的情况下，甚至又会导致系统整体呈现卡死的状态。</p>

<p>8、内存 + 磁盘并行写机制</p>

<p>所以此时正确的并发优化代码，应该是发现内存缓冲区1满了，然后就交换两个缓冲区。</p>

<p>接着直接就释放锁，释放锁了之后再由这个线程将数据刷入磁盘中，刷磁盘的过程是不会占用锁的，然后后续的线程都可以继续获取锁，快速写入内存，接着释放锁。</p>

<p>大家先看看下面的伪代码的优化：</p>

<p><figure><img src="media/16144392642134/16144460799293.jpg" alt=""/></figure></p>

<p>按照上面的伪代码的优化，此时磁盘的刷写和内存的写入，完全可以并行同时进行。</p>

<p>因为这里核心的要点就在于大幅度降低了锁占用的时间，这是java并发锁优化的一个非常核心的思路。</p>

<p>大家看下面的图，一起来感受一下：</p>

<p><figure><img src="media/16144392642134/16144460942330.jpg" alt=""/></figure></p>

<h2 id="toc_6">9、为什么必须要用双缓冲机制？</h2>

<p>其实看到这里，大家可能或多或少都体会到了一些双缓冲机制的设计思想了，如果只用单块内存缓冲的话，那么从里面读数据刷入磁盘的过程，也需要占用锁，而此时想要获取锁写入内存缓冲的线程是获取不到锁的。</p>

<p>所以假如只用单块缓冲，必然导致读内存数据，刷入磁盘的过程，长时间占用锁。进而导致大量线程卡在锁的获取上，无法获取到锁，然后无法将数据写入内存。这就是必须要在这里使用双缓冲机制的核心原因。</p>

<h2 id="toc_7">10、总结</h2>

<p>最后做一下总结，本文从笔者团队自研的百万并发量级中间件系统的内核机制出发，给大家展示了Java并发中加锁的时候：</p>

<p>如何利用双缓冲机制</p>

<p>内存缓冲分片机制</p>

<p>分段加锁机制</p>

<p>磁盘 + 内存并行写入机制</p>

<p>高并发场景下大幅度优化多线程对锁的串行化争用问题</p>

<p>长时间占用锁的问题</p>

<p>其实在很多开源的优秀中间件系统中，都有很多类似的Java并发优化的机制，主要就是应对高并发的场景下大幅度的提升系统的并发性能以及吞吐量。大家如果感兴趣，也可以去了解阅读一下相关的底层源码。1、大部分人对Java并发仍停留在理论阶段</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[正向代理与反向代理]]></title>
    <link href="http://www.throne4j.com/16117185311755.html"/>
    <updated>2021-01-27T11:35:31+08:00</updated>
    <id>http://www.throne4j.com/16117185311755.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">正向代理服务器</h2>

<p>正向代理是一个位于客户端和目标服务器之间的服务器(代理服务器)，为了从目标服务器取得内容，客户端向代理服务器发送一个请求并指定目标，然后代理服务器向目标服务器转交请求并将获得的内容返回给客户端。</p>

<p><figure><img src="media/16117185311755/16117185757355.jpg" alt="正向代理fuwuqi"/><figcaption>正向代理fuwuqi</figcaption></figure></p>

<h2 id="toc_1">反向代理服务器</h2>

<p>反向代理是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。</p>

<p><figure><img src="media/16117133488224/16117148072309.jpg" alt="反向代理"/><figcaption>反向代理</figcaption></figure></p>

<h3 id="toc_2">反向代理服务器与正向代理服务器的区别</h3>

<p>正向代理：&quot;代理服务器&quot;代理了&quot;客户端&quot;，去和&quot;目标服务器&quot;进行交互。<br/>
反向代理：&quot;反向代理服务器&quot;代理了&quot;真实的服务提供者&quot;,去和&quot;客户端&quot;进行交互</p>

<ul>
<li>正向代理其实是客户端的代理，帮助客户端访问其无法访问的服务器资源。反向代理则是服务器的代理，帮助服务器做负载均衡，安全防护等。</li>
<li>正向代理一般是客户端架设的，比如在自己的机器上安装一个代理软件。而反向代理一般是服务器架设的，比如在自己的机器集群中部署一个反向代理服务器。</li>
<li>正向代理中，服务器不知道真正的客户端到底是谁，以为访问自己的就是真实的客户端。而在反向代理中，客户端不知道真正的服务器是谁，以为自己访问的就是真实的服务器。</li>
<li>正向代理和反向代理的作用和目的不同。正向代理主要是用来解决访问限制问题。而反向代理则是提供负载均衡、安全防护等作用。二者均能提高访问速度。</li>
</ul>

<h4 id="toc_3">正向代理用途</h4>

<ul>
<li><p>突破访问限制<br/>
例如经常使用的 VPN 科学上网技术</p></li>
<li><p>提高访问速度<br/>
可以在代理端做缓存提高响应速度</p></li>
<li><p>隐藏客户端真实IP<br/>
网络喷子也可以通过这种方法隐藏自己的IP，免受攻击。</p></li>
</ul>

<h4 id="toc_4">反向代理用途</h4>

<ul>
<li><p>隐藏服务器真实IP<br/>
使用反向代理，可以对客户端隐藏服务器的IP地址。</p></li>
<li><p>负载均衡<br/>
反向代理服务器可以做负载均衡，根据所有真实服务器的负载情况，将客户端请求分发到不同的真实服务器上。</p></li>
<li><p>提高访问速度<br/>
反向代理服务器可以对于静态内容及短时间内有大量访问请求的动态内容提供缓存服务，提高访问速度。</p></li>
<li><p>提供安全保障<br/>
反向代理服务器可以作为应用层防火墙，为网站提供对基于Web的攻击行为（例如DoS/DDoS）的防护，更容易排查恶意软件等。还可以为后端服务器统一提供加密和SSL加速（如SSL终端代理），提供HTTP访问认证等。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高并发的解决方案]]></title>
    <link href="http://www.throne4j.com/16117133488224.html"/>
    <updated>2021-01-27T10:09:08+08:00</updated>
    <id>http://www.throne4j.com/16117133488224.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">应用和静态资源分离</h2>

<h2 id="toc_1">页面缓存</h2>

<p>可以使用 Nginx、squid来实现</p>

<h2 id="toc_2">集群和分布式</h2>

<p>集群是每个节点都具有相同的功能，处理请求时调用到哪个集群节点结果都是一样的，主要起到分流的作用。<br/>
分布式是不同业务功能的服务放到不同的服务器中，这时完成一个请求肯能需要调用到多台服务器，每台服务器专门处理某个模块的业务代码（而不是各个模块的代码耦合在一个应用服务器中），提高单模块的处理能力。</p>

<p><figure><img src="media/16117133488224/16117138267304.jpg" alt="" style="width:862px;"/></figure></p>

<h2 id="toc_3">反向代理服务器</h2>

<p>反向代理是客户端访问的服务器并不真正提供服务，而是从其他服务器获取资源后再返回给客户端，服务端的负载均衡就是反向代理</p>

<p><figure><img src="media/16117133488224/16117148072309.jpg" alt="反向代理"/><figcaption>反向代理</figcaption></figure></p>

<h2 id="toc_4">代码层面的优化</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[海量数据与高并发解决方案]]></title>
    <link href="http://www.throne4j.com/16117121084096.html"/>
    <updated>2021-01-27T09:48:28+08:00</updated>
    <id>http://www.throne4j.com/16117121084096.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">海量数据方案</h2>

<h3 id="toc_1">缓存和页面静态化</h3>

<h4 id="toc_2">缓存问题</h4>

<p>适用于变动并不频繁的数据</p>

<h5 id="toc_3">缓存失效机制</h5>

<h5 id="toc_4">一致性问题</h5>

<h5 id="toc_5">缓存雪崩</h5>

<h5 id="toc_6">缓存击穿</h5>

<h3 id="toc_7">数据库优化</h3>

<h4 id="toc_8">表优化</h4>

<h4 id="toc_9">sql语句优化</h4>

<h4 id="toc_10">索引优化</h4>

<h4 id="toc_11">分库分表</h4>

<h4 id="toc_12">热点数据分离</h4>

<p>有这样一种情况，表中的数据量非常大，但是出于活跃状态的数据很少，此时将活跃的数据单独分离出来将会是一种行之有效的方案。</p>

<h4 id="toc_13">批量读取或者延迟修改</h4>

<p>批量读取和延迟修改都是通过降低操作的次数来提高效率的手段</p>

<h5 id="toc_14">批量读取</h5>

<p>比如数据库的 batch insert 操作，现在有 1W 条数据要插入数据库，数据在插入之前查询数据库中是否已经存在，如果这 1W 条数据都在插入之前查询数据库，将会产生 1W 此获取连接的操作，这样很明显是糟糕的。</p>

<p>如果首先一次查询完这 1W 的存在情况，然后再依据查询结果进行插入操作将节省大量的数据库连接资源，进而达到提高效率的目的。</p>

<h5 id="toc_15">延迟修改</h5>

<p>延迟修改主要使用与高并发下的频繁修改场景，比如秒杀。<br/>
这种情况可以首先将需要修改的数据做缓存，接下来的每次修改的结果存入缓存中，程序定时将缓存的数据同步到数据库。</p>

<p>但是这种方案有一个风险：缓存一旦宕机，数据将会丢失，对于重要数据更是灾难一样的风险。</p>

<h4 id="toc_16">读写分离</h4>

<p><figure><img src="media/16117121084096/16117132567561.jpg" alt="读写分离示意图"/><figcaption>读写分离示意图</figcaption></figure></p>

<h2 id="toc_17">高并发方案</h2>

<h3 id="toc_18">集群和分布式</h3>

<p>集群是每个节点都具有相同的功能，处理请求时调用到哪个集群节点结果都是一样的，主要起到分流的作用。<br/>
分布式是不同业务功能的服务放到不同的服务器中，这时完成一个请求肯能需要调用到多台服务器，每台服务器专门处理某个模块的业务代码（而不是各个模块的代码耦合在一个应用服务器中），提高单模块的处理能力。</p>

<p><figure><img src="media/16117133488224/16117138267304.jpg" alt="集群"/><figcaption>集群</figcaption></figure></p>

<h3 id="toc_19">反向代理</h3>

<p><a href="16117185311755.html">正向代理与反向代理</a></p>

<h3 id="toc_20">CDN</h3>

<p>CDN是一种特殊的页面缓存服务器集群，CDN 服务器是分布在全国各地的，当接受到用户的请求后会将请求分配到最适合的 CDN 服务器节点获取资源。</p>

<p>CDN 的请求方式比较特殊，他并不是使用普通的负载均衡服务器来分配的，而是专门的 CDN 域名解析服务器在解析域名的时候就分配好的，一般的做法是在 ISP(网络服务提供商) 哪里使用 CNAME 将域名解析到一个特定的域名，然后再将解析到的那个域名用专门的 CDN 服务器解析到响应的 CDN 节点。</p>

<p><figure><img src="media/16117133488224/16117191605724.jpg" alt="CDN 结构图"/><figcaption>CDN 结构图</figcaption></figure></p>

<p>访问CDN 的 DNS 服务器是因为 CNAME 记录的目标域名使用 NS 记录指向了 CDN 的 DNS 服务器，CDN 的每个节点可能也是一个集群</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一致性算法]]></title>
    <link href="http://www.throne4j.com/15983668905198.html"/>
    <updated>2020-08-25T22:48:10+08:00</updated>
    <id>http://www.throne4j.com/15983668905198.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、什么是一致性</h2>

<p>CAP理论，对于一个分布式系统，不能同时满足一下三点</p>

<ul>
<li>一致性（Consistency）</li>
<li>可用性（Availability）</li>
<li>分区容错性（Partition Tolerance）</li>
</ul>

<p><figure><img src="media/15983668905198/16008790045537.jpg" alt=""/></figure></p>

<h2 id="toc_1">2、一致性模型</h2>

<ul>
<li>弱一致性
<ul>
<li>最终一致性
<ul>
<li>DNS（Domain Name System）</li>
<li>Gossip（Cassandra的通信协议）</li>
</ul></li>
</ul></li>
<li>强一致性
<ul>
<li>同步</li>
<li>Paxos</li>
<li>Raft（multi-paxos)</li>
<li>ZAB（multi-paxos）</li>
</ul></li>
</ul>

<p>数据不能存在单点上<br/>
分布式系统对 fault tolorence 的一般解决方案是 state machine replication</p>

<p>state machine replication的公式（consensus）算法</p>

<p>paxos其实是一个共识算法。系统的最终一致性，不仅需要达成共识，还会取决于client 的行为</p>

<h2 id="toc_2">强一致性算法---主从同步</h2>

<ul>
<li>master接受写请求</li>
<li>master复制日志到slave</li>
<li>master等待，知道所有从库返回成功</li>
</ul>

<p>不足之处： 一个节点失败，master阻塞，导致整个集群不可用，保证了一致性，但是可用性非常低</p>

<h2 id="toc_3">强一致性算法---多数派</h2>

<p>基本思路：每次写都保证写入大于N/2个节点，每次度保证大于N/2个节点中读</p>

<p>不足之处： 并发环境下，无法保证执行指令的顺序，系统正确性不能得到保证，这种算法顺序非常重要</p>

<h2 id="toc_4">强一致性算法---Paxos</h2>

<h3 id="toc_5">由来</h3>

<p>Lesile Lamport，Latex的发明者。为描述Paxos算法，Paxos的坐着 lamport 虚拟了一个叫做Paxos的希腊城邦，这个岛按照议会民主制的政治模型制定法律，但是没有人愿意将自己的全部时间和精力放在这种事情上。所以无论是议员或者递纸条的服务员都不能承诺别人需要时一定会出现，也无法承诺批准决议或者传递消息的时间。</p>

<p>Paxos</p>

<ul>
<li>Basic paxos</li>
<li>multi paxos</li>
<li>fast paxos</li>
</ul>

<h3 id="toc_6">basic Paxos 角色介绍：</h3>

<ul>
<li>client：系统外部角色，请求发起者，比如民众，不参与投票的人</li>
<li>Propser： 接受client请求，向集群提出提议（propose）。并在冲突发生时，起到冲突调节的作用，像议员，替民众提出议案</li>
<li>Accepetor（voter）： 提议投票和接受者，只有在形成法定人数（Quorum，一般即为majority多数派）时，提议才会最终被接受，像国会</li>
<li>Learner： 提议接受者，backup，备份，对集群一致性没有影响，想记录员</li>
</ul>

<h3 id="toc_7">basic Paxos 阶段步骤</h3>

<ul>
<li>Phase 1a： prepare<br/>
proposer提出一个提案，编号为N，此N大于这个proposer之前提出提案编号。请求acceptors的quorum接受</li>
<li>Phase 1b： Promise<br/>
如果N大于此acceptor之前接受的任何提案编号则接受，否则拒绝</li>
<li>phase 2a： accept<br/>
如果达到了多数派，proposer会发出accept请求，此请求包含提案编号N，以及提案内容</li>
<li>phase 2b：accepted</li>
<li>如果此acceptor在此期间没有收到任何编号大于N的提案，则接受此提案内容，否则忽略</li>
</ul>

<p>基本流程：<br/>
<figure><img src="media/15983668905198/16012212157714.jpg" alt=""/></figure></p>

<p>部分节点失败，但达到了 quorums，3个人里面的2人接受提案</p>

<p><figure><img src="media/15983668905198/16012214247282.jpg" alt=""/></figure></p>

<p>proposer失败场景</p>

<p><figure><img src="media/15983668905198/16012215680680.jpg" alt=""/></figure></p>

<p>basic paxos 潜在问题： 活锁（liveness）或dueling，难实现、效率低（两轮rpc）<br/>
<figure><img src="media/15983668905198/16012217390496.jpg" alt=""/></figure></p>

<p>使用rundom的实际时间来让请求休息一下</p>

<h2 id="toc_8">multi Paxos:</h2>

<p>加入新概念 Leader : 唯一的 propser 所有请求都需要经过leader</p>

<p><figure><img src="media/15983668905198/16012224581326.jpg" alt=""/></figure></p>

<p>上面一轮是 要竞选出leader，下面一轮请求过来之后，只需要和选出来的leader交互就可以了。</p>

<p>进一步简化，减少角色<br/>
<figure><img src="media/15983668905198/16012226175886.jpg" alt=""/></figure></p>

<h2 id="toc_9">强一致性算法---raft</h2>

<ul>
<li>Raft
<ul>
<li>划分成三个子问题<br/>
-领袖选举（leader election）
<ul>
<li>日志复制（log replication）</li>
<li>safety</li>
</ul></li>
<li>重定义角色
<ul>
<li>leader</li>
<li>follower</li>
<li>candidate</li>
</ul></li>
<li>原理动画解释： <a href="http://thesecretlivesofdata.com/raft/">http://thesecretlivesofdata.com/raft/</a></li>
</ul></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式事务]]></title>
    <link href="http://www.throne4j.com/15979251824377.html"/>
    <updated>2020-08-20T20:06:22+08:00</updated>
    <id>http://www.throne4j.com/15979251824377.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">首先需要了解基本的事务知识</h2>

<p><a href="16022490047332.html">MySql 事务</a></p>

<h2 id="toc_1">分布式事务</h2>

<h3 id="toc_2">分布式事务产生的原因</h3>

<p>随着互联网高速发展，事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用。在这种环境中，我们之前说过数据库的 ACID 四大特性，已经无法满足我们分布式事务。</p>

<h3 id="toc_3">CAP理论</h3>

<p>CAP定理又被称为布鲁尔定理<br/>
CAP指的是 一致性(Consistency)、可用性(Availability)、分区容错性(Partition Tolerance)<br/>
<figure><img src="media/15979251824377/16022571868294.jpg" alt=""/></figure></p>

<p>CAP 定律说的是，在一个分布式系统中，最多只能满足 C、A、P 中的两个，不可能三个同时满足。 而在分布式系统中，网络无法 100% 可靠，分区其实是一个必然现象。</p>

<p>如果我们选择了 CA 而放弃了 P，那么当发生分区现象时，为了保证一致性，这个时候必须拒绝请求，但是 A 又不允许，所以分布式系统理论上 不可能选择 CA 架构，只能选择 CP 或者 AP 架构。</p>

<h3 id="toc_4">BASE 理论</h3>

<p>往往在分布式系统中无法实现完全一致性，于是有了 BASE 理论，它是对 CAP 定律的进一步扩充</p>

<p>BASE 指的是:</p>

<ul>
<li>Basically Available(基本可用) : 分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。</li>
<li>Soft state(软状态) : 允许系统中存在中间状态，这个状态不影响系统可用性。</li>
<li>Eventually consistent(最终一致性) : 经过一段时间后，所有节点数据都将会达到一致。</li>
</ul>

<p>BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果</p>

<p>BASE 理论核心思想就是:我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。</p>

<p>BASE 和 ACID 是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时 间内是不一致的，但最终达到一致状态。</p>

<h3 id="toc_5">基于 XA 协议的两阶段提交</h3>

<p>X/Open 组织提出了分布式事务的规范 ----- XA 协议。</p>

<p>XA 协议包含两部分:事务管理器和本地资源管理器。</p>

<p>其中本地资源管理器往往由数据库实现，目前主流的关系型数据库都实现了 XA 接口，而事务管理器作为全局的调度者，负责各个本地资源的提交和回滚。</p>

<p>XA 的核心，便是全局事务，通过 XA 二阶段提交协议，与各分布式数据交互，分准备与提交两个阶段。</p>

<p>逻辑流程如下图所示：<br/>
<figure><img src="media/15979251824377/16022618808551.jpg" alt=""/></figure></p>

<p>在 XA 协议中事务分为两阶段：</p>

<ul>
<li>事务管理器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交。</li>
<li>事务协调器要求每个数据库提交数据，或者回滚数据</li>
</ul>

<p>优点：</p>

<ul>
<li>尽量保证了数据的强一致性，实现成本较低，在各大主流数据库都有自己的实现，mysql从 5.5版本开始支持</li>
</ul>

<p>缺点：</p>

<ul>
<li>单点问题:事务管理器在整个流程中扮演的角色很关键，如果其宕机，比如在第一阶段已经完成，在第二阶段正准备提交 的时候事务管理器宕机，资源管理器就会一直阻塞，导致数据库无法使用。</li>
<li>同步阻塞:在准备就绪之后，资源管理器中的资源一直处于阻塞，直到提交完成，释放资源</li>
<li><p>数据不一致:两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，比如在第二阶段中，假设协调者发出了事务 Commit 的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行 了 Commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。</p>
<p>两阶段提交方案锁定资源时间长，对性能影响很大，基本不适合解决微服务事务问题。</p></li>
</ul>

<h3 id="toc_6">3PC事务</h3>

<p>3PC，全称 “three phase commit”，是 2PC 的改进版，其将 2PC 的 “提交事务请求” 过程一分为二。</p>

<p><figure><img src="media/15979251824377/16022621823701.jpg" alt=""/></figure></p>

<h4 id="toc_7">第一个阶段: CanCommit</h4>

<ul>
<li>事务询问<br/>
协调者向所有的参与者发送一个包含事务内容的 canCommit 请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。 </li>
<li>各参与者向协调者反馈事务询问的响应<br/>
参与者接收来自协调者的 canCommit 请求，如果参与者认为自己可以顺利执行事务，就返回 Yes，否则反馈 No 响应。</li>
</ul>

<p>这一阶段主要是确定分布式事务的参与者是否具备了完成 commit 的条件，并不会执行事务操作。</p>

<h4 id="toc_8">第二阶段: precommit</h4>

<p>协调者在得到所有参与者的响应之后，会根据结果执行两种操作: 执行事务预提交 或者 中断事务。</p>

<p>1、执行事务预提交 分三步走：</p>

<ul>
<li>发送预提交请求：协调者向所有参与者节点发出 preCommit 请求，并进入 prepared 状态</li>
<li>事务预提交： 参与者收到 preCommit 请求后，会执行事务操作，对应 2PC 中的 “执行事务”，也会 Undo 和 Redo 信息记录到事务日志中。</li>
<li>各参与者向协调者反馈事务执行的结果: 如果参与者成功执行了事务，就反馈 Ack 响应，同时等待指令: 提交(commit) 或终止(abor)。</li>
</ul>

<p>2、中断事务 分两步走</p>

<ul>
<li>发送中断请求： 协调者向所有参与者节点发出 abort 请求</li>
<li>中断事务： 参与者如果收到 abort 请求或者超时了，都会中断事务。</li>
</ul>

<h4 id="toc_9">第三阶段： doCommit</h4>

<p>1、执行提交</p>

<ul>
<li>发送提交请求: 进入这一阶段，如果协调者正常工作，并且接收到了所有协调者的 Ack 响应，那么协调者将从 “预提交” 状态变为 “提 交” 状态，并向所有的参与者发送 doCommit 请求 。</li>
<li>事务提交: 参与者收到 doCommit 请求后，会正式执行事务提交操作，并在完成之后释放在整个事务执行期间占用的事务资源。</li>
<li>反馈事务提交结果: 参与者完成事务提交后，向协调者发送 Ack 消息。</li>
<li>完成事务: 协调者接收到所有参与者反馈的 Ack 消息后，完成事务。</li>
</ul>

<p>2、中断事务(假设有任何参与者反馈了 no 响应，或者超时了，就中断事务)。</p>

<ul>
<li>发送中断请求: 协调者向所有的参与者节点发送 abort 请求。</li>
<li>事务回滚: 参与者接收到 abort 请求后，会利用其在二阶段记录的 undo 信息来执行事务回滚操作，并在完成回滚之后释放整个事务执行期间占用的资源。</li>
<li>反馈事务回滚结果: 参与者在完成事务回滚之后，想协调者发送 Ack 消息。</li>
<li>中断事务: 协调者接收到所有的 Ack 消息后，中断事务。</li>
</ul>

<h4 id="toc_10">3PC与2PC的区别</h4>

<p>注意:在阶段三，可能会出现 2 种故障:</p>

<ul>
<li>协调者出现问题/协调者</li>
<li>参与者之间的网络故障 </li>
</ul>

<p>出现了任一种情况，最终都会导致参与者无法收到 doCommit 请求或者 abort 请求，针对这种情况，参与者都会在等待超时之后，继续进行事务提交。</p>

<p>优点:<br/>
相比较 2PC，最大的优点是减少了参与者的阻塞范围(第一个阶段是不阻塞的)，并且能够在单点故障后继续达成一致(2PC 在提交阶段会出现此问题，而 3PC 会根据协调者的状态进行回滚或者提交)。</p>

<p>缺点:<br/>
如果参与者收到了 preCommit 消息后，出现了网络分区，那么参与者等待超时后，都会进行事务的提交，这必然会出现事务不一致的问题</p>

<h3 id="toc_11">TCC 方案</h3>

<p>TCC 其实就是采用的补偿机制，其核心思想是: 针对每个操作，都要注册一个与其业务逻辑对应的确认和补偿(撤销)操作。</p>

<p>其将整个业务逻辑的每个分支显式的分成了 Try、Confirm、Cancel 三个操作。Try 部分完成业务的准备工作，confirm 部分完成业务的提交，cancel<br/>
部分完成事务的回滚。</p>

<p><figure><img src="media/15979251824377/16022631802348.jpg" alt=""/></figure></p>

<p>优点: 跟 2PC 比起来，实现以及流程相对简单了一些，但数据的一致性比 2PC 也要差一些</p>

<p>缺点:TCC 属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，而且补偿的时候也有可能失败，在一些场景中，一些 业务流程可能用 TCC 不太好定义及处理</p>

<h3 id="toc_12">MQ(事务消息)</h3>

<p>目前，仅阿里云的 RocketMQ 支持事务消息。帮助用户实现类似 X/Open XA 的分布事务功能，通过 MQ 事务消息能达到分布式事务的最终一致。</p>

<p><figure><img src="media/15979251824377/16022635944292.jpg" alt=""/></figure></p>

<ul>
<li>1、发送方向 MQ 服务端发送消息</li>
<li>2、MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功，此时消息为半消息</li>
<li>3、发送方开始执行本地事务逻辑</li>
<li>4、发送方根据本地事务执行结果向 MQ Server 提交二次确认(Commit 或是 Rollback)，MQ Server 收到 Commit 状态则将半消息标记为可投递，订阅方最终将收到该消息;MQ Server 收到 Rollback 状态则删除半消息，订阅方将不会接受该消息</li>
<li>5、在断网或者是应用重启的特殊情况下，上述步骤 4 提交的二次确认最终未到达 MQ Server，经过固定时间后 MQ Server 将对该消息发起消息回查</li>
<li>6、发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果</li>
<li>7、发送方根据检查得到的本地事务的最终状态再次提交二次确认，MQ Server 仍按照步骤 4 对半消息进行操作</li>
</ul>

<p>其中，事务消息发送对应步骤 1、2、3、4，事务消息回查对应步骤 5、6、7</p>

<h2 id="toc_13">Lcn 事务</h2>

<p>LCN 并不生产事务，LCN 只是本地事务的协调工。</p>

<p>TX-LCN 定位于一款事务协调性框架，框架其本身并不操作事务，而是基于对事务的协调从而达到事务一致性的效果。</p>

<h3 id="toc_14">事务控制原理</h3>

<p>TX-LCN 由两大模块组成, TxClient、TxManager</p>

<p>TxClient 作为模块的依赖框架，提供 TX-LCN 的标准支持，TxManager 作为分布式事务的控制方。事务发起方或者参与方都由 TxClient 端来控制。</p>

<p><figure><img src="media/15979251824377/16023864582745.jpg" alt=""/></figure></p>

<ul>
<li>创建事务组<br/>
是指在事务发起方开始执行业务代码之前先调用 TxManager 创建事务组对象，然后拿到事务标示 GroupId 的过程。</li>
<li>加入事务组<br/>
添加事务组是指参与方在执行完业务方法以后，将该模块的事务信息通知给 TxManager 的操作。</li>
<li>通知事务组<br/>
是指在发起方执行完业务代码以后，将发起方执行结果状态通知给 TxManager,TxManager 将根据事务最终状态和事务组的信息 来通知相应的参与模块提交或回滚事务，并返回结果给事务发起方。</li>
</ul>

<h2 id="toc_15">Seata 事务</h2>

<p>Seata 是 阿里巴巴 开元的分布式事务中间件，以高效并且对业务 零侵入的方式，解决微服务场景下面临的分布式事务问题。</p>

<h3 id="toc_16">设计思想</h3>

<p>Seata 的AT 模式采用的是大量运用在数据库软件的 write ahead log 思想，即把事务的信息以事务日志的方式记录下来。这种处理方式实际上是对传统二阶段提交的一种改进和优化，主要有几个关键点：</p>

<ul>
<li>传统两阶段提交协议是阻塞协议，性能差</li>
<li>传统两阶段提交协议高可用性不好</li>
<li>传统两阶段提交协议的不支持全局事务隔离机制</li>
<li>根据八二原则，80% 的涉及到全局事务的业务是能正常完成并提交的</li>
</ul>

<p>因此，在 AT 模式下，seata 采取的做法是，一个事务分支的数据库操作执行完后，马上进行本地事务的提交，从而释放相关的数据库资源。</p>

<p><figure><img src="media/15979251824377/16023872296004.jpg" alt=""/></figure></p>

<ul>
<li>分支事务中数据的本地锁由本地事务管理，在分支事务 Phase1 结束时释放。</li>
<li>同时，随着本地事务结束，连接也得以释放。</li>
<li>分支事务中数据的全局锁在事务协调器侧管理，在决议 Phase2 全局提交时，全局锁马上可以释放。只有在决议全局回滚的情况下，全局锁才被持有至分支的Phase2 结束。</li>
</ul>

<h3 id="toc_17">本地事务执行流程</h3>

<p>在进行本地提交的前提是，seata 会解析 SQL，获取数据库表的元数据，根绝 SQL 类型，选择性地生成数据的前置镜像和后置镜像， 保存在 undo_log 表中，并且要求与保存 undo_log 与业务 SQL 在同一个本地事务内。</p>

<p>这就保证了如果一个本地事务被提交，那么必定对应这一条 undo_log数据，如果保存 undo_log失败，那么业务sql 也会失败</p>

<p><figure><img src="media/15979251824377/16023979641559.jpg" alt=""/></figure></p>

<h3 id="toc_18">全局事务提交流程</h3>

<p>因为每个分支事务的本地事务都已经被提交，所以如果全局事务能够顺利进行到“提交“这一阶段，那么意味着所有事务分支的本地事 务都已经被提交了，数据的一致性已经得到了保证。</p>

<p>这个时候全局事务的提交就变得十分轻量级，就是把 undo_log 对应的记录删掉即可，即使是当时删除失败了，也已经不会影响全局事务的最终结果，这次删不了，那就待会再删，程序删不了，没事，顶多人工删。</p>

<p><figure><img src="media/15979251824377/16023980661316.jpg" alt=""/></figure></p>

<h3 id="toc_19">全局事务回滚流程</h3>

<p>如果全局事务的任何一个事务分支失败了，那么全局事务就进入“回滚“流程，回滚时依据先前保存好数据镜像，将原来的数据回放回去。</p>

<p>如果全局回放成功，那么数据的一致性也就得到了保证，如果回放不成功，那么事务就进入异常。应对异常，可能需要重试，可能需要人工介入。</p>

<p><figure><img src="media/15979251824377/16023981351122.jpg" alt=""/></figure></p>

]]></content>
  </entry>
  
</feed>
