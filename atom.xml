<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大爷来玩儿啊~]]></title>
  <link href="http://www.throne4j.com/atom.xml" rel="self"/>
  <link href="http://www.throne4j.com/"/>
  <updated>2020-09-09T23:11:55+08:00</updated>
  <id>http://www.throne4j.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[LVS  --- ip 链路层负载]]></title>
    <link href="http://www.throne4j.com/15996615430684.html"/>
    <updated>2020-09-09T22:25:43+08:00</updated>
    <id>http://www.throne4j.com/15996615430684.html</id>
    <content type="html"><![CDATA[
<p>tcpdump 抓包的</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[zookeeper 入门]]></title>
    <link href="http://www.throne4j.com/15996345259637.html"/>
    <updated>2020-09-09T14:55:25+08:00</updated>
    <id>http://www.throne4j.com/15996345259637.html</id>
    <content type="html"><![CDATA[
<p>zkServer start<br/>
zkCli.sh -server 127.0.0.1:2181</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Object 对象]]></title>
    <link href="http://www.throne4j.com/15993982232051.html"/>
    <updated>2020-09-06T21:17:03+08:00</updated>
    <id>http://www.throne4j.com/15993982232051.html</id>
    <content type="html"><![CDATA[
<p>waitSet</p>

<p>entrySet</p>

<h2 id="toc_0">wait 方法</h2>

<h2 id="toc_1">sleep 与 wait 区别</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[redis.conf 详解]]></title>
    <link href="http://www.throne4j.com/15991189115875.html"/>
    <updated>2020-09-03T15:41:51+08:00</updated>
    <id>http://www.throne4j.com/15991189115875.html</id>
    <content type="html"><![CDATA[
<pre><code class="language-text"># Redis configuration file example.
#
# Note that in order to read the configuration file, Redis must be
# started with the file path as first argument:
#
# ./redis-server /path/to/redis.conf
#以上--redis启动说明：redis启动指令的第一个参数必须是配置文件路径

# Note on units: when memory size is needed, it is possible to specify
# it in the usual form of 1k 5GB 4M and so forth:
#
# 1k =&gt; 1000 bytes
# 1kb =&gt; 1024 bytes
# 1m =&gt; 1000000 bytes
# 1mb =&gt; 1024*1024 bytes
# 1g =&gt; 1000000000 bytes
# 1gb =&gt; 1024*1024*1024 bytes
#
# units are case insensitive so 1GB 1Gb 1gB are all the same.
# 以上--units单位说明：定义了基本度量单位，并且说明不区分单位大小写

################################## INCLUDES ###################################

# Include one or more other config files here.  This is useful if you
# have a standard template that goes to all Redis servers but also need
# to customize a few per-server settings.  Include files can include
# other files, so use this wisely.
#
# Notice option &quot;include&quot; won&#39;t be rewritten by command &quot;CONFIG REWRITE&quot;
# from admin or Redis Sentinel. Since Redis always uses the last processed
# line as value of a configuration directive, you&#39;d better put includes
# at the beginning of this file to avoid overwriting config change at runtime.
#
# If instead you are interested in using includes to override configuration
# options, it is better to use include as the last line.
#
# include /path/to/local.conf
# include /path/to/other.conf
#以上--INCLUDES：redis.conf作为配置总闸，可以在此处关联其它配置文件

################################## NETWORK #####################################

# By default, if no &quot;bind&quot; configuration directive is specified, Redis listens
# for connections from all the network interfaces available on the server.
# It is possible to listen to just one or multiple selected interfaces using
# the &quot;bind&quot; configuration directive, followed by one or more IP addresses.
#
# Examples:
#
# bind 192.168.1.100 10.0.0.1
# bind 127.0.0.1 ::1
#
# ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the
# internet, binding to all the interfaces is dangerous and will expose the
# instance to everybody on the internet. So by default we uncomment the
# following bind directive, that will force Redis to listen only into
# the IPv4 lookback interface address (this means Redis will be able to
# accept connections only from clients running into the same computer it
# is running).
#
# IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES
# JUST COMMENT THE FOLLOWING LINE.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
bind 127.0.0.1
#以上--IP绑定说明，默认绑定本次127.0.0.1，可以设置绑定单个或多个IP，如果不设置，则redis表示对全部IP开放

# Protected mode is a layer of security protection, in order to avoid that
# Redis instances left open on the internet are accessed and exploited.
#
# When protected mode is on and if:
#
# 1) The server is not binding explicitly to a set of addresses using the
#    &quot;bind&quot; directive.
# 2) No password is configured.
#
# The server only accepts connections from clients connecting from the
# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain
# sockets.
#
# By default protected mode is enabled. You should disable it only if
# you are sure you want clients from other hosts to connect to Redis
# even if no authentication is configured, nor a specific set of interfaces
# are explicitly listed using the &quot;bind&quot; directive.
protected-mode yes
#以上--redis3.2版本后新增protected-mode配置，默认是yes，即开启。设置外部网络连接redis服务，设置方式如下：1、关闭protected-mode模式，此时外部网络可以直接访问；2、开启protected-mode保护模式，需配置bind ip或者设置访问密码

# Accept connections on the specified port, default is 6379 (IANA #815344).
# If port 0 is specified Redis will not listen on a TCP socket.
port 6379
#以上--redis默认端口号

# TCP listen() backlog.
#
# In high requests-per-second environments you need an high backlog in order
# to avoid slow clients connections issues. Note that the Linux kernel
# will silently truncate it to the value of /proc/sys/net/core/somaxconn so
# make sure to raise both the value of somaxconn and tcp_max_syn_backlog
# in order to get the desired effect.
tcp-backlog 511
#以上--tcp-backlog，设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog两个值来达到想要的效果

# Unix socket.
#
# Specify the path for the Unix socket that will be used to listen for
# incoming connections. There is no default, so Redis will not listen
# on a unix socket when not specified.
#
# unixsocket /tmp/redis.sock
# unixsocketperm 700
#以上--Unix socket，没有默认值，即默认不监听Unix socket

# Close the connection after a client is idle for N seconds (0 to disable)
timeout 0
#以上-timeout：指一个连接闲置多久后会被关闭，默认0，表示不关闭

# TCP keepalive.
#
# If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence
# of communication. This is useful for two reasons:
#
# 1) Detect dead peers.
# 2) Take the connection alive from the point of view of network
#    equipment in the middle.
#
# On Linux, the specified value (in seconds) is the period used to send ACKs.
# Note that to close the connection the double of the time is needed.
# On other kernels the period depends on the kernel configuration.
#
# A reasonable value for this option is 300 seconds, which is the new
# Redis default starting with Redis 3.2.1.
tcp-keepalive 300
#以上--TCP keepalive： 单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60 

################################# GENERAL #####################################

# By default Redis does not run as a daemon. Use &#39;yes&#39; if you need it.
# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.
daemonize no
#以上--daemonize：redis是否已后台进程的方式运行，默认NO

# If you run Redis from upstart or systemd, Redis can interact with your
# supervision tree. Options:
#   supervised no      - no supervision interaction
#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode
#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET
#   supervised auto    - detect upstart or systemd method based on
#                        UPSTART_JOB or NOTIFY_SOCKET environment variables
# Note: these supervision methods only signal &quot;process is ready.&quot;
#       They do not enable continuous liveness pings back to your supervisor.
supervised no
#以上--supervised：可以通过upstart和systemd管理Redis守护进程。
   #supervised no - 没有监督互动
   #supervised upstart - 通过将Redis置于SIGSTOP模式来启动信号
   #supervised systemd - signal systemd将READY = 1写入$ NOTIFY_SOCKET
   #supervised auto - 检测upstart或systemd方法基于 UPSTART_JOB或NOTIFY_SOCKET环境变量

# If a pid file is specified, Redis writes it where specified at startup
# and removes it at exit.
#
# When the server runs non daemonized, no pid file is created if none is
# specified in the configuration. When the server is daemonized, the pid file
# is used even if not specified, defaulting to &quot;/var/run/redis.pid&quot;.
#
# Creating a pid file is best effort: if Redis is not able to create it
# nothing bad happens, the server will start and run normally.
pidfile /var/run/redis_6379.pid
#以上-pidfile：配置PID文件路径，当redis作为守护进程运行的时候，它会把 pid 默认写到 /var/redis/run/redis_6379.pid 文件里面

# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
loglevel notice
#以上-loglevel：redis日志级别。  debug（记录大量日志信息，适用于开发、测试阶段）；verbose（较多日志信息）；notice（适量日志信息，使用于生产环境）；warning（仅有部分重要、关键信息才会被记录）

# Specify the log file name. Also the empty string can be used to force
# Redis to log on the standard output. Note that if you use standard
# output for logging but daemonize, logs will be sent to /dev/null
logfile &quot;&quot;
#以上--logfile:日志文件的位置，当指定为空字符串时，为标准输出，如果redis已守护进程模式运行，那么日志将会输出到/dev/null

# To enable logging to the system logger, just set &#39;syslog-enabled&#39; to yes,
# and optionally update the other syslog parameters to suit your needs.
# syslog-enabled no
#以上--syslog-enabled：要想把日志记录到系统日志，就把它改成 yes，也可以可选择性的更新其他的syslog 参数以达到你的要求

# Specify the syslog identity.
# syslog-ident redis
#以上--syslog-ident：设置系统日志的ID

# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.
# syslog-facility local0
#以上--syslog-facility：指定系统日志设置，必须是 USER 或者是 LOCAL0-LOCAL7 之间的值

# Set the number of databases. The default database is DB 0, you can select
# a different one on a per-connection basis using SELECT &lt;dbid&gt; where
# dbid is a number between 0 and &#39;databases&#39;-1
databases 16
#以上--databases：设置数据库的数目。默认的数据库是DB 0 ，可以在每个连接上使用select  &lt;dbid&gt; 命令选择一个不同的数据库，dbid是一个介于0到databases - 1 之间的数值。

################################ SNAPSHOTTING  ################################
#
# Save the DB on disk:
#
#   save &lt;seconds&gt; &lt;changes&gt;
#
#   Will save the DB if both the given number of seconds and the given
#   number of write operations against the DB occurred.
#
#   In the example below the behaviour will be to save:
#   after 900 sec (15 min) if at least 1 key changed
#   after 300 sec (5 min) if at least 10 keys changed
#   after 60 sec if at least 10000 keys changed
#
#   Note: you can disable saving completely by commenting out all &quot;save&quot; lines.
#
#   It is also possible to remove all the previously configured save
#   points by adding a save directive with a single empty string argument
#   like in the following example:
#
#   save &quot;&quot;

save 900 1
save 300 10
save 60 10000
#以上--Save the DB on disk：
    #格式：save &lt;间隔时间（秒）&gt; &lt;写入次数&gt;
    #根据给定的时间间隔和写入次数将数据保存到磁盘
    #下面的例子的意思是：
    #900 秒内如果至少有 1 个 key 的值变化，则保存
    #300 秒内如果至少有 10 个 key 的值变化，则保存
    #60 秒内如果至少有 10000 个 key 的值变化，则保存
    #注意：你可以注释掉所有的 save 行来停用保存功能。
    #也可以直接一个空字符串来实现停用：

# By default Redis will stop accepting writes if RDB snapshots are enabled
# (at least one save point) and the latest background save failed.
# This will make the user aware (in a hard way) that data is not persisting
# on disk properly, otherwise chances are that no one will notice and some
# disaster will happen.
#
# If the background saving process will start working again Redis will
# automatically allow writes again.
#
# However if you have setup your proper monitoring of the Redis server
# and persistence, you may want to disable this feature so that Redis will
# continue to work as usual even if there are problems with disk,
# permissions, and so forth.
stop-writes-on-bgsave-error yes
#以上--stop-writes-on-bgsave-error：
  #如果用户开启了RDB快照功能，那么在redis持久化数据到磁盘时如果出现失败，默认情况下，redis会停止接受所有的写请求。
  #这样做的好处在于可以让用户很明确的知道内存中的数据和磁盘上的数据已经存在不一致了。
  #如果redis不顾这种不一致，一意孤行的继续接收写请求，就可能会引起一些灾难性的后果。
  #如果下一次RDB持久化成功，redis会自动恢复接受写请求。
  #如果不在乎这种数据不一致或者有其他的手段发现和控制这种不一致的话，可以关闭这个功能，
  #以便在快照写入失败时，也能确保redis继续接受新的写请求。

# Compress string objects using LZF when dump .rdb databases?
# For default that&#39;s set to &#39;yes&#39; as it&#39;s almost always a win.
# If you want to save some CPU in the saving child set it to &#39;no&#39; but
# the dataset will likely be bigger if you have compressible values or keys.
rdbcompression yes
#以上--rdbcompression： 对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。

# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.
# This makes the format more resistant to corruption but there is a performance
# hit to pay (around 10%) when saving and loading RDB files, so you can disable it
# for maximum performances.
#
# RDB files created with checksum disabled have a checksum of zero that will
# tell the loading code to skip the check.
rdbchecksum yes
#以上--rdbchecksum：在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。

# The filename where to dump the DB
dbfilename dump.rdb
#以上--dbfilename：设置快照的文件名

# The working directory.
#
# The DB will be written inside this directory, with the filename specified
# above using the &#39;dbfilename&#39; configuration directive.
#
# The Append Only File will also be created inside this directory.
#
# Note that you must specify a directory here, not a file name.
dir ./
#以上--dir：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名

################################# REPLICATION #################################

# Master-Slave replication. Use slaveof to make a Redis instance a copy of
# another Redis server. A few things to understand ASAP about Redis replication.
#
# 1) Redis replication is asynchronous, but you can configure a master to
#    stop accepting writes if it appears to be not connected with at least
#    a given number of slaves.
# 2) Redis slaves are able to perform a partial resynchronization with the
#    master if the replication link is lost for a relatively small amount of
#    time. You may want to configure the replication backlog size (see the next
#    sections of this file) with a sensible value depending on your needs.
# 3) Replication is automatic and does not need user intervention. After a
#    network partition slaves automatically try to reconnect to masters
#    and resynchronize with them.
#
# slaveof &lt;masterip&gt; &lt;masterport&gt;
#以上--slaveof：  主从复制，使用 slaveof 来让一个 redis 实例成为另一个reids 实例的副本，默认关闭。注意这个只需要在 slave 上配置

# If the master is password protected (using the &quot;requirepass&quot; configuration
# directive below) it is possible to tell the slave to authenticate before
# starting the replication synchronization process, otherwise the master will
# refuse the slave request.
#
# masterauth &lt;master-password&gt;
#以上--masterauth：如果 master 需要密码认证，就在这里设置，默认不设置

# When a slave loses its connection with the master, or when the replication
# is still in progress, the slave can act in two different ways:
#
# 1) if slave-serve-stale-data is set to &#39;yes&#39; (the default) the slave will
#    still reply to client requests, possibly with out of date data, or the
#    data set may just be empty if this is the first synchronization.
#
# 2) if slave-serve-stale-data is set to &#39;no&#39; the slave will reply with
#    an error &quot;SYNC with master in progress&quot; to all the kind of commands
#    but to INFO and SLAVEOF.
#
slave-serve-stale-data yes
#以上--slave-serve-stale-data：
  #当一个 slave 与 master 失去联系，或者复制正在进行的时候，
  #slave 可能会有两种表现：
  #1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，
  #   或者数据可能是空的在第一次同步的时候
  #2) 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，
  #   slave 都将返回一个 &quot;SYNC with master in progress&quot; 的错误

# You can configure a slave instance to accept writes or not. Writing against
# a slave instance may be useful to store some ephemeral data (because data
# written on a slave will be easily deleted after resync with the master) but
# may also cause problems if clients are writing to it because of a
# misconfiguration.
#
# Since Redis 2.6 by default slaves are read-only.
#
# Note: read only slaves are not designed to be exposed to untrusted clients
# on the internet. It&#39;s just a protection layer against misuse of the instance.
# Still a read only slave exports by default all the administrative commands
# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve
# security of read only slaves using &#39;rename-command&#39; to shadow all the
# administrative / dangerous commands.
slave-read-only yes
#以上--slave-read-only:   
  #你可以配置一个 slave 实体是否接受写入操作。
  #通过写入操作来存储一些短暂的数据对于一个 slave 实例来说可能是有用的，
  #因为相对从 master 重新同步数而言，据数据写入到 slave 会更容易被删除。
  #但是如果客户端因为一个错误的配置写入，也可能会导致一些问题。
  #从 redis 2.6 版起，默认 slaves 都是只读的。

# Replication SYNC strategy: disk or socket.
#
# -------------------------------------------------------
# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY
# -------------------------------------------------------
#
# New slaves and reconnecting slaves that are not able to continue the replication
# process just receiving differences, need to do what is called a &quot;full
# synchronization&quot;. An RDB file is transmitted from the master to the slaves.
# The transmission can happen in two different ways:
#
# 1) Disk-backed: The Redis master creates a new process that writes the RDB
#                 file on disk. Later the file is transferred by the parent
#                 process to the slaves incrementally.
# 2) Diskless: The Redis master creates a new process that directly writes the
#              RDB file to slave sockets, without touching the disk at all.
#
# With disk-backed replication, while the RDB file is generated, more slaves
# can be queued and served with the RDB file as soon as the current child producing
# the RDB file finishes its work. With diskless replication instead once
# the transfer starts, new slaves arriving will be queued and a new transfer
# will start when the current one terminates.
#
# When diskless replication is used, the master waits a configurable amount of
# time (in seconds) before starting the transfer in the hope that multiple slaves
# will arrive and the transfer can be parallelized.
#
# With slow disks and fast (large bandwidth) networks, diskless replication
# works better.
repl-diskless-sync no
#以上--repl-diskless-sync
  #主从数据复制是否使用无硬盘复制功能。
  #新的从站和重连后不能继续备份的从站，需要做所谓的“完全备份”，即将一个RDB文件从主站传送到从站。
  #这个传送有以下两种方式：
  #1）硬盘备份：redis主站创建一个新的进程，用于把RDB文件写到硬盘上。过一会儿，其父进程递增地将文件传送给从站。
  #2）无硬盘备份：redis主站创建一个新的进程，子进程直接把RDB文件写到从站的套接字，不需要用到硬盘。
  #在硬盘备份的情况下，主站的子进程生成RDB文件。一旦生成，多个从站可以立即排成队列使用主站的RDB文件。
  #在无硬盘备份的情况下，一次RDB传送开始，新的从站到达后，需要等待现在的传送结束，才能开启新的传送。
  #如果使用无硬盘备份，主站会在开始传送之间等待一段时间（可配置，以秒为单位），希望等待多个子站到达后并行传送。
  #在硬盘低速而网络高速（高带宽）情况下，无硬盘备份更好。

# When diskless replication is enabled, it is possible to configure the delay
# the server waits in order to spawn the child that transfers the RDB via socket
# to the slaves.
#
# This is important since once the transfer starts, it is not possible to serve
# new slaves arriving, that will be queued for the next RDB transfer, so the server
# waits a delay in order to let more slaves arrive.
#
# The delay is specified in seconds, and by default is 5 seconds. To disable
# it entirely just set it to 0 seconds and the transfer will start ASAP.
repl-diskless-sync-delay 5
#以上--repl-diskless-sync-delay：
  #当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。
  #这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段
  #时间以期更多的从站到达。
  #延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动。

# Slaves send PINGs to server in a predefined interval. It&#39;s possible to change
# this interval with the repl_ping_slave_period option. The default value is 10
# seconds.
#
# repl-ping-slave-period 10
#以上--repl-ping-slave-period： 从redis会周期性的向主redis发出PING包，你可以通过repl_ping_slave_period指令来控制其周期，默认是10秒。

# The following option sets the replication timeout for:
#
# 1) Bulk transfer I/O during SYNC, from the point of view of slave.
# 2) Master timeout from the point of view of slaves (data, pings).
# 3) Slave timeout from the point of view of masters (REPLCONF ACK pings).
#
# It is important to make sure that this value is greater than the value
# specified for repl-ping-slave-period otherwise a timeout will be detected
# every time there is low traffic between the master and the slave.
#
# repl-timeout 60
#以上--repl-timeout：
  #接下来的选项为以下内容设置备份的超时时间：
  #1）从从站的角度，同步期间的批量传输的I/O
  #2）从站角度认为的主站超时（数据，ping）
  #3）主站角度认为的从站超时（REPLCONF ACK pings)
  #确认这些值比定义的repl-ping-slave-period要大，否则每次主站和从站之间通信低速时都会被检测为超时。

# Disable TCP_NODELAY on the slave socket after SYNC?
#
# If you select &quot;yes&quot; Redis will use a smaller number of TCP packets and
# less bandwidth to send data to slaves. But this can add a delay for
# the data to appear on the slave side, up to 40 milliseconds with
# Linux kernels using a default configuration.
#
# If you select &quot;no&quot; the delay for data to appear on the slave side will
# be reduced but more bandwidth will be used for replication.
#
# By default we optimize for low latency, but in very high traffic conditions
# or when the master and slaves are many hops away, turning this to &quot;yes&quot; may
# be a good idea.
repl-disable-tcp-nodelay no
#以上--repl-disable-tcp-nodelay：
  #同步之后是否禁用从站上的TCP_NODELAY
  #如果你选择yes，redis会使用较少量的TCP包和带宽向从站发送数据。但这会导致在从站增加一点数据的延时。
  #Linux内核默认配置情况下最多40毫秒的延时。
  #如果选择no，从站的数据延时不会那么多，但备份需要的带宽相对较多。
  #默认情况下我们将潜在因素优化，但在高负载情况下或者在主从站都跳的情况下，把它切换为yes是个好主意。

# Set the replication backlog size. The backlog is a buffer that accumulates
# slave data when slaves are disconnected for some time, so that when a slave
# wants to reconnect again, often a full resync is not needed, but a partial
# resync is enough, just passing the portion of data the slave missed while
# disconnected.
#
# The bigger the replication backlog, the longer the time the slave can be
# disconnected and later be able to perform a partial resynchronization.
#
# The backlog is only allocated once there is at least a slave connected.
#
# repl-backlog-size 1mb
#以上--repl-backlog-size：
  #设置备份的工作储备大小。工作储备是一个缓冲区，当从站断开一段时间的情况时，它替从站接收存储数据，
  #因此当从站重连时，通常不需要完全备份，只需要一个部分同步就可以，即把从站断开时错过的一部分数据接收。
  #工作储备越大，从站可以断开并稍后执行部分同步的断开时间就越长。
  #只要有一个从站连接，就会立刻分配一个工作储备。


# After a master has no longer connected slaves for some time, the backlog
# will be freed. The following option configures the amount of seconds that
# need to elapse, starting from the time the last slave disconnected, for
# the backlog buffer to be freed.
#
# A value of 0 means to never release the backlog.
#
# repl-backlog-ttl 3600
#以上--repl-backlog-ttl：
  #主站有一段时间没有与从站连接，对应的工作储备就会自动释放。
  #这个选项用于配置释放前等待的秒数，秒数从断开的那一刻开始计算，值为0表示不释放。

# The slave priority is an integer number published by Redis in the INFO output.
# It is used by Redis Sentinel in order to select a slave to promote into a
# master if the master is no longer working correctly.
#
# A slave with a low priority number is considered better for promotion, so
# for instance if there are three slaves with priority 10, 100, 25 Sentinel will
# pick the one with priority 10, that is the lowest.
#
# However a special priority of 0 marks the slave as not able to perform the
# role of master, so a slave with priority of 0 will never be selected by
# Redis Sentinel for promotion.
#
# By default the priority is 100.
slave-priority 100
#以上--slave-priority：
  #从站优先级是可以从redis的INFO命令输出中查到的一个整数。当主站不能正常工作时
  #redis sentinel使用它来选择一个从站并将它提升为主站。
  #优先级的从站被认为更适合于提升，因此如果有三个从站优先级分别是10，
  #100，25，sentinel会选择优先级为10的从站，因为它的优先级最低。
  #然而优先级值为0的从站不能执行主站的角色，因此优先级为0的从站永远不会被redis sentinel提升。
  #默认优先级是100

# It is possible for a master to stop accepting writes if there are less than
# N slaves connected, having a lag less or equal than M seconds.
#
# The N slaves need to be in &quot;online&quot; state.
#
# The lag in seconds, that must be &lt;= the specified value, is calculated from
# the last ping received from the slave, that is usually sent every second.
#
# This option does not GUARANTEE that N replicas will accept the write, but
# will limit the window of exposure for lost writes in case not enough slaves
# are available, to the specified number of seconds.
#
# For example to require at least 3 slaves with a lag &lt;= 10 seconds use:
#
# min-slaves-to-write 3
# min-slaves-max-lag 10
#
# Setting one or the other to 0 disables the feature.
#
# By default min-slaves-to-write is set to 0 (feature disabled) and
# min-slaves-max-lag is set to 10.
#以上
  #主站可以停止接受写请求，当与它连接的从站少于N个，滞后少于M秒，N个从站必须是在线状态。
  #延迟的秒数必须&lt;=所定义的值，延迟秒数是从最后一次收到的来自从站的ping开始计算。ping通常是每秒一次。
  #这一选项并不保证N个备份都会接受写请求，但是会限制在指定秒数内由于从站数量不够导致的写操作丢失的情况。
  #如果想要至少3个从站且延迟少于10秒，如上配置即可

# A Redis master is able to list the address and port of the attached
# slaves in different ways. For example the &quot;INFO replication&quot; section
# offers this information, which is used, among other tools, by
# Redis Sentinel in order to discover slave instances.
# Another place where this info is available is in the output of the
# &quot;ROLE&quot; command of a masteer.
#
# The listed IP and address normally reported by a slave is obtained
# in the following way:
#
#   IP: The address is auto detected by checking the peer address
#   of the socket used by the slave to connect with the master.
#
#   Port: The port is communicated by the slave during the replication
#   handshake, and is normally the port that the slave is using to
#   list for connections.
#
# However when port forwarding or Network Address Translation (NAT) is
# used, the slave may be actually reachable via different IP and port
# pairs. The following two options can be used by a slave in order to
# report to its master a specific set of IP and port, so that both INFO
# and ROLE will report those values.
#
# There is no need to use both the options if you need to override just
# the port or the IP address.
#
# slave-announce-ip 5.5.5.5
# slave-announce-port 1234
#以上--
 #Redis master能够以不同的方式列出所连接slave的地址和端口。
 #例如，“INFO replication”部分提供此信息，除了其他工具之外，Redis Sentinel还使用该信息来发现slave实例。
 #此信息可用的另一个地方在masterser的“ROLE”命令的输出中。
 #通常由slave报告的列出的IP和地址,通过以下方式获得：
 #IP：通过检查slave与master连接使用的套接字的对等体地址自动检测地址。
 #端口：端口在复制握手期间由slavet通信，并且通常是slave正在使用列出连接的端口。
 #然而，当使用端口转发或网络地址转换（NAT）时，slave实际上可以通过(不同的IP和端口对)来到达。 slave可以使用以下两个选项，以便向master报告一组特定的IP和端口，
 #以便INFO和ROLE将报告这些值。
 #如果你需要仅覆盖端口或IP地址，则没必要使用这两个选项。


################################## SECURITY ###################################

# Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other
# commands.  This might be useful in environments in which you do not trust
# others with access to the host running redis-server.
#
# This should stay commented out for backward compatibility and because most
# people do not need auth (e.g. they run their own servers).
#
# Warning: since Redis is pretty fast an outside user can try up to
# 150k passwords per second against a good box. This means that you should
# use a very strong password otherwise it will be very easy to break.
#
# requirepass foobared
#以上--requirepass：设置redis连接密码

# Command renaming.
#
# It is possible to change the name of dangerous commands in a shared
# environment. For instance the CONFIG command may be renamed into something
# hard to guess so that it will still be available for internal-use tools
# but not available for general clients.
#
# Example:
#
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#
# It is also possible to completely kill a command by renaming it into
# an empty string:
#
# rename-command CONFIG &quot;&quot;
#
# Please note that changing the name of commands that are logged into the
# AOF file or transmitted to slaves may cause problems.
#以上--rename-command CONFIG： 将命令重命名，为了安全考虑，可以将某些重要的、危险的命令重命名。当你把某个命令重命名成空字符串的时候就等于取消了这个命令。

################################### LIMITS ####################################

# Set the max number of connected clients at the same time. By default
# this limit is set to 10000 clients, however if the Redis server is not
# able to configure the process file limit to allow for the specified limit
# the max number of allowed clients is set to the current file limit
# minus 32 (as Redis reserves a few file descriptors for internal uses).
#
# Once the limit is reached Redis will close all the new connections sending
# an error &#39;max number of clients reached&#39;.
#
# maxclients 10000
#以上--maxclients：
  #设置客户端最大并发连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件
  #描述符数-32（redis server自身会使用一些），如果设置 maxclients为0
  #表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息

# Don&#39;t use more memory than the specified amount of bytes.
# When the memory limit is reached Redis will try to remove keys
# according to the eviction policy selected (see maxmemory-policy).
#
# If Redis can&#39;t remove keys according to the policy, or if the policy is
# set to &#39;noeviction&#39;, Redis will start to reply with errors to commands
# that would use more memory, like SET, LPUSH, and so on, and will continue
# to reply to read-only commands like GET.
#
# This option is usually useful when using Redis as an LRU cache, or to set
# a hard memory limit for an instance (using the &#39;noeviction&#39; policy).
#
# WARNING: If you have slaves attached to an instance with maxmemory on,
# the size of the output buffers needed to feed the slaves are subtracted
# from the used memory count, so that network problems / resyncs will
# not trigger a loop where keys are evicted, and in turn the output
# buffer of slaves is full with DELs of keys evicted triggering the deletion
# of more keys, and so forth until the database is completely emptied.
#
# In short... if you have slaves attached it is suggested that you set a lower
# limit for maxmemory so that there is some free RAM on the system for slave
# output buffers (but this is not needed if the policy is &#39;noeviction&#39;).
#
# maxmemory &lt;bytes&gt;
#以上--maxmemory：
  #指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key
  #当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，
  #会把Key存放内存，Value会存放在swap区，格式：maxmemory &lt;bytes&gt;

# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory
# is reached. You can select among five behaviors:
#
# volatile-lru -&gt; remove the key with an expire set using an LRU algorithm
# allkeys-lru -&gt; remove any key according to the LRU algorithm
# volatile-random -&gt; remove a random key with an expire set
# allkeys-random -&gt; remove a random key, any key
# volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)
# noeviction -&gt; don&#39;t expire at all, just return an error on write operations
#
# Note: with any of the above policies, Redis will return an error on write
#       operations, when there are no suitable keys for eviction.
#
#       At the date of writing these commands are: set setnx setex append
#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
#       getset mset msetnx exec sort
#
# The default is:
#
# maxmemory-policy noeviction
#以上--maxmemory-policy：
  #当内存使用达到最大值时，redis使用的清楚策略。有以下几种可以选择：
  #1）volatile-lru   利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used )
  #2）allkeys-lru   利用LRU算法移除任何key
  #3）volatile-random 移除设置过过期时间的随机key
  #4）allkeys-random  移除随机ke
  #5）volatile-ttl   移除即将过期的key(minor TTL)
  #6）noeviction  noeviction   不移除任何key，只是返回一个写错误 ，默认选项


# LRU and minimal TTL algorithms are not precise algorithms but approximated
# algorithms (in order to save memory), so you can tune it for speed or
# accuracy. For default Redis will check five keys and pick the one that was
# used less recently, you can change the sample size using the following
# configuration directive.
#
# The default of 5 produces good enough results. 10 Approximates very closely
# true LRU but costs a bit more CPU. 3 is very fast but not very accurate.
#
# maxmemory-samples 5
#以上--maxmemory-samples：LRU 和 minimal TTL 算法都不是精准的算法，但是相对精确的算法(为了节省内存)；随意你可以选择样本大小进行检，redis默认选择3个样本进行检测，你可以通过maxmemory-samples进行设置样本数


############################## APPEND ONLY MODE ###############################

# By default Redis asynchronously dumps the dataset on disk. This mode is
# good enough in many applications, but an issue with the Redis process or
# a power outage may result into a few minutes of writes lost (depending on
# the configured save points).
#
# The Append Only File is an alternative persistence mode that provides
# much better durability. For instance using the default data fsync policy
# (see later in the config file) Redis can lose just one second of writes in a
# dramatic event like a server power outage, or a single write if something
# wrong with the Redis process itself happens, but the operating system is
# still running correctly.
#
# AOF and RDB persistence can be enabled at the same time without problems.
# If the AOF is enabled on startup Redis will load the AOF, that is the file
# with the better durability guarantees.
#
# Please check http://redis.io/topics/persistence for more information.

appendonly no
#以上--appendonly：
  #默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，
  #会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，
  #可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入appendonly.aof文件，
  #每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。

# The name of the append only file (default: &quot;appendonly.aof&quot;)

appendfilename &quot;appendonly.aof&quot;
#以上--appendfilename：aof文件名

# The fsync() call tells the Operating System to actually write data on disk
# instead of waiting for more data in the output buffer. Some OS will really flush
# data on disk, some other OS will just try to do it ASAP.
#
# Redis supports three different modes:
#
# no: don&#39;t fsync, just let the OS flush the data when it wants. Faster.
# always: fsync after every write to the append only log. Slow, Safest.
# everysec: fsync only one time every second. Compromise.
#
# The default is &quot;everysec&quot;, as that&#39;s usually the right compromise between
# speed and data safety. It&#39;s up to you to understand if you can relax this to
# &quot;no&quot; that will let the operating system flush the output buffer when
# it wants, for better performances (but if you can live with the idea of
# some data loss consider the default persistence mode that&#39;s snapshotting),
# or on the contrary, use &quot;always&quot; that&#39;s very slow but a bit safer than
# everysec.
#
# More details please check the following article:
# http://antirez.com/post/redis-persistence-demystified.html
#
# If unsure, use &quot;everysec&quot;.

# appendfsync always
appendfsync everysec
# appendfsync no
#以上--
  #aof持久化策略的配置
  #no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。
  #always表示每次写入都执行fsync，以保证数据同步到磁盘。
  #everysec表示每秒执行一次fsync，可能会导致丢失这1s数据

# When the AOF fsync policy is set to always or everysec, and a background
# saving process (a background save or AOF log background rewriting) is
# performing a lot of I/O against the disk, in some Linux configurations
# Redis may block too long on the fsync() call. Note that there is no fix for
# this currently, as even performing fsync in a different thread will block
# our synchronous write(2) call.
#
# In order to mitigate this problem it&#39;s possible to use the following option
# that will prevent fsync() from being called in the main process while a
# BGSAVE or BGREWRITEAOF is in progress.
#
# This means that while another child is saving, the durability of Redis is
# the same as &quot;appendfsync none&quot;. In practical terms, this means that it is
# possible to lose up to 30 seconds of log in the worst scenario (with the
# default Linux settings).
#
# If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as
# &quot;no&quot; that is the safest pick from the point of view of durability.

no-appendfsync-on-rewrite no
#以上--no-appendfsync-on-rewrite：
   #在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，
   #执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。
   #如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。
   #设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。
   #Linux的默认fsync策略是30秒。可能丢失30秒数据。

# Automatic rewrite of the append only file.
# Redis is able to automatically rewrite the log file implicitly calling
# BGREWRITEAOF when the AOF log size grows by the specified percentage.
#
# This is how it works: Redis remembers the size of the AOF file after the
# latest rewrite (if no rewrite has happened since the restart, the size of
# the AOF at startup is used).
#
# This base size is compared to the current size. If the current size is
# bigger than the specified percentage, the rewrite is triggered. Also
# you need to specify a minimal size for the AOF file to be rewritten, this
# is useful to avoid rewriting the AOF file even if the percentage increase
# is reached but it is still pretty small.
#
# Specify a percentage of zero in order to disable the automatic AOF
# rewrite feature.

auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
#以上--
  #aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，
  #即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。
  #当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。
  #设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写

# An AOF file may be found to be truncated at the end during the Redis
# startup process, when the AOF data gets loaded back into memory.
# This may happen when the system where Redis is running
# crashes, especially when an ext4 filesystem is mounted without the
# data=ordered option (however this can&#39;t happen when Redis itself
# crashes or aborts but the operating system still works correctly).
#
# Redis can either exit with an error when this happens, or load as much
# data as possible (the default now) and start if the AOF file is found
# to be truncated at the end. The following option controls this behavior.
#
# If aof-load-truncated is set to yes, a truncated AOF file is loaded and
# the Redis server starts emitting a log to inform the user of the event.
# Otherwise if the option is set to no, the server aborts with an error
# and refuses to start. When the option is set to no, the user requires
# to fix the AOF file using the &quot;redis-check-aof&quot; utility before to restart
# the server.
#
# Note that if the AOF file will be found to be corrupted in the middle
# the server will still exit with an error. This option only applies when
# Redis will try to read more data from the AOF file but not enough bytes
# will be found.
aof-load-truncated yes
#以上--aof-load-truncated：
  #aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。
  #重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项，出现这种现象
  #redis宕机或者异常终止不会造成尾部不完整现象，可以选择让redis退出，或者导入尽可能多的数据。
  #如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。
  #如果是no，用户必须手动redis-check-aof修复AOF文件才可以。

################################ LUA SCRIPTING  ###############################

# Max execution time of a Lua script in milliseconds.
#
# If the maximum execution time is reached Redis will log that a script is
# still in execution after the maximum allowed time and will start to
# reply to queries with an error.
#
# When a long running script exceeds the maximum execution time only the
# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be
# used to stop a script that did not yet called write commands. The second
# is the only way to shut down the server in the case a write command was
# already issued by the script but the user doesn&#39;t want to wait for the natural
# termination of the script.
#
# Set it to 0 or a negative value for unlimited execution without warnings.
lua-time-limit 5000
#以上--lua-time-limit：
  #如果达到最大时间限制（毫秒），redis会记个log，然后返回error。当一个脚本超过了最大时限。
  #只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write命令的东西。
  #要是已经调用了write，只能用第二个命令杀
  
################################ REDIS CLUSTER  ###############################
#
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however
# in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage
# of users to deploy it in production.
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#
# Normal Redis instances can&#39;t be part of a Redis Cluster; only nodes that are
# started as cluster nodes can. In order to start a Redis instance as a
# cluster node enable the cluster support uncommenting the following:
#
# cluster-enabled yes
#以上--cluster-enabled：集群开关，默认是不开启集群模式


# Every cluster node has a cluster configuration file. This file is not
# intended to be edited by hand. It is created and updated by Redis nodes.
# Every Redis Cluster node requires a different cluster configuration file.
# Make sure that instances running in the same system do not have
# overlapping cluster configuration file names.
#
# cluster-config-file nodes-6379.conf
#以上--cluster-config-file
 #集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。
 #这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件
 #请确保与实例运行的系统中配置文件名称不冲突


# Cluster node timeout is the amount of milliseconds a node must be unreachable
# for it to be considered in failure state.
# Most other internal time limits are multiple of the node timeout.
#
# cluster-node-timeout 15000
#以上--cluster-node-timeou： 节点互连超时的阀值，集群节点超时毫秒数



# A slave of a failing master will avoid to start a failover if its data
# looks too old.
#
# There is no simple way for a slave to actually have a exact measure of
# its &quot;data age&quot;, so the following two checks are performed:
#
# 1) If there are multiple slaves able to failover, they exchange messages
#    in order to try to give an advantage to the slave with the best
#    replication offset (more data from the master processed).
#    Slaves will try to get their rank by offset, and apply to the start
#    of the failover a delay proportional to their rank.
#
# 2) Every single slave computes the time of the last interaction with
#    its master. This can be the last ping or command received (if the master
#    is still in the &quot;connected&quot; state), or the time that elapsed since the
#    disconnection with the master (if the replication link is currently down).
#    If the last interaction is too old, the slave will not try to failover
#    at all.
#
# The point &quot;2&quot; can be tuned by user. Specifically a slave will not perform
# the failover if, since the last interaction with the master, the time
# elapsed is greater than:
#
#   (node-timeout * slave-validity-factor) + repl-ping-slave-period
#
# So for example if node-timeout is 30 seconds, and the slave-validity-factor
# is 10, and assuming a default repl-ping-slave-period of 10 seconds, the
# slave will not try to failover if it was not able to talk with the master
# for longer than 310 seconds.
#
# A large slave-validity-factor may allow slaves with too old data to failover
# a master, while a too small value may prevent the cluster from being able to
# elect a slave at all.
#
# For maximum availability, it is possible to set the slave-validity-factor
# to a value of 0, which means, that slaves will always try to failover the
# master regardless of the last time they interacted with the master.
# (However they&#39;ll always try to apply a delay proportional to their
# offset rank).
#
# Zero is the only value able to guarantee that when all the partitions heal
# the cluster will always be able to continue.
#
# cluster-slave-validity-factor 10
#以上--cluster-slave-validity-factor：
  #在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，
  #导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。
  #判断方法是：
  #   比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period
  #   如果节点超时时间为三十秒, 并且slave-validity-factor为10,
  #   假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移

# Cluster slaves are able to migrate to orphaned masters, that are masters
# that are left without working slaves. This improves the cluster ability
# to resist to failures as otherwise an orphaned master can&#39;t be failed over
# in case of failure if it has no working slaves.
#
# Slaves migrate to orphaned masters only if there are still at least a
# given number of other working slaves for their old master. This number
# is the &quot;migration barrier&quot;. A migration barrier of 1 means that a slave
# will migrate only if there is at least 1 other working slave for its master
# and so forth. It usually reflects the number of slaves you want for every
# master in your cluster.
#
# Default is 1 (slaves migrate only if their masters remain with at least
# one slave). To disable migration just set it to a very large value.
# A value of 0 can be set but is useful only for debugging and dangerous
# in production.
#
# cluster-migration-barrier 1
#以上--cluster-migration-barrier：
  #master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，
  #那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。

# By default Redis Cluster nodes stop accepting queries if they detect there
# is at least an hash slot uncovered (no available node is serving it).
# This way if the cluster is partially down (for example a range of hash slots
# are no longer covered) all the cluster becomes, eventually, unavailable.
# It automatically returns available as soon as all the slots are covered again.
#
# However sometimes you want the subset of the cluster which is working,
# to continue to accept queries for the part of the key space that is still
# covered. In order to do so, just set the cluster-require-full-coverage
# option to no.
#
# cluster-require-full-coverage yes
#以上--cluster-require-full-coverage：
  #默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。
  #设置为no，可以在slot没有全部分配的时候提供服务。
  #不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致

# In order to setup your cluster make sure to read the documentation
# available at http://redis.io web site. 

################################## SLOW LOG ###################################

# The Redis Slow Log is a system to log queries that exceeded a specified
# execution time. The execution time does not include the I/O operations
# like talking with the client, sending the reply and so forth,
# but just the time needed to actually execute the command (this is the only
# stage of command execution where the thread is blocked and can not serve
# other requests in the meantime).
#
# You can configure the slow log with two parameters: one tells Redis
# what is the execution time, in microseconds, to exceed in order for the
# command to get logged, and the other parameter is the length of the
# slow log. When a new command is logged the oldest one is removed from the
# queue of logged commands.

# The following time is expressed in microseconds, so 1000000 is equivalent
# to one second. Note that a negative number disables the slow log, while
# a value of zero forces the logging of every command.
slowlog-log-slower-than 10000

# There is no limit to this length. Just be aware that it will consume memory.
# You can reclaim memory used by the slow log with SLOWLOG RESET.
slowlog-max-len 128
#以上--slowlog-log-slower-than： 慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉，这个长度没有限制。只要有足够的内存就行，你可以通过 SLOWLOG RESET 来释放内存

################################ LATENCY MONITOR ##############################

# The Redis latency monitoring subsystem samples different operations
# at runtime in order to collect data related to possible sources of
# latency of a Redis instance.
#
# Via the LATENCY command this information is available to the user that can
# print graphs and obtain reports.
#
# The system only logs operations that were performed in a time equal or
# greater than the amount of milliseconds specified via the
# latency-monitor-threshold configuration directive. When its value is set
# to zero, the latency monitor is turned off.
#
# By default latency monitoring is disabled since it is mostly not needed
# if you don&#39;t have latency issues, and collecting data has a performance
# impact, that while very small, can be measured under big load. Latency
# monitoring can easily be enabled at runtime using the command
# &quot;CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;&quot; if needed.
latency-monitor-threshold 0
#以上-latency-monitor-threshold:
  #延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。
  #只记录大于等于下边设置的值的操作，0的话，就是关闭监视。
  #默认延迟监控功能是关闭的，如果你需要打开，也可以通过CONFIG SET命令动态设置。

############################# EVENT NOTIFICATION ##############################

# Redis can notify Pub/Sub clients about events happening in the key space.
# This feature is documented at http://redis.io/topics/notifications
#
# For instance if keyspace events notification is enabled, and a client
# performs a DEL operation on key &quot;foo&quot; stored in the Database 0, two
# messages will be published via Pub/Sub:
#
# PUBLISH __keyspace@0__:foo del
# PUBLISH __keyevent@0__:del foo
#
# It is possible to select the events that Redis will notify among a set
# of classes. Every class is identified by a single character:
#
#  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.
#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.
#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...
#  $     String commands
#  l     List commands
#  s     Set commands
#  h     Hash commands
#  z     Sorted set commands
#  x     Expired events (events generated every time a key expires)
#  e     Evicted events (events generated when a key is evicted for maxmemory)
#  A     Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.
#
#  The &quot;notify-keyspace-events&quot; takes as argument a string that is composed
#  of zero or multiple characters. The empty string means that notifications
#  are disabled.
#
#  Example: to enable list and generic events, from the point of view of the
#           event name, use:
#
#  notify-keyspace-events Elg
#
#  Example 2: to get the stream of the expired keys subscribing to channel
#             name __keyevent@0__:expired use:
#
#  notify-keyspace-events Ex
#
#  By default all notifications are disabled because most users don&#39;t need
#  this feature and the feature has some overhead. Note that if you don&#39;t
#  specify at least one of K or E, no events will be delivered.
notify-keyspace-events &quot;&quot;
#以上--notify-keyspace-events &quot;&quot;：
键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。
 #notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：
 # K 键空间通知，所有通知以 __keyspace@__ 为前缀
 # E 键事件通知，所有通知以 __keyevent@__ 为前缀
 # g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知
 # $ 字符串命令的通知
 # l 列表命令的通知
 # s 集合命令的通知
 # h 哈希命令的通知
 # z 有序集合命令的通知
 # x 过期事件：每当有过期键被删除时发送
 # e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送
 # A 参数 g$lshzxe 的别名
 #输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。

############################### ADVANCED CONFIG ###############################

# Hashes are encoded using a memory efficient data structure when they have a
# small number of entries, and the biggest entry does not exceed a given
# threshold. These thresholds can be configured using the following directives.
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
#以上--hash-max-ziplist-entries：
 #hash类型的数据结构在编码上可以使用ziplist和hashtable。
 #ziplist的特点就是文件存储(以及内存存储)所需的空间较小,在内容较小时,性能和hashtable几乎一样。
 #因此redis对hash类型默认采取ziplist。如果hash中条目的条目个数或者value长度达到阀值,将会被重构为hashtable。
 #这个参数指的是ziplist中允许存储的最大条目个数，，默认为512，建议为128
#以上--hash-max-ziplist-value：ziplist中允许条目value值最大字节数，默认为64，建议为1024

# Lists are also encoded in a special way to save a lot of space.
# The number of entries allowed per internal list node can be specified
# as a fixed maximum size or a maximum number of elements.
# For a fixed maximum size, use -5 through -1, meaning:
# -5: max size: 64 Kb  &lt;-- not recommended for normal workloads
# -4: max size: 32 Kb  &lt;-- not recommended
# -3: max size: 16 Kb  &lt;-- probably not recommended
# -2: max size: 8 Kb   &lt;-- good
# -1: max size: 4 Kb   &lt;-- good
# Positive numbers mean store up to _exactly_ that number of elements
# per list node.
# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),
# but if your use case is unique, adjust the settings as necessary.
list-max-ziplist-size -2
#以上--list-max-ziplist-size:
    #当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。
    #当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值，每个值含义如下：
    #    -5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =&gt; 1024 bytes）
    #    -4: 每个quicklist节点上的ziplist大小不能超过32 Kb。
    #    -3: 每个quicklist节点上的ziplist大小不能超过16 Kb。
    #    -2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值）
    #    -1: 每个quicklist节点上的ziplist大小不能超过4 Kb。

# Lists may also be compressed.
# Compress depth is the number of quicklist ziplist nodes from *each* side of
# the list to *exclude* from compression.  The head and tail of the list
# are always uncompressed for fast push/pop operations.  Settings are:
# 0: disable all list compression
# 1: depth 1 means &quot;don&#39;t start compressing until after 1 node into the list,
#    going from either the head or tail&quot;
#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]
#    [head], [tail] will always be uncompressed; inner nodes will compress.
# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]
#    2 here means: don&#39;t compress head or head-&gt;next or tail-&gt;prev or tail,
#    but compress all nodes between them.
# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]
# etc.
list-compress-depth 0
#以上--list-compress-depth:
    #这个参数表示一个quicklist两端不被压缩的节点个数。
    #注：这里的节点个数是指quicklist双向链表的节点个数，而不是指ziplist里面的数据项个数。
    #实际上，一个quicklist节点上的ziplist，如果被压缩，就是整体被压缩的。
    #参数list-compress-depth的取值含义如下：
    #    0: 是个特殊值，表示都不压缩。这是Redis的默认值。
    #    1: 表示quicklist两端各有1个节点不压缩，中间的节点压缩。
    #    2: 表示quicklist两端各有2个节点不压缩，中间的节点压缩。
    #    3: 表示quicklist两端各有3个节点不压缩，中间的节点压缩。
    #    依此类推…
    #由于0是个特殊值，很容易看出quicklist的头节点和尾节点总是不被压缩的，以便于在表的两端进行快速存取。

# Sets have a special encoding in just one case: when a set is composed
# of just strings that happen to be integers in radix 10 in the range
# of 64 bit signed integers.
# The following configuration setting sets the limit in the size of the
# set in order to use this special memory saving encoding.
set-max-intset-entries 512
#以上--set-max-intset-entries： 数据量小于等于set-max-intset-entries用intset，大于set-max-intset-entries用set

# Similarly to hashes and lists, sorted sets are also specially encoded in
# order to save a lot of space. This encoding is only used when the length and
# elements of a sorted set are below the following limits:
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
#以上--：数据量小于等于zset-max-ziplist-entries用ziplist，大于zset-max-ziplist-entries用zset

# HyperLogLog sparse representation bytes limit. The limit includes the
# 16 bytes header. When an HyperLogLog using the sparse representation crosses
# this limit, it is converted into the dense representation.
#
# A value greater than 16000 is totally useless, since at that point the
# dense representation is more memory efficient.
#
# The suggested value is ~ 3000 in order to have the benefits of
# the space efficient encoding without slowing down too much PFADD,
# which is O(N) with the sparse encoding. The value can be raised to
# ~ 10000 when CPU is not a concern, but space is, and the data set is
# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.
hll-sparse-max-bytes 3000
#以上--hll-sparse-max-bytes:
  #value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse）
  #大于hll-sparse-max-bytes使用稠密的数据结构（dense），一个比16000大的value是几乎没用的，
  #建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右

# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in
# order to help rehashing the main Redis hash table (the one mapping top-level
# keys to values). The hash table implementation Redis uses (see dict.c)
# performs a lazy rehashing: the more operation you run into a hash table
# that is rehashing, the more rehashing &quot;steps&quot; are performed, so if the
# server is idle the rehashing is never complete and some more memory is used
# by the hash table.
#
# The default is to use this millisecond 10 times every second in order to
# actively rehash the main dictionaries, freeing memory when possible.
#
# If unsure:
# use &quot;activerehashing no&quot; if you have hard latency requirements and it is
# not a good thing in your environment that Redis can reply from time to time
# to queries with 2 milliseconds delay.
#
# use &quot;activerehashing yes&quot; if you don&#39;t have such hard requirements but
# want to free memory asap when possible.
activerehashing yes
#以上--activerehashing：
  #Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。
  #当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。
  #如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存

# The client output buffer limits can be used to force disconnection of clients
# that are not reading data from the server fast enough for some reason (a
# common reason is that a Pub/Sub client can&#39;t consume messages as fast as the
# publisher can produce them).
#
# The limit can be set differently for the three different classes of clients:
#
# normal -&gt; normal clients including MONITOR clients
# slave  -&gt; slave clients
# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern
#
# The syntax of every client-output-buffer-limit directive is the following:
#
# client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;
#
# A client is immediately disconnected once the hard limit is reached, or if
# the soft limit is reached and remains reached for the specified number of
# seconds (continuously).
# So for instance if the hard limit is 32 megabytes and the soft limit is
# 16 megabytes / 10 seconds, the client will get disconnected immediately
# if the size of the output buffers reach 32 megabytes, but will also get
# disconnected if the client reaches 16 megabytes and continuously overcomes
# the limit for 10 seconds.
#
# By default normal clients are not limited because they don&#39;t receive data
# without asking (in a push way), but just after a request, so only
# asynchronous clients may create a scenario where data is requested faster
# than it can read.
#
# Instead there is a default limit for pubsub and slave clients, since
# subscribers and slaves receive data in a push fashion.
#
# Both the hard or the soft limit can be disabled by setting them to zero.
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit slave 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
#以上--client-output-buffer-limit normal：
 #对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。
 #对于normal client，第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的
#以上--client-output-buffer-limit slave：对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接。
#以上--client-output-buffer-limit pubsub：对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接

# Redis calls an internal function to perform many background tasks, like
# closing connections of clients in timeout, purging expired keys that are
# never requested, and so forth.
#
# Not all tasks are performed with the same frequency, but Redis checks for
# tasks to perform according to the specified &quot;hz&quot; value.
#
# By default &quot;hz&quot; is set to 10. Raising the value will use more CPU when
# Redis is idle, but at the same time will make Redis more responsive when
# there are many keys expiring at the same time, and timeouts may be
# handled with more precision.
#
# The range is between 1 and 500, however a value over 100 is usually not
# a good idea. Most users should use the default of 10 and raise this up to
# 100 only in environments where very low latency is required.
hz 10
#以上--hz ：redis执行任务的频率为1s除以hz

# When a child rewrites the AOF file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
aof-rewrite-incremental-fsync yes
#以上--aof-rewrite-incremental-fsync：
  #在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。
  #这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[redis.conf 详解]]></title>
    <link href="http://www.throne4j.com/15991181642194.html"/>
    <updated>2020-09-03T15:29:24+08:00</updated>
    <id>http://www.throne4j.com/15991181642194.html</id>
    <content type="html"><![CDATA[
<pre><code class="language-text">#以上--redis启动说明：redis启动指令的第一个参数必须是配置文件路径
# ./redis-server /path/to/redis.conf

# 引入配置，可以将公共配置抽取出来，采用引入的方式，存在参数覆盖，注意include放置的位置，覆盖效果不同。
# include /path/to/local.conf

################################## MODULES #####################################

# 启动时加载so模块，如果服务不能加载指定模块
# 服务器将忽略该模块
# loadmodule /path/to/my_module.so
# loadmodule /path/to/other_module.so

################################## NETWORK #####################################
# 
# 如果，bind没有特别指定，redis可以接受任意可访问到该服务IP的请求，
# 一般来说，只可能只监听一个或者多个IP的请求，不要完全开放。
#
#  ~~~ 注意 ~~~ 如果redis服务是运行在互联网可访问的环境下，暴露任意IP可访问是相当危险的。
# 所以，默认情况下，我们只开放127.0.0.1的可访问IP，那就意味着只有本地才能访问redis服务。
#
# 如果你非要开放，你就需要注释下面这段配置。
bind 127.0.0.1


# 保护模式是一个避免redis暴露在公网后可以任意访问的安全层。 
#
# 当在如下条件下，保护模式将开启：
# 1.服务没有明确绑定具体IP
# 2.服务没有配置密码
#
# 保护模式开启后，服务只能接受ipv4/v6的环路路由，或者unix socket。
#
# 默认情况下，保护模式是开启的，如果你确信要让客户端可以不需要密码访问
# redis服务，或者不明确bindIP的化，可以关闭保护模式。
protected-mode yes

# 监听端口
port 6379

# TCP listen() backlog.
# backlog其实是一个连接监听队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。
# 在高并发的redis访问场景下，你需要提高tcp的监听队列大小，来避免慢客户端连接问题，否则将出现tcp连接耗尽问题
# 同时修改此处配置的时候，也要一并修改linux的系统参数/proc/sys/net/core/somaxconn
# 否则不生效。somaxconn &gt;= tcp-backlog
tcp-backlog 511

# Unix socket.
#
# redis采用unix socket作为客户端的数据传输通道，据说可以提高25%的性能，但是只能用于本机进程间通信，
# 用处不大
# 默认不开启
# unixsocket /tmp/redis.sock
# unixsocketperm 700


# Close the connection after a client is idle for N seconds (0 to disable)

# 客户端连接空闲后自动关闭的等待时间，0表示不关闭。 
timeout 0

# TCP keepalive， tcp长连接
# 如果非0，redis的tcp连接将在长时间未通信的情况下发送心跳包给客户端
# 这样做有两个好处:
# 1.回收已断开的连接
# 2.在存在网络中间件，比如路由器，网关的条件下，保证连接的可用
# 在Linux系统中，这个数值标识TCP发送心跳包的时间间隔，在两次发送心跳包无响应时，将废弃该连接
# 在其他系统，可能有Kernels的内核参数决定心跳包时间，该参数无效。
tcp-keepalive 300

################################# GENERAL #####################################

# 默认情况下，redis不在后台运行，如果你需要后台静默运行，设置为yes.
# 后台运行的状态，redis将pid写入/var/run/redis.pid 文件
daemonize yes

# 如果redis是通过upstart或者systemd开机自启动，你可以将redis的运行状态，写入开机启动服务的状态数中
# 有四种选择
#   supervised no      - no supervision interaction
#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode
#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET
#   supervised auto    - detect upstart or systemd method based on
#                        UPSTART_JOB or NOTIFY_SOCKET environment variables
# 注意：redis在开机启动树只有“运行中”这样的状态，没有是否可联通的状态，
# `个人理解:这块做关联启动，有些开机启动服务需要依赖redis的启动，所以增加这个配置`
supervised no


# 如果pid文件有显式指定，redis在启动后，写入进程号，退出时，删除文件
# 当服务是非后台模式运行时，如果没有指定pid文件，redis将不会创建该文件，当服务是后台模式运行时，
# 即使没有指定pid文件，redis也会创建该文件，同时默认值为&quot;/var/run/redis.pid&quot;
# 创建pid是将会对redis的管理有好处，但是不创建也不会对redis运行有影响。
pidfile /var/run/redis_6379.pid

# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
# 日志级别
loglevel notice

# 指定日志文件的名称，如果是空字符串，redis的日志将写入Linux的标准输出，
# 如果redis是后台模式运行，日志文件为&quot;&quot;,日志将输出到/dev/null，也就是不输出日志
logfile &quot;&quot;


# 要想把日志记录到系统日志，就把它改成 yes，也可以可选择性的更新其他的syslog 参数以达到你的要求
# syslog-enabled no


# Specify the syslog identity.
# 系统日志的标识
# syslog-ident redis


# 产生系统日志的设施，必须是Linux的用户或者从local0 ~ local7
# syslog-facility local0

# 设置数据库的数目。默认的数据库是DB 0 ，可以在每个连接上使用select  &lt;dbid&gt; 命令选择一个不同的数据库，dbid是一个介于0到databases - 1 之间的数值
databases 16

#  控制台显示LOGO
always-show-logo yes

################################ SNAPSHOTTING  ################################
#
# Save the DB on disk:
#
#   save &lt;seconds&gt; &lt;changes&gt;
#
# 格式：save &lt;间隔时间（秒）&gt; &lt;写入次数&gt;
# 根据给定的时间间隔和写入次数将数据保存到磁盘
# 下面的例子的意思是：
# 900 秒内如果至少有 1 个 key 的值变化，则保存
# 300 秒内如果至少有 10 个 key 的值变化，则保存
# 60 秒内如果至少有 10000 个 key 的值变化，则保存
# 注意：你可以注释掉所有的 save 行来停用保存功能。
# 也可以直接一个空字符串来实现停用：
#  数据的持久化的规则

save 900 1
save 300 10
save 60 10000

# 如果用户开启了RDB快照功能，那么在redis持久化数据到磁盘时如果出现失败，默认情况下，redis会停止接受所有的写请求。
# 这样做的好处在于可以让用户很明确的知道内存中的数据和磁盘上的数据已经存在不一致了。
# 如果redis不顾这种不一致，一意孤行的继续接收写请求，就可能会引起一些灾难性的后果。
# 如果下一次RDB持久化成功，redis会自动恢复接受写请求。
# 如果不在乎这种数据不一致或者有其他的手段发现和控制这种不一致的话，可以关闭这个功能，
# 以便在快照写入失败时，也能确保redis继续接受新的写请求。
stop-writes-on-bgsave-error yes


# dump.rdb数据库采用LZF算法进行字符压缩
# 默认是开启rdb压缩
# 如果你想在保存rdb时，节省CPU，可以设置为no
rdbcompression yes

#
# 从redis5开始，rdb文件采用CRC64算法校验文件的完整性。
# 这将保证rdb文件的完整性和不可篡改，但是将保存和加载rdb文件时，多耗费10%的性能损耗。
# 如果希望发挥REDIS最大性能，可以关闭该请求
rdbchecksum yes

#
# The filename where to dump the DB
# rdb文件的存储文件名
dbfilename dump.rdb

# The working directory.
# RDB文件将写入这个目录,文件名就是前面dbfilename定义的。
# 同时redis的增量文件页也写入这个目录
# 注意，这个参数必须是一个目录，不能是一个文件
dir ./

################################# REPLICATION （主从复制）#################################

# Master-Replica replication. Use replicaof to make a Redis instance a copy of
# another Redis server. A few things to understand ASAP about Redis replication.
#
#   +------------------+      +---------------+
#   |      Master      | ---&gt; |    Replica    |
#   | (receive writes) |      |  (exact copy) |
#   +------------------+      +---------------+
#
#
# 1）redis 主从复制是异步的，但是你可以设置，主节点没有一个正常运行的从节点时，禁止主节点写操作
# 2）redis从节点可以向主节点进行部分同步，这块你需要在下一个配置中指定同步块大小。
# 3）主从复制是自动进行的，不需要用户介入。

# replicaof &lt;masterip&gt; &lt;masterport&gt;

# 如果主节点设置了requirepass，从节点需要配置主节点的接入密码

# masterauth &lt;master-password&gt;

# 当一个 slave 与 master 失去联系，或者复制正在进行的时候，
# slave 可能会有两种表现：
# 1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，
#    或者数据可能是空的在第一次同步的时候
# 2) 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，
#    slave 都将返回一个 &quot;SYNC with master in progress&quot; 的错误
replica-serve-stale-data yes

#你可以配置一个 slave 实体是否接受写入操作。
#通过写入操作来存储一些短暂的数据对于一个 slave 实例来说可能是有用的，
#因为相对从 master 重新同步数而言，据数据写入到 slave 会更容易被删除。
#但是如果客户端因为一个错误的配置写入，也可能会导致一些问题。
#从 redis 2.6 版起，默认 slaves 都是只读的。
replica-read-only yes

# 主从同步策略：disk和socket
#
# -------------------------------------------------------
# 注意：socket同步是实验性功能
# -------------------------------------------------------
#
# Disk-backed策略在新同步和重连同步无法进行增量同步，只能进行全量同步。
# 主从同步有两种方式，默认采用Disk-backed
#
# 1) Disk-backed: redis新建一个独立进程，将RDB写入到磁盘，稍后由父进程将数据传输给各个节点。
# 
# 2) Diskless: redis创建一个独立进程，直接将数据通过与从节点的socket通道传递，无需写入硬盘。
#
# 在disk-backed的策略下，RDB数据是持有化到磁盘的，多个从节点再逐个接收数据，无法同时传输。
# 在diskless的策略下，从节点一旦接入主节点，在等待指定的时间后，主从开始通过socket传递数据，多个从节点可以同时进行。
#
# 如果在磁盘读写慢，网络速度快的环境下，可以采用diskless
# works better.
repl-diskless-sync no

# 当采用diskless的同步策略启动时，可以配置从节点接入主节点后，等待多少时间后，进行同步。
# 当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。
# 这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段
# 时间以期更多的从站到达。
# 延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动。
repl-diskless-sync-delay 5

# 从redis会周期性的向主redis发出PING包，你可以通过repl_ping_slave_period指令来控制其周期，默认是10秒
# repl-ping-replica-period 10

# 接下来的选项为以下内容设置备份的超时时间：
# 1）从从站的角度，同步期间的批量传输的I/O
# 2）从站角度认为的主站超时（数据，ping）
# 3）主站角度认为的从站超时（REPLCONF ACK pings)
# 确认这些值比定义的repl-ping-slave-period要大，否则每次主站和从站之间通信低速时都会被检测为超时。
# repl-timeout 60

#同步之后是否禁用从站上的TCP_NODELAY
#如果你选择yes，redis会使用较少量的TCP包和带宽向从站发送数据。但这会导致在从站增加一点数据的延时。
#Linux内核默认配置情况下最多40毫秒的延时。
#如果选择no，从站的数据延时不会那么多，但备份需要的带宽相对较多。
#默认情况下我们将潜在因素优化，但在高负载情况下或者在主从站都跳的情况下，把它切换为yes是个好主意。
repl-disable-tcp-nodelay no


# 设置备份的工作储备大小。工作储备是一个缓冲区，当从站断开一段时间的情况时，它替从站接收存储数据，
# 因此当从站重连时，通常不需要完全备份，只需要一个部分同步就可以，即把从站断开时错过的一部分数据接收。
# 工作储备越大，从站可以断开并稍后执行部分同步的断开时间就越长。
# 只要有一个从站连接，就会立刻分配一个工作储备。
# repl-backlog-size 1mb


# 主站有一段时间没有与从站连接，对应的工作储备就会自动释放。
# 这个选项用于配置释放前等待的秒数，秒数从断开的那一刻开始计算，值为0表示不释放。
# repl-backlog-ttl 3600

#从站优先级是可以从redis的INFO命令输出中查到的一个整数。当主站不能正常工作时
#redis sentinel使用它来选择一个从站并将它提升为主站。
#优先级的从站被认为更适合于提升，因此如果有三个从站优先级分别是10，100，25，sentinel会选择优先级为10的从站，因为它的优先级最低。
#然而优先级值为0的从站不能执行主站的角色，因此优先级为0的从站永远不会被redis sentinel提升。
#默认优先级是100
replica-priority 100

# It is possible for a master to stop accepting writes if there are less than
# N replicas connected, having a lag less or equal than M seconds.
#
# The N replicas need to be in &quot;online&quot; state.
#
# The lag in seconds, that must be &lt;= the specified value, is calculated from
# the last ping received from the replica, that is usually sent every second.
#
# This option does not GUARANTEE that N replicas will accept the write, but
# will limit the window of exposure for lost writes in case not enough replicas
# are available, to the specified number of seconds.
#
# For example to require at least 3 replicas with a lag &lt;= 10 seconds use:
#
# min-replicas-to-write 3
# min-replicas-max-lag 10
#
# Setting one or the other to 0 disables the feature.
#
# By default min-replicas-to-write is set to 0 (feature disabled) and
# min-replicas-max-lag is set to 10.

# A Redis master is able to list the address and port of the attached
# replicas in different ways. For example the &quot;INFO replication&quot; section
# offers this information, which is used, among other tools, by
# Redis Sentinel in order to discover replica instances.
# Another place where this info is available is in the output of the
# &quot;ROLE&quot; command of a master.
#
# The listed IP and address normally reported by a replica is obtained
# in the following way:
#
#   IP: The address is auto detected by checking the peer address
#   of the socket used by the replica to connect with the master.
#
#   Port: The port is communicated by the replica during the replication
#   handshake, and is normally the port that the replica is using to
#   listen for connections.
#
# However when port forwarding or Network Address Translation (NAT) is
# used, the replica may be actually reachable via different IP and port
# pairs. The following two options can be used by a replica in order to
# report to its master a specific set of IP and port, so that both INFO
# and ROLE will report those values.
#
# There is no need to use both the options if you need to override just
# the port or the IP address.
#
# replica-announce-ip 5.5.5.5
# replica-announce-port 1234

################################## SECURITY ###################################

#
# 要求客户端调用时需要进行auth认证，这个特性用于你开放redis服务给非完全信任的客户端接
#
# 警告：由于redis的运行高效性，它可以支持每秒150K次的密码验证，所以你必须设置足够复杂的密码防止暴力破解
#
# requirepass foobared

# Command renaming.
#
# It is possible to change the name of dangerous commands in a shared
# environment. For instance the CONFIG command may be renamed into something
# hard to guess so that it will still be available for internal-use tools
# but not available for general clients.
#
# Example:
#
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#
# It is also possible to completely kill a command by renaming it into
# an empty string:
#
# rename-command CONFIG &quot;&quot;
#
# Please note that changing the name of commands that are logged into the
# AOF file or transmitted to replicas may cause problems.

################################### CLIENTS ####################################


# 设置redis最大同时接入的客户端，默认是10000个，如果redis没有设置这个参数，
# 最大的客户端数量是Linux进程的最大文件句柄数-32，因为redis内部需要占用一定的文件句柄
#
# 当连接客户端超过最大数，将提示  &#39;max number of clients reached&#39;
#
# maxclients 10000

############################## MEMORY MANAGEMENT ################################

# maxmemory 可以设置redis的最大占用内存，如果redis实际使用达到阈值，
# 将按照maxmemory-policy策略移除key
# 如果redis不能通过策略移除，或者策略采用的是noeviction，redis将回报错误，对于一些写的指令
# 比如SET，LPUSH这些指令，但是读的指令可以正常回报
#
# 这个选项一般让redis作为LRU或者LFU的缓存服务，如果策略设置为noeviction，限制将是物理内存大小。
#
# WARNING: If you have replicas attached to an instance with maxmemory on,
# the size of the output buffers needed to feed the replicas are subtracted
# from the used memory count, so that network problems / resyncs will
# not trigger a loop where keys are evicted, and in turn the output
# buffer of replicas is full with DELs of keys evicted triggering the deletion
# of more keys, and so forth until the database is completely emptied.
#
# In short... if you have replicas attached it is suggested that you set a lower
# limit for maxmemory so that there is some free RAM on the system for replica
# output buffers (but this is not needed if the policy is &#39;noeviction&#39;).
#
# maxmemory &lt;bytes&gt;

# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory
# is reached. You can select among five behaviors:
#
# volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.
# allkeys-lru -&gt; Evict any key using approximated LRU.
# volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.
# allkeys-lfu -&gt; Evict any key using approximated LFU.
# volatile-random -&gt; Remove a random key among the ones with an expire set.
# allkeys-random -&gt; Remove a random key, any key.
# volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)
# noeviction -&gt; Don&#39;t evict anything, just return an error on write operations.
#
# LRU means Least Recently Used
# LFU means Least Frequently Used
#
# Both LRU, LFU and volatile-ttl are implemented using approximated
# randomized algorithms.
#
# Note: with any of the above policies, Redis will return an error on write
#       operations, when there are no suitable keys for eviction.
#
#       At the date of writing these commands are: set setnx setex append
#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
#       getset mset msetnx exec sort
#
# The default is:
#
# maxmemory-policy noeviction

# LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated
# algorithms (in order to save memory), so you can tune it for speed or
# accuracy. For default Redis will check five keys and pick the one that was
# used less recently, you can change the sample size using the following
# configuration directive.
#
# The default of 5 produces good enough results. 10 Approximates very closely
# true LRU but costs more CPU. 3 is faster but not very accurate.
#
# maxmemory-samples 5

# Starting from Redis 5, by default a replica will ignore its maxmemory setting
# (unless it is promoted to master after a failover or manually). It means
# that the eviction of keys will be just handled by the master, sending the
# DEL commands to the replica as keys evict in the master side.
#
# This behavior ensures that masters and replicas stay consistent, and is usually
# what you want, however if your replica is writable, or you want the replica to have
# a different memory setting, and you are sure all the writes performed to the
# replica are idempotent, then you may change this default (but be sure to understand
# what you are doing).
#
# Note that since the replica by default does not evict, it may end using more
# memory than the one set via maxmemory (there are certain buffers that may
# be larger on the replica, or data structures may sometimes take more memory and so
# forth). So make sure you monitor your replicas and make sure they have enough
# memory to never hit a real out-of-memory condition before the master hits
# the configured maxmemory setting.
#
# replica-ignore-maxmemory yes

############################# LAZY FREEING ####################################

# Redis has two primitives to delete keys. One is called DEL and is a blocking
# deletion of the object. It means that the server stops processing new commands
# in order to reclaim all the memory associated with an object in a synchronous
# way. If the key deleted is associated with a small object, the time needed
# in order to execute the DEL command is very small and comparable to most other
# O(1) or O(log_N) commands in Redis. However if the key is associated with an
# aggregated value containing millions of elements, the server can block for
# a long time (even seconds) in order to complete the operation.
#
# For the above reasons Redis also offers non blocking deletion primitives
# such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and
# FLUSHDB commands, in order to reclaim memory in background. Those commands
# are executed in constant time. Another thread will incrementally free the
# object in the background as fast as possible.
#
# DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.
# It&#39;s up to the design of the application to understand when it is a good
# idea to use one or the other. However the Redis server sometimes has to
# delete keys or flush the whole database as a side effect of other operations.
# Specifically Redis deletes objects independently of a user call in the
# following scenarios:
#
# 1) On eviction, because of the maxmemory and maxmemory policy configurations,
#    in order to make room for new data, without going over the specified
#    memory limit.
# 2) Because of expire: when a key with an associated time to live (see the
#    EXPIRE command) must be deleted from memory.
# 3) Because of a side effect of a command that stores data on a key that may
#    already exist. For example the RENAME command may delete the old key
#    content when it is replaced with another one. Similarly SUNIONSTORE
#    or SORT with STORE option may delete existing keys. The SET command
#    itself removes any old content of the specified key in order to replace
#    it with the specified string.
# 4) During replication, when a replica performs a full resynchronization with
#    its master, the content of the whole database is removed in order to
#    load the RDB file just transferred.
#
# In all the above cases the default is to delete objects in a blocking way,
# like if DEL was called. However you can configure each case specifically
# in order to instead release memory in a non-blocking way like if UNLINK
# was called, using the following configuration directives:

lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no

############################## APPEND ONLY MODE ###############################

# By default Redis asynchronously dumps the dataset on disk. This mode is
# good enough in many applications, but an issue with the Redis process or
# a power outage may result into a few minutes of writes lost (depending on
# the configured save points).
#
# The Append Only File is an alternative persistence mode that provides
# much better durability. For instance using the default data fsync policy
# (see later in the config file) Redis can lose just one second of writes in a
# dramatic event like a server power outage, or a single write if something
# wrong with the Redis process itself happens, but the operating system is
# still running correctly.
#
# AOF and RDB persistence can be enabled at the same time without problems.
# If the AOF is enabled on startup Redis will load the AOF, that is the file
# with the better durability guarantees.
#
# Please check http://redis.io/topics/persistence for more information.

appendonly no

# The name of the append only file (default: &quot;appendonly.aof&quot;)

appendfilename &quot;appendonly.aof&quot;

# The fsync() call tells the Operating System to actually write data on disk
# instead of waiting for more data in the output buffer. Some OS will really flush
# data on disk, some other OS will just try to do it ASAP.
#
# Redis supports three different modes:
#
# no: don&#39;t fsync, just let the OS flush the data when it wants. Faster.
# always: fsync after every write to the append only log. Slow, Safest.
# everysec: fsync only one time every second. Compromise.
#
# The default is &quot;everysec&quot;, as that&#39;s usually the right compromise between
# speed and data safety. It&#39;s up to you to understand if you can relax this to
# &quot;no&quot; that will let the operating system flush the output buffer when
# it wants, for better performances (but if you can live with the idea of
# some data loss consider the default persistence mode that&#39;s snapshotting),
# or on the contrary, use &quot;always&quot; that&#39;s very slow but a bit safer than
# everysec.
#
# More details please check the following article:
# http://antirez.com/post/redis-persistence-demystified.html
#
# If unsure, use &quot;everysec&quot;.

# appendfsync always
appendfsync everysec
# appendfsync no

# When the AOF fsync policy is set to always or everysec, and a background
# saving process (a background save or AOF log background rewriting) is
# performing a lot of I/O against the disk, in some Linux configurations
# Redis may block too long on the fsync() call. Note that there is no fix for
# this currently, as even performing fsync in a different thread will block
# our synchronous write(2) call.
#
# In order to mitigate this problem it&#39;s possible to use the following option
# that will prevent fsync() from being called in the main process while a
# BGSAVE or BGREWRITEAOF is in progress.
#
# This means that while another child is saving, the durability of Redis is
# the same as &quot;appendfsync none&quot;. In practical terms, this means that it is
# possible to lose up to 30 seconds of log in the worst scenario (with the
# default Linux settings).
#
# If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as
# &quot;no&quot; that is the safest pick from the point of view of durability.

no-appendfsync-on-rewrite no

# Automatic rewrite of the append only file.
# Redis is able to automatically rewrite the log file implicitly calling
# BGREWRITEAOF when the AOF log size grows by the specified percentage.
#
# This is how it works: Redis remembers the size of the AOF file after the
# latest rewrite (if no rewrite has happened since the restart, the size of
# the AOF at startup is used).
#
# This base size is compared to the current size. If the current size is
# bigger than the specified percentage, the rewrite is triggered. Also
# you need to specify a minimal size for the AOF file to be rewritten, this
# is useful to avoid rewriting the AOF file even if the percentage increase
# is reached but it is still pretty small.
#
# Specify a percentage of zero in order to disable the automatic AOF
# rewrite feature.

auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# An AOF file may be found to be truncated at the end during the Redis
# startup process, when the AOF data gets loaded back into memory.
# This may happen when the system where Redis is running
# crashes, especially when an ext4 filesystem is mounted without the
# data=ordered option (however this can&#39;t happen when Redis itself
# crashes or aborts but the operating system still works correctly).
#
# Redis can either exit with an error when this happens, or load as much
# data as possible (the default now) and start if the AOF file is found
# to be truncated at the end. The following option controls this behavior.
#
# If aof-load-truncated is set to yes, a truncated AOF file is loaded and
# the Redis server starts emitting a log to inform the user of the event.
# Otherwise if the option is set to no, the server aborts with an error
# and refuses to start. When the option is set to no, the user requires
# to fix the AOF file using the &quot;redis-check-aof&quot; utility before to restart
# the server.
#
# Note that if the AOF file will be found to be corrupted in the middle
# the server will still exit with an error. This option only applies when
# Redis will try to read more data from the AOF file but not enough bytes
# will be found.
aof-load-truncated yes

# When rewriting the AOF file, Redis is able to use an RDB preamble in the
# AOF file for faster rewrites and recoveries. When this option is turned
# on the rewritten AOF file is composed of two different stanzas:
#
#   [RDB file][AOF tail]
#
# When loading Redis recognizes that the AOF file starts with the &quot;REDIS&quot;
# string and loads the prefixed RDB file, and continues loading the AOF
# tail.
aof-use-rdb-preamble yes

################################ LUA SCRIPTING  ###############################

# Max execution time of a Lua script in milliseconds.
#
# If the maximum execution time is reached Redis will log that a script is
# still in execution after the maximum allowed time and will start to
# reply to queries with an error.
#
# When a long running script exceeds the maximum execution time only the
# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be
# used to stop a script that did not yet called write commands. The second
# is the only way to shut down the server in the case a write command was
# already issued by the script but the user doesn&#39;t want to wait for the natural
# termination of the script.
#
# Set it to 0 or a negative value for unlimited execution without warnings.
lua-time-limit 5000

################################ REDIS CLUSTER  ###############################
#
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however
# in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage
# of users to deploy it in production.
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#
# 一般情况下，redis未开启集群模式，只有开启如下参数，才能开启集群模式。
#
# cluster-enabled yes

#
# 每个集群节点都有集群配置文件，这个文件不是用来提供给使用者编辑，
# 它将由集群节点自身创建并通过集群通信后修改。
# 每个集群节点如果在同一个宿主机上都要有不同的文件，否则将会被覆盖。
# cluster-config-file nodes-6379.conf


# 集群节点被认定为不可达的时间阈值，单位是毫秒。
# 大多数时间节点的阈值都是超时时间的整数倍。
# cluster-node-timeout 15000

# A replica of a failing master will avoid to start a failover if its data
# looks too old.
# 故障主节点的备份将在数据太旧的时候启动失败。
#
# 目前没有简易的方法判断数据是否过旧，一般采用如下两种判定：
# 1）如果有多个故障备份，他们将交换数据对备份数据的时间进行排序，
#     取最新的故障节点作为主节点。
# 1) If there are multiple replicas able to failover, they exchange messages
#    in order to try to give an advantage to the replica with the best
#    replication offset (more data from the master processed).
#    Replicas will try to get their rank by offset, and apply to the start
#    of the failover a delay proportional to their rank.
# 2）
# 2) Every single replica computes the time of the last interaction with
#    its master. This can be the last ping or command received (if the master
#    is still in the &quot;connected&quot; state), or the time that elapsed since the
#    disconnection with the master (if the replication link is currently down).
#    If the last interaction is too old, the replica will not try to failover
#    at all.
#
# The point &quot;2&quot; can be tuned by user. Specifically a replica will not perform
# the failover if, since the last interaction with the master, the time
# elapsed is greater than:
#
#   (node-timeout * replica-validity-factor) + repl-ping-replica-period
#
# So for example if node-timeout is 30 seconds, and the replica-validity-factor
# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the
# replica will not try to failover if it was not able to talk with the master
# for longer than 310 seconds.
#
# A large replica-validity-factor may allow replicas with too old data to failover
# a master, while a too small value may prevent the cluster from being able to
# elect a replica at all.
#
# For maximum availability, it is possible to set the replica-validity-factor
# to a value of 0, which means, that replicas will always try to failover the
# master regardless of the last time they interacted with the master.
# (However they&#39;ll always try to apply a delay proportional to their
# offset rank).
#
# Zero is the only value able to guarantee that when all the partitions heal
# the cluster will always be able to continue.
#
# cluster-replica-validity-factor 10

# Cluster replicas are able to migrate to orphaned masters, that are masters
# that are left without working replicas. This improves the cluster ability
# to resist to failures as otherwise an orphaned master can&#39;t be failed over
# in case of failure if it has no working replicas.
#
# Replicas migrate to orphaned masters only if there are still at least a
# given number of other working replicas for their old master. This number
# is the &quot;migration barrier&quot;. A migration barrier of 1 means that a replica
# will migrate only if there is at least 1 other working replica for its master
# and so forth. It usually reflects the number of replicas you want for every
# master in your cluster.
#
# Default is 1 (replicas migrate only if their masters remain with at least
# one replica). To disable migration just set it to a very large value.
# A value of 0 can be set but is useful only for debugging and dangerous
# in production.
#
# cluster-migration-barrier 1

# By default Redis Cluster nodes stop accepting queries if they detect there
# is at least an hash slot uncovered (no available node is serving it).
# This way if the cluster is partially down (for example a range of hash slots
# are no longer covered) all the cluster becomes, eventually, unavailable.
# It automatically returns available as soon as all the slots are covered again.
#
# However sometimes you want the subset of the cluster which is working,
# to continue to accept queries for the part of the key space that is still
# covered. In order to do so, just set the cluster-require-full-coverage
# option to no.
#
# cluster-require-full-coverage yes

# This option, when set to yes, prevents replicas from trying to failover its
# master during master failures. However the master can still perform a
# manual failover, if forced to do so.
#
# This is useful in different scenarios, especially in the case of multiple
# data center operations, where we want one side to never be promoted if not
# in the case of a total DC failure.
#
# cluster-replica-no-failover no

# In order to setup your cluster make sure to read the documentation
# available at http://redis.io web site.

########################## CLUSTER DOCKER/NAT support  ########################

# 在某些环境，redis集群节点的地址发现是失败的。主要原因是NAT网络或者Docker等容器化环境，导致地址发现是错误的。
# 
# 为了解决redis在这些网络环境的正常运行，redis提供的可配置化的可访问IP配置。
# 如下是配置参数：
#
# * cluster-announce-ip
# * cluster-announce-port
# * cluster-announce-bus-port
# 
#
# 如果这些配置未开启，使用默认的集群自动发现。
# 
# Note that when remapped, the bus port may not be at the fixed offset of
# clients port + 10000, so you can specify any port and bus-port depending
# on how they get remapped. If the bus-port is not set, a fixed offset of
# 10000 will be used as usually.
#
# 一般来说，数据端口(port)和集群信息交换（bus-port）约定是port+10000.
# Example:
#
# cluster-announce-ip 10.1.1.5
# cluster-announce-port 6379
# cluster-announce-bus-port 6380

################################## SLOW LOG ###################################

# redis慢日志是为了记录执行时间过长的指令。这些指令不包含IO操作，比如和客户端的数据通，只是记录
# 指令在redis中的执行时间（因为redis是单线程的，每条指令执行都是堵塞其他指令，这样的机制，可以简单的记录下每条指令的执行时间）
#
# 你可以配置慢日志的两个参数，一个是慢日志的界定阈值，单位是微秒，另一个是慢日志的指令最大数量，
# 超过最大数量，旧的慢日志将被删除。


# 下面单位是微秒，1秒要写成1000000，如果数值为负数，表示不记录慢日志，如果数值为0，将会记录每条指令
slowlog-log-slower-than 10000


# 慢日志最大长度如果不设置，将没有限制，一直存储下去，这将导致内存暴增。
# 你可以通过SLOWLOG RESET来重置慢日志记录
slowlog-max-len 128

################################ LATENCY MONITOR ##############################

#
# redis延时监控是为了在运行状态收集redis的慢操作（和慢日志的区别，其监控范围更广，不仅包括命令耗时，还包括内部指令，比如key过期回收这些的耗时）
# 通过latency可以打印耗时图表
# 通过latency-monitor-threshold（单位毫秒）的阈值记录延时日志，如果设置0，表示关闭延时日志监控。
#
# 默认情况下，延时监控是关闭的，大多数情况下，没有必要开启，除非redis存在性能问题。
# 延时监控开启后，会有一定的性能损耗，不过相当小，即使在大负载运行的情
# 延时监控也可以通过CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;来进行热启动
latency-monitor-threshold 0

############################# EVENT NOTIFICATION ##############################

# Redis can notify Pub/Sub clients about events happening in the key space.
# This feature is documented at http://redis.io/topics/notifications
#
# For instance if keyspace events notification is enabled, and a client
# performs a DEL operation on key &quot;foo&quot; stored in the Database 0, two
# messages will be published via Pub/Sub:
#
# PUBLISH __keyspace@0__:foo del
# PUBLISH __keyevent@0__:del foo
#
# It is possible to select the events that Redis will notify among a set
# of classes. Every class is identified by a single character:
#
#  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.
#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.
#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...
#  $     String commands
#  l     List commands
#  s     Set commands
#  h     Hash commands
#  z     Sorted set commands
#  x     Expired events (events generated every time a key expires)
#  e     Evicted events (events generated when a key is evicted for maxmemory)
#  A     Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.
#
#  The &quot;notify-keyspace-events&quot; takes as argument a string that is composed
#  of zero or multiple characters. The empty string means that notifications
#  are disabled.
#
#  Example: to enable list and generic events, from the point of view of the
#           event name, use:
#
#  notify-keyspace-events Elg
#
#  Example 2: to get the stream of the expired keys subscribing to channel
#             name __keyevent@0__:expired use:
#
#  notify-keyspace-events Ex
#
#  By default all notifications are disabled because most users don&#39;t need
#  this feature and the feature has some overhead. Note that if you don&#39;t
#  specify at least one of K or E, no events will be delivered.
notify-keyspace-events &quot;&quot;

############################### ADVANCED CONFIG ###############################

# Hashes are encoded using a memory efficient data structure when they have a
# small number of entries, and the biggest entry does not exceed a given
# threshold. These thresholds can be configured using the following directives.
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# Lists are also encoded in a special way to save a lot of space.
# The number of entries allowed per internal list node can be specified
# as a fixed maximum size or a maximum number of elements.
# For a fixed maximum size, use -5 through -1, meaning:
# -5: max size: 64 Kb  &lt;-- not recommended for normal workloads
# -4: max size: 32 Kb  &lt;-- not recommended
# -3: max size: 16 Kb  &lt;-- probably not recommended
# -2: max size: 8 Kb   &lt;-- good
# -1: max size: 4 Kb   &lt;-- good
# Positive numbers mean store up to _exactly_ that number of elements
# per list node.
# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),
# but if your use case is unique, adjust the settings as necessary.
list-max-ziplist-size -2

# Lists may also be compressed.
# Compress depth is the number of quicklist ziplist nodes from *each* side of
# the list to *exclude* from compression.  The head and tail of the list
# are always uncompressed for fast push/pop operations.  Settings are:
# 0: disable all list compression
# 1: depth 1 means &quot;don&#39;t start compressing until after 1 node into the list,
#    going from either the head or tail&quot;
#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]
#    [head], [tail] will always be uncompressed; inner nodes will compress.
# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]
#    2 here means: don&#39;t compress head or head-&gt;next or tail-&gt;prev or tail,
#    but compress all nodes between them.
# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]
# etc.
list-compress-depth 0

# Sets have a special encoding in just one case: when a set is composed
# of just strings that happen to be integers in radix 10 in the range
# of 64 bit signed integers.
# The following configuration setting sets the limit in the size of the
# set in order to use this special memory saving encoding.
set-max-intset-entries 512

# Similarly to hashes and lists, sorted sets are also specially encoded in
# order to save a lot of space. This encoding is only used when the length and
# elements of a sorted set are below the following limits:
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

# HyperLogLog sparse representation bytes limit. The limit includes the
# 16 bytes header. When an HyperLogLog using the sparse representation crosses
# this limit, it is converted into the dense representation.
#
# A value greater than 16000 is totally useless, since at that point the
# dense representation is more memory efficient.
#
# The suggested value is ~ 3000 in order to have the benefits of
# the space efficient encoding without slowing down too much PFADD,
# which is O(N) with the sparse encoding. The value can be raised to
# ~ 10000 when CPU is not a concern, but space is, and the data set is
# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.
hll-sparse-max-bytes 3000

# Streams macro node max size / items. The stream data structure is a radix
# tree of big nodes that encode multiple items inside. Using this configuration
# it is possible to configure how big a single node can be in bytes, and the
# maximum number of items it may contain before switching to a new node when
# appending new stream entries. If any of the following settings are set to
# zero, the limit is ignored, so for instance it is possible to set just a
# max entires limit by setting max-bytes to 0 and max-entries to the desired
# value.
stream-node-max-bytes 4096
stream-node-max-entries 100

# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in
# order to help rehashing the main Redis hash table (the one mapping top-level
# keys to values). The hash table implementation Redis uses (see dict.c)
# performs a lazy rehashing: the more operation you run into a hash table
# that is rehashing, the more rehashing &quot;steps&quot; are performed, so if the
# server is idle the rehashing is never complete and some more memory is used
# by the hash table.
#
# The default is to use this millisecond 10 times every second in order to
# actively rehash the main dictionaries, freeing memory when possible.
#
# If unsure:
# use &quot;activerehashing no&quot; if you have hard latency requirements and it is
# not a good thing in your environment that Redis can reply from time to time
# to queries with 2 milliseconds delay.
#
# use &quot;activerehashing yes&quot; if you don&#39;t have such hard requirements but
# want to free memory asap when possible.
activerehashing yes

# The client output buffer limits can be used to force disconnection of clients
# that are not reading data from the server fast enough for some reason (a
# common reason is that a Pub/Sub client can&#39;t consume messages as fast as the
# publisher can produce them).
#
# The limit can be set differently for the three different classes of clients:
#
# normal -&gt; normal clients including MONITOR clients
# replica  -&gt; replica clients
# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern
#
# The syntax of every client-output-buffer-limit directive is the following:
#
# client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;
#
# A client is immediately disconnected once the hard limit is reached, or if
# the soft limit is reached and remains reached for the specified number of
# seconds (continuously).
# So for instance if the hard limit is 32 megabytes and the soft limit is
# 16 megabytes / 10 seconds, the client will get disconnected immediately
# if the size of the output buffers reach 32 megabytes, but will also get
# disconnected if the client reaches 16 megabytes and continuously overcomes
# the limit for 10 seconds.
#
# By default normal clients are not limited because they don&#39;t receive data
# without asking (in a push way), but just after a request, so only
# asynchronous clients may create a scenario where data is requested faster
# than it can read.
#
# Instead there is a default limit for pubsub and replica clients, since
# subscribers and replicas receive data in a push fashion.
#
# Both the hard or the soft limit can be disabled by setting them to zero.
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

# Client query buffers accumulate new commands. They are limited to a fixed
# amount by default in order to avoid that a protocol desynchronization (for
# instance due to a bug in the client) will lead to unbound memory usage in
# the query buffer. However you can configure it here if you have very special
# needs, such us huge multi/exec requests or alike.
#
# client-query-buffer-limit 1gb

# In the Redis protocol, bulk requests, that are, elements representing single
# strings, are normally limited ot 512 mb. However you can change this limit
# here.
#
# proto-max-bulk-len 512mb

# Redis calls an internal function to perform many background tasks, like
# closing connections of clients in timeout, purging expired keys that are
# never requested, and so forth.
#
# Not all tasks are performed with the same frequency, but Redis checks for
# tasks to perform according to the specified &quot;hz&quot; value.
#
# By default &quot;hz&quot; is set to 10. Raising the value will use more CPU when
# Redis is idle, but at the same time will make Redis more responsive when
# there are many keys expiring at the same time, and timeouts may be
# handled with more precision.
#
# The range is between 1 and 500, however a value over 100 is usually not
# a good idea. Most users should use the default of 10 and raise this up to
# 100 only in environments where very low latency is required.
hz 10

# Normally it is useful to have an HZ value which is proportional to the
# number of clients connected. This is useful in order, for instance, to
# avoid too many clients are processed for each background task invocation
# in order to avoid latency spikes.
#
# Since the default HZ value by default is conservatively set to 10, Redis
# offers, and enables by default, the ability to use an adaptive HZ value
# which will temporary raise when there are many connected clients.
#
# When dynamic HZ is enabled, the actual configured HZ will be used as
# as a baseline, but multiples of the configured HZ value will be actually
# used as needed once more clients are connected. In this way an idle
# instance will use very little CPU time while a busy instance will be
# more responsive.
dynamic-hz yes

# When a child rewrites the AOF file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
aof-rewrite-incremental-fsync yes

# When redis saves RDB file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
rdb-save-incremental-fsync yes

# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good
# idea to start with the default settings and only change them after investigating
# how to improve the performances and how the keys LFU change over time, which
# is possible to inspect via the OBJECT FREQ command.
#
# There are two tunable parameters in the Redis LFU implementation: the
# counter logarithm factor and the counter decay time. It is important to
# understand what the two parameters mean before changing them.
#
# The LFU counter is just 8 bits per key, it&#39;s maximum value is 255, so Redis
# uses a probabilistic increment with logarithmic behavior. Given the value
# of the old counter, when a key is accessed, the counter is incremented in
# this way:
#
# 1. A random number R between 0 and 1 is extracted.
# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).
# 3. The counter is incremented only if R &lt; P.
#
# The default lfu-log-factor is 10. This is a table of how the frequency
# counter changes with a different number of accesses with different
# logarithmic factors:
#
# +--------+------------+------------+------------+------------+------------+
# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |
# +--------+------------+------------+------------+------------+------------+
# | 0      | 104        | 255        | 255        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 1      | 18         | 49         | 255        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 10     | 10         | 18         | 142        | 255        | 255        |
# +--------+------------+------------+------------+------------+------------+
# | 100    | 8          | 11         | 49         | 143        | 255        |
# +--------+------------+------------+------------+------------+------------+
#
# NOTE: The above table was obtained by running the following commands:
#
#   redis-benchmark -n 1000000 incr foo
#   redis-cli object freq foo
#
# NOTE 2: The counter initial value is 5 in order to give new objects a chance
# to accumulate hits.
#
# The counter decay time is the time, in minutes, that must elapse in order
# for the key counter to be divided by two (or decremented if it has a value
# less &lt;= 10).
#
# The default value for the lfu-decay-time is 1. A Special value of 0 means to
# decay the counter every time it happens to be scanned.
#
# lfu-log-factor 10
# lfu-decay-time 1

########################### ACTIVE DEFRAGMENTATION #######################
#
# 注意，该特性是实验性的，尽管经过了众多开发者生产环境验证和人工测试，但还是不能保证没问题。
#
# 什么是碎片热整理？
# -------------------------------
# 碎片热整理是让redis整合内存空间的碎片化数据块和废弃数据，这样可以回收更大的内存空间用于分配。
# 
# 
# Fragmentation is a natural process that happens with every allocator (but
# less so with Jemalloc, fortunately) and certain workloads. 
# 一般来说，服务需要重启才能减少内存碎片，或至少要释放所有数据内存，再次重新构建一次内存数据。
# 然而，感谢Oran Agra在redis4.0实现了服务在运行时可整理碎片的机制。
#
# 基本上，当碎片达到一定级别（看下方的配置），redis将在临近的内存区域通过Jemalloc（可以更好的实现内存回收和碎片整理）构建一个备份，
# 同时，将释放旧的内存数据，这个进程采用递增的方式逐个处理key值直到内存碎片降低的合理值。
#
# 重要的知识点:
#
# 1. This feature is disabled by default, and only works if you compiled Redis
#    to use the copy of Jemalloc we ship with the source code of Redis.
#    This is the default with Linux builds.
# 2.你不需要开启该特性，如果你的系统没有碎片问题。
# 3.一旦你想体验该特性，你可以通过CONFIG SET activedefrag yes指令开启
#
# 如下配置将更好的调整碎片整理的行为。如果你不确定参数的作用，建议采用默认值。

# 开启碎片整理
# activedefrag yes

# 碎片大小下限值，碎片大小&gt;=100M,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-ignore-bytes 100mb

# 碎片占比下限值，&gt;=10%,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-threshold-lower 10

# 碎片占比上限值，&lt;=100%,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-threshold-upper 100

# CPU的使用率下限值，&gt;=5%,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-cycle-min 5

# CPU的使用率上限值，&lt;=75%,才可以触发整理，但是不一定触发（其他因素限制）
# active-defrag-cycle-max 75

# Maximum number of set/hash/zset/list fields that will be processed from
# the main dictionary scan
# active-defrag-max-scan-fields 1000
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[]]></title>
    <link href="http://www.throne4j.com/15991122990129.html"/>
    <updated>2020-09-03T13:51:39+08:00</updated>
    <id>http://www.throne4j.com/15991122990129.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式和集群的概念区别]]></title>
    <link href="http://www.throne4j.com/15990991988342.html"/>
    <updated>2020-09-03T10:13:18+08:00</updated>
    <id>http://www.throne4j.com/15990991988342.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">　　一、集群概念</h2>

<h2 id="toc_1">1、两大关键特性</h2>

<p>集群是一组协同工作的服务实体，用以提供比单一服务实体更具扩展性与可用性的服务平台。在客户端看来，一个集群就象是一个服务实体，但事实上集群由一组服务实体组成。与单一服务实体相比较，集群提供了以下两个关键特性：</p>

<ul>
<li>可扩展性－－集群的性能不限于单一的服务实体，新的服务实体可以动态地加入到集群，从而增强集群的性能。</li>
<li>高可用性－－集群通过服务实体冗余使客户端免于轻易遇到out of service的警告。在集群中，同样的服务可以由多个服务实体提供。如果一个服务实体失败了，另一个服务实体会接管失败的服务实体。集群提供的从一个出 错的服务实体恢复到另一个服务实体的功能增强了应用的可用性。</li>
</ul>

<p>　　2. 两大能力 </p>

<p>　　为了具有可扩展性和高可用性特点，集群的必须具备以下两大能力：</p>

<p>　　·  负载均衡－－负载均衡能把任务比较均衡地分布到集群环境下的计算和网络资源。</p>

<p>　　·  错误恢复－－由于某种原因，执行某个任务的资源出现故障，另一服务实体中执行同一任务的资源接着完成任务。这种由于一个实体中的资源不能工作，另一个实体中的资源透明的继续完成任务的过程叫错误恢复。</p>

<p>　　负载均衡和错误恢复都要求各服务实体中有执行同一任务的资源存在，而且对于同一任务的各个资源来说，执行任务所需的信息视图（信息上下文）必须是一样的。</p>

<p>　　3. 两大技术</p>

<p>　　实现集群务必要有以下两大技术：</p>

<p>　　·  集群地址－－集群由多个服务实体组成，集群客户端通过访问集群的集群地址获取集群内部各服务实体的功能。具有单一集群地址（也叫单一影像）是集群的一个基 本特征。维护集群地址的设置被称为负载均衡器。负载均衡器内部负责管理各个服务实体的加入和退出，外部负责集群地址向内部服务实体地址的转换。有的负载均 衡器实现真正的负载均衡算法，有的只支持任务的转换。只实现任务转换的负载均衡器适用于支持ACTIVE-STANDBY的集群环境，在那里，集群中只有 一个服务实体工作，当正在工作的服务实体发生故障时，负载均衡器把后来的任务转向另外一个服务实体。</p>

<p>　　·  内部通信－－为了能协同工作、实现负载均衡和错误恢复，集群各实体间必须时常通信，比如负载均衡器对服务实体心跳测试信息、服务实体间任务执行上下文信息的通信。</p>

<p>　　具有同一个集群地址使得客户端能访问集群提供的计算服务，一个集群地址下隐藏了各个服务实体的内部地址，使得客户要求的计算服务能在各个服务实体之间分布。内部通信是集群能正常运转的基础，它使得集群具有均衡负载和错误恢复的能力。</p>

<h2 id="toc_2">　　二、集群分类</h2>

<p>　　Linux集群主要分成三大类(高可用集群， 负载均衡集群，科学计算集群)</p>

<p>高可用集群(High Availability Cluster)<br/>
负载均衡集群(Load Balance Cluster)<br/>
科学计算集群(High Performance Computing Cluster)<br/>
　　具体包括：</p>

<p>　　Linux High Availability 高可用集群<br/><br/>
　　(普通两节点双机热备，多节点HA集群，RAC, shared, share-nothing集群等)</p>

<p>　　Linux Load Balance 负载均衡集群<br/><br/>
　　 (LVS等....)</p>

<p>　　Linux High Performance Computing 高性能科学计算集群<br/><br/>
　　 (Beowulf 类集群....)</p>

<h2 id="toc_3">　　三、详细介绍</h2>

<p>　　1. 高可用集群(High Availability Cluster)</p>

<p>　　常见的就是2个节点做成的HA集群，有很多通俗的不科学的名称，比如&quot;双机热备&quot;，&quot;双机互备&quot;，&quot;双机&quot;。</p>

<p>　　高可用集群解决的是保障用户的应用程序持续对外提供服务的能力。 (请注意高可用集群既不是用来保护业务数据的，保护的是用户的业务程序对外不间断提供服务，把因软件/硬件/人为造成的故障对业务的影响降低到最小程度)。</p>

<p>　　2. 负载均衡集群(Load Balance Cluster)</p>

<p>　　负载均衡系统：集群中所有的节点都处于活动状态，它们分摊系统的工作负载。一般Web服务器集群、数据库集群和应用服务器集群都属于这种类型。</p>

<p>　　负载均衡集群一般用于相应网络请求的网页服务器，数据库服务器。这种集群可以在接到请求时，检查接受请求较少，不繁忙的服务器，并把请求转到这些服务器上。从检查其他服务器状态这一点上看，负载均衡和容错集群很接近，不同之处是数量上更多。</p>

<p>　　3. 科学计算集群(High Performance Computing Cluster)</p>

<p>　　高性能计算(High Perfermance Computing)集群，简称HPC集群。这类集群致力于提供单个计算机所不能提供的强大的计算能力。</p>

<p>　　3.1 高性能计算分类　　　</p>

<p>　　3.1.1 高吞吐计算(High-throughput Computing)</p>

<p>　　有一类高性能计算，可以把它分成若干可以并行的子任务，而且各个子任务彼此间没有什么关联。象在家搜寻外星人（ SETI@HOME -- Search for Extraterrestrial Intelligence at Home ）就是这一类型应用。这一项目是利用Internet上的闲置的计算资源来搜寻外星人。SETI项目的服务器将一组数据和数据模式发给Internet上 参加SETI的计算节点，计算节点在给定的数据上用给定的模式进行搜索，然后将搜索的结果发给服务器。服务器负责将从各个计算节点返回的数据汇集成完整的 数据。因为这种类型应用的一个共同特征是在海量数据上搜索某些模式，所以把这类计算称为高吞吐计算。所谓的Internet计算都属于这一类。按照 Flynn的分类，高吞吐计算属于SIMD（Single Instruction/Multiple Data）的范畴。</p>

<p>　　3.1.2 分布计算(Distributed Computing)</p>

<p>　　另一类计算刚好和高吞吐计算相反，它们虽然可以给分成若干并行的子任务，但是子任务间联系很紧密，需要大量的数据交换。按照Flynn的分类，分布式的高性能计算属于MIMD（Multiple Instruction/Multiple Data）的范畴。</p>

<h2 id="toc_4">　　四、分布式（集群）与集群的联系与区别</h2>

<p>　　分布式是指将不同的业务分布在不同的地方；而集群指的是将几台服务器集中在一起，实现同一业务。</p>

<p>　　分布式中的每一个节点，都可以做集群。 而集群并不一定就是分布式的。 </p>

<p>　　举例：就比如新浪网，访问的人多了，他可以做一个群集，前面放一个响应服务器，后面几台服务器完成同一业务，如果有业务访问的时候，响应服务器看哪台服务器的负载不是很重，就将给哪一台去完成。 </p>

<p>　　而分布式，从窄意上理解，也跟集群差不多， 但是它的组织比较松散，不像集群，有一个组织性，一台服务器垮了，其它的服务器可以顶上来。</p>

<p>　　分布式的每一个节点，都完成不同的业务，一个节点垮了，那这个业务就不可访问了。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[linux和macOS下top命令区别]]></title>
    <link href="http://www.throne4j.com/15983681960215.html"/>
    <updated>2020-08-25T23:09:56+08:00</updated>
    <id>http://www.throne4j.com/15983681960215.html</id>
    <content type="html"><![CDATA[
<p>top命令是常用的性能分析工具，被广泛用于监视服务器的负载，能够实时显示系统中各个进程的资源占用情况。</p>

<p>前言<br/>
开发环境使用Mac后，经常使用 活动监视器 查看所有进程CPU、内存等。top命令的快捷键在Mac下的快捷键不生效。一直这样用下来，感觉不是很顺手。整理记录。</p>

<h2 id="toc_0">1、linux top</h2>

<pre><code class="language-text">P 键 按照cpu使用率排序
M 键 按照内存使用率排序
l 键 切换显示平均负载和启动时间信息
m 键 切换显示内存信息
t 键 切换显示进程和cpu状态信息
c 键 切换显示命令名称和完成命令行信息
</code></pre>

<pre><code class="language-text">top - 11:15:45 up 14 min,  1 user,  load average: 0.74, 0.58, 0.31
Tasks: 143 total,   1 running, 142 sleeping,   0 stopped,   0 zombie
%Cpu(s):  2.4 us,  2.2 sy,  0.0 ni, 95.3 id,  0.0 wa,  0.0 hi,  0.2 si,  0.0 st
</code></pre>

<h2 id="toc_1">2、Mac top</h2>

<p>先输入 o 键 ,再输入 cpu 则按cpu使用量排序，输入 rsize 按内存使用量排序。</p>

<h2 id="toc_2">3、 字符含义</h2>

<pre><code class="language-shell">top - 11:25:56 up 25 min,  1 user,  load average: 0.22, 0.36, 0.31
Tasks: 144 total,   1 running, 143 sleeping,   0 stopped,   0 zombie
%Cpu(s):  2.2 us,  1.7 sy,  0.0 ni, 95.9 id,  0.0 wa,  0.0 hi,  0.2 si,  0.0 st
KiB Mem :  1863088 total,    97124 free,   934460 used,   831504 buff/cache
KiB Swap:        0 total,        0 free,        0 used.   767876 avail Mem

   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
  2383 root      20   0  481976 274180  39152 S   3.3 14.7   0:48.03 kube-apiserver --advertise-address=172.16.65.134 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enabl+
   738 root      20   0 1225828  73716  34748 S   2.0  4.0   0:32.22 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --cgroup-driver=systemd --network-plugi+
  1002 root      20   0  566956  87928  26144 S   1.0  4.7   0:15.37 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
  2384 root      20   0   10.1g  50352  12152 S   1.0  2.7   0:18.25 etcd --advertise-client-urls=https://172.16.65.134:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --initial-advertise-peer-urls=https://172.16.+
  2429 root      20   0  221900  65236  30152 S   1.0  3.5   0:18.03 kube-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf --bind-addre+
   442 root      20   0       0      0      0 S   0.3  0.0   0:01.02 [xfsaild/dm-0]
  1000 root      20   0 1155792  44968  14332 S   0.3  2.4   0:00.95 /usr/bin/containerd
  2188 root      20   0  107688   6524   2700 S   0.3  0.4   0:00.04 containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/4cbd4244ccf55f156b620e442678e20a85fc2f28c4edb5e7f517c3539b5fdea1 -address /run/containerd/containerd.+
  
</code></pre>

<p>l 键 切换显示平均负载和启动时间信息:</p>

<table>
<thead>
<tr>
<th>top - 11:12:47</th>
<th>up 11 min,</th>
<th>1 user,</th>
<th>load average: 0.17, 0.23, 0.15</th>
</tr>
</thead>

<tbody>
<tr>
<td>当前系统时间</td>
<td>系统已运行时间</td>
<td>在线用户，包含系统用户</td>
<td>系统负载。分别是1，5，15分钟前到潜在的平均值</td>
</tr>
</tbody>
</table>

<table>
<thead>
<tr>
<th>Tasks</th>
<th>227 total</th>
<th>1 running</th>
<th>225 sleeping</th>
<th>1 stopped</th>
<th>0 zombie</th>
</tr>
</thead>

<tbody>
<tr>
<td>-</td>
<td>总进程数</td>
<td>正在运行的进程数</td>
<td>正在睡眠的进程数</td>
<td>停止的进程数</td>
<td>僵死进程数</td>
</tr>
</tbody>
</table>

<p>t键，cpu信息：</p>

<table>
<thead>
<tr>
<th>%Cpu(s)</th>
<th>0.8 us</th>
<th>1.0 sy</th>
<th>0.0 ni</th>
<th>98.2 id</th>
<th>0.0 wa</th>
<th>0.0 hi</th>
<th>0.0 si</th>
<th>0.0 st</th>
</tr>
</thead>

<tbody>
<tr>
<td>-</td>
<td>cpu占用率(%)，用户进程占用cpu百分率</td>
<td>系统占用cpu百分率</td>
<td>用户进程空间内改变过优先级的进程占用CPU百分比</td>
<td>cpu空闲率</td>
<td>等待IO的CPU时间百分比</td>
<td>硬中断（Hardware IRQ）占用CPU的百分比</td>
<td>软中断（Software Interrupts）占用CPU的百分比</td>
<td>虚拟机占用百分比</td>
</tr>
</tbody>
</table>

<p>m键 内存信息：</p>

<table>
<thead>
<tr>
<th>KiB Mem</th>
<th>8175028 total</th>
<th>635844 free</th>
<th>3024460 used</th>
<th>4514724 buff/cache</th>
</tr>
</thead>

<tbody>
<tr>
<td>-</td>
<td>内存总量</td>
<td>内存空闲量</td>
<td>内存使用量</td>
<td>缓存的内存量</td>
</tr>
</tbody>
</table>

<p>交换区信息：</p>

<table>
<thead>
<tr>
<th>KiB Swap</th>
<th>15624016 total</th>
<th>15606756 free</th>
<th>17260 used</th>
<th>4678020 avail Mem</th>
</tr>
</thead>

<tbody>
<tr>
<td>-</td>
<td>交换区总量</td>
<td>交换区空闲量</td>
<td>交换区使用量</td>
<td>缓冲交换区总量</td>
</tr>
</tbody>
</table>

<table>
<thead>
<tr>
<th>PID</th>
<th>USER</th>
<th>PR</th>
<th>NI</th>
<th>VIRT</th>
<th>RES</th>
<th>SHR</th>
<th>S</th>
<th>%CPU</th>
<th>%MEM</th>
<th>TIME+</th>
<th>COMMAND</th>
</tr>
</thead>

<tbody>
<tr>
<td>进程号</td>
<td>进程创建者</td>
<td>进程优先级</td>
<td>nice值</td>
<td>进程使用的虚拟内存总量</td>
<td>进程使用的、未被换出的物理内存大小</td>
<td>共享内存大小</td>
<td>进程状态</td>
<td>进程占用cpu百分比</td>
<td>进程占用内存百分比</td>
<td>进程运行时间</td>
<td>进程名称</td>
</tr>
</tbody>
</table>

<ul>
<li>NI nice值。越小优先级越高，最小-20，最大20（用户设置最大19）</li>
<li>VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES</li>
<li>RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA</li>
<li>SHR 共享内存大小，单位kb</li>
<li>S 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一致性Hash]]></title>
    <link href="http://www.throne4j.com/15983668905198.html"/>
    <updated>2020-08-25T22:48:10+08:00</updated>
    <id>http://www.throne4j.com/15983668905198.html</id>
    <content type="html"><![CDATA[
<p>01.分布式与集群</p>

<p>分布式：把一个系统拆分为多个子系统，每个子系统负责各自功能实现，独立部署，各司其职。体现的是对系统的拆分。<br/>
集群：体现的是多个实例共同工作，最简单/常见的集群即一个应用复制多份部署，实现高可用。<br/>
分布式一定是集群，但集群不一定是分布式。（因为集群就是多个实例一起工作，分布式将一个系统拆分之后就是多个实例，所以分布式一定是集群，而集群并不一定是分布式，因为复制型的集群不是拆分而是复制）。</p>

<h2 id="toc_0">一致性 Hash 算法</h2>

<p>Hash 算法常见应用场景<br/>
    比如在安全加密领域MD5、SHA等加密算法，在数据存储和查找方面有 hash 表，Java中的hashcode等都应用到了 Hash 算法。<br/>
    Hash 算法在很多分布式集群产品中都有应用，比如分布式集群架构 Redis、Hadoop、ElasticSearch，MySQL 分库分表，Nginx 负载均衡等。Hash 算法等使用主要场景分为两个：<br/>
请求的负载均衡（比如 Nginx 的 ip_hash 策略）。</p>

<p>Nginx 的 IP_hash 策略可以在客户端 IP 不变的情况下，将其发出的请求始终路由到同一个目标服务器上，实现会话粘滞，避免处理 session 共享问题。</p>

<p>如果没有 IP_hash 策略，又想实现会话粘滞，可以维护一个映射表，存储客户端 ip 或者 sessionid 与具体目标服务器的映射关系。缺点：1、在客户端很多的情况下，映射表非常大，浪费内存空间；2、客户端上下线、目标服务器上下线，都会导致重新维护映射表。</p>

<p>分布式存储。通过 Hash 算法将不同服务器的请求路由到不同的服务器，进而将数据存储到不同的服务器中。</p>

<p>为什么需要使用 Hash 算法<br/>
    Hash 算法较多的应用在数据存储和查找领域，最经典的 Hash 表，其查询效率非常高，如果 Hash 算法设计的比较好的话，那么 Hash 表的数据查询时间复杂度可以接近于O(1)。<br/>
    比如：判断一个结合中是否包含某个元素，例如集合数据：1、3、6、4、8、2、9、12、7 中是否包含数字 4 ，最普通的方法是循环遍历数组，逐个进行判断，或者使用二分查找（需要对元素进行排序）。<br/>
直接寻址法<br/>
    首先创建一个数组，数组的长度根据集合中元素的最大值来确定，数组长度要大于等于集合中的最大值 +1 ，然后将数组中的数据根据下标进行存放入数组中，比如元素 1 存放到数组下标为 1 的位置，元素 3 存放在数组下标为 3 的位置，依次类推，如下图：</p>

<pre><code class="language-text">只需根据数组下标进行判断，当前位置是否有值即可。
优点：查询速度快，只需一次查找即可确定。
缺点：
</code></pre>

<p>浪费内存空间。比如图中的 0、5、10、11 内存位置，并没有存放任何数据，但是需要预留内存空间。更夸张的是，如果集合中元素跨度很大，比如集合中增加元素 12306，其余都不变，那么数组长度将是 12307，数组中 13～12306 的下标位置都将浪费。</p>

<p>集合中的元素要求无重复，否则无法存放集合中所有元素。例如将集合元素修改为：1、3、6、4、8、2、9、12、7、4、2 ，那么数组长度变成了15，但是最大值还是 12 ，存放时，元素 2 和 4 要么被覆盖，要么无法存放。</p>

<p>除留余数法</p>

<pre><code class="language-text">数组的长度可以任意，集合中元素的存放位置通过对数组长度求模后对值来确定：存放位置 = 集合中元素值 % 数组长度 。



这种方式算是一种简单的 Hash 算法，也可以提高查询效率，但是会导致 Hash 冲突。即不同的元素求模之后存放的数组位置是相同的。
</code></pre>

<p>开放寻址法</p>

<pre><code class="language-text">哈希冲突时向前或向后占用空闲位置，数据比较混乱，这种方式一般不会使用。而且，当数组的长度确定，且小于集合中数据元素个数时，无论是否发生 hash 冲突，都无法存放集合中所有元素。
</code></pre>

<p>拉链法</p>

<pre><code class="language-text">为了解决在除留余数法中产生的 Hash 冲突问题，当有两个元素求模后存放在相同下标位置时， 通过链表结构，将不同元素存放在相同的下标位置。
使用拉链法之后，查询效率相比直接寻址法会稍有逊色，但是如果 Hash 算法设计的好的话，元素在数组中存放比较均匀，Hash 冲突机率比较低，其查询效率依然很高，且节省了内存空间。
</code></pre>

<p>普通 Hash 算法存在的问题<br/>
    普通 hash 算法通过取模来定位请求的具体服务器地址，这种情况下，增减服务器数量，影响到 hash 结果，导致会话失效。<br/>
一致性 Hash 算法</p>

<p>原理<br/>
首先将 0 ~ 2<sup>32-1</sup> 按照顺指针方向放在一个圆环中，这个环称为 Hash 环。</p>

<p>假设当前集群中有4个服务器节点，分别是 node1、node2、node3、node4，根据这 4 个服务器节点的 IP (也可以是其他属性) 计算出一个 Hash 值，分别对应 Hash 环中的某个位置，这里假设 4 个服务器节点经过 Hash 算法之后分别对应 Hash 环中的1、2、3、4 的位置。</p>

<p>当请求到达时，再通过 Hash 算法，计算出当前请求在 Hash 环中对应的位置，根据对请求计算出的 Hash 值，顺时针查找最近的一个服务器节点，该节点就是处理当前请求的节点。比如：如果请求通过 Hash 算法之后，在 Hash 环中对应的位置落在 4～1 之间，那么处理当前请求的服务器节点就是 node1，如果请求通过 Hash 算法之后，在 Hash 环中对应的位置落在 1～2 之间，那么处理当前请求的服务器节点就是 node2，依次类推。</p>

<p>缩容</p>

<pre><code class="language-text">当有服务器下线时，比如 node3 节点下线，原来路由到 node3 的客户端，重新路由到了 node4，对于其他客户端没有影响，请求的迁移达到了最小，这样的算法对于分布式集群来说非常合适，避免了大量请求的迁移。
</code></pre>

<p>扩容</p>

<pre><code class="language-text">当新增一个服务器节点5之后，原来路由到 node3 的部分客户端路由到了新增服务器 node5 上，受影响的只有新增节点与其前一个节点之间的请求，其他请求也不会收到影响。请求的迁移达到了最小，这样的算法对于分布式集群来说非常合适，避免了大量请求的迁移。

每台服务器负责一部分客户端的请求，一致性 Hash 算法对于服务器节点的增减都只需要定位环空间中的一小部分数据，具有较好的容错性和可扩展性。
</code></pre>

<p>虚拟节点方式</p>

<pre><code class="language-text">对于一致性 Hash 算法，在服务器节点太少时，容易因为节点分布不均匀而导致数据倾斜问题。例如系统中只有两台服务器，节点2只能负责很小的一部分请求，大量的客户端请求落在了节点1上。

为了解决这种数据倾斜问题，一致性 Hash 算法引入了虚拟节点机制。即对每一个服务节点计算多个 Hash，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器 IP 或主机名后面增加编号来实现。比如，可以为每台服务器计算三个虚拟节点，于是可以分别计算“节点1的ip#1”、“节点1的ip#2”、“节点1的ip#3”、“节点2的ip#1”、“节点2的ip#2”、“节点2的ip#3”的 Hash 值，于是形成 6 个虚拟节点，当客户端被路由到虚拟节点的时候其实是被路由到该虚拟节点对应的真实节点。
</code></pre>

<p>Nginx 配置一致性 Hash 负载均衡策略<br/>
    ngx_http_upstream_consistent_hash 模块是一个负载均衡器，使用一个内部一致性 Hash 算法来选择合适的后端节点，  Nginx 默认并没有安装一致性 Hash 模块，需要自己手动安装。</p>

<pre><code class="language-text">该模块可以根据不同的配置参数采取不同的方式将请求映射到后端机器：
</code></pre>

<p>consistent_hash $remote_addr：可以根据客户端的 ip 映射</p>

<p>consistent_hash $request_uri：根据客户端请求的 uri 映射</p>

<p>consistent_hash $args：根据客户端携带的参数进行映射</p>

<p>安装一致性 Hash 负载均衡器<br/>
下载并上传至云服务器</p>

<p>下载地址：<a href="https://github.com/replay/ngx_http_consistent_hash">https://github.com/replay/ngx_http_consistent_hash</a></p>

<p>以压缩包的形式将其下载到本地，并通过 FTP 工具上传至云服务器，此处上传到服务器的 /soft/ 目录下。</p>

<p>在此之前已经编译并安装过 Nginx ，此时进入 Nginx 源码目录，执行一下命令进行安装：</p>

<h1 id="toc_1">进入 Nginx 源码目录</h1>

<p>cd /soft/nginx-1.18.0</p>

<h1 id="toc_2">配置添加一致性 Hash 负载均衡器模块</h1>

<p>./configure --add-module=/soft/ngx_http_consistent_hash-master # 配置<br/>
make # 编译<br/>
make install # 安装</p>

<pre><code class="language-text">此时，Nginx 一致性 Hash 负载均衡器已经安装完成。
</code></pre>

<p>使用 Nginx 一致性 Hash 负载均衡器<br/>
    安装完成后，只需要在 nginx.conf 文件中添加如下配置即可使用一致性 Hash 负载均衡策略：</p>

<pre><code class="language-text">cd /usr/local/nginx/conf
vim nginx.conf
</code></pre>

<pre><code class="language-text">upstream testServer {
  consistent_hash $request_uri;
  server 127.0.0.1:8080;
  server 127.0.0.1:8081;
}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[线程]]></title>
    <link href="http://www.throne4j.com/15981846149666.html"/>
    <updated>2020-08-23T20:10:14+08:00</updated>
    <id>http://www.throne4j.com/15981846149666.html</id>
    <content type="html"><![CDATA[
<p>java 线程的本质--Thread--jvm--os</p>

<p>java 线程模型</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[幂等方案]]></title>
    <link href="http://www.throne4j.com/15979251824377.html"/>
    <updated>2020-08-20T20:06:22+08:00</updated>
    <id>http://www.throne4j.com/15979251824377.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Arthas]]></title>
    <link href="http://www.throne4j.com/15978529329852.html"/>
    <updated>2020-08-20T00:02:12+08:00</updated>
    <id>http://www.throne4j.com/15978529329852.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">简介</h2>

<p>Arthas 是 Alibaba 开源的 Java 诊断工具,在线排查问题，无需重启；动态跟踪Java代码；实时监控JVM状态。</p>

<p><a href="https://alibaba.github.io/arthas/">官方文档参考</a><br/>
<a href="https://arthas.aliyun.com/doc/quick-start.html">快速入门</a></p>

<p>当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决：</p>

<p>这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？<br/>
我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？<br/>
遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？<br/>
线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！<br/>
是否有一个全局视角来查看系统的运行状况？<br/>
有什么办法可以监控到JVM的实时运行状态？<br/>
怎么快速定位应用的热点，生成火焰图？</p>

<h2 id="toc_1">下载和安装</h2>

<p>不需要安装，就是一个 jar 包</p>

<pre><code class="language-text">curl -O https://alibaba.github.io/arthas/arthas-boot.jar 

java -jar arthas-boot.jar
</code></pre>

<p>启动 arthas 的 jar 包是 arthas-boot.jar</p>

<p>直接 java -jar arthas-boot.jar。选择 attach 的进程绑定<br/>
<figure><img src="media/15773440983590/15976833500370.jpg" alt=""/></figure></p>

<h2 id="toc_2">arthas 命令</h2>

<p>输入help查看 arthas 支持的命令</p>

<pre><code class="language-shell">[arthas@29087]$ help
 NAME         DESCRIPTION
 help         Display Arthas Help
 keymap       Display all the available keymap for the specified connection.
 sc           Search all the classes loaded by JVM
 sm           Search the method of classes loaded by JVM
 classloader  Show classloader info
 jad          Decompile class
 getstatic    Show the static field of a class
 monitor      Monitor method execution statistics, e.g. total/success/failure count, average rt, fail rate, etc.
 stack        Display the stack trace for the specified class and method
 thread       Display thread info, thread stack
 trace        Trace the execution time of specified method invocation.
 watch        Display the input/output parameter, return object, and thrown exception of specified method invocation
 tt           Time Tunnel
 jvm          Display the target JVM information
 perfcounter  Display the perf counter infornation.
 ognl         Execute ognl expression.
 mc           Memory compiler, compiles java files into bytecode and class files in memory.
 redefine     Redefine classes. @see Instrumentation#redefineClasses(ClassDefinition...)
 dashboard    Overview of target jvm&#39;s thread, memory, gc, vm, tomcat info.
 dump         Dump class byte array from JVM
 heapdump     Heap dump
 options      View and change various Arthas options
 cls          Clear the screen
 reset        Reset all the enhanced classes
 version      Display Arthas version
 session      Display current session information
 sysprop      Display, and change the system properties.
 sysenv       Display the system env.
 vmoption     Display, and update the vm diagnostic options.
 logger       Print logger info, and update the logger level
 history      Display command history
 cat          Concatenate and print files
 echo         write arguments to the standard output
 pwd          Return working directory name
 mbean        Display the mbean information
 grep         grep command for pipes.
 tee          tee command for pipes.
 profiler     Async Profiler. https://github.com/jvm-profiling-tools/async-profiler
 stop         Stop/Shutdown Arthas server and exit the console.
</code></pre>

<h3 id="toc_3">dashboard</h3>

<p><figure><img src="media/15773440983590/15976836704891.jpg" alt="" style="width:1891px;"/></figure></p>

<h3 id="toc_4">thread</h3>

<p>这个命令和 jstack 很相似，但是功能更加强大，主要是查看当前 JVM 的线程堆栈信息 同时可以结合使用 thread –b 来进行死锁的排查死锁。</p>

<p>参数说明:</p>

<pre><code class="language-text">-n 指定最忙的前 n 个线程并打印堆栈
-b 找出阻塞当前线程的线程
-i 指定 cpu 占比统计的采样间隔，单位为毫秒
</code></pre>

<pre><code class="language-text">[arthas@29087]$ thread -b
&quot;Thread-0&quot; Id=11 BLOCKED on java.lang.Object@602bace6 owned by &quot;Thread-1&quot; Id=12
    at com.goddess.base.concurrent.SynchronizedObjDeadLock.lambda$deadLock$0(SynchronizedObjDeadLock.java:27)
    -  blocked on java.lang.Object@602bace6
    -  locked java.lang.Object@12487489 &lt;---- but blocks 1 other threads!
    at com.goddess.base.concurrent.SynchronizedObjDeadLock$$Lambda$1/122883338.run(Unknown Source)
    at java.lang.Thread.run(Thread.java:745)
</code></pre>

<p>thread -i 1000 -n 3 每过 1000 毫秒进行采样，显示最占 CPU 时间的前 3 个线程</p>

<p>thread --state WAITING 查看处于等待状态的线程</p>

<h3 id="toc_5">jvm</h3>

<p>查看jvm信息<br/>
<figure><img src="media/15773440983590/15976840064874.jpg" alt=""/></figure></p>

<h3 id="toc_6">jad 反编译指定已加载类的源码</h3>

<p><figure><img src="media/15773440983590/15976841522972.jpg" alt="" style="width:1293px;"/></figure></p>

<h3 id="toc_7">trace</h3>

<p>使用 trace 命令可以跟踪统计方法耗时。</p>

<p>例如：trace com.goddess.base.controller.UserController get</p>

<h3 id="toc_8">monitor 方法监控</h3>

<p>监控的维度说明：</p>

<table>
<thead>
<tr>
<th>监控项</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>timestamp</td>
<td>时间戳</td>
</tr>
<tr>
<td>class</td>
<td>Java类</td>
</tr>
<tr>
<td>method</td>
<td>方法（构造方法、普通方法）</td>
</tr>
<tr>
<td>total</td>
<td>调用次数</td>
</tr>
<tr>
<td>success</td>
<td>成功次数</td>
</tr>
<tr>
<td>fail</td>
<td>失败次数</td>
</tr>
<tr>
<td>rt</td>
<td>平均RT</td>
</tr>
<tr>
<td>fail-rate</td>
<td>失败率</td>
</tr>
</tbody>
</table>

<p>每 5 秒统计一次 com.goddess.base.controller.UserController 类的 get 方法执行情况</p>

<pre><code class="language-text">&gt; monitor -c 5 com.goddess.base.controller.UserController get
timestamp            class          method        total  success  fail  avg-rt(ms)  fail-rate
-----------------------------------------------------------------------------------------------
 2018-12-03 19:06:38  demo.MathGame  primeFactors  5      1        4     1.15        80.00%
</code></pre>

<h3 id="toc_9">watch</h3>

<p>让你能方便的观察到指定方法的调用情况。能观察到的范围为：返回值、抛出异常、入参，通过编写 OGNL 表达式进行对应变量的查看。</p>

<p>参数说明：</p>

<ul>
<li>class-pattern 类名表达式</li>
<li>method-pattern 方法名表达式匹配</li>
<li>express 观察表达式</li>
<li>condition-express 条件表达式</li>
<li>b 在方法调用之前观察</li>
<li>e 在方法调用之后观察,异常抛出时才触发</li>
<li>s 在方法返回之后观察</li>
<li>f 在方法结束之后观察</li>
<li>E 开启正则表达式匹配，默认为通配符匹配</li>
<li>[x:] 指定输出结果的属性遍历深度，默认为1</li>
</ul>

<p>特别说明：</p>

<ul>
<li><p>watch 命令定义了4个观察事件点，即 -b 方法调用前，-e 方法异常后，-s 方法返回后，-f 方法结束后</p></li>
<li><p>4个观察事件点 -b、-e、-s 默认关闭，-f 默认打开，当指定观察点被打开后，在相应事件点会对观察表达式进行求值并输出</p></li>
<li><p>这里要注意方法入参和方法出参的区别，有可能在中间被修改导致前后不一致，除了 -b 事件点 params 代表方法入参外，其余事件都代表方法出参</p></li>
<li><p>当使用 -b 时，由于观察事件点是在方法调用前，此时返回值或异常均不存在</p></li>
</ul>

<p>变量说明：</p>

<table>
<thead>
<tr>
<th>变量名</th>
<th>变量解释</th>
</tr>
</thead>

<tbody>
<tr>
<td>loader</td>
<td>本次调用类所在的 ClassLoader</td>
</tr>
<tr>
<td>clazz</td>
<td>本次调用类的 Class 引用</td>
</tr>
<tr>
<td>method</td>
<td>本次调用方法反射引用</td>
</tr>
<tr>
<td>target</td>
<td>本次调用类的实例</td>
</tr>
<tr>
<td>params</td>
<td>本次调用参数列表，这是一个数组，如果方法是无参方法则为空数组</td>
</tr>
<tr>
<td>returnObj</td>
<td><code>本次调用返回的对象。当且仅当 isReturn==true 成立时候有效，表明方法调用是以正常返回的方式结束。如果当前方法无返回值 void，则值为 null</code></td>
</tr>
<tr>
<td>throwExp</td>
<td><code>本次调用抛出的异常。当且仅当 isThrow==true 成立时有效，表明方法调用是以抛出异常的方式结束。</code></td>
</tr>
<tr>
<td>isBefore</td>
<td><code>辅助判断标记，当前的通知节点有可能是在方法一开始就通知，此时 isBefore==true 成立，同时 isThrow==false 和 isReturn==false，因为在方法刚开始时，还无法确定方法调用将会如何结束。</code></td>
</tr>
<tr>
<td>isThrow</td>
<td>辅助判断标记，当前的方法调用以抛异常的形式结束。</td>
</tr>
<tr>
<td>isReturn</td>
<td>辅助判断标记，当前的方法调用以正常返回的形式结束。</td>
</tr>
</tbody>
</table>

<pre><code class="language-shell"># 查看get方法的入参和出参
&gt; watch com.goddess.base.controller.UserController get &#39;{params[0],returnObj}&#39; -x 2

# 按照耗时进行过滤,#cost&gt;200(单位是ms)表示只有当耗时大于200ms时才会输出，过滤掉执行时间小于200ms的调用
&gt; watch com.goddess.base.controller.UserController get &#39;{params[0],returnObj}&#39; &#39;#cost&gt;200&#39; -x 2
&gt; 
</code></pre>

<h3 id="toc_10">stack 输出当前方法被调用的调用路径</h3>

<p>参数说明：</p>

<ul>
<li>class-pattern 类名表达式匹配</li>
<li>method-pattern 方法名表达式匹配</li>
<li>condition-express 条件表达式</li>
<li>[n:] 执行次数限制</li>
<li>[E] 开启正则表达式匹配，默认为通配符匹配</li>
</ul>

<p>据执行时间来过滤：<br/>
stack demo.MathGame primeFactors &#39;#cost&gt;5&#39;</p>

<h3 id="toc_11">tt</h3>

<p>方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测</p>

<h3 id="toc_12">vmoption 查看，更新JVM 诊断相关参数</h3>

<p>查看JVM诊断相关参数：</p>

<pre><code class="language-shell">[arthas@56963]$ vmoption
 KEY                    VALUE                   ORIGIN                 WRITEABLE
---------------------------------------------------------------------------------------------
 HeapDumpBeforeFullGC   false                   DEFAULT                true
 HeapDumpAfterFullGC    false                   DEFAULT                true
 HeapDumpOnOutOfMemory  false                   DEFAULT                true
 Error
 HeapDumpPath                                   DEFAULT                true
 CMSAbortablePrecleanW  100                     DEFAULT                true
 aitMillis
 CMSWaitDuration        2000                    DEFAULT                true
 CMSTriggerInterval     -1                      DEFAULT                true
 PrintGC                false                   DEFAULT                true
 PrintGCDetails         true                    MANAGEMENT             true
 PrintGCDateStamps      false                   DEFAULT                true
 PrintGCTimeStamps      false                   DEFAULT                true
 PrintGCID              false                   DEFAULT                true
 PrintClassHistogramBe  false                   DEFAULT                true
 foreFullGC
 PrintClassHistogramAf  false                   DEFAULT                true
 terFullGC
 PrintClassHistogram    false                   DEFAULT                true
 MinHeapFreeRatio       0                       DEFAULT                true
 MaxHeapFreeRatio       100                     DEFAULT                true
 PrintConcurrentLocks   false                   DEFAULT                true
</code></pre>

<p>查看指定option</p>

<pre><code class="language-shell">[arthas@56963]$ vmoption PrintGCDetails
 KEY                    VALUE                   ORIGIN                 WRITEABLE
---------------------------------------------------------------------------------------------
 PrintGCDetails         false                   MANAGEMENT             true

</code></pre>

<p>更新指定option：</p>

<pre><code class="language-shell">[arthas@56963]$ vmoption PrintGCDetails true
Successfully updated the vm option.
PrintGCDetails=true
</code></pre>

<h3 id="toc_13">sc 查看jvm已加载的类信息</h3>

<p>参数说明：<br/>
<figure><img src="media/15773440983590/15978503405145.jpg" alt=""/></figure></p>

<pre><code class="language-text">#模糊搜索
$ sc demo.*
demo.MathGame
Affect(row-cnt:1) cost in 55 ms.

</code></pre>

<h3 id="toc_14">sm 查看已加载类的方法信息</h3>

<h3 id="toc_15">classloader 查看 classloader的继承树，urls，类加载信息</h3>

<h3 id="toc_16">heapdum 类似jmap命令的heap dump功能</h3>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[InnoDB 存储引擎]]></title>
    <link href="http://www.throne4j.com/15973328663419.html"/>
    <updated>2020-08-13T23:34:26+08:00</updated>
    <id>http://www.throne4j.com/15973328663419.html</id>
    <content type="html"><![CDATA[
<p>InnoDB存储引擎支持事务，其设计目标主要面向在线事务处理（OLTP）的应用。</p>

<p>其特点是</p>

<ul>
<li>行锁设计</li>
<li>支持外检- 支持外键</li>
<li>非锁定读（默认读取操作不会产生锁）</li>
</ul>

<p>InnoDB存储引擎将数据放在一个逻辑的表空间中，这块空间有它自己进行管理。</p>

<p>InnoDB使用多版本并发控制（MVCC）来获得高并发性，并且实现了sql的标准的4中隔离级别，默认 repeatable级别。</p>

<p>使用一种被称为next-key locking的策略来避免幻读现象的产生。</p>

<p>InnoDB关键特性提供高性能和高可用性：</p>

<ul>
<li>插入缓冲 </li>
<li>二次写</li>
<li>自适应哈希索引</li>
<li>异步IO</li>
<li>刷新临近页</li>
<li>预读</li>
</ul>

<p>InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。</p>

<p>InnoDB的整体架构包括多个内存组成的多个后台线程和缓冲池。</p>

<h2 id="toc_0">InnoDB 多后台线程</h2>

<p>InnoDB存储引擎是多线程模型，其后台线程执行不同的任务</p>

<ul>
<li>Master Thread：负责将缓冲池中的数据异步刷新到硬盘</li>
<li>IO Thread：负责InnoDB存储引擎中的大量的AIO的请求回调处理</li>
<li>Purge thread：事务提交后，其所使用的的undolog可能不在需要，此线程是回收已经使用并分配的undo页</li>
<li>Page cleaner thread：刷新脏页</li>
</ul>

<h2 id="toc_1">缓冲池</h2>

<p>InnoDB是基于磁盘存储的，为了提高数据库的整体性能，引入了缓冲池技术。</p>

<p>在数据库中进行读取页的操作首先将从磁盘读取到的页存放在缓冲池中，这个过程称为“FIX”在缓冲池中，下次读取相同页的时候，首先判断页是否在缓冲池中，若在，称该页在缓冲池中被命中，否则从磁盘上读取该页数据。</p>

<p>对数据库中的页进行修改操作，首先修改缓冲池中的页，在以一定频路刷新到磁盘，但是并不是每次页发生改变的时候就进行刷新，而是通过一种称为 Checkpoint的机制刷新回磁盘。</p>

<p>因此缓冲池的大小直接影响着数据库的整体性能。</p>

<p>缓冲池中缓冲的数据页类型主要有如下几种：</p>

<ul>
<li>索引页</li>
<li>数据页</li>
<li>undo页</li>
<li>插入缓冲页（insert buffer）</li>
<li>自适应哈希索引（adaptive hash index）</li>
<li>InnoDB 存储的锁信息（lock info）</li>
<li>数据字典信息</li>
</ul>

<p>允许有多个缓冲池实例，每个页根据hash值平均分派到不同的缓冲池实例中，可以减少数据库内部资源的竞争，增加数据库的并发处理能力。</p>

<p>缓冲池中的页通过LRU（Latest recent used，最近最少使用）算法来进行管理的。使用最频繁的页放在 LRU 列表的前端。</p>

<p>缓冲池的默认大小是16KB,也可能将页进行压缩然后存放到unzip_LRU列表进行管理。</p>

<p>在LRU列表中的页被修改后，称该页为 脏页，即缓冲池中的页和磁盘中的页数据不一致了。这是数据库通过checkpoint机制将脏页刷新会磁盘。Flush列表中的页即为脏页列表。</p>

<p>通过 show engine innodb status命令查看innodb的状态</p>

<pre><code class="language-text">&gt; show engine innodb status;
.....
BUFFER POOL AND MEMORY
----------------------
Total large memory allocated 137363456
Dictionary memory allocated 415854
Buffer pool size   8191  缓冲池大小
Free buffers       6922  剩余缓存
Database pages     1264 页数量
Old database pages 486  
Modified db pages  0    脏页数量
Pending reads      0
Pending writes: LRU 0, flush list 0, single page 0
Pages made young 0, not young 0
0.00 youngs/s, 0.00 non-youngs/s
Pages read 1122, created 142, written 150
0.00 reads/s, 0.00 creates/s, 0.00 writes/s
No buffer pool page gets since the last printout
Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s
LRU len: 1264, unzip_LRU len: 0
I/O sum[0]:cur[0], unzip sum[0]:cur[0]

</code></pre>

<h3 id="toc_2">重做日志缓冲</h3>

<p>InnoDB 存储引擎的内存区域除了有缓冲池外，还有重做日志缓冲（redo log buffer）。innodb存储引擎首先将重做日志信息放入这个缓冲区，然后按照一定频率将其刷新到重做日志文件。这个区域不用设置很大，基本是每秒产生的事务量在这个缓冲大小之内即可(innodb_log_buffer_size参数设置其大小，通常8MB可以满足大部分应用)。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[初识 MySql数据库]]></title>
    <link href="http://www.throne4j.com/15973285844161.html"/>
    <updated>2020-08-13T22:23:04+08:00</updated>
    <id>http://www.throne4j.com/15973285844161.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">MySql 体系结构</h2>

<p>要了解 MySql 必须牢牢记住器体系结构，如下图所示</p>

<p><figure><img src="media/15973285844161/15973287823877.jpg" alt=""/></figure></p>

<p>从上图中发现，MySql 有一下几部分组成：</p>

<ul>
<li>连接池组件</li>
<li>管理服务和工具组件</li>
<li>SQL接口组件</li>
<li>查询分析器组件</li>
<li>优化器组件</li>
<li>缓冲组件</li>
<li>插件式存储引擎</li>
<li>物理文件</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[八、java内存模型]]></title>
    <link href="http://www.throne4j.com/15972869856630.html"/>
    <updated>2020-08-13T10:49:45+08:00</updated>
    <id>http://www.throne4j.com/15972869856630.html</id>
    <content type="html"><![CDATA[
<p>MMU：虚拟地址映射<br/>
MMAP：</p>

<p>大小端存储</p>

<p>偏向延迟</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[七、 JVM 性能调优]]></title>
    <link href="http://www.throne4j.com/15962980278783.html"/>
    <updated>2020-08-02T00:07:07+08:00</updated>
    <id>http://www.throne4j.com/15962980278783.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、调优需要考虑的内容</h2>

<p>业务场景的设定，计算内存需求，选定cpu，选择合适垃圾回收器，设定新生代大小、分代年龄，设定日志参数</p>

<h2 id="toc_1">2、apache bench 压测工具进行接口优化</h2>

<p>ab -c 10 -n 100 url<br/>
其中－n表示请求数，－c表示并发数</p>

<pre><code class="language-shell">&gt; ab -c 10 -n 100 https://www.baidu.com

....

Server Software:        BWS/1.1
Server Hostname:        www.baidu.com
Server Port:            443
SSL/TLS Protocol:       TLSv1.2,ECDHE-RSA-AES128-GCM-SHA256,2048,128
Server Temp Key:        ECDH P-256 256 bits
TLS Server Name:        www.baidu.com

Document Path:          /
Document Length:        227 bytes

# 并发请求数
Concurrency Level:      100
# 整个测试持续的时间
Time taken for tests:   0.849 seconds
# 完成的请求数
Complete requests:      100
# 失败的请求数
Failed requests:        0
# 整个场景中的网络传输量
Total transferred:      108197 bytes
# 整个场景中的HTML内容传输量
HTML transferred:       22700 bytes
# 吞吐率
Requests per second:    117.76 [#/sec] (mean)
# 用户平均请求等待时间
Time per request:       849.153 [ms] (mean)
# 服务器平均请求处理时间
Time per request:       8.492 [ms] (mean, across all concurrent requests)
# 平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题
Transfer rate:          124.43 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:       62  541 150.3    662     666
Processing:    15  148 120.4     61     295
Waiting:       11  146 118.8     61     291
Total:         76  689  66.5    704     773

Percentage of the requests served within a certain time (ms)
  50%    704
  66%    710
  75%    714
  80%    716
  90%    723
  95%    725
  98%    731
  99%    773
 100%    773 (longest request)
</code></pre>

<p>性能指标：</p>

<ul>
<li><p>吞吐率（Requests per second）<br/>
概念：服务器并发处理能力的量化描述，单位是reqs/s，指的是某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。<br/>
计算公式：总请求数 / 处理完成这些请求数所花费的时间，即<br/>
Request per second = Complete requests / Time taken for tests</p></li>
<li><p>用户平均请求等待时间（Time per request）<br/>
计算公式：处理完成所有请求数所花费的时间/ （总请求数 / 并发用户数），即<br/>
Time per request = Time taken for tests /（ Complete requests / Concurrency Level）</p></li>
<li><p>服务器平均请求等待时间（Time per request: across all concurrent requests）<br/>
计算公式：处理完成所有请求数所花费的时间 / 总请求数，即<br/>
Time taken for / testsComplete requests<br/>
可以看到，它是吞吐率的倒数。<br/>
同时，它也=用户平均请求等待时间/并发用户数，即<br/>
Time per request / Concurrency Level</p></li>
</ul>

<h2 id="toc_2">3、gc优化</h2>

<p>首先把优化策略发出来：</p>

<ul>
<li><p>新生代大小选择</p>
<ul>
<li>响应时间优先的应用:尽可能设大,直到接近系统的最低响应时间限制(根据实际情况选择)。在此种情况下,新生代收集发生的频率也是最小的。同时,减少到达老年代的对象。</li>
<li>吞吐量优先的应用:尽可能的设置大,可能到达 Gbit 的程度.因为对响应时间没有要求,垃圾收集可以并行进行,一般适合 8CPU 以上的应用。</li>
<li>避免设置过小.当新生代设置过小时会导致:1.MinorGC 次数更加频繁 2.可能导致 MinorGC 对象直接进入老年代,如果此时老年代满了,会触发FullGC. </li>
</ul></li>
<li><p>老年代大小选择</p>
<ul>
<li>响应时间优先的应用:老年代使用并发收集器,所以其大小需要小心设置,一般要考虑并发会话率和会话持续时间等一些参数.如果堆设置小了,可能会造成内存碎片,高回收频率以及应用暂停而使用传统的标记清除方式; 如果堆大了,则需要较长的收集时间。<br/>
最优化的方案,一般需要参考以下数据获得:并发垃圾收集信息、持久代并发收集次数、传统 GC 信息、花在新生代和老年代回收上的时间比例。</li>
<li>吞吐量优先的应用:一般吞吐量优先的应用都有一个很大的新生代和一个较小的老年代.原因是,这样可以尽可能回收掉大部分短期对象,减少中期的对象,而 老年代尽存放长期存活对象。</li>
</ul></li>
</ul>

<h3 id="toc_3">3.1、gc性能指标</h3>

<ul>
<li><p>吞吐量:这里的衡量吞吐量是指应用程序所花费的时间和系统总运行时间的比值。<br/>
我们可以按照这个公式来计算 GC 的吞吐量:系统总运行时间 = 应用程序耗时 +GC 耗时。如果系统运行了 100 分钟，GC 耗时 1 分钟，则系统吞吐量为 99%。GC 的吞吐量一般不能低于 95%。</p></li>
<li><p>停顿时间: 指垃圾回收器正在运行时，应用程序的暂停时间。<br/>
对于串行回收器而言，停顿时间可能会比较长;而使用并发回收器，由于垃圾收集器和应用程序交替 运行，程序的停顿时间就会变短，但其效率很可能不如独占垃圾收集器，系统的吞吐量也很可能会降低。</p></li>
<li><p>垃圾回收频率: 通常垃圾回收的频率越低越好，增大堆内存空间可以有效降低垃圾回收发生的频率，但同时也意味着堆积的回收对象越多，最终也会增加回收时的停顿 时间。所以我们需要适当地增大堆内存空间，保证正常的垃圾回收频率即可。</p></li>
</ul>

<h3 id="toc_4">3.2、GC 调优策略</h3>

<h4 id="toc_5">3.2.1、降低 Minor GC 频率</h4>

<p>由于新生代空间较小，Eden 区很快被填满，就会导致频繁 Minor GC，因此我们可以通过增大新生代空间来降低 Minor GC 的频率。 单次 Minor GC 时间是由两部分组成:T1(扫描新生代)和 T2(复制存活对象)。</p>

<p>情况 1: 假设一个对象在 Eden 区的存活时间为 500ms，Minor GC 的时间间隔是 300ms，因为这个对象存活时间 &gt; 间隔时间，那么正常情况下，Minor GC 的时间为 :T1+T2。</p>

<p>情况 2:当我们增大新生代空间，Minor GC 的时间间隔可能会扩大到 600ms，此时一个存活 500ms 的对象就会在 Eden 区中被回收掉，此时就不 存在复制存活对象了，所以再发生 Minor GC 的时间为:即 <code>T1*2(空间大了)+T2*0</code><br/>
可见，扩容后，Minor GC 时增加了 T1，但省去了 T2 的时间。</p>

<p>在 JVM 中，复制对象的成本要远高于扫描成本。如果在堆内存中存在较多的长期存活的对象，此时增加年轻代空间，反而会增加 Minor GC 的时间。如 果堆中的短期对象很多，那么扩容新生代，单次 Minor GC 时间不会显著增加。因此，单次 Minor GC 时间更多取决于 GC 后存活对象的数量，而非 Eden 区的大小。</p>

<h4 id="toc_6">3.2.2、降低 Full GC 的频率</h4>

<p>由于堆内存空间不足或老年代对象太多，会触发 Full GC，频繁的 Full GC 会带来上下文切换，增加系统的性能开销。 </p>

<p>减少创建大对象: 在平常的业务场景中，我们一次性从数据库中查询出一个大对象用于 web 端显示。比如，一次性查询出 60 个字段的业务操作，这种大对象如果超过年轻代最大对象阈值，会被直接创建在老年代; 即使被创建在了年轻代，由于年轻代的内存空间有限，通过 Minor GC 之后也会进入到老年代。</p>

<p>这种大对象很容易产生较多的 Full GC。 增大堆内存空间:在堆内存不足的情况下，增大堆内存空间，且设置初始化堆内存为最大堆内存，也可以降低 Full GC 的频率。</p>

<h2 id="toc_7">4、问题排查</h2>

<h3 id="toc_8">4.1、CPU占用过高排查</h3>

<p>使用top命令查看进程各种运行状况，请参考<a href="15983681960215.html">linux和macOS下top命令区别</a></p>

<p>1、先通过 top 命令找到消耗 cpu 很高的进程 PID<br/>
<figure><img src="media/15962980278783/15983692600595.jpg" alt="" style="width:1008px;"/></figure></p>

<p>2、执行 top -p PID 单独监控该进程<br/>
3、在第 2 步的监控界面输入 H，获取当前进程下的所有线程信息<br/>
4、找到消耗 cpu 特别高的线程编号，假设是 2734(要等待一阵)<br/>
5、执行 jstack PID 对当前的进程做 dump，输出所有的线程信息<br/>
6、将第 4 步得到的线程编号 PID 转成 16 进制是 0x???<br/>
7、根据第 6 步得到的 0x??? 在第 5 步的线程信息里面去找对应线程内容<br/>
8、解读线程信息，定位具体代码位置，此处可能并不是代码问题引起的cpu占用过高，可能由于 GC 引起频繁的垃圾回收，可使用jstat -gc 250 10查看gc统计情况<a href="%5B%E5%9B%9B%E3%80%81JVM%E8%87%AA%E5%8A%A8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86--%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%EF%BC%8C%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%5D(15773440983590.html)"></a></p>

<h3 id="toc_9">4.2、内存占用过高</h3>

<p>可以使用jmap命令来查看堆空间信息<br/>
打印出排名前20的对象<br/>
jmap –histo JVM_ID | head -20</p>

<p><figure><img src="media/15962980278783/15983702156050.jpg" alt=""/></figure></p>

<p>从此命令的返回结果中可以看出排名前几的可能就是引发内存占用过高的对象，进而找出那部分代码出了问题</p>

<h3 id="toc_10">4.3、总结</h3>

<p>在 JVM 出现性能问题的时候。(表现上是 CPU100%，内存一直占用)<br/>
1、 如果 CPU 的 100%，要从两个角度出发，一个有可能是业务线程疯狂运行，比如说想很多死循环。还有一种可能性，就是 GC 线程在疯狂的回收，因<br/>
为 JVM 中垃圾回收器主流也是多线程的，所以很容易导致 CPU 的 100%<br/>
2、 在遇到内存溢出的问题的时候，一般情况下我们要查看系统中哪些对象占用得比较多，我的是一个很简单的代码，在实际的业务代码中，找到对应的<br/>
对象，分析对应的类，找到为什么这些对象不能回收的原因，就是我们前面讲过的可达性分析算法，JVM 的内存区域，还有垃圾回收器的基础，当然， 如果遇到更加复杂的情况，你要掌握的理论基础远远不止这些(JVM 很多理论都是排查问题的关键)</p>

<h2 id="toc_11">5、常见问题</h2>

<h3 id="toc_12">5.1、超大对象</h3>

<p>代码中创建了很多大对象 , 且一直因为被引用不能被回收，这些大对象会进入老年代，导致内存一直被占用，很容易引发 GC 甚至是 OOM</p>

<h3 id="toc_13">5.2、内存泄漏</h3>

<p>大量对象引用没有释放，JVM 无法对其自动回收。</p>

<p>内存泄漏和内存溢出辨析：<br/>
内存溢出:实实在在的内存空间不足导致; 内存泄漏:该释放的对象没有释放，常见于使用容器保存元素的情况下。 </p>

<p>如何避免:<br/>
内存溢出:检查代码以及设置足够的空间 内存泄漏:一定是代码有问题 往往很多情况下，内存溢出往往是内存泄漏造成的。</p>

<h3 id="toc_14">5.3、长生命周期的对象持有短生命周期对象的引用</h3>

<p>例如将 HashMap 设置为静态变量，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏</p>

<h3 id="toc_15">5.4、连接未关闭</h3>

<p>如数据库连接、网络连接和 IO 连接等，只有连接被关闭后，垃圾回收器才会回收对应的对象。</p>

<h3 id="toc_16">5.5、变量作用域不合理</h3>

<p>例如，1.一个变量的定义的作用范围大于其使用范围，2.如果没有及时地把对象设置为 null</p>

<h2 id="toc_17">6、MAT Analyzer(TODO)</h2>

<p>MAT(Memory Analyzer Tool)工具是eclipse的一个插件(MAT也可以单独使用)，使用起来非常方便，尤其是在分析大内存的dump文件时，可以非常直观的看到各个对象在堆空间中所占用的内存大小、类实例数量、对象引用关系、利用OQL对象查询，以及可以很方便的找出对象GC Roots的相关信息，当然最吸引人的还是能够快速为开发人员生成内存泄露报表，方便定位问题和分析问题。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[五、深入理解JVM---垃圾回收机制]]></title>
    <link href="http://www.throne4j.com/15960948965127.html"/>
    <updated>2020-07-30T15:41:36+08:00</updated>
    <id>http://www.throne4j.com/15960948965127.html</id>
    <content type="html"><![CDATA[
<p>对java的垃圾回收机制来说，我们需要考虑3个问题</p>

<ol>
<li>哪些内存需要回收</li>
<li>什么时候回收</li>
<li>如何回收</li>
</ol>

<p>引用计数算法</p>

<p>给对象添加一个引用计数器，当一个地方引用它，则计数器加1，引用失效，计数器减1，任何时候 计数器为0 的对象就是不可在此使用的对象。<br/>
它很难解决对象直减的相互循环引用的问题。  </p>

<pre><code class="language-text">
/**
 * 这个示例展示两个对象相互引用，程序计数器不会为0的，
 * 如果gc采用引用计数算法，这两个对象将不会得到回收。
 * 但实际情况是，这两个对象得到了回收，hospital jvm采用的不是引用计数垃圾回收算法。
 * -XX:+PrintGCDetails -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8
 *
 * @author qinshengke
 * @since 2020/1/9
 */
public class ReferenceCountingGC {

    public Object instance = null;

    private static final int _1MB = 1024 * 1024;

    private byte[] bigSize = new byte[2 * _1MB];

    public static void testGC() {
        ReferenceCountingGC objA = new ReferenceCountingGC();
        ReferenceCountingGC objB = new ReferenceCountingGC();
        objA.instance = objB;
        objB.instance = objA;

        objA = null;
        objB = null;

        System.gc();
    }


    public static void main(String[] args) {
        testGC();
    }
}
垃圾回收结果
[GC (System.gc()) [PSYoungGen: 8028K-&gt;624K(76288K)] 8028K-&gt;632K(251392K), 0.0016257 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[Full GC (System.gc()) [PSYoungGen: 624K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;418K(175104K)] 632K-&gt;418K(251392K), [Metaspace: 3153K-&gt;3153K(1056768K)], 0.0134161 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
Heap
 PSYoungGen      total 76288K, used 1966K [0x000000076ab00000, 0x0000000770000000, 0x00000007c0000000)
  eden space 65536K, 3% used [0x000000076ab00000,0x000000076aceb9e0,0x000000076eb00000)
  from space 10752K, 0% used [0x000000076eb00000,0x000000076eb00000,0x000000076f580000)
  to   space 10752K, 0% used [0x000000076f580000,0x000000076f580000,0x0000000770000000)
 ParOldGen       total 175104K, used 418K [0x00000006c0000000, 0x00000006cab00000, 0x000000076ab00000)
  object space 175104K, 0% used [0x00000006c0000000,0x00000006c0068b30,0x00000006cab00000)
 Metaspace       used 3173K, capacity 4496K, committed 4864K, reserved 1056768K
  class space    used 356K, capacity 388K, committed 512K, reserved 1048576K
</code></pre>

<p>根搜索算法 GC Roots Tracing <br/>
可作为GC Roots的对象包括下面几种：</p>

<ul>
<li>虚拟机栈(栈帧中的本地变量表)中的引用对象</li>
<li>方法区中的类静态属性引用的对象</li>
<li>方法区中的常量引用的对象</li>
<li>本地方法中JNI引用的对象</li>
</ul>

<p>方法区主要回收两部分的内容： 废弃常量和无用类。<br/>
类回收需要满足如下3个条件：</p>

<ul>
<li>该类所有的实例都已经别GC,也就是JVM中不存在该Class的任何实例</li>
<li>加载该类的ClassLoader已经被GC</li>
<li>该类对应的java.lang.Class对象没有在任何地方被引用，如不能在任何地方通过反射访问该类的方法。</li>
</ul>

<p>常见的垃圾收集算法(gc)</p>

<ul>
<li>标记-清除算法 mark-sweep</li>
<li>标记整理算法 mark-compact</li>
<li>复制算法 copying</li>
<li>分代算法 generational</li>
</ul>

<p>年轻代</p>

<ul>
<li>新生成的对象都放在新生代，<strong>年轻代用复制算法进行gc</strong>(理论上，年轻代对象的生命周期非常短，是和复制算法)</li>
<li>年轻代分为3个区域，Eden区、from survivor、 to survivor，Eden区满的时候，还存活的对象将被复制到一个from survivor，当from survivor区域满了之后，依然存活的对象被移动到to survivor 区域，to survivor区域满了之后，依然存活的对象会被复制到老年代。</li>
<li>Eden和两个survivor的缺省比例是8:1:1</li>
</ul>

<p>老年代</p>

<ul>
<li>存放了经过一个或多次GC还存活的对象</li>
<li>一般采用Mark-Sweep或者Mark-Compact算法进行GC</li>
<li>有多种垃圾收集器可以选择。每种垃圾收集器可以看做一个GC算法的具体实现。可以根据具体应用的需求选用何时的垃圾收集器(追求吞吐量还是追求最短的湘阴那个时间？)</li>
</ul>

<p>大对象在内存中会直接分配到老年代上<br/>
原子类型的内存分批是分配在java虚拟机栈上</p>

<h2 id="toc_0">垃圾回收</h2>

<p>GC要做的是将那些死亡(没有被引用对象)的对象所占用的内存回收掉。在进行full gc的时候会对Reference类型的应用那个进行特殊处理。<br/>
无论是引用计数算法还是根搜索算法，都和对象的引用有关，那么我们看一下java中的引用概念，java将引用分为强引用、软引用、弱引用、虚引用四种</p>

<ul>
<li>强引用是通过new关键字创建的对象，只要存在强引用，则垃圾回收机制不能对此对象进行回收；</li>
<li>软引用是用来描述非必须对象的，它通过SoftReference类实现的，软引用在JVM将要发生内存溢出时或者长期没有被使用的会将此类引用纳入可回收的范围内进行回收</li>
<li>弱引用 也是藐视非必须对象的，它通过WeekReference类实现，但是它的地位要比软引用还要低，它存活于下一次垃圾回收之前，当下一次垃圾回收发生时，弱引用也会被回收掉。</li>
<li>虚引用，它是最弱的一种引用关系，一个对象是否有序引用的存在，完全不会影响其生存时间，一万五发通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是希望在这个对象被收集器回收时收到一个系统通知。</li>
</ul>

<p>在根算法中不可达的对象，这个对象至少要经历两次标记过程，算法得出对象不可达后，第一次标记并进行一次筛选(根据对象是否有必要执行finalize()</p>

<ul>
<li>如果对象没有覆写finalize()方法</li>
<li>finalize()方法已经被虚拟机调用过<br/>
以上两种情况被视为没有必要执行回收操作</li>
</ul>

<p>如果对象被判定有必要执行finalize()方法，那么这个对象会被放置在一个名为F-Queue的队列之中，稍后由一条虚拟机自动建立的、低优先级的Finalizer线程去执行。</p>

<p>年轻代的垃圾收集算法有 Serial、ParNew、Parallel Scavenge<br/>
老年代的垃圾收集算法有 CMS、Serial Old(MSC)、Parallel Old</p>

<p>[GC (Allocation Failure) [PSYoungGen: 2615K-&gt;663K(9216K)] 9783K-&gt;7839K(19456K), 0.0017269 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] </p>

<p>(Allocation Failure)  gc触发原因<br/>
2615K: 新生代gc时存活的对象<br/>
663K： 新生代gc后存活的对象大小<br/>
9216K: 新生代中总大小</p>

<p>9783K: 堆中存活的对象大小<br/>
7839K:</p>

<h3 id="toc_1">GC的时机</h3>

<ul>
<li>在分代模型的基础上，GC从时机上分为两种: Scavenge GC和Full GC</li>
<li>Scavenge GC(Minor GC)
<ul>
<li>触发时机: 新对象生成时，Eden空间满了</li>
<li>理论上Eden区域大多数对象会在Scavenge GC 回收，复制算法的执行效率会非常高，Scavenge GC时间比较短。</li>
</ul></li>
<li>Full GC 
<ul>
<li>对整个JVM进行整理吗，包括Young、old和Perm/MetaSpace</li>
<li>主要的触发时机: <br/>
a) Old满了 <br/>
b) Perm/MetaSpace满了<br/>
c) System.gc()</li>
<li>效率低，尽量减少Full GC。</li>
</ul></li>
</ul>

<h4 id="toc_2">垃圾回收器</h4>

<h5 id="toc_3">Serial</h5>

<p>单线程收集器，收集时会暂停所有的工作线程</p>

<ul>
<li>最早的收集器，单线程执行</li>
<li>New和Old Generation都可以使用</li>
<li>在新生代采用复式算法；在老年代使用Mark-Compact算法</li>
<li>虚拟机运行在client模式时的默认新生代垃圾收集器。</li>
</ul>

<h5 id="toc_4">ParNew收集器</h5>

<ul>
<li>ParNew收集器是Serial收集器的多线程版本</li>
<li>虚拟机运行在Server模式的默认新生代收集器</li>
<li>通过-XX:ParallelGCThreads来控制GC线程数的多少</li>
</ul>

<h5 id="toc_5">Parallel Scavenge 收集器</h5>

<ul>
<li>多线程收集器</li>
<li>采用复制算法</li>
<li>实现以吞吐量最大化为目标(允许较长时间内的STOP THE WORLD)</li>
</ul>

<h5 id="toc_6">CMS (Concurrent mark sweep)</h5>

<ul>
<li>以最短停顿时间为目标的垃圾收集器</li>
<li>采用 标记-清除算法 mark-sweep</li>
</ul>

<p>缺点：</p>

<ul>
<li>以牺牲CPU资源为代价来提高gc吞吐量</li>
<li>会产生内存碎片，可能导致频繁的Full GC操作<br/>
##### Serial Old(MSC)、</li>
<li>采用Mark-compact算法</li>
</ul>

<h5 id="toc_7">Parallel Old</h5>

<ul>
<li>Parallel Scavenge 在老年代的实现</li>
<li>采用Mark-compact算法</li>
<li>更注重吞吐量</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TCP/IP协议]]></title>
    <link href="http://www.throne4j.com/15957430515176.html"/>
    <updated>2020-07-26T13:57:31+08:00</updated>
    <id>http://www.throne4j.com/15957430515176.html</id>
    <content type="html"><![CDATA[
<p><figure><img src="media/15955594725422/15955601439229.jpg" alt=""/></figure></p>

<h2 id="toc_0">1、计算机网络体系结构分层</h2>

<p><figure><img src="media/15955594725422/15955601585104.jpg" alt=""/></figure></p>

<p><figure><img src="media/15955594725422/15955601789832.jpg" alt=""/></figure><br/>
TCP/IP 与 OSI 在分层模块上稍有区别。OSI 参考模型注重“通信协议必要的功能是什么”，而 TCP/IP 则更强调“在计算机上实现协议应该开发哪种程序”。</p>

<h2 id="toc_1">2、 TCP/IP基础</h2>

<h3 id="toc_2">2.1、TCP/IP 的具体含义</h3>

<p>从字面意义上讲，有人可能会认为 TCP/IP 是指 TCP 和 IP 两种协议。实际生活当中有时也确实就是指这两种协议。然而在很多情况下，它只是利用 IP 进行通信时所必须用到的协议群的统称。具体来说，IP 或 ICMP、TCP 或 UDP、TELNET 或 FTP、以及 HTTP 等都属于 TCP/IP 协议。他们与 TCP 或 IP 的关系紧密，是互联网必不可少的组成部分。TCP/IP 一词泛指这些协议，因此，有时也称 TCP/IP 为网际协议群。互联网进行通信时，需要相应的网络协议，TCP/IP 原本就是为使用互联网而开发制定的协议族。因此，互联网的协议就是 TCP/IP，TCP/IP 就是互联网的协议。</p>

<p><figure><img src="media/15955594725422/15955738573555.jpg" alt=""/></figure></p>

<h3 id="toc_3">2.2、数据包</h3>

<p>包、帧、数据包、段、消息以上五个术语都用来表述数据的单位，大致区分如下：</p>

<ul>
<li>包可以说是全能性术语；</li>
<li>帧用于表示数据链路层中包的单位；</li>
<li>数据包是 IP 和 UDP 等网络层以上的分层中包的单位；</li>
<li>段则表示 TCP 数据流中的信息；</li>
<li>消息是指应用协议中数据的单位。</li>
</ul>

<p>每个分层中，都会对所发送的数据附加一个首部，在这个首部中包含了该层必要的信息，如发送的目标地址以及协议相关信息。通常，为协议提供的信息为包首部，所要发送的内容为数据。在下一层的角度看，从上一层收到的包全部都被认为是本层的数据。</p>

<p><figure><img src="media/15955594725422/15955739013238.jpg" alt=""/></figure></p>

<p>网络中传输的数据包由两部分组成：一部分是协议所要用到的首部，另一部分是上一层传过来的数据。首部的结构由协议的具体规范详细定义。在数据包的首部，明确标明了协议应该如何读取数据。反过来说，看到首部，也就能够了解该协议必要的信息以及所要处理的数据。包首部就像协议的脸。</p>

<h3 id="toc_4">2.3、 数据处理流程</h3>

<p>下图以用户a 向 用户b 发送邮件为例子<br/>
<figure><img src="media/15955594725422/15955739368710.jpg" alt=""/></figure></p>

<p>① 应用程序处理首先应用程序会进行编码处理，这些编码相当于 OSI 的表示层功能；编码转化后，邮件不一定马上被发送出去，这种何时建立通信连接何时发送数据的管理功能，相当于 OSI 的会话层功能。<br/>
② TCP 模块的处理TCP 根据应用的指示，负责建立连接、发送数据以及断开连接。TCP 提供将应用层发来的数据顺利发送至对端的可靠传输。为了实现这一功能，需要在应用层数据的前端附加一个 TCP 首部。<br/>
③ IP 模块的处理IP 将 TCP 传过来的 TCP 首部和 TCP 数据合起来当做自己的数据，并在 TCP 首部的前端加上自己的 IP 首部。IP 包生成后，参考路由控制表决定接受此 IP 包的路由或主机。<br/>
④ 网络接口（以太网驱动）的处理从 IP 传过来的 IP 包对于以太网来说就是数据。给这些数据附加上以太网首部并进行发送处理，生成的以太网数据包将通过物理层传输给接收端。<br/>
⑤ 网络接口（以太网驱动）的处理主机收到以太网包后，首先从以太网包首部找到 MAC 地址判断是否为发送给自己的包，若不是则丢弃数据。如果是发送给自己的包，则从以太网包首部中的类型确定数据类型，再传给相应的模块，如 IP、ARP 等。这里的例子则是 IP 。<br/>
⑥ IP 模块的处理IP 模块接收到 数据后也做类似的处理。从包首部中判断此 IP 地址是否与自己的 IP 地址匹配，如果匹配则根据首部的协议类型将数据发送给对应的模块，如 TCP、UDP。这里的例子则是 TCP。另外吗，对于有路由器的情况，接收端地址往往不是自己的地址，此时，需要借助路由控制表，在调查应该送往的主机或路由器之后再进行转发数据。<br/>
⑦ TCP 模块的处理在 TCP 模块中，首先会计算一下校验和，判断数据是否被破坏。然后检查是否在按照序号接收数据。最后检查端口号，确定具体的应用程序。数据被完整地接收以后，会传给由端口号识别的应用程序。<br/>
⑧ 应用程序的处理接收端应用程序会直接接收发送端发送的数据。通过解析数据，展示相应的内容。</p>

<h2 id="toc_5">3、传输层中的 TCP 和 UDP</h2>

<p>TCP/IP 中有两个具有代表性的传输层协议，分别是 TCP 和 UDP。</p>

<ul>
<li>TCP 是面向连接的、可靠的流协议。流就是指不间断的数据结构，当应用程序采用 TCP 发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端。TCP 为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。</li>
<li>UDP 是不具有可靠性的数据报协议。细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。</li>
<li>TCP 和 UDP 的优缺点无法简单地、绝对地去做比较：TCP 用于在传输层有必要实现可靠传输的情况；而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。TCP 和 UDP 应该根据应用的目的按需使用。</li>
</ul>

<h3 id="toc_6">3.1、端口号</h3>

<p>数据链路和 IP 中的地址，分别指的是 MAC 地址和 IP 地址。前者用来识别同一链路中不同的计算机，后者用来识别 TCP/IP  网络中互连的主机和路由器。在传输层也有这种类似于地址的概念，那就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。</p>

<h4 id="toc_7">3.1.1、根据端口号识别应用</h4>

<p>一台计算机上同时可以运行多个程序。传输层协议正是利用这些端口号识别本机中正在进行通信的应用程序，并准确地将数据传输。</p>

<p><figure><img src="media/15955594725422/15955776803707.jpg" alt=""/></figure></p>

<h4 id="toc_8">3.1.2、通过IP地址、端口号、协议号进行通信识别</h4>

<p>仅凭目标端口好识别某一个通信是远远不够的。</p>

<p><figure><img src="media/15955594725422/15955782698920.jpg" alt=""/></figure></p>

<p><figure><img src="media/15955594725422/15955782793025.jpg" alt="通过源IP地址、目标IP地址、协议号、源端口号以及目标端口号这五个元素识别一个通信"/><figcaption>通过源IP地址、目标IP地址、协议号、源端口号以及目标端口号这五个元素识别一个通信</figcaption></figure></p>

<p>① 和② 的通信是在两台计算机上进行的。它们的目标端口号相同，都是80。这里可以根据源端口号加以区分。<br/>
③ 和 ① 的目标端口号和源端口号完全相同，但它们各自的源 IP 地址不同。<br/>
此外，当 IP 地址和端口号全都一样时，我们还可以通过协议号来区分（TCP 和 UDP）。</p>

<h4 id="toc_9">3.1.3、 端口号的确定</h4>

<ul>
<li><p>标准既定的端口号<br/>
这种方法也叫静态方法。它是指每个应用程序都有其指定的端口号。但并不是说可以随意使用任何一个端口号。例如 HTTP、FTP、TELNET 等广为使用的应用协议中所使用的端口号就是固定的。这些端口号被称为知名端口号，分布在 0~1023 之间；除知名端口号之外，还有一些端口号被正式注册，它们分布在 1024~49151 之间，不过这些端口号可用于任何通信用途。</p></li>
<li><p>时序分配法<br/>
服务器有必要确定监听端口号，但是接受服务的客户端没必要确定端口号。在这种方法下，客户端应用程序完全可以不用自己设置端口号，而全权交给操作系统进行分配。动态分配的端口号范围在 49152~65535 之间。</p></li>
</ul>

<h4 id="toc_10">3.1.4、端口号与协议</h4>

<ul>
<li>端口号由其使用的传输层协议决定。因此，不同的传输层协议可以使用相同的端口号。<br/>
此外，那些知名端口号与传输层协议并无关系。只要端口一致都将分配同一种应用程序进行处理。</li>
</ul>

<h3 id="toc_11">3.2、UDP</h3>

<p>UDP 不提供复杂的控制机制，利用IP提供面向无连接的通信服务，并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为。此外，传输途中出现丢包，UDP 也不负责重发。甚至当包的到达顺序出现乱序时也没有纠正的功能。如果需要以上的细节控制，不得不交由采用 UDP 的应用程序去处理。</p>

<p>UDP 常用于一下几个方面：1.包总量较少的通信（DNS、SNMP等）；2.视频、音频等多媒体通信（即时通信）；3.限定于 LAN 等特定网络中的应用通信；4.广播通信（广播、多播）。</p>

<h3 id="toc_12">3.3、TCP</h3>

<p>TCP 与 UDP 的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。</p>

<p>根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信，主要通过一下机制来保证：</p>

<ul>
<li>检验和<br/>
TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。</li>
<li>序列号</li>
<li>确认应答</li>
<li>重发控制</li>
<li>连接管理</li>
<li>窗口控制</li>
</ul>

<h4 id="toc_13">3.3.1、三次握手</h4>

<p>TCP 提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好两端之间的准备工作。</p>

<p>所谓三次握手是指建立一个 TCP 连接时需要客户端和服务器端总共发送三个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发。</p>

<p>三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。</p>

<p>下面来看看三次握手的流程图：</p>

<p><figure><img src="media/15955594725422/15956910155926.jpg" alt=""/></figure></p>

<ul>
<li>第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给服务器端，客户端进入SYN_SENT状态，等待服务器端确认。</li>
<li>第二次握手：服务器端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器端将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务器端进入SYN_RCVD状态。</li>
<li>第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务器端，服务器端检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器端进入ESTABLISHED状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。</li>
</ul>

<h4 id="toc_14">3.3.2、四次挥手</h4>

<p>四次挥手即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发。</p>

<p>由于TCP连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。</p>

<p>下面来看看四次挥手的流程图：</p>

<p><figure><img src="media/15955594725422/15956917850227.jpg" alt=""/></figure></p>

<p>中断连接端可以是客户端，也可以是服务器端。</p>

<ul>
<li>第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说&quot;我客户端没有数据要发给你了&quot;，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。</li>
<li>第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。</li>
<li>第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。</li>
<li>第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。</li>
</ul>

<p>上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况：<br/>
<figure><img src="media/15955594725422/15956918440314.jpg" alt=""/></figure></p>

<p>SYN洪泛攻击<br/>
服务端会维护一个半连接队列 大小 &lt;= 10<br/>
无效连接监控释放、延缓TCB分配方法、防火墙</p>

<h4 id="toc_15">3.3.3、 通过序列号与确认应答提高可靠性</h4>

<p>TCP缓冲区：每个tcp的socket的内核中都有一个发送缓冲区和一个接受缓冲区</p>

<p>如何提高TCP的可靠性与高效率？<br/>
确认与重发机制、序列号</p>

<p>在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。这个消息叫做确认应答（ACK）。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。反之，则数据丢失的可能性很大。</p>

<p>在一定时间内没有等待到确认应答，发送端就可以认为数据已经丢失，并进行重发。由此，即使产生了丢包，仍然能够保证数据能够到达对端，实现可靠传输。</p>

<p>未收到确认应答并不意味着数据一定丢失。也有可能是数据对方已经收到，只是返回的确认应答在途中丢失。这种情况也会导致发送端误以为数据没有到达目的地而重发数据。</p>

<p>此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也屡见不鲜。此时，源主机只要按照机制重发数据即可。</p>

<p>对于目标主机来说，反复收到相同的数据是不可取的。为了对上层应用提供可靠的传输，目标主机必须放弃重复的数据包。为此我们引入了序列号。</p>

<p>序列号是按照顺序给发送数据的每一个字节（8位字节）都标上号码的编号。接收端查询接收数据 TCP 首部中的序列号和数据的长度，将自己下一步应该接收的序列号作为确认应答返送回去。通过序列号和确认应答号，TCP 能够识别是否已经接收数据，又能够判断是否需要接收，从而实现可靠传输。</p>

<p><figure><img src="media/15955594725422/15956919436214.jpg" alt=""/></figure></p>

<h4 id="toc_16">3.3.4、 重发超时的确定</h4>

<p>重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。如果超过这个时间仍未收到确认应答，发送端将进行数据重发。最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。</p>

<p>TCP 要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差。将这个往返时间和偏差时间相加，重发超时的时间就是比这个总和要稍大一点的值。</p>

<p>在 BSD 的 Unix 以及 Windows 系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍。不过，最初其重发超时的默认值一般设置为6秒左右。</p>

<p>数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。</p>

<p>此外，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。</p>

<h4 id="toc_17">3.3.5、 以段为单位发送数据</h4>

<p>在建立 TCP 连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS）。最理想的情况是，最大消息长度正好是 IP 中不会被分片处理的最大数据长度。</p>

<p>TCP 在传送大量数据时，是以 MSS 的大小将数据进行分割发送。进行重发时也是以 MSS  为单位。</p>

<p>MSS 在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写入 MSS  选项，告诉对方自己的接口能够适应的 MSS 的大小。然后会在两者之间选择一个较小的值投入使用。</p>

<h4 id="toc_18">3.3.6、利用窗口控制提高速度</h4>

<p>TCP 以1个段为单位，每发送一个段进行一次确认应答的处理。这样的传输方式有一个缺点，就是包的往返时间越长通信性能就越低。</p>

<p>为解决这个问题，TCP 引入了窗口这个概念。确认应答不再是以每个分段，而是以更大的单位进行确认，转发时间将会被大幅地缩短。也就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送。如下图所示：<br/>
<figure><img src="media/15955594725422/15956920512186.jpg" alt=""/></figure></p>

<p>窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。上图中窗口大小为4个段。这个机制实现了使用大量的缓冲区，通过对多个段同时进行确认应答的功能。</p>

<h4 id="toc_19">3.3.7、滑动窗口控制</h4>

<p><figure><img src="media/15955594725422/15957306505366.jpg" alt=""/></figure></p>

<p>上图中的窗口内的数据即便没有收到确认应答也可以被发送出去。不过，在整个窗口的确认应答没有到达之前，如果其中部分数据出现丢包，那么发送端仍然要负责重传。为此，发送端主机需要设置缓存保留这些待被重传的数据，直到收到他们的确认应答。</p>

<p>在滑动窗口以外的部分包括未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再进行重发，此时数据就可以从缓存区清除。</p>

<p>收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也别称为滑动窗口控制。</p>

<h4 id="toc_20">3.3.8、窗口控制中的重发控制</h4>

<p>在使用窗口控制中， 出现丢包一般分为两种情况：</p>

<ul>
<li><p>① 确认应答未能返回的情况。在这种情况下，数据已经到达对端，是不需要再进行重发的，如下图：<br/>
<figure><img src="media/15955594725422/15957353198269.jpg" alt=""/></figure></p></li>
<li><p>② 某个报文段丢失的情况。接收主机如果收到一个自己应该接收的序列号以外的数据时，会针对当前为止收到数据返回确认应答。如下图所示，当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，因此，在窗口比较大，又出现报文段丢失的情况下，同一个序列号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答，就会将其对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称为高速重发控制。<br/>
<figure><img src="media/15955594725422/15957353491515.jpg" alt=""/></figure></p></li>
</ul>

<h2 id="toc_21">4、网络层的IP协议</h2>

<p>IP（IPv4、IPv6）相当于 OSI 参考模型中的第3层——网络层。网络层的主要作用是“实现终端节点之间的通信”。这种终端节点之间的通信也叫“点对点通信”。</p>

<p>网络的下一层——数据链路层的主要作用是在互连同一种数据链路的节点之间进行包传递。而一旦跨越多种数据链路，就需要借助网络层。网络层可以跨越不同的数据链路，即使是在不同的数据链路上也能实现两端节点之间的数据包传输。</p>

<p>IP 大致分为三大作用模块，它们是 IP 寻址、路由（最终节点为止的转发）以及 IP 分包与组包。</p>

<h3 id="toc_22">4.1、IP地址</h3>

<p>在计算机通信中，为了识别通信对端，必须要有一个类似于地址的识别码进行标识。在数据链路中的 MAC 地址正是用来标识同一个链路中不同计算机的一种识别码。<br/>
作为网络层的 IP ,也有这种地址信息，一般叫做 IP 地址。IP 地址用于在“连接到网络中的所有主机中识别出进行通信的目标地址”。因此，在 TCP/IP 通信中所有主机或路由器必须设定自己的 IP 地址。<br/>
不论一台主机与哪种数据链路连接，其 IP 地址的形式都保持不变。<br/>
IP 地址（IPv4 地址）由32位正整数来表示。IP 地址在计算机内部以二进制方式被处理。然而，由于我们并不习惯于采用二进制方式，我们将32位的 IP 地址以每8位为一组，分成4组，每组以 “.” 隔开，再将每组数转换成十进制数。如下：<br/>
<figure><img src="media/15955594725422/15957356769851.jpg" alt=""/></figure></p>

<h4 id="toc_23">4.1.1、 IP 地址由网络和主机两部分标识组成</h4>

<p>如下图，网络标识在数据链路的每个段配置不同的值。网络标识必须保证相互连接的每个段的地址不相重复。而相同段内相连的主机必须有相同的网络地址。IP 地址的“主机标识”则不允许在同一个网段内重复出现。由此，可以通过设置网络地址和主机地址，在相互连接的整个网络中保证每台主机的 IP 地址都不会相互重叠。即 IP 地址具有了唯一性。<br/>
<figure><img src="media/15955594725422/15957356923189.jpg" alt="IP地址的主机标识"/><figcaption>IP地址的主机标识</figcaption></figure></p>

<p>如下图，IP 包被转发到途中某个路由器时，正是利用目标 IP 地址的网络标识进行路由。因为即使不看主机标识，只要一见到网络标识就能判断出是否为该网段内的主机。<br/>
<figure><img src="media/15955594725422/15957357130579.jpg" alt="IP地址的网络标识"/><figcaption>IP地址的网络标识</figcaption></figure></p>

<h4 id="toc_24">4.1.2、 IP 地址的分类</h4>

<p>IP 地址分为四个级别，分别为A类、B类、C类、D类。它根据 IP 地址中从第 1 位到第 4 位的比特列对其网络标识和主机标识进行区分。<br/>
A 类 IP 地址是首位以 “0” 开头的地址。从第 1 位到第 8 位是它的网络标识。用十进制表示的话，0.0.0.0~127.0.0.0 是 A 类的网络地址。A 类地址的后 24 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为16,777,214个。<br/>
B 类 IP 地址是前两位 “10” 的地址。从第 1 位到第 16 位是它的网络标识。用十进制表示的话，128.0.0.0~191.255.0.0 是 B 类的网络地址。B 类地址的后 16 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为65,534个。<br/>
C 类 IP 地址是前三位为 “110” 的地址。从第 1 位到第 24 位是它的网络标识。用十进制表示的话，192.0.0.0~223.255.255.0 是 C 类的网络地址。C 类地址的后 8 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为254个。<br/>
D 类 IP 地址是前四位为 “1110” 的地址。从第 1 位到第 32 位是它的网络标识。用十进制表示的话，224.0.0.0~239.255.255.255 是 D 类的网络地址。D 类地址没有主机标识，常用于多播。<br/>
在分配 IP 地址时关于主机标识有一点需要注意。即要用比特位表示主机地址时，不可以全部为 0 或全部为 1。因为全部为 0 只有在表示对应的网络地址或 IP 地址不可以获知的情况下才使用。而全部为 1 的主机通常作为广播地址。因此，在分配过程中，应该去掉这两种情况。这也是为什么 C 类地址每个网段最多只能有 254（ 28 - 2 = 254）个主机地址的原因。</p>

<h4 id="toc_25">4.1.3、 广播地址</h4>

<p>广播地址用于在同一个链路中相互连接的主机之间发送数据包。将 IP 地址中的主机地址部分全部设置为 1，就成了广播地址。<br/>
广播分为本地广播和直接广播两种。在本网络内的广播叫做本地广播；在不同网络之间的广播叫做直接广播。</p>

<h4 id="toc_26">4.1.4、 IP 多播</h4>

<p>多播用于将包发送给特定组内的所有主机。由于其直接使用 IP 地址，因此也不存在可靠传输。</p>

<p>相比于广播，多播既可以穿透路由器，又可以实现只给那些必要的组发送数据包。请看下图：IP 多播<br/>
<figure><img src="media/15955594725422/15957357583375.jpg" alt=""/></figure></p>

<p>多播使用 D 类地址。因此，如果从首位开始到第 4 位是 “1110”，就可以认为是多播地址。而剩下的 28 位可以成为多播的组编号。<br/>
x<br/>
此外， 对于多播，所有的主机（路由器以外的主机和终端主机）必须属于 224.0.0.1 的组，所有的路由器必须属于 224.0.0.2 的组。</p>

<h4 id="toc_27">4.1.5、 子网掩码</h4>

<p>现在一个 IP 地址的网络标识和主机标识已不再受限于该地址的类别，而是由一个叫做“子网掩码”的识别码通过子网网络地址细分出比 A 类、B 类、C 类更小粒度的网络。这种方式实际上就是将原来 A 类、B 类、C 类等分类中的主机地址部分用作子网地址，可以将原网络分为多个物理网络的一种机制。<br/>
子网掩码用二进制方式表示的话，也是一个 32 位的数字。它对应 IP 地址网络标识部分的位全部为 “1”，对应 IP 地址主机标识的部分则全部为 “0”。由此，一个 IP 地址可以不再受限于自己的类别，而是可以用这样的子网掩码自由地定位自己的网络标识长度。当然，子网掩码必须是 IP 地址的首位开始连续的 “1”。<br/>
对于子网掩码，目前有两种表示方式。第一种是，将 IP 地址与子网掩码的地址分别用两行来表示。以 172.20.100.52 的前 26 位是网络地址的情况为例，如下：<br/>
<figure><img src="media/15955594725422/15957358144400.jpg" alt=""/></figure></p>

<p>第二种表示方式是，在每个 IP 地址后面追加网络地址的位数用 “/ ” 隔开，如下：</p>

<p><figure><img src="media/15955594725422/15957358402864.jpg" alt=""/></figure></p>

<p>另外，在第二种方式下记述网络地址时可以省略后面的 “0” 。例如：172.20.0.0/26 跟 172.20/26 其实是一个意思。</p>

<h3 id="toc_28">4.2、 路由</h3>

<p>发送数据包时所使用的地址是网络层的地址，即 IP 地址。然而仅仅有 IP 地址还不足以实现将数据包发送到对端目标地址，在数据发送过程中还需要类似于“指明路由器或主机”的信息，以便真正发往目标地址。保存这种信息的就是路由控制表。</p>

<p>该路由控制表的形成方式有两种：一种是管理员手动设置，另一种是路由器与其他路由器相互交换信息时自动刷新。前者也叫做静态路由控制，而后者叫做动态路由控制。</p>

<p>IP 协议始终认为路由表是正确的。然后，IP 本身并没有定义制作路由控制表的协议。即 IP 没有制作路由控制表的机制。该表示由一个叫做“路由协议”的协议制作而成。</p>

<h4 id="toc_29">4.2.1、 IP 地址与路由控制</h4>

<p>IP 地址的网络地址部分用于进行路由控制。<br/>
路由控制表中记录着网络地址与下一步应该发送至路由器的地址。<br/>
在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择一个最为吻合的网络地址。<br/>
<figure><img src="media/15955594725422/15957359215309.jpg" alt="路由控制表与 IP 包发送"/><figcaption>路由控制表与 IP 包发送</figcaption></figure></p>

<h3 id="toc_30">4.3、 IP 分包与组包</h3>

<p>每种数据链路的最大传输单元（MTU）都不尽相同，因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。</p>

<p>任何一台主机都有必要对 IP 分片进行相应的处理。分片往往在网络上遇到比较大的报文无法一下子发送出去时才会进行处理。</p>

<p>经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行。路由器虽然做分片但不会进行重组。</p>

<h4 id="toc_31">4.3.1、 路径 MTU 发现</h4>

<p>分片机制也有它的不足。如路由器的处理负荷加重之类。因此，只要允许，是不希望由路由器进行 IP 数据包的分片处理的。<br/>
为了应对分片机制的不足，“路径 MTU 发现” 技术应运而生。路径 MTU 指的是，从发送端主机到接收端主机之间不需要分片是最大 MTU 的大小。即路径中存在的所有数据链路中最小的 MTU 。<br/>
进行路径 MTU 发现，就可以避免在中途的路由器上进行分片处理，也可以在 TCP 中发送更大的包。</p>

<h3 id="toc_32">4.4、 IPv6</h3>

<p>IPv6（IP version 6）是为了根本解决 IPv4 地址耗尽的问题而被标准化的网际协议。IPv4 的地址长度为 4 个 8 位字节，即 32 比特。而 IPv6 的地址长度则是原来的 4 倍，即 128 比特，一般写成 8 个 16 位字节。</p>

<h4 id="toc_33">4.4.1、 IPv6 的特点</h4>

<p>IP 得知的扩大与路由控制表的聚合。<br/>
性能提升。包首部长度采用固定的值（40字节），不再采用首部检验码。简化首部结构，减轻路由器负担。路由器不再做分片处理。<br/>
支持即插即用功能。即使没有DHCP服务器也可以实现自动分配 IP 地址。<br/>
采用认证与加密功能。应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能。<br/>
多播、Mobile IP 成为扩展功能。</p>

<h4 id="toc_34">4.4.2、 IPv6 中 IP 地址的标记方法</h4>

<p>一般人们将 128 比特 IP 地址以每 16 比特为一组，每组用冒号（“：”）隔开进行标记。<br/>
而且如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号（“：：”）隔开。但是，一个 IP 地址中只允许出现一次两个连续的冒号。</p>

<h4 id="toc_35">4.4.3、 IPv6 地址的结构</h4>

<p>IPv6 类似 IPv4，也是通过 IP 地址的前几位标识 IP 地址的种类。<br/>
在互联网通信中，使用一种全局的单播地址。它是互联网中唯一的一个地址，不需要正式分配 IP 地址。</p>

<p><figure><img src="media/15955594725422/15957360738922.jpg" alt=""/></figure></p>

<h4 id="toc_36">4.4.4、 全局单播地址</h4>

<p>全局单播地址是指世界上唯一的一个地址。它是互联网通信以及各个域内部通信中最为常用的一个 IPv6 地址。<br/>
格式如下图所示，现在 IPv6 的网络中所使用的格式为，n = 48，m = 16 以及 128 - n - m = 64。即前 64 比特为网络标识，后 64 比特为主机标识。<br/>
<figure><img src="media/15955594725422/15957360990321.jpg" alt="全局单播地址"/><figcaption>全局单播地址</figcaption></figure></p>

<h4 id="toc_37">4.4.5、 链路本地单播地址</h4>

<p>链路本地单播地址是指在同一个数据链路内唯一的地址。它用于不经过路由器，在同一个链路中的通信。通常接口 ID 保存 64 比特版的 MAC 地址。<br/>
<figure><img src="media/15955594725422/15957361211675.jpg" alt="链路本地单播地址"/><figcaption>链路本地单播地址</figcaption></figure></p>

<h4 id="toc_38">4.4.6、 唯一本地地址</h4>

<p>唯一本地地址是不进行互联网通信时所用的地址。<br/>
唯一本地地址虽然不会与互联网连接，但是也会尽可能地随机生成一个唯一的全局 ID。<br/>
L 通常被置为 1 <br/>
全局 ID 的值随机决定<br/>
子网 ID 是指该域子网地址<br/>
接口 ID 即为接口的 ID<br/>
<figure><img src="media/15955594725422/15957361414840.jpg" alt="唯一本地地址"/><figcaption>唯一本地地址</figcaption></figure></p>

<h4 id="toc_39">4.4.7、 IPv6 分段处理</h4>

<p>IPv6 的分片处理只在作为起点的发送端主机上进行，路由器不参与分片。<br/>
IPv6 中最小 MTU 为 1280 字节，因此，在嵌入式系统中对于那些有一定系统资源限制的设备来说，不需要进行“路径 MTU 发现”，而是在发送 IP 包时直接以 1280 字节为单位分片送出。</p>

<h2 id="toc_40">5、 IP 协议相关技术</h2>

<p>IP 旨在让最终目标主机收到数据包，但是在这一过程中仅仅有 IP 是无法实现通信的。必须还有能够解析主机名称和 MAC 地址的功能，以及数据包在发送过程中异常情况处理的功能。</p>

<h3 id="toc_41">5.1、 DNS</h3>

<p>我们平常在访问某个网站时不适用 IP 地址，而是用一串由罗马字和点号组成的字符串。而一般用户在使用 TCP/IP 进行通信时也不使用 IP 地址。能够这样做是因为有了 DNS （Domain Name System）功能的支持。DNS 可以将那串字符串自动转换为具体的 IP 地址。<br/>
这种 DNS 不仅适用于 IPv4，还适用于 IPv6。</p>

<h3 id="toc_42">5.2、 ARP</h3>

<p>只要确定了 IP 地址，就可以向这个目标地址发送 IP 数据报。然而，在底层数据链路层，进行实际通信时却有必要了解每个 IP 地址所对应的 MAC 地址。<br/>
ARP 是一种解决地址问题的协议。以目标 IP 地址为线索，用来定位下一个应该接收数据分包的网络设备对应的 MAC 地址。不过 ARP 只适用于 IPv4，不能用于 IPv6。IPv6 中可以用 ICMPv6 替代 ARP 发送邻居探索消息。<br/>
RARP 是将 ARP 反过来，从 MAC 地址定位 IP 地址的一种协议。</p>

<h3 id="toc_43">5.3、 ICMP</h3>

<p>ICMP 的主要功能包括，确认 IP 包是否成功送达目标地址，通知在发送过程当中 IP 包被废弃的具体原因，改善网络设置等。<br/>
IPv4 中 ICMP 仅作为一个辅助作用支持 IPv4。也就是说，在 IPv4 时期，即使没有 ICMP，仍然可以实现 IP 通信。然而，在 IPv6 中，ICMP 的作用被扩大，如果没有 ICMPv6，IPv6 就无法进行正常通信。</p>

<h3 id="toc_44">5.4、 DHCP</h3>

<p>如果逐一为每一台主机设置 IP 地址会是非常繁琐的事情。特别是在移动使用笔记本电脑、只能终端以及平板电脑等设备时，每移动到一个新的地方，都要重新设置 IP 地址。<br/>
于是，为了实现自动设置 IP 地址、统一管理 IP 地址分配，就产生了 DHCP（Dynamic Host Configuration Protocol）协议。有了 DHCP，计算机只要连接到网络，就可以进行 TCP/IP 通信。也就是说，DHCP 让即插即用变得可能。<br/>
DHCP 不仅在 IPv4 中，在 IPv6 中也可以使用。</p>

<h3 id="toc_45">5.5、 NAT</h3>

<p>NAT（Network Address Translator）是用于在本地网络中使用私有地址，在连接互联网时转而使用全局 IP 地址的技术。<br/>
除转换 IP 地址外，还出现了可以转换 TCP、UDP 端口号的 NAPT（Network Address Ports Translator）技术，由此可以实现用一个全局 IP 地址与多个主机的通信。<br/>
NAT（NAPT）实际上是为正在面临地址枯竭的 IPv4 而开发的技术。不过，在 IPv6 中为了提高网络安全也在使用 NAT，在 IPv4 和 IPv6 之间的相互通信当中常常使用 NAT-PT。</p>

<h3 id="toc_46">5.6、 IP 隧道夹着 IPv4 网络的两个 IPv6 网络</h3>

<p><figure><img src="media/15955594725422/15957362138379.jpg" alt=""/></figure></p>

<p>如上图的网络环境中，网络 A 与网络 B 之间无法直接进行通信，为了让它们之间正常通信，这时必须得采用 IP 隧道的功能。<br/>
IP 隧道可以将那些从网络 A 发过来的 IPv6 的包统合为一个数据，再为之追加一个 IPv4 的首部以后转发给网络 C。<br/>
一般情况下，紧接着 IP 首部的是 TCP 或 UDP 的首部。然而，现在的应用当中“ IP 首部的后面还是 IP 首部”或者“ IP 首部的后面是 IPv6 的首部”等情况与日俱增。这种在网络层的首部后面追加网络层首部的通信方法就叫做“ IP 隧道”。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP协议（六）-- 与 HTTP 协作的 Web 服务器]]></title>
    <link href="http://www.throne4j.com/15957418105856.html"/>
    <updated>2020-07-26T13:36:50+08:00</updated>
    <id>http://www.throne4j.com/15957418105856.html</id>
    <content type="html"><![CDATA[
<p>HTTP 通信时，除客户端和服务器外，还有一些用于协助通信的应用程序。如下列出比较重要的几个：代理、缓存、网关、隧道、Agent 代理。</p>

<p>1.代理<br/>
<figure><img src="media/15955168840534/15957390472021.jpg" alt="代理"/><figcaption>代理</figcaption></figure></p>

<p>HTTP 代理服务器是 Web 安全、应用集成以及性能优化的重要组成模块。代理位于客户端和服务器端之间，接收客户端所有的 HTTP 请求，并将这些请求转发给服务器（可能会对请求进行修改之后再进行转发）。对用户来说，这些应用程序就是一个代理，代表用户访问服务器。<br/>
出于安全考虑，通常会将代理作为转发所有 Web 流量的可信任中间节点使用。代理还可以对请求和响应进行过滤，安全上网或绿色上网。</p>

<ol>
<li>缓存<br/>
浏览器第一次请求：
<figure><img src="media/15955168840534/15957390923745.jpg" alt="浏览器第一次请求"/><figcaption>浏览器第一次请求</figcaption></figure></li>
</ol>

<p>浏览器再次请求：<br/>
<figure><img src="media/15955168840534/15957391037011.jpg" alt="浏览器再次请求"/><figcaption>浏览器再次请求</figcaption></figure></p>

<p>Web 缓存或代理缓存是一种特殊的 HTTP 代理服务器，可以将经过代理传输的常用文档复制保存起来。下一个请求同一文档的客户端就可以享受缓存的私有副本所提供的服务了。客户端从附近的缓存下载文档会比从远程 Web 服务器下载快得多。</p>

<ol>
<li>网关
<figure><img src="media/15955168840534/15957391163572.jpg" alt="HTTP / FTP 网关"/><figcaption>HTTP / FTP 网关</figcaption></figure></li>
</ol>

<p>网关是一种特殊的服务器，作为其他服务器的中间实体使用。通常用于将 HTTP 流量转换成其他的协议。网关接收请求时就好像自己是资源的源服务器一样。客户端可能并不知道自己正在跟一个网关进行通信。</p>

<ol>
<li>隧道
<figure><img src="media/15955168840534/15957391265275.jpg" alt="HTTP/SSL 隧道"/><figcaption>HTTP/SSL 隧道</figcaption></figure></li>
</ol>

<p>隧道是会在建立起来之后，就会在两条连接之间对原始数据进行盲转发的 HTTP 应用程序。HTTP 隧道通常用来在一条或多条 HTTP 连接上转发非 HTTP 数据，转发时不会窥探数据。</p>

<p>HTTP 隧道的一种常见用途就是通过 HTTP 连接承载加密的安全套接字层（SSL）流量，这样 SSL 流量就可以穿过只允许 Web 流量通过的防火墙了。</p>

<ol>
<li>Agent 代理
<figure><img src="media/15955168840534/15957391378461.jpg" alt="自动搜索引擎“网络蜘蛛”"/><figcaption>自动搜索引擎“网络蜘蛛”</figcaption></figure></li>
</ol>

<p>Agent 代理是代表用户发起 HTTP 请求的客户端应用程序。所有发布 Web 请求的应用程序都是 HTTP Agent 代理。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP协议（五）-- 响应状态码]]></title>
    <link href="http://www.throne4j.com/15957408756364.html"/>
    <updated>2020-07-26T13:21:15+08:00</updated>
    <id>http://www.throne4j.com/15957408756364.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">HTTP 响应状态码（重点分析）</h2>

<h3 id="toc_1">1. 状态码概述</h3>

<p>HTTP 状态码负责表示客户端 HTTP 请求的返回结果、标记服务器端的处理是否正常、通知出现的错误等工作。</p>

<p>HTTP 状态码如 200 OK ，以 3 位数字和原因短语组成。数字中的第一位指定了响应类别，后两位无分类。</p>

<p>不少返回的响应状态码都是错误的，但是用户可能察觉不到这点。比如 Web 应用程序内部发生错误，状态码依然返回 200 OK。</p>

<h3 id="toc_2">2. 状态码类别</h3>

<table>
<thead>
<tr>
<th>响应码</th>
<th>类别</th>
<th>原因短语</th>
</tr>
</thead>

<tbody>
<tr>
<td>1xx</td>
<td>Informational(信息性状态码)</td>
<td>接收的请求正在处理</td>
</tr>
<tr>
<td>2xx</td>
<td>Success(成功状态码)</td>
<td>请求正常处理完毕</td>
</tr>
<tr>
<td>3xx</td>
<td>Redirection(重定向状态码)</td>
<td>需要进行附加操作以完成请求</td>
</tr>
<tr>
<td>4xx</td>
<td>Client Error(客户端错误状态码）</td>
<td>服务器无法处理请求</td>
</tr>
<tr>
<td>5xx</td>
<td>Server Error(服务器错误状态码)</td>
<td>服务器处理请求出错</td>
</tr>
</tbody>
</table>

<p>我们可以自行改变 RFC2616 中定义的状态码或者服务器端自行创建状态码，只要遵守状态码的类别定义就可以了。</p>

<h3 id="toc_3">3. 常用状态码解析</h3>

<p>HTTP 状态码种类繁多，数量达几十种。其中最常用的有以下 14 种，一起来看看。</p>

<h4 id="toc_4">3.1 、200 OK</h4>

<p>表示从客户端发来的请求在服务器端被正常处理了。</p>

<h4 id="toc_5">3.2、 204 No Content</h4>

<p>代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。<br/>
一般在只需要从客户端向服务器端发送消息，而服务器端不需要向客户端发送新消息内容的情况下使用。</p>

<h4 id="toc_6">3.3、 206 Partial Content</h4>

<p>表示客户端进行了范围请求，而服务器成功执行了这部分的 GET 请求。响应报文中包含由 Content-Range 首部字段指定范围的实体内容。</p>

<h4 id="toc_7">3.4、 301 Moved Permanently</h4>

<p>永久性重定向。表示请求的资源已被分配了新的 URI。以后应使用资源现在所指的 URI。也就是说，如果已经把资源对应的 URI 保存为书签了，这时应该按 Location 首部字段提示的 URI 重新保存。</p>

<h4 id="toc_8">3.5、 302 Found</h4>

<p>临时性重定向。表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。</p>

<p>和 301 Moved Permanently 状态码相似，但 302 Found 状态码代表资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的 URI 将来还有可能发生改变。</p>

<h4 id="toc_9">3.6、 303 See Other</h4>

<p>表示由于请求的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源。</p>

<p>303 See Other 和 302 Found 状态码有着相同的功能，但 303 See Other 状态码明确表示客户端应采用 GET 方法获取资源，这点与 302 Found 状态码有区别。</p>

<h4 id="toc_10">3.7、 304 Not Modified</h4>

<p>表示客户端发送附带条件的请求时，服务器端允许请求访问的资源，但未满足条件的情况。</p>

<p>304 Not Modified 状态码返回时，不包含任何响应的主体部分。</p>

<p>304 Not Modified 虽然被划分到 3xx 类别中，但和重定向没有关系。</p>

<h4 id="toc_11">3.8、 307 Temporary Redirect</h4>

<p>临时重定向。该状态码与 302 Found 有着相同的含义。</p>

<h4 id="toc_12">3.9、 400 Bad Request</h4>

<p>表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。<br/>
另外，浏览器会像 200 OK 一样对待该状态码。</p>

<h4 id="toc_13">3.10、 401 Unauthorized</h4>

<p>表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。<br/>
另外，若之前已进行过 1 次请求，则表示用户认证失败。<br/>
返回含有 401 Unauthorized 的响应必须包含一个适用于被请求资源的 WWW-Authenticate 首部用以质询（challenge）用户信息。</p>

<h4 id="toc_14">3.11、 403 Forbidden</h4>

<p>表明对请求资源的访问被服务器拒绝了。服务器端没有必要给出详细的拒绝理由，当然也可以在响应报文的实体主体部分对原因进行描述。</p>

<h4 id="toc_15">3.12、 404 Not Found</h4>

<p>表明服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由的时候使用。</p>

<h4 id="toc_16">3.13、 500 Internal Server Error</h4>

<p>表明服务器端在执行请求时发生了错误。也可能是 Web 应用存在的 bug 或某些临时的故障。</p>

<h4 id="toc_17">3.14、 503 Service Unavailable</h4>

<p>表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入 Retry-After 首部字段再返回给客户端。</p>

]]></content>
  </entry>
  
</feed>
