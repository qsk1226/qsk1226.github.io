<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大爷来玩儿啊~]]></title>
  <link href="http://www.throne4j.com/atom.xml" rel="self"/>
  <link href="http://www.throne4j.com/"/>
  <updated>2020-07-20T23:56:38+08:00</updated>
  <id>http://www.throne4j.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[过期键的删除策略]]></title>
    <link href="http://www.throne4j.com/15952588914829.html"/>
    <updated>2020-07-20T23:28:11+08:00</updated>
    <id>http://www.throne4j.com/15952588914829.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">redis过期键删除策略</h2>

<p>一个键过期了，它什么时候被删除呢？</p>

<p>Redis 服务器采用惰性删除策略和定期删除两种策略，通过分配使用这两种删除策略，redis服务器可以很好的利用cpu时间和避免内存浪费之间取得一个较好的平衡</p>

<ul>
<li>定时删除:在设置键的过期时间的同时,创建一个定时器( timer),让定时器在键的过期时间来临时,立即执行对键的删除操作。</li>
<li>惰性删除:放任键过期不管,但是每次从键空间中获取健时,都检查取得的键是否过期,如果过期的话,就删除该键;如果没有过期,就返回该键。</li>
<li>定期删除:每隔一段时间,程序就对数据库进行一次检查,删除里面的过期键。至于要删除多少过期键,以及要检査多少个数据库,则由算法决定。<br/>
在这三种策略中,第一种和第三种为主动删除策略,而第二种则为被动删除策略。</li>
</ul>

<h2 id="toc_1">定时删除策略</h2>

<p>定时删除策略，设置键过期时间的同时，创建定时器，让定时器在键的过期时间来来临时立即执行对键的删除操作。</p>

<p>优点是：可以保证过期键会尽可能快的被删除，并释放过期键所占用的内存，</p>

<p>但缺点也很明显：会占用一定的cpu时间，影响服务器的响应时间和吞吐量，</p>

<p>除此之外，创建定时器需要用到 redis 服务器的时间事件，而当前时间事件的实现方式是无序链表，查找一个时间的时间复杂度为 O(N)，并不能高效的处理大量的时间事件。</p>

<h2 id="toc_2">惰性删除策略</h2>

<p>惰性删除策略，访问数据库键时，校验该键是否过期，如果过期则删除</p>

<p>优点是：对cpu时间来说最友好，程序只会在取出键时才对键进行过期检查，可以保证删除过期键的操作只会在费做不可的情况下进行，并且删除过期键的操作仅限当前处理的键，</p>

<p>但是此种策略非常占用内存，有内存泄漏的风险，已过期的键不会立马删除，占着内存直到下次访问时才会释放内存空间。</p>

<h2 id="toc_3">定期删除策略</h2>

<p>定期删除策略，周期性删除过期键，redisServer启动过程最后一步(开启事件循环，会触发Redis的定时任务的时间事件，查看 <a href="15934396305281.html">三、redis命令处理生命周期</a>) </p>

<ul>
<li>每个一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对cpu时间的影响</li>
<li>通过定期删除过期键，有效的减少了过期键带来的内存损耗。</li>
</ul>

<p>定期删除策略的难点是确定删除操作执行的时长和频率：</p>

<ul>
<li>如果删除操作执行得太频繁,或者执行的时间太长,定期删除策略就会退化成定时除策略,以至于将CPU时间过多地消耗在删除过期键上面。</li>
<li>如果删除操作执行得太少,或者执行的时间太短,定期删除策略又会和惰性删除策略一样,出现浪费内存的情况。</li>
</ul>

<h2 id="toc_4">AOF、RDB和复制功能对过期键的处理</h2>

<h3 id="toc_5">RDB 文件生成</h3>

<p>在执行SAⅣE命令或者 BGSAVE命令创建一个新的RDB文件时,程序会对数据库中的键进行检查,已过期的键不会被保存到新创建的RDB文件中。</p>

<h3 id="toc_6">载入RDB文件</h3>

<p>在启动 Redis服务器时,如果服务器开启了RDB功能,那么服务器将对RDB文件进行载人: </p>

<ul>
<li>如果服务器以主服务器模式运行,那么在载入RDB文件时,程序会对文件中保存的键进行检查,未过期的键会被载入到数据库中,而过期键则会被忽略,所以过期键对载入RDB文件的主服务器不会造成影响</li>
<li>如果服务器以从服务器模式运行,那么在载入RDB文件时,文件中保存的所有键, 不论是否过期,都会被载人到数据库中。不过,因为主从服务器在进行数据同步的时候,从服务器的数据库就会被清空,所以一般来讲,过期键对载人RDB文件的从服务器也不会造成影响。</li>
</ul>

<h3 id="toc_7">AOF 文件写入</h3>

<p>当服务器以AOF持久化模式运行时,如果数据库中的某个键已经过期,但它还没有被惰性删除或者定期删除,那么AOF文件不会因为这个过期键而产生任何影响。</p>

<p>当过期键被惰性删除或者定期删除之后, 程序会向AOF文件迫加( append)一条DEL 命令,来显式地记录该键已被删除。</p>

<p>举个例子,如果客户端使用 GET message命令,试图访向问过期的 message键,那么服务器将执行以下三个动作: </p>

<p>1)从数据库中删除 message键。<br/>
2)追加一条 DEL message命令到AOF文件。<br/>
3)向执行GET命令的客户端返回空回复。</p>

<p>和生成RDB文件时类似,在执行AOF重写的过程中,程序会对数据库中的键进行检査,已过期的键不会被保存到重写后的AOF文件中。</p>

<h2 id="toc_8">复制</h2>

<p>当服务器运行在复制模式下时,从服务器的过期键删除动作由主服务器控制</p>

<ul>
<li>主服务器在删除一个过期键之后,会显式地向所有从服务器发送一个DEL命令,告知从服务器删除这个过期键。</li>
<li>从服务器在执行客户端发送的读命令时,即使碰到过期键也不会将过期健删除,而是继续像处理未过期的键一样来处理过期键。</li>
<li>从服务器只有在接到主服务器发来的DEL命令之后,才会删除过期键。</li>
</ul>

<p>通过由主服务器来控制从服务器统一地删除过期键,可以保证主从服务器数据的一致性,也正是因为这个原因,当一个过期键仍然存在于主服务器的数据库时,这个过期键在从服务器里的复制品也会继续存在。</p>

<p>如果这时有客户端向从服务器发送命令 GET message,那么从服务器将发现 message 键已经过期,但从服务器并不会删除 message键,而是继续将 message键的值返回给客户端,就好像 message健并没有过期一样。</p>

<p>假设在此之后,有客户端向主服务器发送命令 GET message,那么主服务器将发现键message已经过期，主服务器会删除 message键,向客户端返回空回复,并向从服务器发送 DEL message命令。</p>

<p>从服务器在接收到主服务器发来的DEL message命令之后,也会从数据库中删除 message键,在这之后,主从服务器都不再保存过期键 message了。</p>

<h2 id="toc_9">总结</h2>

<p>Redis使用惰性删除和定期删除两种策略来删除过期的键:惰性删除策略只在碰到过期键时才进行删除操作,定期删除策略则每隔一段时间主动査找并删除过期键。</p>

<p>执行SAVE命令或者 BGSAVE命令所产生的新RDB文件不会包含已经过期的键。</p>

<p>执行 BGREWRITEAOF命令所产生的重写AOF文件不会包含已经过期的键。</p>

<p>当一个过期键被删除之后,服务器会追加一条DEL命令到现有AOF文件的末尾, 显式地删除过期键。</p>

<p>当主服务器删除一个过期键之后,它会向所有从服务器发送一条DEL命令,显式地删除过期键。</p>

<p>从服务器即使发现过期键也不会自作主张地删除它,而是等待主节点发来DEL命令, 这种统一、中心化的过期键删除策略可以保证主从服务器数据的一致性。</p>

<p>当 Redis命令对数据库进行修改之后,服务器会根据配置向客户端发送数据库通知。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[集群]]></title>
    <link href="http://www.throne4j.com/15951723810785.html"/>
    <updated>2020-07-19T23:26:21+08:00</updated>
    <id>http://www.throne4j.com/15951723810785.html</id>
    <content type="html"><![CDATA[
<p>redis集群是在redis 3.0版本推出的一个功能，Redis 集群 提供的分布式数据库方案, 集群通过分片( sharding)来进行数据共享,并提供复制和故障转移功能。其有效的解决了redis在分布式方面的需求。</p>

<p>当遇到单机内存，并发和流量瓶颈等问题时，可采用Cluster方案达到负载均衡的目的。</p>

<p>从另一方面讲，redis中sentinel有效的解决了故障转移的问题，也解决了主节点下线客户端无法识别新的可用节点的问题，但是如果是从节点下线了，sentinel是不会对其进行故障转移的，并且连接从节点的客户端也无法获取到新的可用从节点，而这些问题在Cluster中都得到了有效的解决。</p>

<p>Redis 集群包括如下几个方面 节点、槽指派、命令执行、重新分片、转向、故障转移、消息等。</p>

<p>开启Redis的集群模式需要修改redis.conf文件：</p>

<pre><code class="language-text">cluster-enabled yes
</code></pre>

<p>如下是一个典型的集群部署方式：<br/>
<figure><img src="media/15951723810785/15952500358343.jpg" alt=""/></figure></p>

<p>集群用来提供横向扩展能力，即当数据量增多之后，通过增加服务节点就可以扩展服务能力。背后理论思想是将数据通过某种算法分布到不同的服务节点，这样当节点越多，单台节点所需提供服务的数据就越少。</p>

<p>集群首先需要解决如下问题：</p>

<ul>
<li>分槽（slot）：即如何决定某条数据应该由哪个节点提供服务；</li>
<li>端如何向集群发起请求（客户端并不知道某个数据应该由哪个节点提供服务，并且如果扩容或者节点发生故障后，不应该影响客户端的访问）？</li>
<li>某个节点发生故障之后，该节点服务的数据该如何处理？</li>
<li>扩容，即向集群中添加新节点该如何操作？</li>
<li>同一条命令需要处理的key分布在不同的节点中（如Redis中集合取并集、交集的相关命令），如何操作？</li>
</ul>

<h2 id="toc_0">redis 节点</h2>

<p>一个 Redis集群通常有多个节点 （node）组成，一个正常工作的Redis集群通常由多个节点构成。连接各个节点的工作可以使用 cluster meet 命令来完成。</p>

<pre><code class="language-shell">cluster meet &lt;ip&gt; &lt;port&gt;
</code></pre>

<p>向一个节点 node发送 cluster meet命令，可以让node节点与ip和port所指定的节点进行握手（handshake），当握手成功时，node节点就会将ip和port所指定的节点添加到node节点当前所在的集群中。</p>

<p>通过命令查看集群当前包含的节点信息</p>

<pre><code class="language-shell">127.0.0.1:6379&gt; cluster nodes
a3e1647af22358f9923f05779c2f36699361e969 :6379@16379 myself,master - 0 0 0 connected
</code></pre>

<p>通过 cluster meet 命令将 指定节点添加到集群后，cluster nodes 命令将返回多个节点信息。</p>

<h2 id="toc_1">slot 槽</h2>

<p>redis集群中数据是和槽（slot）挂钩的，Redis将键空间分为了16384个slot，所有的数据根据一致哈希算法会被映射到这16384个槽中的某个槽中；另一方面，这16384个槽是按照设置被分配到不同的redis节点上的。</p>

<p>Redis 通过如下算法计算出每个key所属的slot</p>

<pre><code class="language-text">HASH_SLOT = CRC16(key) mod 16384
</code></pre>

<p>客户端可以请求任意一个节点，每个节点中都会保存所有16384个slot对应到哪一个节点的信息。如果一个key所属的slot正好由被请求的节点提供服务，则直接处理并返回结果，否则返回MOVED重定向信息。</p>

<p>实际应用中，Redis客户端可以通过向集群请求slot 和节点的映射关系并缓存，然后通过本地计算要操作的key所属的slot，查询映射关系，直接向正确的节点发起请求，这样可以获得几乎等价于单节点部署的性能。</p>

<p>集群中的数据分片之后由不同的节点提供服务，即每个主节点的数据都不相同，此种情况下，为了确保没有单点故障，主服务必须挂载至少一个从服务。</p>

<p>客户端请求时可以向任意一个主节点或者从节点发起，当向从节点发起请求时，从节点会返回MOVED信息重定向到相应的主节点。</p>

<p><strong>注意：</strong>Redis集群中，客户端只能在主节点执行读写操作。如果需要在从节点中进行读操作，需要满足如下条件：</p>

<ul>
<li>首先在客户端中执行readonly命令</li>
<li>如果一个key所属的slot由主节点A提供服务，则请求该key时可以向A所属的从节点发起读请求。该请求不会被重定向。</li>
</ul>

<p>当一个主节点发生故障后，其挂载的从节点会切换为主节点继续提供服务。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[十一、哨兵]]></title>
    <link href="http://www.throne4j.com/15948275035029.html"/>
    <updated>2020-07-15T23:38:23+08:00</updated>
    <id>http://www.throne4j.com/15948275035029.html</id>
    <content type="html"><![CDATA[
<p>哨兵是Redis的高可用方案，可以在Redis Master发生故障时自动选择一个Redis Slave切换为Master，继续对外提供服务。</p>

<p>redis中 sentinel 有效的解决了故障转移的问题，也解决了主节点下线客户端无法识别新的可用节点的问题，但是如果是从节点下线了，sentinel是不会对其进行故障转移的，并且连接从节点的客户端也无法获取到新的可用从节点，而这些问题在Cluster中都得到了有效的解决。</p>

<h2 id="toc_0">Redis 哨兵</h2>

<p>首先我们看一个典型的哨兵部署方案，如下图所示：<br/>
<figure><img src="media/15948275035029/15949126995404.jpg" alt="" style="width:845px;"/></figure></p>

<p>该方案中，有一个Redis Master，该Master下有两个Slave。3个哨兵同时与Master和Slave建立连接，并且哨兵之间也互相建立了连接。</p>

<p>哨兵通过与Master和Slave的通信，能够清楚每个Redis服务的健康状态。这样，当Master发生故障时，哨兵能够知晓Master的此种情况，然后通过对Slave健康状态、优先级、同步数据状态等的综合判断，选取其中一个Slave切换为Master，并且修改其他Slave指向新的Master地址。</p>

<p>为什么实际中至少会部署3个以上哨兵并且哨兵数量最好是奇数呢？</p>

<p>哨兵是Redis的高可用机制，保证了Redis服务不出现单点故障。如果哨兵只部署一个，哨兵本身就成为了一个单点。那假如部署2个哨兵呢？当Redis的Master发生故障时，如果2个哨兵同时执行切换操作肯定不行，哨兵之间必须先约定好由谁来执行此次切换操作，此时就涉及了哨兵之间选leader的操作。</p>

<p>思考如下问题：<br/>
1、切换完成之后，客户端和其他哨兵如何知道现在提供服务的Redis Master是哪一个呢？<br/>
答: 可以通过subscribe__sentinel__:hello频道，知道当前提供服务的Master的IP和Port。<br/>
2、假设执行切换的哨兵发生了故障，切换操作是否会由其他哨兵继续完成呢？<br/>
答 ：执行切换的哨兵发生故障后，剩余哨兵会重新选主，并且重新开始执行切换流程<br/>
3、当故障Master恢复之后，会继续作为Master提供服务还是会作为一个Slave提供服务？<br/>
答 ：Redis中主从切换完成之后，当故障Master恢复之后，会作为新Master的一个Slave来提供服务。</p>

<p>这里有一份典型的哨兵配置文件（哨兵的配置文件必须具有可写权限。）：</p>

<pre><code class="language-conf">//监控一个名称为mymaster的Redis Master服务，地址和端口号为127.0.0.1:6379,quorum为2 
sentinel monitor mymaster 127.0.0.1 6379 2 
//如果哨兵60s内未收到mymaster的有效ping回复，则认为mymaster处于down的状态
sentinel down-after-milliseconds mymaster 60000 
//执行切换的超时时间为180s
sentinel failover-timeout mymaster 180000 
//切换完成后同时向新的Redis Master发起同步数据请求的Redis Slave个数为1，
//即切换完成后依次让每个Slave去同步数据，前一个Slave同步完成后下一个Slave才发起同步数据的请求
sentinel parallel-syncs mymaster 1 

//监控一个名称为resque的Redis Master服务，地址和端口号为127.0.0.1:6380,quorum为4 
sentinel monitor resque 192.168.1.3 6380 4 
sentinel down-after-milliseconds resque 10000 
sentinel failover-timeout resque 180000 
sentinel parallel-syncs resque 5
</code></pre>

<p>quorum在哨兵中有两层含义。</p>

<ul>
<li>第一层含义为：如果某个哨兵认为其监听的Master处于下线的状态，这个状态在Redis中标记为S_DOWN，即<strong>主观下线</strong>。假设quorum配置为2，则当有两个哨兵同时认为一个Master处于下线的状态时，会标记该Master为O_DOWN，即客观下线。只有一个Master处于客观下线状态时才会开始执行切换。</li>
<li>第二层含义为：假设有5个哨兵，quorum配置为4。首先，判断<strong>客观下线</strong>需要4个哨兵才能认定。其次，当开始执行切换时，会从5个哨兵中选择一个leader执行该次选举，此时一个哨兵也必须得到4票才能被选举为leader，而不是3票（即哨兵的大多数）。</li>
</ul>

<p>可以看到配置文件中首先配置了需要监控的Redis Master服务器，然后设置了一些服务相关的参数，并没有Redis Slave和其他哨兵的配置。而通过图22-1，我们看到每个哨兵都必须与所有监控的Redis Master下的Slave服务器以及其他监控该Master的哨兵建立连接。显然，哨兵只通过配置文件是不能知道这些信息的。进一步，如果在配置文件中硬编码写出从服务器和其他哨兵的信息，会丧失灵活性。</p>

<p>那么，Redis是如何实现如上所述的信息发现呢，我们通过下面的章节来了解一下。</p>

<h3 id="toc_1">哨兵机制的实现</h3>

<p>哨兵启动之后会先与配置文件中监控的Master建立两条连接，一条称为命令连接，另一条称为消息连接。哨兵就是通过如上两条连接发现其他哨兵和Redis Slave服务器，并且与每个Redis Slave也建立同样的两条连接。</p>

<p>哨兵可以直接使用 redis-server 命令启动，如下：</p>

<pre><code class="language-shell">redis-server /path/sentinel.conf --sentinel
或者
redis-sentinel /path/sentinel.conf
</code></pre>

<p>sentinel 启动时的执行步骤如下：<br/>
1)初始化服务器。<br/>
2)将普通 Redis服务器使用的代码替换成 Sentinel专用代码。<br/>
3)初始化 Sentinel状态。<br/>
4)根据给定的配置文件,初始化 Sentinel的监视主服务器列表。<br/>
5)创建连向主服务器的网络连接。</p>

<p>单个哨兵连接示意图：</p>

<p><figure><img src="media/15948275035029/15950831184191.jpg" alt=""/></figure></p>

<p>那么哨兵启动后两条连接是怎么建立的呢？</p>

<pre><code class="language-c">main() {     ...
    //检测是否以sentinel模式启动    
    server.sentinel_mode = checkForSentinelMode(argc,argv);    
     ...
    if (server.sentinel_mode) { 
        //将监听端口置为26379
        initSentinelConfig(); 
        //更改哨兵可执行命令。哨兵中只能执行有限的几种服务端命令，如ping,sentinel,subscribe,publish,info等等。该函数还会对哨兵进行一些初始化
        initSentinel();     
    }    
    ...
    sentinelHandleConfiguration();        //解析配置文件，进行初始化 
    ...
    sentinelIsRunning(); //随机生成一个40字节的哨兵ID，打印启动日志
    ...
}
</code></pre>

<p>查看哨兵启动的主流程发现，并没有建立连接相关的逻辑。那么只可能是 Redis的时间任务 serverCron了，</p>

<pre><code class="language-c">serverCron(){
    if (server.sentinel_mode) sentinelTimer();
}
</code></pre>

<p>哨兵中每次执行serverCron时，都会调用sentinelTimer()函数。该函数会建立连接，并且定时发送心跳包并采集信息。该函数主要功能如下：</p>

<ul>
<li>建立命令连接和消息连接。消息连接建立之后会订阅Redis服务的__sentinel__:hello频道。</li>
<li><p>在命令连接上每10s发送info命令进行信息采集；每1s在命令连接上发送ping命令探测存活性；每2s在命令连接上发布一条信息，信息格式如下:</p>
<pre><code class="language-text">sentinel_ip,sentinel_port,sentinel_runid,current_epoch,master_name,master_ip,master_port,master_config_epoch 
</code></pre>
<p>哨兵的IP、哨兵的端口、哨兵的ID（即上文所述40字节的随机字符串）、当前纪元（用于选举和主从切换）、Redis Master的名称、Redis Master的IP、Redis Master的端口、Redis Master的配置纪元（用于选举和主从切换）。</p></li>
<li><p>检测服务是否处于主观下线状态。<br/>
主观下线状态的探测针对所有的Master，Slave和哨兵。</p></li>
<li><p>检测服务是否处于客观下线状态并且需要进行主从切换。<br/>
只会对Master服务器进行客观下线的判断。</p></li>
</ul>

<p>哨兵启动之后通过info命令进行信息采集，据此能够知道一个Redis Master有多少Slaves，然后在下一次执行sentinelTimer函数时会和所有的Slaves分别建立命令连接与消息连接。而通过订阅消息连接上的消息可以知道其他的哨兵。哨兵与哨兵之间只会建立一条命令连接，每1s发送一个ping命令进行存活性探测，每2s推送（publish）一条消息。</p>

<p>对于哨兵来说，如果有大于等于quorum个哨兵同时认为一台Master处于主观下线状态，才会将该Master标记为客观下线。那么，一个哨兵如何知道其他哨兵对一台Master服务器的判断状态呢？</p>

<p>Redis会向监控同一台Master的所有哨兵通过命令连接发送如下格式的命令:</p>

<pre><code class="language-text">SENTINEL   is-master-down-by-addr    master_ip   master_port   current_epoch   sentinel_runid或者* 
</code></pre>

<p>其中最后一项当需要投票时发送sentinel_runid，否则发送一个* 号。</p>

<p>据此能够知道其他哨兵对该Master服务状态的判断，如果达到要求，就标记该Master为客观下线。</p>

<p>如果判断一个Redis Master处于客观下线状态，这时就需要开始执行主从切换了。</p>

<h2 id="toc_2">选举哨兵领头节点</h2>

<p>Sentinel系统选举领头 Sentinel的方法是对Raf算法的领头选举方法的实现。<br/>
当一个主服务器被判断为客观下线时,监视这个下线主服务器的各个 Sentinel会进行协商，选举出一个领头 Sentinel,并由领头 Sentinel对下线主服务器执行故障转移操作。</p>

<p>Redis选举领头 Sentinel的规则和方法：</p>

<ul>
<li>所有在线的 Sentinel都有被选为领头 Sentinel的资格,换句话说,监视同一个主服务器的多个在线 Sentinel中的任意一个都有可能成为领头 Sentinel 口每次进行领头 Sentinel选举之后,不论选举是否成功,所有 Sentinel的配置纪元( configuration epoch)的值都会自增一次。配置纪元实际上就是一个计数器,并没有什么特别的。</li>
<li>在一个配置纪元里面,所有 Sentinel都有一次将某个 Sentinel设置为局部领头Sentinel的机会,并且局部领头一旦设置,在这个配置纪元里面就不能再更改。</li>
<li>每个发现主服务器进人客观下线的 Sentinel都会要求其他 Sentinel将自己设置为局部领头 Sentinel。</li>
<li>当一个 Sentinel(源 Sentinel)向另一个 Sentinel(目标 Sentinel)发送 SENTINEL is- master-down-by-adr命令,并且命令中的 runid参数不是*符号而是源Sentinel的运行ID时,这表示源 Sentinel要求目标 Sentinel将前者设置为后者的局部领头 Sentinel</li>
<li>Sentinel设置局部领头 Sentinel的规则是先到先得:最先向目标 Sentinel发送设置要求的源 Sentinel将成为目标 Sentinel的局部领头 Sentinel,而之后接收到的所有设置要求都会被目标 Sentinel拒绝。</li>
<li>目标 Sentinel在接收到 SENTINEL is- master-down-by-addr命令之后,将向源 Sentinel返回一条命令回复,回复中的1 eader_ runid参数和 leader epoch 参数分别记录了目标 Sentinel的局部领头 Sentinel的运行ID和配置纪元。</li>
<li>源 Sentinel在接收到目标 Sentinel返回的命令回复之后,会检查回复中1 eader epoch参数的值和自己的配置纪元是否相同,如果相同的话,那么源 Sentinel g继续取出回复中的1 eader runid参数,如果1 eader runid参数的值和源 Sentinel 的运行D一致,那么表示目标 Sentinel将源 Sentinel设置成了局部领头 Sentinel</li>
<li>如果有某个 Sentinel被半数以上的 Sentinel设置成了局部领头 Sentinel,那么这个Sentinel成为领头 Sentinel。举个例子,在一个由10个 Sentinel组成的 Sentinel系统里面,只要有大于等于10/2+1=6个 Sentinel将某个 Sentinel设置为局部领头Sentinel,那么被设置的那个 Sentinel就会成为领头 Sentinel </li>
<li>因为领头 Sentinel的产生需要半数以上 Sentinel I的支持,并且每个 Sentinel在每个配置纪元里面只能设置一次局部领头 Sentinel,所以在一个配置纪元里面,只会出现个领头 Sentinel 在一段时间之后再次进行选举,直到选出领头 Sentinel为此。</li>
<li>那如果在给定时限内,没有一个 Sentinel被选举为领头 Sentinel，那么各个 Sentinel将在一段时间之后再次进行选举，直到选出领头sentinel为止。</li>
</ul>

<h2 id="toc_3">故障转移</h2>

<p>在选举产生出领头 Sentinel之后,领头 Sentinel将对已下线的主服务器执行故障转移操作,该操作包含以下三个步骤: <br/>
1)在已下线主服务器属下的所有从服务器里面,挑选出一个从服务器,并将其转换为主服务器。<br/>
2)让已下线主服务器属下的所有从服务器改为复制新的主服务器。<br/>
3)将已下线主服务器设置为新的主服务器的从服务器,当这个旧的主服务器重新上线时,它就会成为新的主服务器的从服务器。</p>

<h2 id="toc_4">主从切换</h2>

<p>当Redis哨兵方案中的Master处于客观下线状态，为了保证Redis 的高可用性，此时需要执行主从切换。即将其中一个Slave提升为Master，其他Slave从该提升的Slave继续同步数据，主从切换有一个状态迁移图，其所有状态定义如下：</p>

<pre><code class="language-c">//没有进行切换
#define SENTINEL_FAILOVER_STATE_NONE 0                  
//等待开始进行切换(等待哨兵之间进行选主) 
#define SENTINEL_FAILOVER_STATE_WAIT_START 1 
//选择一台从服务器作为新的主服务器
#define SENTINEL_FAILOVER_STATE_SELECT_SLAVE 2        
//将被选中的从服务器切换为主服务器
#define SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE 3 
//等待被选中的从服务器上报状态
#define SENTINEL_FAILOVER_STATE_WAIT_PROMOTION 4
//将其他Slave切换为向新的主服务器要求同步数据
#define SENTINEL_FAILOVER_STATE_RECONF_SLAVES 5  
//重置Master，将Master的IP：PORT设置为被选中从服务器的IP：PORT        
#define SENTINEL_FAILOVER_STATE_UPDATE_CONFIG 6
</code></pre>

<p>主从切换状态转换图</p>

<p><figure><img src="media/15948275035029/15951641443338.jpg" alt="" style="width:622px;"/></figure></p>

<p>当一个哨兵发现一台Master处于主观下线状态时，会首先将切换状态更新为SENTINEL_FAILOVER_STATE_WAIT_START，并且将当前纪元加1。然后发送如下命令要求其他哨兵给自己投票。</p>

<pre><code class="language-text">SENTINEL   is-master-down-by-addr    master_ip   master_port   current_epoch   sentinel_runid或者*
</code></pre>

<p>最后一项参数为sentinel_runid，即该哨兵的ID，第5项current_epoch在开始执行切换后会加1。 当从哨兵中选出一个主哨兵之后，接下来的切换都由该主哨兵执行。</p>

<p>主哨兵首先会将当前切换状态更改为SENTINEL_FAILOVER_STATE_SELECT_SLAVE，即开始选择一台从服务器作为新的主服务器。那么，假设有多台从服务器，该选择哪台呢？</p>

<p>Redis中选择主服务器的规则如下:</p>

<ul>
<li>如果该Slave处于主观下线状态，则不能被选中。</li>
<li>如果该Slave 5s之内没有有效回复ping命令或者与主服务器断开时间过长，则不能被选中</li>
<li>如果slave-prio-rity为0，则不能被选中（slave-priority可以在配置文件中指定。正整数，值越小优先级越高，当指定为0时，不能被选为主服务器）。</li>
<li>在剩余Slave中比较优先级，优先级高的被选中；如果优先级相同，则有较大复制偏移量的被选中；否则按字母序选择排名靠前的Slave。</li>
</ul>

<p>当选中从服务器之后，将当前切换状态更改为SENTINEL_FAILOVER_STATE_SEND_SLAVEOF_NOONE，并且在下一次时间任务调度时执行该步骤。该状态需要把选择的Redis Slave切换为Redis Master。</p>

<pre><code class="language-text">//开启一个事务
MULTI
//关闭该从服务器的复制功能，将其转换为一个主服务器     
SLAVEOF NO ONE    
//将redis.conf文件重写(会根据当前运行中的配置重写原来的配置)     
CONFIG REWRITE          
//关闭连接到该服务的客户端(关闭之后客户端会重连，重连时会重新获取Redis Master的地址)
CLIENT KILL TYPE normal
//执行事务
EXEC                
</code></pre>

<p>执行完该步骤之后，会将切换状态更新为SENTINEL_FAILOVER_STATE_WAIT_PRO-MOTION, 上一步我们向被选中的从服务器发送了slaveof no one命令，执行完之后Redis中并没有处理返回值，而是在下一次info命令的返回中检查该从服务器的role字段，如果返回role:master，说明该从服务器已变更自己的角色为主服务器。于是切换状态变更为SENTINEL_FAILOVER_STATE_RECONF_SLAVES。</p>

<p>在该步骤设置SENTINEL_FAILOVER_STATE_RECONF_SLAVES后，哨兵会依次向其他从服务器发送切换主服务器的slaveof命令 ：</p>

<pre><code class="language-text">//开启一个事务
MULTI
//将该服务器设置为向新的主服务器请求数据
SLAVEOF IP PORT
//将redis.conf文件重写(会根据当前运行中的配置重写原来的配置) 
CONFIG REWRITE
//关闭连接到该服务的客户端(关闭之后客户端会重连，重连时会重新获取Redis Master的地址) 
CLIENT KILL TYPE normal
//执行事务
EXEC
</code></pre>

<p>如果所有的从服务器都已更新完毕，则切换状态更新为SENTINEL_FAILOVER_STATE_UPDATE_CONFIG。该步骤会将哨兵中监听的Master（旧Master）重置为被选中的从服务器（新Master），并且将旧Master也配置为新Master的从服务器。然后将切换状态更新为SENTINEL_FAILOVER_STATE_NONE。至此，主从切换已完成。</p>

<h2 id="toc_5">哨兵相关命令</h2>

<ul>
<li>SENTINEL MASTERS：返回该哨兵监控的所有Master的相关信息。</li>
<li>SENTINEL MASTER<name>：返回指定名称Master的相关信息。</li>
<li>SENTINEL SLAVES<master-name>：返回指定名称Master的所有Slave的相关信息。</li>
<li>SENTINEL SENTINELS<master-name>：返回指定名称Master 的所有哨兵的相关信息。</li>
<li>SENTINEL IS-MASTER-DOWN-BY-ADDR<ip><port> <current-epoch><runid>：如果runid是*，返回由IP和Port指定的Master 是否处于主观下线状态。如果runid是某个哨兵的ID，则同时会要求对该runid进行选举投票。</li>
<li>SENTINEL RESET<pattern>：重置所有该哨兵监控的匹配模式（pattern）的Masters（刷新状态，重新建立各类连接）</li>
<li>SENTINEL GET-MASTER-ADDR-BY-NAME<master- name>：返回指定名称的Master对应的IP和Port。</li>
<li>SENTINEL FAILOVER<master-name>：对指定的Mmaster手动强制执行一次切换。</li>
<li>SENTINEL MONITOR<name><ip><port><quorum>：指定该哨兵监听一个Master。</li>
<li>SENTINEL flushconfig：将配置文件刷新到磁盘。</li>
<li>SENTINEL REMOVE<name>：从监控中去除掉指定名称的Master。</li>
<li>SENTINEL CKQUORUM<name>：根据可用哨兵数量，计算哨兵可用数量是否满足配置数量（认定客观下线的数量）；是否满足切换数量（即哨兵数量的一半以上）。</li>
<li>SENTINEL SET<mastername>[<option><value>...]：设置指定名称的Master的各类参数（例如超时时间等）。</li>
<li>SENTINEL SIMULATE-FAILURE<flag><flag>...<flag>：模拟崩溃。flag可以为crash-after-election或者crash-after-promotion，分别代表切换时选举完成主哨兵之后崩溃以及将被选中的从服务器推举为Master之后崩溃。</li>
</ul>

<h2 id="toc_6">总结</h2>

<ul>
<li>Sentinel只是一个运行在特殊模式下的 Redis服务器,它使用了和普通模式不同的命第三部分多机据库的实现令表,所以 Sentinel模式能够使用的命令和普通 Redis服务器能够使用的命令不同。</li>
<li>Sentinel会读入用户指定的配置文件,为每个要被监视的主服务器创建相应的实例结构,并创建连向主服务器的命令连接和订阅连接,其中命令连接用于向主服务器发送命令请求,而订阅连接则用于接收指定频道的消息。</li>
<li>Sentinel通过向主服务器发送INFO命令来获得主服务器属下所有从服务器的地址信息,并为这些从服务器创建相应的实例结构,以及连向这些从服务器的命令连接和订阅连接。</li>
<li>在一般情况下, Sentinel以每十秒一次的频率向被监视的主服务器和从服务器发送INFO命令,当主服务器处于下线状态,或者 Sentinel正在对主服务器进行故障转移操作时, Sentinel I向从服务器发送INFO命令的频率会改为每秒一次。</li>
<li>对于监视同一个主服务器和从服务器的多个 Sentinel来说,它们会以每两秒一次的频率,通过向被监视服务器的 sentinel:he11o频道发送消息来向其他Sentinel宣告自己的存在。</li>
<li>每个 Sentinel也会从 sentinel1:he1o频道中接收其他 Sentinel发来的信息, 并根据这些信息为其他 Sentinel 1创建相应的实例结构,以及命令连接。</li>
<li>Sentinel只会与主服务器和从服务器创建命令连接和订阅连接, Sentinel与 Sentinel 之间则只创建命令连接。</li>
<li>Sentinel以每秒一次的频率向实例(包括主服务器、从服务器、其他 Sentinel)发送PING命令,并根据实例对PNG命令的回复来判断实例是否在线,当一个实例在指定的时长中连续向 Sentinel发送无效回复时, Sentinel会将这个实例判断为主观下线。</li>
<li>当 Sentinel将一个主服务器判断为主观下线时,它会向同样监视这个主服务器的其他Sentinel进行询问,看它们是否同意这个主服务器已经进入主观下线状态。</li>
<li>当 Sentinel l收集到足够多的主观下线投票之后,它会将主服务器判断为客观下线,并发起一次针对主服务器的故障转移操作。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[十、主从复制]]></title>
    <link href="http://www.throne4j.com/15945438416733.html"/>
    <updated>2020-07-12T16:50:41+08:00</updated>
    <id>http://www.throne4j.com/15945438416733.html</id>
    <content type="html"><![CDATA[
<p>Redis 支持主从复制功能，用户可以通过执行slaveof 命令或者在配置文件中设置slaveof选项来开启复制功能。例如</p>

<pre><code class="language-shell">127.0.0.1:6379&gt;slaveof 127.0.0.1  7000
OK
</code></pre>

<p>服务器127.0.0.1:6379 会成为服务器127.0.0.1:7000的从服务器(slaver)，127.0.0.1:7000 是主服务器(master),通过复制功能，从服务器127.0.0.1:6379的数据可以和主服务器127.0.0.1:7000的数据保持同步。</p>

<p>用户可以通过执行 slaveof  no one取消复制功能，此时主从服务器之间会断开连接，从服务器成为普通的Redis实例。</p>

<h2 id="toc_0">1、主从复制功能实现</h2>

<p>主从复制功能主要有以下两点作用</p>

<ul>
<li>读写分离，单台服务器能支撑的QPS是有上限的，我们可以部署一台主服务器、多台从服务器，主服务器只处理写请求，从服务器通过复制功能同步主服务器数据，只处理读请求，以此提升Redis 服务能力；另外我们还可以通过复制功能来让主服务器免于执行持久化操作：只要关闭主服务器的持久化功能，然后由从服务器去执行持久化操作即可。</li>
<li>数据容灾，任何服务器都有宕机的可能，我们同样可以通过主从复制功能提升Redis服务的可靠性；由于从服务器与主服务器数据保持同步，一旦主服务器宕机，可以立即将请求切换到从服务器，从而避免Redis服务中断。</li>
</ul>

<h3 id="toc_1">1.1、 老版Redis复制功能</h3>

<p>在redis 2.8之前的版本中实现主从复制功能分为同步(sync)和命令传播(command propagate)两个操作</p>

<ul>
<li>同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态。</li>
<li>命令传播操作则用于在主服务器的数据库状态被修改,导致主从服务器的数据库状态出现不一致时,让主从服务器的数据库重新回到一致状态。</li>
</ul>

<p>slaveof命令流程如下图所示：<br/>
<figure><img src="media/15945438416733/15947441756075.jpg" alt="" style="width:729px;"/></figure></p>

<p>此版本的slavof复制功能缺陷：</p>

<ul>
<li>初次复制: 从服务器以前没有复制过任何主服务器, 或者从服务器当前要复制的主服务器和上一次复制的主服务器不同。</li>
<li>断线后重复制: 处于命令传播阶段的主从服务器因为网络原因而中断了复制,但从服务器通过自动重连接重新连上了主服务器,并继续复制主服务器。<br/>
对于中断后重复制，假如在断开连接之前从服务已经复制了主服务器大部分数据，但是由于中断，在从服务器重新连接上主服务器之后，会重新发送sync命令，生成并发送RDB文件（包含从服务器已经复制过的那部分数据），但是这种续传的方式并不是必须得这样，对于从服务器已经复制过的数据，完全没必要再传输一遍。因此这种方式是比较效率的复制方式。</li>
</ul>

<p><strong>每次执行SYNC命令的耗时操作</strong>：<br/>
1)主服务器需要执行 BGSAVE命令来生成RDB文件,这个生成操作会耗费主服务器大量的CPU、内存和融盘IO资源。<br/>
2)主服务器需要将自已生成的RDB文件发送给从服务器,这个发送操作会耗费主从服务器大量的网络资源(带宽和流量),并对主服务器响应命令请求的时间产生彩响。<br/>
3)接收到RDB文件的从服务器需要載入主服务器发来的RDB文件,并且在載入期间,从服务器会因为阻塞而没办法处理命令请求。</p>

<p>因为SYVC命令是一个如此耗费资源的操作,所以 Redis有必要保证在真正有需要时才执行SYNC命令。</p>

<h3 id="toc_2">1.2、新版的复制功能</h3>

<p>为了解决老版本的效率低下问题，新版复制功能使用PSYNC命令代替SYNC命令来执行复制时的同步操作。</p>

<p>PSYNC命令具有完整重同步( full resynchronization)和部分重同步( partial resynchronization 两种模式:</p>

<ul>
<li>完整重同步用于处理初次复制情况: 完整重同步的执行步骤和SYNC命令的执行步骤基本一样, 它们都是通过让主服务器创建并发送RDB文件,以及向从服务器发送保存在缓冲区里面的写命令来进行同步。</li>
<li>部分重同步则用于处理断线后重复制情况:  当从服务器在断线后重新连接主服务器时,如果条件允许,主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器,从服务器只要接收并执行这些写命令,就可以将数据库更新至主服务器当前所处的状态。</li>
</ul>

<p>新版slaveof命令流程如下图所示：<br/>
<figure><img src="media/15945438416733/15947488155003.jpg" alt="" style="width:833px;"/></figure></p>

<p>部分重同步功能由以下三个部分构成: </p>

<ul>
<li>主服务器的复制偏移量( replication offset)和从服务器的复制偏移量。</li>
<li>主服务器的复制积压缓冲区( replication backlog) </li>
<li>服务器的运行ID( run ID)。</li>
</ul>

<h4 id="toc_3">1.2.1、复制偏移量</h4>

<p>执行复制的双方 主服务器和从服务器会分别维护一个复制偏移量:</p>

<ul>
<li>主服务器每次向从服务器传播N个字节的数据时,就将自己的复制偏移量的值加上N。</li>
<li>从服务器每次收到主服务器传播来的N 个字节的数据时,就将自已的复制偏移量的值加上N。</li>
</ul>

<p>通过对比主从服务器的复制偏移量,程序可以很容易地知道主从服务器是否处于一致状态:</p>

<ul>
<li>如果主从服务器处于一致状态,那么主从服务器两者的偏移量总是相同的。</li>
<li>相反,如果主从服务器两者的偏移量并不相同,那么说明主从服务器并未处于一致状态。</li>
</ul>

<p>问：如果主服务器向从服务器复制的时候，从服务器掉线后就立即重新连接主服务器,并且成功,那么接下来,从服务器将向主服务器发送 PSYNC命令,报告从服务器当前的复制偏移量为offset, 那么这时, 主服务器应该对从服务器执行完整重同步还是部分重同步呢? </p>

<p>答： 和复制缓冲区有关。</p>

<h4 id="toc_4">1.2.2、复制缓冲区</h4>

<p>复制缓冲区是有主服务器维护的一个固定长度的先进先出的队列。当主服务器进行命令传播的时候，它不仅会将写命令发送给所有的从服务器，还会将写命令入队复制缓冲区。因此主服务器的复制缓冲区会保存一部分最近传播的写命令，并且复制缓冲区会为队列中的每个字节记录相应的复制偏移量。</p>

<p>当从服务器重新连上主服务器时,从服务器会通过PSYC命令将自己的复制偏移量offset发送给主服务器,主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作:</p>

<ul>
<li>如果offset偏移量之后的数据(也即是偏移量。 offset+1开始的数据)仍然存在于复制积压缓冲区里面,那么主服务器将对从服务器执行部分重同步操作。</li>
<li>相反,如果 offset偏移量之后的数据已经不存在于复制积压缓冲区,那么主服务器将对从服务器执行完整重同步操作。</li>
</ul>

<p><strong>注意：</strong> 正确估算和设置复制缓冲区的大小非常重要。如果主服务器需要执行大量写命令，或者主从服务器断线很长时间后重新连接，复制缓冲区的大小不合理的话，可能导致psync命令的复制重同步模式不能正常发挥作用。</p>

<p>复制缓冲区的大小可根据 公式：断线到重连的平均时间秒数 * 主服务器每秒产生的写命令数据量，为了安全起见可以double 一下这个结果值。</p>

<h4 id="toc_5">1.2.3、 服务器的运行ID</h4>

<p>每台Redis服务器都有一个运行ID，从服务器每次发送psync请求同步数据时，会携带自己需要同步主服务器的运行ID。主服务器接收到psync命令时，需要判断命令参数运行ID与自己的运行ID是否相等，只有相等才有可能执行部分重同步。而当从服务器首次请求主服务器同步数据时，从服务器显然是不知道主服务器的运行ID，此时运行ID以“？”填充，同时复制偏移量初始化为-1。</p>

<h3 id="toc_6">1.3、新版复制同步机制的生产问题</h3>

<p>当在生产环境中，经常会发生如下情况</p>

<ul>
<li>从服务器重启，复制信息丢失</li>
<li>主服务器故障导致主从切换(从多台 从服务器中选举出一台作为主服务器，此时，主服务器的运行ID发生变化)<br/>
这时候显然是无法执行部分重同步的，而这两种情况又很常见，因此Redis 4.0针对主从复制又提出了psync2协议，使得主服务器故障导致主从切换后，依然有可能执行部分重同步。而这时候当主服务器接收到psync命令时，向客户端回复的是“+CONTINUE<new_repl_id>”。参数“psync2”表明从服务器支持psync2协议。。</li>
</ul>

<h4 id="toc_7">方案一： 持久化主从复制信息</h4>

<p>Redis服务器关闭时，将主从复制信息（复制的主服务器RUN_ID 与复制偏移量）作为辅助字段存储在RDB文件中；Redis服务器启动加载RDB文件时，恢复主从复制信息，重新同步主服务器时携带。</p>

<h4 id="toc_8">方案二： 存储上一个主服务器复制信息</h4>

<p>当主服务器发生故障的时候，从服务器成为新的主服务器时，便使用前一个主服务器的运行ID和复制偏移量。</p>

<p>代码如下所示:</p>

<pre><code class="language-c">char replid2[CONFIG_RUN_ID_SIZE+1];
long long second_replid_offset;
</code></pre>

<p>假设m为主服务器（运行ID为M_ID），A、B和C为三个从服务器；某一时刻主服务器m发生故障，从服务器A升级为主服务器（同时会记录replid2=M_ID），从服务器B和C重新向主服务器A发送“psync M_ID psync_offset”请求；显然根据上面条件，只要psync_offset满足条件，就可以执行部分重同步。</p>

<h3 id="toc_9">主从复制的其它问题</h3>

<ul>
<li>心跳检测<br/>
主服务器和从服务器之间是通过TCP长连接交互数据的，就必然需要周期性地发送心跳包来检测连接有效性，该字段表示发送心跳包的周期，主服务器以此周期向所有从服务器发送心跳包。可通过配置参数repl-ping-replica-period或者repl-ping- slave-period设置，默认为10。</li>
</ul>

<p>发送心跳检测从服务器是否有效，那么每次检测多长时间后判定从服务器失效呢？</p>

<p>主服务器会记录每个从服务器上次心跳检测成功的时间repl_ack_time，并且定时检测当前时间距离repl_ack_time是否超过一定超时门限，如果超过则认为从服务器处于失效状态。字段repl_min_slaves_max_lag存储的就是该超时门限，可通过配置参数min-slaves-max-lag或者min- replicas-max-lag设置该超时阈值，默认为10，单位秒。</p>

<p>repl_min_slaves_to_write表示当有效从服务器的数目小于该值时，主服务器会拒绝执行写命令。</p>

<p>当主服务器配置了“requirepass password”时，即表示从服务器必须通过密码认证才能同步主服务器数据。同样的需要在从服务器配置“masterauth<master-password>”，用于设置请求同步主服务器时的认证密码。</p>

<p>当主从服务器断开连接时，通过配置参数slave-serve-stale-data 或者replica-serve-stale-data设置，默认为1，设置从服务器是否继续处理命令请求。</p>

<p>可通过配置参数slave-read-only或者replica-read-only设置，默认为1，设置从服务器是否可以处理写命令请求，默认是从服务器是只读的，除非该命令是主服务器发送过来的。</p>

<p>复制缓冲区，用于缓存主服务器已执行且待发送给从服务器的命令请求；缓冲区大小由字段repl_backlog_size指定，其可通过配置参数repl-backlog-size设置，默认为1MB。</p>

<p>从服务器通过时间事件处理函数 serverCron，以一秒为周期执行主从复制操作。在时间事件处理是，从服务器想主服务器发起连接请求，成功连接之后，创建对应的文件事件。此外事件事件还用于检测主从连接是否超时，定时向服务器发送心跳包，定时报告自己的复制偏移量等。</p>

<p>用户可通过参数repl-timeout 配置，默认为60，单位秒，超过此时间则认为主从服务器之间的连接出现故障，从服务器会主动断开连接。</p>

<p>当从服务器接收到slaveof命令时，会主动连接主服务器请求同步数据，这并不是一蹴而就的，需要若干个步骤交互：</p>

<ul>
<li>设置主服务器的地址和端口号</li>
<li>连接Socket；</li>
<li>发送PING请求包确认连接是否正确；</li>
<li>发起密码认证（如果需要，通过 masterauth  <master-pwd>进行验证）；</li>
<li>信息同步；</li>
<li>发送PSYNC命令；</li>
<li>接收RDB文件并载入；</li>
<li>连接建立完成，等待主服务器同步命令请求。</li>
</ul>

<p>当从服务器支持eof 功能时 主服务器可以直接将数据库中数据以RDB协议格式通过socket发送给从服务器，免去了本地磁盘文件不必要的读写操作；</p>

<p>通过配置参数repl-diskless-sync进行设置完整同步是生成RDB文件持久化到磁盘发送还是直接通过socket进行发送，默认为0；即默认情况下，主服务器都是先持久化数据到本地文件，再将该文件发送给从服务器。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[九、Redis 持久化--AOF（二）]]></title>
    <link href="http://www.throne4j.com/15943917797824.html"/>
    <updated>2020-07-10T22:36:19+08:00</updated>
    <id>http://www.throne4j.com/15943917797824.html</id>
    <content type="html"><![CDATA[
<p>AOF是Redis的另外一种持久化方式。简单来说，AOF就是将Redis服务端执行过的每一条命令都保存到一个文件，这样当Redis重启时只要按顺序回放这些命令就会恢复到原始状态。</p>

<hr/>

<p><strong>问</strong>：既然已经有了RDB为什么还需要AOF呢？</p>

<p>答：RDB保存的是一个时间点的快照，那么如果Redis出现了故障，丢失的就是从最后一次RDB执行的时间点到故障发生的时间间隔之内产生的数据。如果Redis数据量很大，QPS很高，那么执行一次RDB需要的时间会相应增加，发生故障时丢失的数据也会增多。</p>

<p>而AOF保存的是一条条命令，理论上可以做到发生故障时只丢失一条命令。但由于操作系统中执行写文件操作代价很大，Redis提供了配置参数，通过对安全性和性能的折中，我们可以设置不同的策略。</p>

<hr/>

<p><strong>问</strong>：既然AOF数据安全性更高，是否可以只使用AOF呢？为什么Redis推荐RDB和AOF同时开启呢？</p>

<p>答：RDB保存的是最终的数据，是一个最终状态，而AOF保存的是达到这个最终状态的过程。很明显，如果Redis有大量的修改操作，RDB中一个数据的最终态可能会需要大量的命令才能达到，这会造成AOF文件过大并且加载时速度过慢（Redis提供了一种AOF重写的策略来解决上述问题，后文会详细描述其实现原理）。</p>

<p>再来考虑一下AOF和RDB文件的加载过程。RDB只需要把相应数据加载到内存并生成相应的数据结构（有些结构如intset、ziplist，保存时直接按字符串保存，所以加载时速度会更快），而AOF文件的加载需要先创建一个伪客户端，然后把命令一条条发送给Redis服务端，服务端再完整执行一遍相应的命令。根据Redis作者做的测试，RDB 10s～20s能加载1GB的文件，AOF的速度是RDB速度的一半（如果做了AOF重写会加快）。因为AOF和RDB各有优缺点，因此Redis一般会同时开启AOF和RDB。</p>

<hr/>

<p>但假设线上同时配置了RDB和AOF，那么会带来如下的两难选择：重启时如果优先加载RDB，加载速度更快，但是数据不是很全；如果优先加载AOF，加载速度会变慢，但是数据会比RDB中的要完整。</p>

<p>能不能结合这两者的优点呢？答案是AOF和RDB的混合持久化方案，</p>

<hr/>

<h2 id="toc_0">1、AOF的执行流程</h2>

<p>先介绍Redis服务端执行命令时如何同步到AOF文件以及AOF文件的格式，然后介绍Redis不同的配置对性能和安全性的影响。</p>

<h3 id="toc_1">1.1、AOF命令同步</h3>

<p>通过《<a href="15934396305281.html">三、redis命令处理生命周期</a> 》的执行流程，我们看到每一条命令的执行都会processCommand命令，processCommand命令的执行都会调用 call 函数，AOF命令的同步就是在 call命令中实现的。</p>

<p><figure><img src="media/15943917797824/15943937599696.jpg" alt="AOF命令同步"/><figcaption>AOF命令同步</figcaption></figure></p>

<p>如果开启了AOF，则每条命令执行完毕后都会同步写入aof_buf 中，aof_buf是个全局的SDS类型的缓冲区。</p>

<p>那么命令是按什么格式写入缓冲区中的呢？</p>

<p>Redis通过catAppendOnlyGenericCommand函数将命令转换为保存在缓冲区中的数据结构，</p>

<pre><code class="language-shell">127.0.0.1:6379&gt; SET redis-key value1
# 保存在缓冲区中的格式
*3\r\n$3\r\nSET\r\n$9\r\nredis-key\r\n$6\r\nvalue1\r\n
</code></pre>

<p><strong>Redis 使用自定义格式区分不同的命令，客户端会对命令请求转换为如下的协议格式，其中换行符 <code>\r\n</code> 用于区分命令请求的若干参数，<code>“*3”</code>表示该命令请求有3个参数，<code>“$3”</code>表示第一个参数长度为3，顺序读取三个字符SET ， <code>“$9”</code>表示第二个参数的长度，读取为redis-key ， <code>“$6”</code> 表示第三个参数长度为，读取为value1</strong></p>

<p>那么命令写入缓冲区后何时同步到文件中呢？</p>

<h3 id="toc_2">1.2、AOF文件写入</h3>

<p>为了提高文件的写入效率,在现代操作系中,当用户调用 write函数,将一些数据写入到文件的时候,操作系统通常会将写入数据暂时保存在一个内存冲区里面, 等到缓冲区的空间被填满、或者超过了指定的时限之后,才真正地将缓冲区中的数据写入到磁盘里面。</p>

<p>这种做法虽然提高了效率,但也为写入数据带来了安全问题,因为如果计算机发生停机,那么保存在内存缓冲区里面的写入数据将会丢失。<br/>
为此,系统提供了 fsync和 fdatasync两个同步函数,它们可以强制让操作系统立即将缓冲区中的数据写入到项盘里面,从而确保写入数据的安全性。</p>

<p>AOF持久化最终需要将缓冲区中的内容写入一个文件，写文件通过操作系统提供的write函数执行。但是write之后数据只是保存在kernel的缓冲区中，真正写入磁盘还需要调用 fsync 函数。fsync是一个阻塞并且缓慢的操作，所以Redis通过appendfsync配置控制执行fsync 的频次。具体有如下3种模式：</p>

<ul>
<li>no ：不执行fsync，将aof_buf 缓冲区中的所有内容写入到AOF文件，但不对AOF文件进行同步，由操作系统负责数据的刷盘。数据安全性最低但Redis性能最高。</li>
<li>always：每执行一次写入就会执行一次fsync。数据安全性最高但会导致Redis性能降低。</li>
<li>everysec： 每1秒执行一次fsync操作。属于折中方案，在数据安全性和性能之间达到一个平衡。</li>
</ul>

<p>生产环境一般配置为appendfsync everysec，即每秒执行一次fsync 操作。</p>

<h3 id="toc_3">1.3、AOF 重写</h3>

<p>随着Redis服务的运行，AOF文件会越来越大，并且当Redis服务有大量的修改操作时，对同一个键可能有成百上千条执行命令。AOF 重写通过fork出一个子进程来执行，重写不会对原有文件进行任何修改和读取，子进程对所有数据库中所有的键各自生成一条相应的执行命令，最后将重写开始后父进程继续执行的命令进行回放，生成一个新的AOF文件。</p>

<p>示例如下：</p>

<pre><code class="language-shell">127.0.0.1:6379&gt; rpush list 1 2 3         //list中增加1,2,3三个元素
(integer)3 
127.0.0.1:6379&gt; rpush list 4             //list中增加4 
(integer)4 
127.0.0.1:6379&gt; rpush list 5         //list中增加5
(integer)5 
127.0.0.1:6379&gt; lpop list            //弹出第一个元素
&quot;1&quot;
</code></pre>

<p>AOF重写就是直接按当前list中的内容写为“rpush list 2345”。4条命令变为了一条命令，既可以减小文件大小，又可以提高加载速度。</p>

<h3 id="toc_4">1.4、AOF重写触发方式</h3>

<p>AOF重写有两种触发方式：一种为通过配置自动触发，一种为手动执行bgrewriteaof命令显式触发。</p>

<ul>
<li><p>看自动触发方式，做如下配置：</p>
<pre><code class="language-text">auto-aof-rewrite-percentage 100 
auto-aof-rewrite-min-size 64mb
</code></pre>
<p>当AOF文件大于64MB时，并且AOF文件当前大小比基准大小增长了100%时会触发一次AOF重写。那么基准大小如何确定呢？起始的基准大小为Redis重启并加载完AOF文件之后，aof_buf的大小。当执行完一次AOF重写之后，基准大小相应更新为重写之后AOF文件的大小。当做了如上配置之后， Redis服务器会根据配置自动触发AOF重写。</p></li>
<li><p>手动触发AOF<br/>
下面我们看下手动触发AOF重写，即通过AOF客户端输入 bgrewriteaof 之后的执行流程。 </p></li>
</ul>

<p><figure><img src="media/15943917797824/15945412157461.jpg" alt="" style="width:1273px;"/></figure></p>

<p>子进程执行重写时可能会有成千上万条命令继续在父进程中执行，那么如何保证重写完成后的文件也包括这些命令呢？</p>

<p>首先需要在父进程中将重写过程中执行的命令进行保存，其次需要将这些命令在重写后的文件中进行回放。</p>

<p>Redis为了尽量减少主进程的阻塞时间，通过管道按批次将父进程累积的命令发送给子进程，由子进程重写完成后进行回放。</p>

<p>那么如何通过管道同步给子进程呢？分析下下图<br/>
<figure><img src="media/15943917797824/15945418134506.jpg" alt=""/></figure></p>

<p>父进程在fork之前会建立3对管道：fd0/fd1、fd2/fd3、fd4/fd5，它们各自配对执行。父进程通过fd1将执行aof重写时累积的命令发送给子进程，子进程通过fd0进行接收并保存。当子进程执行完重写之后，向fd3写入一个“！”号通知父进程不需要继续通过管道发送累积命令，父进程通过fd2接收到“！”号之后向fd5也写入一个“！”号进行确认。子进程通过fd4同步阻塞接收到“！”号后才可进行后续的退出操作。退出时首先会将接收到的累积命令进行回放，然后执行fsync。</p>

<h3 id="toc_5">1.5、混合持久化</h3>

<p>混合持久化指进行AOF重写时子进程将当前时间点的数据快照保存为RDB文件格式，而后将父进程累积命令保存为AOF格式。最终形成 RDB file和 AOF file共存的保存形式。</p>

<p>加载时，首先会识别AOF文件是否以REDIS字符串开头，如果是，就按RDB格式加载，加载完RDB后继续按AOF格式加载剩余部分。</p>

<p>是否开启混合持久化由如下配置设置</p>

<pre><code class="language-text">aof-use-rdb-preamble yes
</code></pre>

<h3 id="toc_6">总结</h3>

<ul>
<li>AOF文件通过保存所有修改数据库的写命令来记录服务器的数据库状态</li>
<li>AOF文件中的所有命令都以Redis命令请求协议的格式保存</li>
<li>命令请求会先保存到AOF缓冲区里面，之后再定期写入并同步到AOF文件</li>
<li>appendfsync选项的不同值对AOF持久化功能的安全性以及 Redis服务器的性能有很大的影响</li>
<li>服务器只要载入并重新执行保存在 AOF文件中的命令，就可以还原数据库本来的状态</li>
<li>AOF重写可以产生一个新的 AOF文件，这个新的 AOF文件和原有的AOF文件保存的数据库状态一样，但体积更小</li>
<li>AOF重写功能是通过读取数据库中的键值对来实现的，程序无需对现有的AOF文件进行任何读入、分析或者写入操作</li>
<li>执行 bgrewriteaof命令的时候，redis 服务器会维护一个AOF重写缓冲区,该缓冲区会在子进程创建新的 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件工作之后，服务器会将重写缓冲区中的所有内容追加到 新AOF文件的末尾，使新旧两个AOF文件所保存的数据库状态一致。最后，服务器使用新的 AOF 文件替换旧的AOF文件，来完成AOF文件的重写操作。</li>
</ul>

<hr/>

<h2 id="toc_7">2、RDB 与 AOF 相关配置指令</h2>

<table>
<thead>
<tr>
<th>配置项</th>
<th>可选值</th>
<th>功能</th>
<th>作用</th>
</tr>
</thead>

<tbody>
<tr>
<td>save</td>
<td><code>&lt;secondes&gt; &lt;changes&gt;</code> 默认：save 900 1、save 300 10、save 60 10000</td>
<td>RDB</td>
<td>自动触发配置</td>
</tr>
<tr>
<td>stop-writes-on-bgsave-error</td>
<td>yes/no(默认yes)</td>
<td>RBD</td>
<td>开启该参数后，如果开启了RDB 快照（即配置了save指令），并且最近一次快照执行失败，则Redis 将停止接收写相关的请求。</td>
</tr>
<tr>
<td>rdbcompression</td>
<td>yes/no(默认yes)</td>
<td>RDB</td>
<td>执行RDB快照时是否将 string类型的数据进行LZF压缩。</td>
</tr>
<tr>
<td>rdbchecksum</td>
<td>yes/no(默认yes)</td>
<td>RDB</td>
<td>是否开启RDB文件内容的校验</td>
</tr>
<tr>
<td>dbfilename</td>
<td>文件名称(默认 dump.rdb)</td>
<td>RDB</td>
<td>RDB文件名称</td>
</tr>
<tr>
<td>dir</td>
<td>文件路径(默认./)</td>
<td>RDB</td>
<td>RDB和AOF文件存放路径</td>
</tr>
<tr>
<td>rdb-save-incremental-fsync</td>
<td>yes/no(默认yes)</td>
<td>RDB</td>
<td>开启该参数后，生成RDB文件时每产生32MB数据就执行一次fsync。</td>
</tr>
<tr>
<td>appendonly</td>
<td>yes/no(默认no)</td>
<td>AOF</td>
<td>是否开启 AOF 功能</td>
</tr>
<tr>
<td>appendfilename</td>
<td>文件名称(默认 appendonly.aof)</td>
<td>AOF</td>
<td>AOF 文件名称</td>
</tr>
<tr>
<td>appendfsync</td>
<td>always/everysec/no (默认 everysec)</td>
<td>AOF</td>
<td>fsync执行频次,always：将aof_buf缓冲区中的所有内容写入并同步到AOF文件；everysec:每1秒执行一次fsync操作。属于折中方案，在数据安全性和性能之间达到一个平衡;no:  不执行fsync，由操作系统负责数据的刷盘。数据安全性最低但Redis性能最高。</td>
</tr>
<tr>
<td>no-appendfsync-on-rewrite</td>
<td>yes/no(默认no)</td>
<td>AOF</td>
<td>开启该参数后，如果后台正在执行一次RDB快照或者AOF重写，则主进程不再进行fsync操作（即使将appendfsync配置为always或者everysec）</td>
</tr>
<tr>
<td>auto-aof-rewrite-percentage</td>
<td>百分比(默认100)</td>
<td>AOF</td>
<td>自动重写配置项，当前AOF文件大于auto-aof-rewrite-min-size 配置的大小 并且比基准文件增长此百分比时触发AOF重写</td>
</tr>
<tr>
<td>auto-aof-rewrite-min-size</td>
<td>文件大小(默认64MB)</td>
<td>AOF</td>
<td>自动重写配置项，当前AOF文件大于此配置值，并且当前AOF文件 比基准文件增长auto-aof-rewrite-percentage配置的百分比时触发AOF重写</td>
</tr>
<tr>
<td>aof-load-truncated</td>
<td>yes/no(默认yes)</td>
<td>AOF</td>
<td>AOF文件以追加日志的方式生成，所以服务端发生故障时可能会有尾部命令不完整的情况。开启该参数后，在此种情况下，AOF文件会截断尾部不完整的命令然后继续加载，并且会在日志中进行提示。如果不开启该参数，则加载AOF文件时会打印错误日志，然后直接退出</td>
</tr>
<tr>
<td>aof-use-rdb-preamble</td>
<td>yes/no(默认yes)</td>
<td>AOF</td>
<td>是否开启混合持久化</td>
</tr>
<tr>
<td>aof-rewrite-incremental-fsync</td>
<td>yes/no(默认yes)</td>
<td>AOF</td>
<td>开启该参数后，AOF重写时没产生32MB数据执行一次fsync</td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[软件设计上的基本知识]]></title>
    <link href="http://www.throne4j.com/15943756601312.html"/>
    <updated>2020-07-10T18:07:40+08:00</updated>
    <id>http://www.throne4j.com/15943756601312.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">API与SPI分离</h2>

<p>框架或组件通常有两类客户，一个是使用者，一个是扩展者，API(Application Programming Interface)是给使用者用的，而SPI(Service Provide Interface)是给扩展者用的，在设计时，尽量把它们隔离开，而不要混在一起，也就是说，使用者是看不到扩展者写的实现的，比如：一个Web框架，它有一个API接口叫Action，里面有个execute()方法，是给使用者用来写业务逻辑的，然后，Web框架有一个SPI接口给扩展者控制输出方式，比如用velocity模板输出还是用json输出等，如果这个Web框架使用一个都继承Action的VelocityAction和一个JsonAction做为扩展方式，要用velocity模板输出的就继承VelocityAction，要用json输出的就继承JsonAction，这就是API和SPI没有分离的反面例子，SPI接口混在了API接口中，合理的方式是，有一个单独的Renderer接口，有VelocityRenderer和JsonRenderer实现，Web框架将Action的输出转交给Renderer接口做渲染输出。</p>

<pre><code class="language-text">![](media/15943756601312/15943757095695.jpg)

![](media/15943756601312/15943757185485.jpg)
</code></pre>

<h2 id="toc_1">服务域/实体域/会话域分离</h2>

<p>任何框架或组件，总会有核心领域模型，比如：<br/>
Spring的Bean，Struts的Action，Dubbo的Service，Napoli的Queue等等<br/>
这个核心领域模型及其组成部分称为实体域，它代表着我们要操作的目标本身，实体域通常是线程安全的，不管是通过不变类，同步状态，或复制的方式，服务域也就是行为域，它是组件的功能集，同时也负责实体域和会话域的生命周期管理，比如Spring的ApplicationContext，Dubbo的ServiceManager等，服务域的对象通常会比较重，而且是线程安全的，并以单一实例服务于所有调用，什么是会话？就是一次交互过程，会话中重要的概念是上下文，什么是上下文？</p>

<p>比如我们说：“老地方见”，这里的“老地方”就是上下文信息，为什么说“老地方”对方会知道，因为我们前面定义了“老地方”的具体内容，所以说，上下文通常持有交互过程中的状态变量等，会话对象通常较轻，每次请求都重新创建实例，请求结束后销毁。</p>

<p>简而言之：<br/>
把元信息交由实体域持有，把一次请求中的临时状态由会话域持有，由服务域贯穿整个过程。</p>

<p><figure><img src="media/15943756601312/15943757281530.jpg" alt=""/></figure>       <figure><img src="media/15943756601312/15943757329746.jpg" alt=""/></figure></p>

<h2 id="toc_2">在重要的过程上设置拦截接口</h2>

<p>如果你要写个远程调用框架，那远程调用的过程应该有一个统一的拦截接口，如果你要写一个ORM框架，那至少SQL的执行过程，Mapping过程要有拦截接口，如果你要写一个Web框架，那请求的执行过程应该要有拦截接口，等等，没有哪个公用的框架可以Cover住所有需求，允许外置行为，是框架的基本扩展方式，这样，如果有人想在远程调用前，验证下令牌，验证下黑白名单，统计下日志，如果有人想在SQL执行前加下分页包装，做下数据权限控制，统计下SQL执行时间，如果有人想在请求执行前检查下角色，包装下输入输出流，统计下请求量，等等，就可以自行完成，而不用侵入框架内部，拦截接口，通常是把过程本身用一个对象封装起来，传给拦截器链，</p>

<p>比如：远程调用主过程为invoke()，那拦截器接口通常invoke(Invocation)，Invocation对象封装了本来要执行过程的上下文，并且Invocation里有一个invoke()方法，由拦截器决定什么时候执行，同时，Invocation也代表拦截器行为本身，这样上一拦截器的Invocation其实是包装的下一拦截器的过程，直到最后一个拦截器的Invocation是包装的最终的invoke()过程，同理，SQL主过程为execute()，那拦截器接口通常为execute(Execution)，原理一样，当然，实现方式可以任意，上面只是举例。</p>

<p><figure><img src="media/15943756601312/15943757516458.jpg" alt=""/></figure></p>

<h2 id="toc_3">重要的状态的变更发送事件并留出监听接口</h2>

<p>这里先要讲一个事件和上面拦截器的区别，拦截器是干预过程的，它是过程的一部分，是基于过程行为的，而事件是基于状态数据的，任何行为改变的相同状态，对事件应该是一致的，事件通常是事后通知，是一个Callback接口，方法名通常是过去式的，比如onChanged()，比如远程调用框架，当网络断开或连上应该发出一个事件，当出现错误也可以考虑发出一个事件，这样外围应用就有可能观察到框架内部的变化，做相应适应。</p>

<p><figure><img src="media/15943756601312/15943757591172.jpg" alt=""/></figure></p>

<h2 id="toc_4">扩展接口职责尽可能单一，具有可组合性</h2>

<p>比如，远程调用框架它的协议是可以替换的，如果只提供一个总的扩展接口，当然可以做到切换协议，但协议支持是可以细分为底层通讯，序列化，动态代理方式等等，如果将接口拆细，正交分解，会更便于扩展者复用已有逻辑，而只是替换某部分实现策略，当然这个分解的粒度需要把握好。</p>

<h2 id="toc_5">微核插件式，平等对待第三方</h2>

<p>大凡发展的比较好的框架，都遵守微核的理念，Eclipse的微核是OSGi， Spring的微核是BeanFactory，Maven的微核是Plexus，通常核心是不应该带有功能性的，而是一个生命周期和集成容器，这样各功能可以通过相同的方式交互及扩展，并且任何功能都可以被替换，如果做不到微核，至少要平等对待第三方，即原作者能实现的功能，扩展者应该可以通过扩展的方式全部做到，原作者要把自己也当作扩展者，这样才能保证框架的可持续性及由内向外的稳定性。</p>

<h2 id="toc_6">不要控制外部对象的生命周期</h2>

<p>比如上面说的Action使用接口和Renderer扩展接口，框架如果让使用者或扩展者把Action或Renderer实现类的类名或类元信息报上来，然后在内部通过反射newInstance()创建一个实例，这样框架就控制了Action或Renderer实现类的生命周期，Action或Renderer的生老病死，框架都自己做了，外部扩展或集成都无能为力，好的办法是让使用者或扩展者把Action或Renderer实现类的实例报上来，框架只是使用这些实例，这些对象是怎么创建的，怎么销毁的，都和框架无关，框架最多提供工具类辅助管理，而不是绝对控制。</p>

<h2 id="toc_7">可配置一定可编程，并保持友好的CoC约定</h2>

<p>因为使用环境的不确定因素很多，框架总会有一些配置，一般都会到classpath直扫某个指定名称的配置，或者启动时允许指定配置路径，做为一个通用框架，应该做到凡是能配置文件做的一定要能通过编程方式进行，否则当使用者需要将你的框架与另一个框架集成时就会带来很多不必要的麻烦，另外，尽可能做一个标准约定，如果用户按某种约定做事时，就不需要该配置项。</p>

<p>比如：配置模板位置，你可以约定，如果放在templates目录下就不用配了，如果你想换个目录，就配置下。</p>

<h2 id="toc_8">区分命令与查询，明确前置条件与后置条件</h2>

<p>这个是契约式设计的一部分，尽量遵守有返回值的方法是查询方法，void返回的方法是命令，查询方法通常是幂等性的，无副作用的，也就是不改变任何状态，调n次结果都是一样的，比如get某个属性值，或查询一条数据库记录，命令是指有副作用的，也就是会修改状态，比如set某个值，或update某条数据库记录，如果你的方法即做了修改状态的操作，又做了查询返回，如果可能，将其拆成写读分离的两个方法，</p>

<p>比如：User deleteUser(id)，删除用户并返回被删除的用户，考虑改为getUser()和void的deleteUser()。另外，每个方法都尽量前置断言传入参数的合法性，后置断言返回结果的合法性，并文档化。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[八、Redis 持久化--RDB（一）]]></title>
    <link href="http://www.throne4j.com/15942163464303.html"/>
    <updated>2020-07-08T21:52:26+08:00</updated>
    <id>http://www.throne4j.com/15942163464303.html</id>
    <content type="html"><![CDATA[
<p>Redis 是一个内存数据库，为了保证数据不丢失，持久化就显得尤为重要了。Redis 有两种持久化方法:RDB方式，RDB保存某一个时间点之前的数据；另一种为AOF方式，AOF保存的是Redis服务器端执行的每一条命令。</p>

<p>通过info命令查看 redis服务端记录的相关持久化状态信息：</p>

<pre><code class="language-shell">127.0.0.1:6379&gt;info
# Persistence 
loading:0                               //是否正在加载RDB文件内容
rdb_changes_since_last_save:2           //最后一次保存之后改变的键的个数
rdb_bgsave_in_progress:0                //是否正在后台执行RDB保存任务
rdb_last_save_time:1540371552           //最后一次执行RDB保存任务的时间
rdb_last_bgsave_status:ok               //最后一次执行RDB保存任务的状态
rdb_last_bgsave_time_sec:0              //最后一次执行RDB保存任务消耗的时间
rdb_current_bgsave_time_sec:-1          //如果正在执行RDB保存任务，则为当前RDB任务已经消耗的时间，否则为-1 
rdb_last_cow_size:6631424               //最后一次执行RDB保存任务消耗的内存
aof_enabled:0                           //是否开启了AOF功能aof_rewrite_in_progress:0               //是否正在后台执行AOF重写任务
aof_rewrite_scheduled:0                 //是否等待调度一次AOF重写任务。如果触发了一次AOF重写，                                          但是后台正在执行RDB保存任务时会将该状态置为1 
aof_last_rewrite_time_sec:-1            //最后一次执行AOF重写任务消耗的时间
aof_current_rewrite_time_sec:-1         //如果正在执行AOF重写任务，则为当前该任务已经消耗的时间，否则为-1 
aof_last_bgrewrite_status:ok            //最后一次执行AOF重写任务的状态
aof_last_write_status:ok                //最后一次执行AOF缓冲区写入的状态（服务端执行命令时会开辟一段内存空间将命令放入其中，然后从该缓冲区中同步到文件。该状态标记最后一次同步到文件的状态
aof_last_cow_size:0                     //最后一次执行AOF重写任务消耗的内存

</code></pre>

<h2 id="toc_0">RDB 持久化方式</h2>

<p>RDB持久化方式是保存一个时间点的快照。</p>

<p>RDB快照有两种触发方式</p>

<ul>
<li>配置参数，在配置文件中写入 <code>save 60 1000</code>，则在60秒内如果有1000个key发生变化，就出发一次RDB快照执行。</li>
<li>通过客户端执行 bgsave 命令显式的触发一次RDB快照的执行。</li>
</ul>

<p>bgsave执行流程如下图所示：</p>

<p><figure><img src="media/15942163464303/15942173127342.jpg" alt="bgsave 执行流程"/><figcaption>bgsave 执行流程</figcaption></figure></p>

<p>在客户端输入 bgsave 命令后，Redis调用 bgsaveCommand 函数，该函数fork一个子进程执行 rdbSave 函数进行实际的快照存储工作，而父进程可以继续处理客户端请求。当子进程退出后，父进程调用相关回调函数进行后续处理。</p>

<h3 id="toc_1">RDB文件结构</h3>

<p>RDB 整体文件结构如下图所示：</p>

<p><figure><img src="media/15942163464303/15942232766455.jpg" alt=""/></figure></p>

<ul>
<li>头部5字节固定为“REDIS”字符串</li>
<li>4字节的RDB版本号（RDB_VERSION，注意不是Redis的版本号），当前RDB版本号为9，填充为4字节之后为0008。</li>
<li><p>辅助字段AUX_FIELD_KEY_VALUE_PAIRS，辅助字段可以标明以下信息</p>
<table>
<thead>
<tr>
<th>字段名称</th>
<th>字段值</th>
</tr>
</thead>
<tbody>
<tr>
<td>redis-ver</td>
<td>5.0.04</td>
</tr>
<tr>
<td>redis-bits</td>
<td>64/32</td>
</tr>
<tr>
<td>ctime</td>
<td>当前时间戳</td>
</tr>
<tr>
<td>used-mem</td>
<td>redis占用内存</td>
</tr>
<tr>
<td>aof-preamble</td>
<td>是否开启aof/rdb混合持久化</td>
</tr>
<tr>
<td>repl-stream-db</td>
<td>主从复制相关</td>
</tr>
<tr>
<td>repl-id</td>
<td>主从复制相关</td>
</tr>
<tr>
<td>repl-offset</td>
<td>主从复制相关</td>
</tr>
</tbody>
</table></li>
<li><p>数据库序号：指明数据需要存放到哪个数据库</p></li>
<li><p>当前数据库键值对散列表的大小，这样在加载时可以直接将散列表扩展到指定大小，提升加载速度。</p></li>
<li><p>当前数据库过期时间散列表的大小</p></li>
<li><p>Redis中具体键值对的存储</p></li>
<li><p>RDB文件结束标志</p></li>
<li><p>8字节校验码</p></li>
</ul>

<p>加载RDB文件的时候怎么区分加载的是辅助字段还是数据库序号或者是其他类型呢？其实在RDB每一部分之前都有一个类型字节，在Redis中称为opcodes，opcodes如下所示：</p>

<pre><code class="language-c">#define RDB_OPCODE_MODULE_AUX    247        //module相关辅助字段
#define RDB_OPCODE_IDLE          248        //lru空闲时间
#define RDB_OPCODE_FREQ          249        //lfu频率
#define RDB_OPCODE_AUX           250        //辅助字段类型
#define RDB_OPCODE_RESIZEDB      251        //RESIZEDB，即上文中介绍的5和6两项
#define RDB_OPCODE_EXPIRETIME_MS 252        //毫秒级别过期时间
#define RDB_OPCODE_EXPIRETIME    253        //秒级别过期时间
#define RDB_OPCODE_SELECTDB      254        //数据库序号，即第4项
#define RDB_OPCODE_EOF           255        //结束标志，即第8项
</code></pre>

<p>带opcodes 的RDB 结构表显形式</p>

<p><figure><img src="media/15942163464303/15942254144953.jpg" alt=""/></figure></p>

<p>下面我们看下 键值对的结构，如下图所示<br/>
<figure><img src="media/15942163464303/15942257282611.jpg" alt=""/></figure></p>

<ul>
<li>EXPIRE_TIME: 可选。根据具体的键是否有过期时间决定，该字段固定为8个字节。</li>
<li>LRU或者LFU：可选。根据配置的内存淘汰算法决定。LRU算法保存秒级别的时间戳，LFU算法只保存counter的计数（0～255，1 字节）</li>
<li><p>VALUE_TYPE：值类型。Redis数据类型和底层编码结构<br/>
<figure><img src="media/15942163464303/15942258850154.jpg" alt=""/></figure></p></li>
<li><p>KEY：键。键保存为字符串，下文会详细介绍字符串的保存形式。</p></li>
<li><p>VALUE：值。值根据数据类型和编码结构保存为不同的形式</p></li>
</ul>

<h3 id="toc_2">RDB键的保存形式</h3>

<p>redis中键都是字符串，比较常见的保存方法如下图所示：<br/>
<figure><img src="media/15942163464303/15943123637192.jpg" alt=""/></figure></p>

<p>前边LENGTH字段表示字符串长度，后边STRING即具体的字符串内容。</p>

<p>Redis中的LENGTH是个变长字段，通过首字节能够知道LENGTH字段有多长，然后读取LENGTH字段可以知道具体的STRING长度。LENGTH字段类型如下:</p>

<pre><code class="language-shell">00xxxxxx   #表示LENGTH字段占用1个字节，STRING的长度保存在后6个比特中，最长为63。
01xxxxxx xxxxxxxx  #表示LENGTH字段占用2个字节，而STRING的长度保存在后14个字节中，最长为16383 
10000000 xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx  表示LENGTH字段共占用5个字节，正好是一个无符号整型，STRING的长度最长为UINT32_MAX。 
10000001 xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx #如果STRING长度大于UINT32_MAX，则首字节表示为10000001，LENGTH字段共占用9个字节。后8字节表示实际长度，为一个LONG类型。
</code></pre>

<p>RDB中对字符串的保存还有两种优化形式：</p>

<ul>
<li><p>一种是尝试将字符串按整型保存<br/>
<figure><img src="media/15942163464303/15943127989186.jpg" alt="字符串按整型保存"/><figcaption>字符串按整型保存</figcaption></figure> </p>
<p>TYPE字段其实类似图20-5中的LENGTH字段，LENGTH字段首字节头两个比特取值为00、01、10这种类型，TYPE字段首字节头两个比特取值为11，后6个比特表明存储的整型类型，如下所示：</p>
<pre><code class="language-text">11000000 xxxxxxxx  INT8   取值范围[-128,127] 
11000001 xxxxxxxx xxxxxxxx INT16 取值范围[-32768,32767] <br/>
11000010 xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx  INT32 取值范围[-2147483648 ,  2147483647] 
</code></pre></li>
<li><p>一种是通过将字符串进行LZF压缩之后保存。<br/>
<figure><img src="media/15942163464303/15943130001731.jpg" alt="RDB LZF保存形式"/><figcaption>RDB LZF保存形式</figcaption></figure></p>
<p>TYPE首字节头两个比特仍然为11，后六个比特是000011。COMPRESS_LEN表明压缩之后的长度，该字段保存形式同图20-5中LENGTH字段的保存。LZF还保存了一个ORIGINAL_LEN字段，该字段记录压缩之前原始字符串的长度，保存形式也与图20-5中LENGTH字段的保存相同。最后一个DATA字段保存具体的LZF压缩之后的数据，数据长度从COMPRESS_LEN字段取得。</p></li>
</ul>

<h3 id="toc_3">RDB 值保存形式</h3>

<p>值类型有如下图所示：<br/>
<figure><img src="media/15942163464303/15943894568628.jpg" alt=""/></figure></p>

<p>其中字符串类型的保存于 上面的《键的保存形式》相同，其余几种值的保存形式各不相同</p>

<h4 id="toc_4">列表类型的保存</h4>

<p>列表在Redis中编码为 quicklist结构，从整体看是一个双向链表，但链表的每个节点在Redis中编码为zipList结构，ziplist结构在一块连续的内存中保存，并且保存时可以选择进行LZF压缩或者不压缩。据此，RDB 保存列表类型的结构如图所示：</p>

<p>ziplist未压缩<br/>
<figure><img src="media/15942163464303/15943897652665.jpg" alt=""/></figure></p>

<p>ziplist压缩：</p>

<p><figure><img src="media/15942163464303/15943898009527.jpg" alt=""/></figure></p>

<p>如果ziplist未压缩，每个ziplist按照字符串保存，如果ziplist进行了压缩，则按照下图方式进行保存<br/>
<figure><img src="media/15942163464303/15943899607716.jpg" alt="" style="width:544px;"/></figure></p>

<h4 id="toc_5">集合类型的保存</h4>

<p>集合类型在Redis中有两种编码方式：一种为intset，另一种为Hash。<br/>
intset在Redis中也是一块连续的内存，所以intset的保存比较简单，直接将intset按字符串保存。</p>

<p>如果编码为Hash，保存结构如下图所示：<br/>
<figure><img src="media/15942163464303/15943908892309.jpg" alt=""/></figure><br/>
第一个字段为字典的大小，接下来逐字段保存字典的键。为什么只保存键呢？其实集合类型使用散列表保存时只使用了键，所有的值都保存为NULL，所以此处只需要保存散列表的键。</p>

<h4 id="toc_6">有序集合类型的保存</h4>

<p>有序集合类型在Redis中也有两种编码方式：一种为ziplist，另一种为skiplist。如果编码为ziplist，即将ziplist整体作为一个字符串保存。所以我们重点看编码为skiplist的保存方式</p>

<p><figure><img src="media/15942163464303/15943913158909.jpg" alt=""/></figure><br/>
第一个字段为skiplist包含的元素个数，接着分别按元素和元素的分值依次保存。元素保存为字符串，元素分值保存为一个双精度浮点数类型（固定为8个字节）</p>

<h4 id="toc_7">散列类型的保存</h4>

<p>散列类型也有两种编码方式：一种为ziplist，一种为Hash。ziplist 编码方式的保存同有序集合。重点看散列类型按Hash编码时的保存方式。<br/>
<figure><img src="media/15942163464303/15943913962043.jpg" alt=""/></figure><br/>
第一个字段为散列表的大小，然后依次保存键值对，键值都保存为字符串类型。</p>

<h4 id="toc_8">Stream类型的保存</h4>

<p>Stream保存为RDB文件时整体格式如图所示：<br/>
<figure><img src="media/15942163464303/15943914536802.jpg" alt=""/></figure><br/>
其中具体的结构体介绍，如listpack，消费组等的介绍参考<a href="15938782048225.html">六、Redis 数据流 stream </a>。其中保存消费组的PEL时并没有保存相关消费者的信息，而是在加载完消费者之后，从消费者的PEL中查找并更新消费组PEL的相关信息。</p>

<h3 id="toc_9">RDB 实例</h3>

<p>我们查看一下空的 redis 库是怎样的</p>

<pre><code class="language-text">127.0.0.1:6379&gt;flushall
ok
127.0.0.1:6379&gt;bgsave
Background saving started
</code></pre>

<pre><code class="language-text">➜  redis xxd dump.rdb
00000000: 5245 4449 5330 3030 39fa 0972 6564 6973  REDIS0009..redis
00000010: 2d76 6572 0535 2e30 2e38 fa0a 7265 6469  -ver.5.0.8..redi
00000020: 732d 6269 7473 c040 fa05 6374 696d 65c2  s-bits.@..ctime.
00000030: 1a45 075f fa08 7573 6564 2d6d 656d c210  .E._..used-mem..
00000040: 0910 00fa 0c61 6f66 2d70 7265 616d 626c  .....aof-preambl
00000050: 65c0 00ff fe39 f4d9 2732 2a22            e....9..&#39;2*&quot;
➜  redis od -cx dump.rdb
0000000    R   E   D   I   S   0   0   0   9 372  \t   r   e   d   i   s
             4552    4944    3053    3030    fa39    7209    6465    7369
0000020    -   v   e   r 005   5   .   0   .   8 372  \n   r   e   d   i
             762d    7265    3505    302e    382e    0afa    6572    6964
0000040    s   -   b   i   t   s 300   @ 372 005   c   t   i   m   e 032
             2d73    6962    7374    40c0    05fa    7463    6d69    c265
0000060  032   E  \a   _ 372  \b   u   s   e   d   -   m   e   m 302 020
             451a    5f07    08fa    7375    6465    6d2d    6d65    10c2
0000100   \t 020  \0 372  \f   a   o   f   -   p   r   e   a   m   b   l
             1009    fa00    610c    666f    702d    6572    6d61    6c62
0000120    e 300  \0 377 376   9 364 331   &#39;   2   *   &quot;
             c065    ff00    39fe    d9f4    3227    222a
0000134
</code></pre>

<ul>
<li>RDB 文件用于保存和还原Redis服务器所有的数据库中的所有的键值对数据</li>
<li>save命令有服务器进行直接执行保存操作，但是会阻塞服务器</li>
<li>bgsave由紫禁城执行保存操作，不会阻塞服务器</li>
<li>服务器状态中会保存所有用save选项设置的保存条件，当人以一个保存条件被满足时，服务器会自动执行 bgsave 命令</li>
<li>RDB 文件是一个经过压缩的二进制文件，由多个部分组成</li>
<li>对于不同类型的键值对，RDB文件会使用不同的方式来保存它们。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[七、Redis 事务]]></title>
    <link href="http://www.throne4j.com/15940318259166.html"/>
    <updated>2020-07-06T18:37:05+08:00</updated>
    <id>http://www.throne4j.com/15940318259166.html</id>
    <content type="html"><![CDATA[
<p>Redis 中的事务能够保证一批命令的原子性操作，redis提供了 事务的命令有 watch、unwatch、multi、exec、discard 。<br/>
事务从开始到结束经历以下三个阶段：</p>

<ul>
<li><p>multi 开启事务<br/>
Redis 的事务 不能嵌套，即不能再一个开启的事务内再次调用multi命令开启新的事务。<br/>
multi命令源码：</p>
<pre><code class="language-redis">void multiCommand(client *c) {     
    //如果已经执行过multi命令，则不能再次执行<br/>
    if (c-&gt;flags &amp; CLIENT_MULTI) {        <br/>
        addReplyError(c,&quot;MULTI calls can not be nested&quot;);         <br/>
        return;     <br/>
    }     <br/>
    //client结构体置CLIENT_MULTI标志<br/>
    c-&gt;flags |= CLIENT_MULTI;                            <br/>
    addReply(c,shared.ok); <br/>
}
</code></pre></li>
<li><p>所有的命令会首先入队而不是直接执行</p>
<ul>
<li>当一个客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行。</li>
<li>当一个客户端处于事务状态后，服务器会根据客户端发来的不同命令执行不同的操作
<ul>
<li>发送命令 exec、discard、watch、unwatch，服务器会立即执行此命令</li>
<li>发送非exec、discard、watch、unwatch 命令，将这个命令放入一个事务队列里面，然后向客户端返回QUEUED回复。</li>
</ul></li>
</ul>
<pre><code class="language-text">int processCommand(client *c) {
    ...<br/>
        if (c-&gt;flags &amp; CLIENT_MULTI <br/>
            &amp;&amp; c-&gt;cmd-&gt;proc != execCommand <br/>
            &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand <br/>
            &amp;&amp;  c-&gt;cmd-&gt;proc != multiCommand <br/>
            &amp;&amp; c-&gt;cmd-&gt;proc != watchCommand) {<br/>
            //如果client有CLIENT_MULTI标志并且不是exec，discard，                                          multi和watch命令，则将该命令放入队列            <br/>
            queueMultiCommand(c);        //放入队列            <br/>
            addReply(c,shared.queued);         <br/>
        } else {                        <br/>
            //否则调用call命令            <br/>
            call(c,CMD_CALL_FULL);         <br/>
            ...<br/>
        } <br/>
 ...<br/>
}
</code></pre></li>
<li><p>exec提交并开始执行事务，exec命令执行所有入队命令，将命令返回值依次返回给客户端。</p></li>
</ul>

<p>watch命令提供了一种乐观锁机制。watch命令可以监听多个key，只有当被监听的key未修改时，事务才会执行。当一个事务发送exec或者discard命令后，所有watch的key会自动unwatch。</p>

<p>unwatch 命令其实就是删除相应client端和server端的监听状态。首先从client端的链表中取出key和对应的db，然后删除server端相应的监听信息，删除成功后再将client端的对应链表节点删除。执行完毕后，该连接所有被监听的key都会恢复到未监听状态。</p>

<p>discard命令放弃事务。放弃一个事务时首先会将所有入队命令清空，然后将client上事务相关的flags清空，最后将所有监听的keys取消监听。</p>

<p><strong><em>Redis 事务不支持事务回滚机制</em></strong>，即使事务队列中的某个命令在执行期间发生错误，整个事务也会继续执行下去，直到将事务队列中的所有命令都执行完毕为止。</p>

<h2 id="toc_0">事务队列</h2>

<p>每个redis 客户端都有自己的事务状态，这个事务状态保存在客户端状态的mstate属性中</p>

<pre><code class="language-c">typedef struct client {
    multiState mstate;   //命令队列，会将所有的命令按照顺序排列好并保存
} client;

typedef struct multiState {
    multiCmd *commands;//命令队列，FIFO顺序
    int count;// 已入队命令计数
}

typedef struct multiCmd {

    robj **argv;//参数
    int argc;//参数数量
    struct redisCommand *cmd;//命令指针
</code></pre>

<p>事务队列以先进先出(FIFO)的方式保存入队命令。</p>

<h2 id="toc_1">判断事务是否安全</h2>

<p>当客户端 执行 exec 提交事务的时候，服务器会根据这个客户端是否打开了 REDIS_DIRTY_CAS 标识来决定是否执行事务。</p>

<ul>
<li>如果客户端的REDIS_DIRTY_CAS (watch命令)标识已经被打开，那么说明客户端所监视的键当中，至少有一个键已经被修改过，这种情况，客户端提交的事务已经不再安全，这是服务器拒绝执行客户端提交的事务。</li>
<li>如果客户端的REDIS_DIRTY_CAS (watch命令)标识没有被打开，说明客户端监视的所有键都没有被修改过，事务仍然安全，服务器将执行客户端提交的事务。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[限流]]></title>
    <link href="http://www.throne4j.com/15938782054278.html"/>
    <updated>2020-07-04T23:56:45+08:00</updated>
    <id>http://www.throne4j.com/15938782054278.html</id>
    <content type="html"><![CDATA[
<p>保证系统能正常稳定的运行</p>

<ul>
<li>限制总并发数<br/>
数据库连接池、线程池</li>
<li>限制瞬时并发数<br/>
如nginx的limit_conn 模块，用来限制瞬时并发连接数</li>
<li>限制时间窗口内的平均速率<br/>
如guava的 RateLimiter、nginx的limit_req 模块，限制每秒平均速率</li>
<li>其它限制<br/>
如限制远程接口调用速率、限制mq的消费速率</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[六、Redis 数据流 stream]]></title>
    <link href="http://www.throne4j.com/15938782048225.html"/>
    <updated>2020-07-04T23:56:44+08:00</updated>
    <id>http://www.throne4j.com/15938782048225.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1、stream 实现</h2>

<p>消息队列是分布式系统中不可缺少的组件之一，主要有异步处理、应用解耦、限流削峰的功能。目前应用较为广泛的消息队列有RabbitMQ、RocketMQ、Kafka等。Redis在最新的5.0.0版本中也加入了消息队列的功能，这就是Stream。</p>

<p>Redis Stream 它主要由消息、生产者、消费者、消费组4部分组成。可以通过如下指令创建一个消息流并项其中加入一条消息<br/>
<figure><img src="media/15938782048225/15939414214436.jpg" alt="" style="width:800px;"/></figure></p>

<pre><code class="language-text">xadd mystream * name zhangsan age 10
</code></pre>

<p>上面的命令中</p>

<ul>
<li>mystream 为 Stream 的名称；</li>
<li>* 代表由Redis自行生成消息ID；</li>
<li>name、age为该消息的field；hb、20则为对应的field的值。</li>
</ul>

<p>每个消息都由以下两部分组成:</p>

<ul>
<li>每个消息有唯一的消息ID，消息ID严格递增。</li>
<li>消息内容由多个field-value对组成。</li>
</ul>

<p>生产者负责向消息队列中生产消息，消费者消费某个消息流。消费者可以归属某个消费组，也可以不归属任何消费组。当消费者不归属于任何消费组时，该消费者可以消费消息队列中的任何消息。</p>

<p>消费组是Stream 具有如下特点</p>

<ul>
<li>每个消费组通过组名称唯一标识，每个消费组都可以消费该消息队列的全部消息，多个消费组之间相互独立。</li>
<li>每个消费组可以有多个消费者，消费者通过名称唯一标识，消费者之间的关系是竞争关系，也就是说一个消息只能由该组的一个成员消费。</li>
<li>组内成员消费消息后需要确认，每个消息组都有一个待确认消息队列（pending entry list，pel），用以维护该消费组已经消费但没有确认的消息。</li>
<li>消费组中的每个成员也有一个待确认消息队列，维护着该消费者已经消费尚未确认的消息。</li>
</ul>

<p>Redis Stream的底层实现主要使用了listpack以及Rax树</p>

<h3 id="toc_1">1.1、stream 底层结构 listpack</h3>

<p>listpack 是一个字符串列表的序列化格式，也就是将一个字符串列表进行序列化存储。Redis listpack可用于存储字符串或者整型。</p>

<p><figure><img src="media/15938782048225/15938831394252.jpg" alt="listpack结构图"/><figcaption>listpack结构图</figcaption></figure></p>

<p>listpack由4部分组成：</p>

<ul>
<li>Total Bytes：整个listpack的空间大小，占用4个字节，每个listpack最多占用4294967295Bytes。</li>
<li>Num Elem：listpack中的元素个数，即Entry的个数，占用2个字节<br/>
虽然占用2个字节，但是并不意味着listpack最多只能存放65535个Entry，当Entry个数大于等于65535时，Num Elem被设置为65535，此时如果需要获取元素个数，需要遍历整个listpack</li>
<li>End：listpack结束标志，占用1个字节，内容为0xFF。</li>
<li>Entry： 每个具体的元素，其内容可以为字符串或者整型。
<ul>
<li>encode： 该entry元素的编码，占用1个字节</li>
<li>content：entry元素内容</li>
<li>backlen： 记录了这个Entry的长度（Encode+content）</li>
</ul></li>
</ul>

<h3 id="toc_2">1.2、Stream底层结构Rax</h3>

<p>前缀树是字符串查找时，经常使用的一种数据结构，能够在一个字符串集合中快速查找到某个字符串, 但是由于前缀树中每个节点只存储字符串中的一个字符，故而有时会造成空间的浪费。Rax的出现就是为了解决这一问题，Rax中不仅可以存储字符串，同时还可以为这个字符串设置一个值，也就是key-value。</p>

<p><figure><img src="media/15938782048225/15939279706367.jpg" alt="含有两个压缩节点的rax"/><figcaption>含有两个压缩节点的rax</figcaption></figure></p>

<p><figure><img src="media/15938782048225/15939288033339.jpg" alt="含有foobar,footer两个key的Rax"/><figcaption>含有foobar,footer两个key的Rax</figcaption></figure></p>

<pre><code class="language-c">typedef struct rax {    
     raxNode *head;     //指向头节点的指针
     uint64_t numele;     //key的个数
     uint64_t numnodes; //节点个数
} rax;

typedef struct raxNode {     
    uint32_t iskey:1;   /* 当前节点是否包含一个key，占用1bit*/     
    uint32_t isnull:1;  /* 当前key对应的value是否为空，占用1bit */     
    uint32_t iscompr:1; /* 当前节点是否为压缩节点，占用1bit */     
    uint32_t size:29;   /* 压缩节点压缩的字符串长度或者非压缩节点的子节点个数，占用29bit */
    unsigned char data[];  /*包含填充字段，同时存储了当前节点包含的字符串以及子节点的指针、key对应的value指针。*/
} raxNode;
</code></pre>

<p>raxNode分为2类，压缩节点和非压缩节点</p>

<ul>
<li>压缩节点 。我们假设该节点存储的内容为字符串ABC
<figure><img src="media/15938782048225/15939314326955.jpg" alt=""/></figure>
<ul>
<li>·iskey为1且isnull为0时，value-ptr存在，否则value-ptr不存在；</li>
<li>·iscompr为1代表当前节点是压缩节点，size为3代表存储了3个字符；</li>
<li>紧随size的是该节点存储的字符串，根据字符串的长度确定是否需要填充字段（填充必要的字节，使得后面的指针地址放到合适的位置上）；</li>
<li>由于是压缩字段，故而只有最后一个字符有子节点。</li>
</ul></li>
<li>非压缩节点 。我们假设其内容为XY
<figure><img src="media/15938782048225/15939394205610.jpg" alt=""/></figure>
每个字符都有一个子节点，值得一提的是，字符个数小于2时，都是非压缩节点。</li>
</ul>

<h2 id="toc_3">2、stream 结构</h2>

<p>Redis Stream的实现依赖于Rax结构以及listpack结构，每个消息的具体信息存储在这个listpack中。Rax用于快速索引；listpack用于存储具体的消息</p>

<p>每个listpack都有一个master entry，该结构中存储了创建这个listpack时待插入消息的所有field，这主要是考虑同一个消息流，消息内容通常具有相似性，如果后续消息的field与master entry内容相同，则不需要再存储其field。</p>

<p>每个listpack中可能存储多条消息</p>

<p><figure><img src="media/15938782048225/15939395823945.jpg" alt="Stream结构"/><figcaption>Stream结构</figcaption></figure></p>

<p>Stream结构如下</p>

<pre><code class="language-c">/*
*每个Stream会有多个消费组，每个消费组通过组名称进行唯一标识，
*同时关联一个streamCG结构，
*/
typedef struct stream {     
   /*
   存储消息生产者生产的具体消息，每个消息有唯一的ID。
   以消息ID为键，消息内容为值存储在rax中，
   值得注意的是，rax中的一个节点可能存储多个消息， 
   */     
    rax *rax;             
    /*当前stream中的消息个数（不包括已经删除的消息）*/
    uint64_t length;     
    /*当前stream中最后插入的消息的ID，stream为空时，设置为0*/   
    streamID last_id;
    /*存储了当前stream相关的消费组，以消费组的组名为键，streamCG为值存储在rax中*/
    rax *cgroups;
} stream;

/*消费组结构定义*/
typedef struct streamCG {
    /*last_id为该消费组已经确认的最后一个消息的ID*/
    streamID last_id; 
    /*该消费组尚未确认的消息，并以消息ID为键，streamNACK（代表一个尚未确认的消息）为值*/
    rax *pel;
    /*为该消费组中所有的消费者，并以消费者的名称为键，streamConsumer（代表一个消费者）为值。*/
    rax *consumers; 
} streamCG;

/*消费者，每个消费者通过streamConsumer唯一标识*/
typedef struct streamConsumer {     
    mstime_t seen_time;     //该消费者最后一次活跃的时间
    sds name;     //消费者的名称
    rax *pel;   //该消费者尚未确认的消息，以消息ID为键，streamNACK 为值。
} streamConsumer;


/*未确认消息，维护了消费组或者消费者尚未确认的消息，
值得注意的是，消费组中的pel的元素与每个消费者的pel中的元素是共享的，
即该消费组消费了某个消息，这个消息会同时放到消费组以及该消费者的pel队列中，并且二者是同一个streamNACK结构。*/
typedef struct streamNACK {     
    mstime_t delivery_time;     //该消息最后发送给消费方的时间
    uint64_t delivery_count;     //该消息已经发送的次数
    streamConsumer *consumer;  //该消息当前归属的消费者。
} streamNACK;
</code></pre>

<hr/>

<h2 id="toc_4">3、Stream 命令</h2>

<h3 id="toc_5">xadd 命令</h3>

<p>将指定消息数据追加到指定的Stream队列中或裁减列中数据长度。</p>

<pre><code class="language-bash">xadd key [MAXLEN [~|=] &lt;count&gt;] &lt;ID or *&gt; [field value] [field value] ...
</code></pre>

<p>每条消息由一或多个阈值对组成，消息插入Stream队列中后会返回唯一的消息ID。xadd是唯一可以向Stream队列添加数据的命令</p>

<ul>
<li>MAXLEN<br/>
当Stream中数据量过大时，可通过此关键字来裁剪长度，删除stream中旧数据至指定的值；当数据量小于等于指定值时，不进行剪切。其中裁剪模式有两种。
<ul>
<li>~：模糊裁剪，优化精确裁剪，一般用此模式，效率更高。</li>
<li>=：精确裁剪，我们知道，在数据存储的listpack结构体中，裁剪长度的所有阈值是依照数据从老到新的方式，依次把listpack释放掉，但在此模式下，删除最后一个listpack中的数据比较费时，所以推荐用模糊裁剪。</li>
</ul></li>
<li>ID：添加消息可指定具体值或用 <code>*</code>代替，<strong>指定的值必须大于当前Stream队列中最大的消息ID</strong>，为<code>*</code>时则默认生成一个最新的ID，ID值取的是当前时间+序列号。</li>
</ul>

<pre><code class="language-shell"># 添加一条数据，使用系统生成的最新ID
&gt; xadd mystream * name doubi age 18
1593943429128-0
# 如果发现添加新元素后的Stream有超过100W+条消息，则删除旧消息，使长度大约缩减至100W个元素
&gt; xadd mystream MAXLEN ~ 1000000 * name tim age 29
</code></pre>

<h3 id="toc_6">xrange命令</h3>

<p>读取给定ID范围内的消息数据，并可以设置返回数据的条数。</p>

<pre><code class="language-shell">&gt; xrange key start end [COUNT count]
</code></pre>

<p>范围起始值分别由start和end字段指定，将返回两个ID之间（闭区间）的所有消息，消息排序为ID递增排序。</p>

<ul>
<li>start: 开始消息ID，指定具体值或通过“-”特殊符号来表示最小ID。</li>
<li>end：结束消息ID，指定具体值或通过“+”特殊符号来表示最大ID。</li>
<li>COUNT：设定返回的消息数量</li>
</ul>

<pre><code class="language-text">127.0.0.1:6379&gt; xrange mystream - + count 2
1) 1) &quot;1593943573938-0&quot;
   2) 1) &quot;name&quot;
      2) &quot;doubi&quot;
      3) &quot;age&quot;
      4) &quot;18&quot;
2) 1) &quot;1593957391373-0&quot;
   2) 1) &quot;name&quot;
      2) &quot;doubi1&quot;
      3) &quot;age&quot;
      4) &quot;19&quot;
</code></pre>

<h3 id="toc_7">xrevrange命令</h3>

<p>xrevrange命令与xrange用法完全一致，唯一区别是返回数据的顺序为消息ID的递减序，正好与xrange返回的数据顺序相反。</p>

<h3 id="toc_8">xdel 命令</h3>

<p>用于删除Stream队列中指定的一或多个消息ID对应的数据。</p>

<pre><code class="language-text">xdel key ID [ID ...]
</code></pre>

<p>key 类型必须为OBJ_STREAM，否则报错。</p>

<h3 id="toc_9">xgroup 命令</h3>

<p>用于队列的消费组管理，包含对消费组的创建、删除、修改等操作。</p>

<pre><code class="language-text">xgroup [CREATE key groupname id-or-$]  [SETID key id-or-$]        [DESTROY key groupname]  [DELCONSUMER key groupname consumername] [HELP]
</code></pre>

<ul>
<li>CREATE：创建一个新消费组。</li>
<li>SETID：修改某个消费组消费的消息last_id。</li>
<li>DESTROY：删除指定消费组。</li>
<li>DELCONSUMER：删除指定消费组中某个消费者。</li>
<li>HELP：查看使用帮助。</li>
</ul>

<pre><code class="language-shell"># 创建一个消费组mmp，从消息id为1593943573938-0的消息开始消费
127.0.0.1:6379&gt; xgroup CREATE mystream mmp 1593943573938-0
OK
</code></pre>

<p>最后一个参数是指定该消费组开始消费的消息ID，其中“0”或“0- 0”，表示从头开始消费，如果使用特殊符“$”，则表示队列中最后一项ID，只读取消息队列中新到的消息。</p>

<h3 id="toc_10">xreadgroup 命令</h3>

<p>用于从消费组中可靠地消费n条消息，如果指定的消费者不存在，则创建之。</p>

<pre><code class="language-text">XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] ID [ID ...]
</code></pre>

<ul>
<li>group：消费组名称</li>
<li>consumer：消费者名称。</li>
<li>COUNT：消费多少条数据。</li>
<li>BLOCK：是否为阻塞模式，milliseconds为阻塞多少毫秒</li>
<li>STREAMS：Stream队列名称，可指定多个。若指定多个，则ID 也要对应指定相同个数。</li>
<li>ID：读取只大于指定消息ID后未确认的消息；特殊符号“&gt;”，读取未传递给其他任何消费者的消息，也就是新消息。</li>
<li>NOACK：该消息不需要确认。</li>
</ul>

<p>客户端必须使用XACK确认消息处理，以便从待处理条目列表中删除待处理条目。可以使用XPENDING命令检查待处理条目列表。</p>

<h3 id="toc_11">xread 命令</h3>

<p>用于从Stream队列中读取N条消息，一般用作遍历队列中的消息。</p>

<p>从一个或者多个流中读取数据，仅返回ID大于调用者报告的最后接收ID的条目。此命令有一个阻塞选项，用于等待可用的项目，类似于BRPOP或者BZPOPMIN等等。</p>

<pre><code class="language-text">XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] ID [ID ...]
</code></pre>

<ul>
<li>COUNT: 读取多少条数据</li>
<li>BLOCK：是否为阻塞模式，milliseconds为阻塞多少毫秒</li>
<li>STREAMS：Stream队列名称</li>
<li>ID：指定从哪个消息ID开始读取，也就是消息ID大于指定的ID 的消息，可为“$”特殊符号，代表从最后一条开始读取。</li>
</ul>

<p>此命令读取消息后无须通过XACK确认，也不需要强制指定消费组名称与消费者名称</p>

<h3 id="toc_12">xacx 命令</h3>

<p>xack命令用于确认一或多个指定ID的消息，使其从待确认列表中删除。</p>

<pre><code class="language-text">xack key groupName ID [ID ...]
</code></pre>

<ul>
<li>group：消费组名称；</li>
<li>ID：确认的消息ID。</li>
</ul>

<pre><code class="language-shell">127.0.0.1:6379&gt; xack mystream mmp 1593957391373-0 1593943573938-0
(integer) 1
</code></pre>

<h3 id="toc_13">xpending 命令</h3>

<p>xpending命令用于读取某消费组或者某个消费者的未确认消息，返回未确认的消息ID、空闲时间、被读取次数。</p>

<pre><code class="language-text">xpending key group [start end count] [consumer]
</code></pre>

<p>group：指定的消费组；·start：范围开始ID，可以为特殊符“-”表示开始或指定ID；·end：范围结束ID，可以为特殊符“+”标识结尾或指定ID；·count：读取条数；·consumer：指定的消费者。</p>

<p>读取消费组cg1中消费者c1的所有待确认消息。</p>

<pre><code class="language-shell">127.0.0.1:6379&gt; xadd mystream * name doubi1 age 19
&quot;1593962280326-0&quot;
127.0.0.1:6379&gt; XREADGROUP GROUP mmp c1 COUNT 2 STREAMS mystream &gt;
1) 1) &quot;mystream&quot;
   2) 1) 1) &quot;1593962280326-0&quot;
         2) 1) &quot;name&quot;
            2) &quot;doubi1&quot;
            3) &quot;age&quot;
            4) &quot;19&quot;
127.0.0.1:6379&gt; xpending mystream mmp - + 2 c1
1) 1) &quot;1593962280326-0&quot;
   2) &quot;c1&quot;
   3) (integer) 3616  # 间隔多长时间没有确认
   4) (integer) 1
</code></pre>

<h3 id="toc_14">xinfo命令</h3>

<p>用于读取消息队列、消费组、消费者等的信息。</p>

<pre><code class="language-text">xinfo [CONSUMERS key groupname] [GROUPS key] [STREAM key] [HELP]
</code></pre>

<p>CONSUMERS：用于查看某个消费组下的消费者信息；·GROUPS：用于查看某个Stream队列下的消费组信息；·STREAM：用于查看某个Stream队列的整体组信息</p>

<pre><code class="language-shell"># 查看消费组c1中消费者消费信息：
127.0.0.1:6379&gt; xinfo consumers mystream mmp
1) 1) &quot;name&quot;
   2) &quot;c1&quot;
   3) &quot;pending&quot;
   4) (integer) 0
   5) &quot;idle&quot;
   6) (integer) 238485
   
   
   # 查看Stream队列信息
   127.0.0.1:6379&gt; xinfo stream mystream
 1) &quot;length&quot;
 2) (integer) 3
 3) &quot;radix-tree-keys&quot;
 4) (integer) 1
 5) &quot;radix-tree-nodes&quot;
 6) (integer) 2
 7) &quot;groups&quot;
 8) (integer) 1
 9) &quot;last-generated-id&quot;
10) &quot;1593962280326-0&quot;
11) &quot;first-entry&quot;
12) 1) &quot;1593961742431-0&quot;
    2) 1) &quot;name&quot;
       2) &quot;doubi&quot;
       3) &quot;age&quot;
       4) &quot;18&quot;
13) &quot;last-entry&quot;
14) 1) &quot;1593962280326-0&quot;
    2) 1) &quot;name&quot;
       2) &quot;doubi1&quot;
       3) &quot;age&quot;
       4) &quot;19&quot;
</code></pre>

<h3 id="toc_15">xlen 命令</h3>

<p>用于获取Stream队列的数据长度</p>

<pre><code class="language-text">xlen key ID [ID ...]
</code></pre>

<pre><code class="language-text">127.0.0.1:6379&gt; xlen mystream
(integer) 3
</code></pre>

<h3 id="toc_16">xtrim 命令</h3>

<p>缩减消息队列。</p>

<pre><code class="language-text">xtrim key MAXLEN [~] count
</code></pre>

<p>参照  xadd 命令</p>

<h3 id="toc_17">xclaim命令</h3>

<p>改变一或多个未确认消息的所有权，新的所有者是在命令参数中指定。</p>

<pre><code class="language-text">XCLAIM  key group consumer min-idle-time ID [ID ...] [IDLE ms] [TIME ms-unix-time] [RETRYCOUNT count] [FORCE] [JUSTID]
</code></pre>

<ul>
<li>consumer：指定新的消费者</li>
<li>min-idle-time：指定消息最小空闲数；</li>
<li>ID：指定消息ID；</li>
<li>IDLE <ms>: 设置消息的空闲时间（自最后一次交付到目前的时间）。如果没有指定IDLE，则假设IDLE值为0，即时间计数被重置，因为消息现在有新的所有者来尝试处理它。</li>
<li>TIME <ms-unix-time>: 这个命令与IDLE相同，但它不是设置相对的毫秒数，而是将空闲时间设置为一个指定的Unix时间（以毫秒为单位）。这对于重写生成XCLAIM命令的AOF文件很有用。</li>
<li>RETRYCOUNT <count>: 将重试计数器设置为指定的值。这个计数器在每一次消息被交付的时候递增。通常，XCLAIM不会更改这个计数器，它只在调用XPENDING命令时提供给客户端：这样客户端可以检测到异常，例如在大量传递尝试后由于某种原因从未处理过的消息。</li>
<li>FORCE: 在待处理条目列表（PEL）中创建待处理消息条目，即使某些指定的ID尚未在分配给不同客户端的待处理条目列表（PEL）中。但是消息必须存在于流中，否则不存在的消息ID将会被忽略。</li>
<li>JUSTID: 只返回成功认领的消息ID数组，不返回实际的消息。</li>
</ul>

<p>在流的消费者组上下文中，此命令改变待处理消息的所有权， 因此新的所有者是在命令参数中指定的消费者。通常是这样的：</p>

<ul>
<li>假设有一个具有关联消费者组的流。</li>
<li>某个消费者A在消费者组的上下文中通过XREADGROUP从流中读取一条消息。</li>
<li>作为读取消息的副作用，消费者组的待处理条目列表（PEL）中创建了一个待处理消息条目：这意味着这条消息已传递给给定的消费者，但是尚未通过XACK确认。</li>
<li>突然这个消费者出现故障，且永远无法恢复。</li>
<li>其他消费者可以使用XPENDING检查已经过时很长时间的待处理消息列表，为了继续处理这些消息，他们使用XCLAIM来获得消息的所有权，并继续处理。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[五、Redis 基本数据类型与其命令]]></title>
    <link href="http://www.throne4j.com/15937003019170.html"/>
    <updated>2020-07-02T22:31:41+08:00</updated>
    <id>http://www.throne4j.com/15937003019170.html</id>
    <content type="html"><![CDATA[
<p>Redis 支持多种类型的数据结构，如 字符串（string）， 散列（hashe）， 列表（list）， 集合（sets）， 有序集合（zset） 与范围查询， bitmap， hyperloglogs 和 地理空间（geospatial） 索引半径查询，stream消息队列。</p>

<p>Redis命令十分丰富，包括的命令组有Cluster、Connection、Geo、Hashes、HyperLogLog、Keys、Lists、Pub/Sub、Scripting、Server、Sets、Sorted Sets、Strings、Transactions一共14个redis命令组两百多个redis命令。</p>

<h2 id="toc_0">1、Redis基本数据类型</h2>

<p>Redis可以存储键与 5 种不同数据结构类型之间映射的数据，这 5 种数据结构类型分别为 string(字符串)、list(列表)、set(集合)、zset(有序集合)、hash(散列)。</p>

<table>
<thead>
<tr>
<th>结构类型</th>
<th>编码类型</th>
<th>结构存储的值</th>
<th>结构的读写能力</th>
</tr>
</thead>

<tbody>
<tr>
<td>string</td>
<td>raw、int、embstr</td>
<td>可以使字符串、整数或者浮点数</td>
<td>对整个字符串或字符串的一部分执行操作；对证书和浮点数执行自增、自减操作</td>
</tr>
<tr>
<td>list</td>
<td>quicklist</td>
<td>底层由链表实现，每个节点都包含一个字符串</td>
<td>从列表的两端推入或者弹出元素；根据偏移量对列表进行修改；读取单个或多个元素；根据值查询或者移除元素</td>
</tr>
<tr>
<td>set</td>
<td>intset、dict</td>
<td>不重复的无序集合，但当底层实现是intset的时候则是有序的</td>
<td>添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素</td>
</tr>
<tr>
<td>zset</td>
<td>ziplist、skiplist+dict</td>
<td>不可重复的有序集合，字符串成员(member)于浮点数分支(score)之间的有序映射，元素的排列顺序由分值的大小决定</td>
<td>添加、获取、移除单个元素；根据分值范围(range)或者成员来获取元素</td>
</tr>
<tr>
<td>hash</td>
<td>dict、ziplist</td>
<td>包含键值对的无序散列表</td>
<td>添加、获取、移除单个键值对；获取所有键值对</td>
</tr>
</tbody>
</table>

<p><strong>关于key的几条建议</strong></p>

<ul>
<li>不建议太长的键值，原因：1、消耗内存；2、这类键值计算成本很高</li>
<li>不建议太短的键值，设计键值要有良好的可读性，太短的话，看不懂就有点尴尬了</li>
<li>最好有一个相对固定的键值模式，比如这样的模式： 业务名:对象名:id:[属性] ，业务有销售订单、采购订单，销售订单的键值可以是： sale:order:100:orderId这样的</li>
</ul>

<h2 id="toc_1">Redis 中的 string 字符串</h2>

<p>字符串在Redis中是以key-value形式存储在redisDb的dict中的。</p>

<p>字符串的key经过Hash 之后作为dict的键，只能是string类型，字符串的value是dict的值，用结构体robj来表示。</p>

<p>字符串值robj 的 type 值为 OBJ_STRING 。当字符串值是string类型时，encoding的值根据字符串的长度(NCODING_EMBSTR_SIZE_LIMIT = 44)分别为OBJ_ENCODING_RAW或OBJ_ENCODING_EMBSTR(字符串长度&lt;=44)；当字符串值是long类型时，encoding的值为OBJ_ENCODING_INT。</p>

<table>
<thead>
<tr>
<th>类型</th>
<th>命令</th>
<th>行为</th>
<th>示例</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>设置</td>
<td>SET key value [NX] [XX] [EX seconds] [PX milliseconds]</td>
<td>设置存储在给定键中的值</td>
<td>set mykey  myvalue</td>
<td>·NX： 当数据库中key不存在时，可以将key-value添加到数据库。·XX： 当数据库中key存在时，可以将key-value设置到数据库，与NX参数互斥。·EX： key的超时秒数。·PX： key的超时毫秒数，与EX参数互斥。</td>
</tr>
<tr>
<td>设置</td>
<td>mset key value [key value ...]</td>
<td>设置多个key-value，如果key之前存在，则使用新的value进行覆盖</td>
<td>mset idear1 eat idear2 play</td>
<td>设置键值对 idear1 : ear 、 idear2  : play</td>
</tr>
<tr>
<td>设置</td>
<td>setex key second value</td>
<td>设置key-value并设置过期时间(单位：秒)</td>
<td>setex mykey 10  hungry</td>
<td>设置的mykey : hungry 10秒钟后过期，10秒后get mykey 返回 nil；</td>
</tr>
<tr>
<td>设置</td>
<td>psetex　key　milliseconds　value</td>
<td>设置key-value并设置过期时间(单位：毫秒)</td>
<td>setex mykey 10  hungry</td>
<td>设置的mykey : hungry 10毫秒钟后过期，10毫秒后get mykey 返回 nil；</td>
</tr>
<tr>
<td>设置</td>
<td>setnx key value</td>
<td>只有key不存在时才会设置key-value</td>
<td>setnx mykey myvalue</td>
<td>如果mykey不存在则设置，如果存在不执行覆盖操作</td>
</tr>
<tr>
<td>设置</td>
<td>msetnx key value [key value ...]</td>
<td>当所有的key都不存在时才会设置这些key-value</td>
<td>msetnx mykey1 myvalue1 mykey2 myvalue2</td>
<td>所有的key都不存在设置这些个key-value</td>
</tr>
<tr>
<td>获取</td>
<td>get key</td>
<td>获取存储在给定键中的值</td>
<td>get mykey</td>
<td>返回myvalue</td>
</tr>
<tr>
<td>获取</td>
<td>getset key value</td>
<td>将给定keuy的值设置为value，并返回key的旧值</td>
<td>getset mykey newValue</td>
<td>返回mykey的旧值myvalue，并设置mykey为新值 newValue</td>
</tr>
<tr>
<td>获取</td>
<td>mget key [key...]</td>
<td>获取多个key</td>
<td>mget mykey1 mykey2</td>
<td>获取mykey1、mykey2的值</td>
</tr>
<tr>
<td>获取</td>
<td>getrange key start end</td>
<td>获取存储在给定键中的值的某一段</td>
<td>get mykey 0 -2</td>
<td>返回myvalue 值递第一位置至倒数第二位置的value 值</td>
</tr>
<tr>
<td>获取</td>
<td>strlen</td>
<td>获取指定key的长度</td>
<td>strlen mykey</td>
<td>复杂度为O(1)</td>
</tr>
<tr>
<td>修改</td>
<td>append key value</td>
<td>追加一个值到key上</td>
<td>append mykey tony</td>
<td>添加完tony之后运行get mykey 得到结果 myvalue tony</td>
</tr>
<tr>
<td>计数</td>
<td>decr key</td>
<td>整数原子减 1</td>
<td>decr mykey</td>
<td>如果mykey原先不存在，在减1之前，age会被置为0</td>
</tr>
<tr>
<td>计数</td>
<td>decrby key decrement</td>
<td>整数原子减指定整数</td>
<td>decrby mykey</td>
<td>如果mykey原先不存在，在减decrement之前，mykey会被置为0</td>
</tr>
<tr>
<td>计数</td>
<td>incr key</td>
<td>整数原子加1</td>
<td>incr mykey</td>
<td>如果mykey原先不存在，在加1之前mykey会被置为0</td>
</tr>
<tr>
<td>计数</td>
<td>incrby key increment</td>
<td>整数原子加指定整数</td>
<td>incrby mykey 10</td>
<td>如果mykey原先不存在，在加increment之前mykey会被置为0</td>
</tr>
<tr>
<td>修改</td>
<td>setrange key offset value</td>
<td>覆盖key的value的offset之后的字符串</td>
<td>setrange mykey 2 qu</td>
<td>mykey之前的值是woca，执行此命令之后的结果就是woqu</td>
</tr>
<tr>
<td>通用</td>
<td>del key</td>
<td>删除存储在给定键中的值</td>
<td>del mykey</td>
<td>删除 mykey 键</td>
</tr>
</tbody>
</table>

<p>此外还有一种字符串的位操作：<br/>
位操作是高级语言的基础，Redis提供了位设置、操作、统计等命令，这些命令主要包括setbit、getbit、bitpos、bitcount、bittop 和 bitfield。抽空在补这部分内容  TODO。</p>

<p>Q：追加字符串时，需要判断追加后的字符串长度必须小于512MB，否则会报错，那么在set命令时为什么没有限制最大长度呢？<br/>
A:在服务端接收到命令的时候，就已经判断了命令的最大长度不能大于512 MB，所以set命令不需要再次判断了</p>

<p>字符串追加会修改原字符串的值，所以必须保证字符串是非共享的。如果字符串是共享的，则需要解除共享，新创建一个值对象。</p>

<h2 id="toc_2">Redis 中的 list 列表</h2>

<p>在 Redis 引入 quicklist之前，Redis采用压缩链表（ziplist）以及双向链表（adlist）作为List的底层实现。当元素个数比较少并且元素长度比较小时，Redis 采用 ziplist 作为其底层存储；当任意一个条件不满足时，Redis采用adlist作为底层存储结构。这么做的主要原因是，当元素长度较小时，采用ziplist可以有效节省存储空间，但ziplist的存储空间是连续的，当元素个数比较多时，修改元素时，必须重新分配存储空间，这无疑会影响Redis的执行效率，故而采用一般的双向链表。</p>

<p>Redis3.2版本之后，列表底层使用快速链表（quicklist）数据结构存储，而快速链表是双向链表与压缩列表 ziplist 的组合。</p>

<p>链表广泛应用于实现 Redis 的各种功能，比如列表键、发布与订阅、慢查询、监视器等。</p>

<table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
<th>示例</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>blpop key [key ...] timeout</td>
<td>lpop的阻塞版本</td>
<td>blpop myList 0</td>
<td>调用返回key和左边第一个元素的组合 myList、list3</td>
</tr>
<tr>
<td>brpop key [key ...] timeout</td>
<td>rpop的阻塞版本</td>
<td>brpop myList</td>
<td>没元素的话阻塞在key的列表上</td>
</tr>
<tr>
<td>lindex key index</td>
<td>通过列表索引获取key列表的value值, index  0：表示第一个元素； -1：表示最后一个元素；-2 ：表示倒数第二个原始</td>
<td>lindex myList 0</td>
<td>返回list3</td>
</tr>
<tr>
<td>linsert key before/after pivot value</td>
<td>把value插入myList 列表中在元素的的前面或后面</td>
<td>linsert myList before  list2 beauty</td>
<td>返回[list3,beauty,list2,list1]</td>
</tr>
<tr>
<td>llen key</td>
<td>获得列表的长度</td>
<td>llen myList</td>
<td>返回3</td>
</tr>
<tr>
<td>lpop key</td>
<td>从队列的左边出队并返回一个元素，列表为空时返回nil</td>
<td>lpop myList</td>
<td>返回并删除了第一个元素list3</td>
</tr>
<tr>
<td>lpush key value [value ...]</td>
<td>从队列的左边入队一个或多个元素</td>
<td>lpush myList list4 list 5</td>
<td>value按照先后顺序插入到列表头，最后列表元素[list5,list4,list3,beauty,list2,list1]</td>
</tr>
<tr>
<td>lpushx key vlaue</td>
<td>当列表存在时，从列表左边入队一个元素</td>
<td>lpushx myList1  hello</td>
<td>myList1 不存在 元素插入不成功</td>
</tr>
<tr>
<td>lrange key startIndex stopIndex</td>
<td>从列表中获取指定位置范围内的元素</td>
<td>lrange myList 0 1</td>
<td>结果[list3,list2]</td>
</tr>
<tr>
<td>lrem key count value</td>
<td>从存于key的列表中移除前count个的值为value的元素，count&gt;0 :从头向尾移除置为value的元素；count&lt;0: 从尾向头移除置为value的元素；count=0： 移除所有值为value的元素</td>
<td>lrem myList 1 list2</td>
<td>[list3,list1]</td>
</tr>
<tr>
<td>lset key index value</td>
<td>设置列表里面的index位置的元素值</td>
<td>lset myList 2 ghost</td>
<td>列表更新为[list3,list2,ghost]</td>
</tr>
<tr>
<td>ltrim key start stop</td>
<td>修剪并保留指定范围内的元素</td>
<td>ltrim myList 1 2</td>
<td>列表被编辑为 [list2,list1]</td>
</tr>
<tr>
<td>rpop key</td>
<td>从列表右边出队并返回一个元素，列表为空时返回nil</td>
<td>rpop myList</td>
<td>列表被编辑为 [list3,list2]</td>
</tr>
<tr>
<td>rpush key value [value ...]</td>
<td>从列表右边入队一个或多个元素</td>
<td>rpush myList niu</td>
<td>列表被编辑为 [list3,list2,list1,niu]</td>
</tr>
<tr>
<td>rpushx key value</td>
<td>列表如果存在，则从列表右边入队一个元素</td>
<td>rpushx myList leng</td>
<td>列表被编辑为 [list3,list2,list1,leng]，如果myList不存在，啥都不干</td>
</tr>
</tbody>
</table>

<h3 id="toc_3">栈和队列命令列表</h3>

<p>栈与队列是操作受限制的线性表</p>

<p>栈只允许在线性表的同一侧执行插入或删除操作，具有先进后出的特性；</p>

<p>队列只允许在一侧插入另一侧删除，具有先进先出的特性。</p>

<table>
<thead>
<tr>
<th>命令类型</th>
<th>左侧</th>
<th>右侧</th>
<th>左侧阻塞</th>
<th>右侧阻塞</th>
<th>左侧必须键存在</th>
<th>右侧必须键存在</th>
</tr>
</thead>

<tbody>
<tr>
<td>push类</td>
<td>lpush</td>
<td>rpush</td>
<td>无</td>
<td>无</td>
<td>lpushx</td>
<td>rpushx</td>
</tr>
<tr>
<td>pop类</td>
<td>lpop</td>
<td>rpop</td>
<td>blpop</td>
<td>brpop</td>
<td>无</td>
<td>无</td>
</tr>
</tbody>
</table>

<h2 id="toc_4">Redis 中的 set 集合</h2>

<p>在Redis中，集合元素为字符串和数字，分别用dict和intset存储。对于单个集合，Redis 实现了元素的新增、删除、遍历等操作；对于多个集合，Redis实现了集合间求交集、并集和差集等操作。</p>

<p>set集合中添加元素的时候分两种情况：</p>

<ul>
<li><p>当encoding方式为OBJ_ENCODING_HT时，set的底层用的是字典，将key直接添加进dict。需要注意的是，用dict存储集合元素时，元素值存储于字典的key中，字典的value值为null。</p></li>
<li><p>当encoding方式为OBJ_ENCODING_INTSET时，又有两种情况：</p>
<ul>
<li>若新增的元素本身非数字（value转long long失败），需要通过setTypeConvert转化后再存储；</li>
<li>若新增的元素本身是数字，则用intsetAdd新增元素。且当新增成功，但intset的元素个数过多（个数大于server.set_max_intset_entries时。该参数可配置，默认为512），同样会触发setTypeConvert，将OBJ_ENCODING_INTSET转化为OBJ_ENCODING_HT，为避免转化过程中发生字典的rehash操作，代码中用 dictExpand主动扩容。</li>
</ul></li>
</ul>

<p>移除元素的时候同样分两种情况进行处理：</p>

<ul>
<li>若encoding为OBJ_ENCODING_HT时，则调用dictDelete处理删除元素时，会检查字典容量，字典容量不足也会触发扩容操作。</li>
<li>当encoding为OBJ_ENCODING_INTSET时，调用intsetRemove处理</li>
</ul>

<p>Set集合相关命令如下表：</p>

<table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
<th>示例</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>sadd key member [member ...]</td>
<td>添加一个或多个指定的member元素到集合key中.</td>
<td>sadd myset &quot;hello&quot;</td>
<td>返回新成功添加到集合里元素的数量，不包括已经存在于集合中的元素.指定的一个或者多个元素member 如果已经在集合key中存在则忽略.如果集合key 不存在，则新建集合key,并添加member元素到集合key中。如果key 的类型不是集合则返回错误。</td>
</tr>
<tr>
<td>scard key</td>
<td>返回集合存储的key的基数 (集合元素的数量).</td>
<td>SCARD myset</td>
<td>集合的基数(元素的数量),如果key不存在,则返回 0.</td>
</tr>
<tr>
<td>sdiff key [key ...]</td>
<td>返回一个集合与给定集合的差集的元素.</td>
<td>sdiff  myset1 myset2</td>
<td>返回myset1和myset2的差集元素，不存在的key认为是空集.</td>
</tr>
<tr>
<td>sdiffstore destination key [key ...]</td>
<td>返回一个集合与给定集合的差集元素的个数，并将结果放入destination中</td>
<td>sdiffstore myset myset1 myset2</td>
<td>将myset1和myset2的差集存储在myset中</td>
</tr>
<tr>
<td>sinter key [key ...]</td>
<td>返回所有集合的元素交集列表</td>
<td>sinter myset1 myset2</td>
<td>如果key不存在则被认为是一个空的集合,当给定的集合为空的时候,结果也为空.(一个集合为空，结果一直为空).</td>
</tr>
<tr>
<td>sinterstore destination key [key ...]</td>
<td>返回所有集合的元素交集的元素数目，并存储到 destination中</td>
<td>sinterstore myset myset1 myset2</td>
<td>myset1和myset2的交集存储到 myset集合中，并返回集合元素的数目，如果destination 集合存在, 则会被重写.</td>
</tr>
<tr>
<td>sismember key member</td>
<td>判断member是否存在于key集合中，存在返回1，不存在返回0</td>
<td>sismember myset &quot;121&quot;</td>
<td>判断121是否存在于myset集合中，myset不存在或121不是myset集合元素返回0，否则返回 1</td>
</tr>
<tr>
<td>smembers key</td>
<td>返回集合所有元素</td>
<td>smembers myset</td>
<td>该命令的作用与使用一个参数的 sinter 命令作用相同.</td>
</tr>
<tr>
<td>smove source destination member</td>
<td>将member 从source集合移动到destination集合中</td>
<td>smove myset1 myset2 &quot;sb&quot;</td>
<td>将sb元素从 myset1 集合 移动到 myset2 集合中</td>
</tr>
<tr>
<td>spop key [count]</td>
<td>从存储在key的集合中移除并返回一个或多个随机元素</td>
<td>spop myset 3</td>
<td>从myset中删除并返回3个元素，被删除的元素，或者当key不存在时返回nil。</td>
</tr>
<tr>
<td>srandmember key [count]</td>
<td>随机返回集合key中count个数元素</td>
<td>srandmember myset 3</td>
<td>随机返回myset集合中的3个元素</td>
</tr>
<tr>
<td>srem key member [member ...]</td>
<td>移除key 集合中指定的元素</td>
<td>srem myset &quot;sb1&quot; &quot;sb2&quot;</td>
<td>从myset中删除sb1 和 sb2，如果集合中不存在 sb1则忽略，myset集合不存在则被视为一个空集合，返回 0</td>
</tr>
<tr>
<td>sscan key cursor [match pattern] [count count]</td>
<td>遍历集合中所有的元素</td>
<td></td>
<td></td>
</tr>
<tr>
<td>sunion key [key ...]</td>
<td>返回给定的多个集合的并集中的所有成员</td>
<td></td>
<td></td>
</tr>
<tr>
<td>sunionstore destination key [key ...]</td>
<td>将多个集合的并集存储到destination集合中</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<h2 id="toc_5">Redis 中的 zset  有序集合</h2>

<p>有序集合中，用到的关键数据结构是ziplist以及dict和skiplist，当服务器属性server.zset_max_ziplist_entries的值大于0且元素的member 长度小于服务器属性server.zset_max_ziplist_value的值（默认为64）时，使用的是ziplist，否则使用的是dict和skiplist。</p>

<p>有序集合里面的成员是不能重复的都是唯一的，但是，不同成员间有可能有相同的分数。当多个成员有相同的分数时，相同分数的成员按照字典规则相对排序，字典顺序排序用的是二进制，它比较的是字符串的字节数组。</p>

<table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
<th>示例</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>zadd key [nx|xx] [ch] [incr] score member [score member]</td>
<td>将一个或多个member元素及其分值score加入到有序集合对应的key当中。其中，分值score可以是整数值或双精度浮点数。XX：只更新已经存在的元素，不添加元素。NX：不更新已经存在的元素，总是添加新的元素。CH：将返回值从添加的新元素数量修改为更改的元素总数。INCR：对成员的分数进行递增操作。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zrem key member [member]</td>
<td>删除有序集合 key中的一个或者多个member</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zcard key</td>
<td>获取有序集合key中的技基数</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zcount key min max</td>
<td>返回有序集合 key 中 scroe 值在 [min,max]区间的成员数量</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zincrby key increment member</td>
<td>在有序集合 key 的 member 的分值上增加 increment</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zrank key member</td>
<td>按照分值从小到大返回有序集合成员member的排名，其中排名从0开始计算</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zrevrank key member</td>
<td>按照分值从大到小返回有序集合成员member的排名</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zscore key member</td>
<td>获取有序集合key中成员member的分值</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zscan key cursor [match parttern] [count count]</td>
<td>迭代有序集合中的元素和分值，match可以通过正则匹配元素，count 是返回的元素数量</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zrange key start stop [withscores]</td>
<td>获取有序集合key中指定区间的成员，成员按照分值递增排序，如果分值相同，成员按照字典序排序</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zrevrange key start stop [withscores]</td>
<td>获取有序集合key中指定区间的成员，成员按照分值递减排序，如果分值相同，成员按照字典序排序</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zrangebyscore key min max [withscores] [limit offset count]</td>
<td>返回有序集key中，所有score值介于min和max之间（包括等于min或max）的成员。有序集成员按score值递增（从小到大）次序排列。具有相同score值的成员按字典序排列。limit 表示分页，offset(起始位置)和count(结果数量)必须输入</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zrevrangebyscore key min max [withscores] [limit offset count]</td>
<td>除了有序集合按score值递减之外，跟zrangebyscore完全一样。limit 表示分页，offset(起始位置)和count(结果数量)必须输入</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zrangebylex key min max [limit offset count]</td>
<td>分数必须相同，返回给定的有序集合键key中值介于min和max之间的成员，根据成员的字典序排序。limit 表示分页，offset(起始位置)和count(结果数量)必须输入</td>
<td></td>
<td>合法的min和max参数必须包含“(”或者“[”，其中“(”表示开区间，“[”表示闭区间；可以使用 “-“ 和 “+” 表示得分最小值和最大值；成员字符串作为二进制数组的字节数进行比较；</td>
</tr>
<tr>
<td>zlexcount key min max</td>
<td>返回给定的有序集合键key中值介于min和max之间的成员数量。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zremrangebyrank key start stop</td>
<td>移除有序集合key 中指定排名区间的所有成员</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zremrangebyscore key min max</td>
<td>移除有序集合key中所有score值介于[min,max]之间的成员</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zremrangebylex key min max</td>
<td>移除该集合中成员字典序介于min和max范围的所有元素</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zunionstore destination numkeys key [key ...] [weights weight] [sumiminimax]</td>
<td>计算给定的numkeys个有序集合的并集，并且把结果放到destination中。WEIGHTS选项可以在使用聚合函数时为每个有序集分别指定一个乘法因子</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zinterstore destination numkeys key [key ...] [WEIGHTS weight] [SUMIMINIMAX]</td>
<td>计算给定的numkeys个有序集合的交集，并且把结果放到destination中。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zpopmax key [count]</td>
<td>删除并返回有序集合key中的最多count个具有最高得分的成员。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zpopmin key [count]</td>
<td>删除并返回有序集合key中的最多count个具有最少得分的成员。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>bzpopmax key [key ...] timeout</td>
<td>删除并返回 有序集合 key 中分值最高的成员，在参数中的所有有序集合均为空的情况下，阻塞连接</td>
<td>bzpopmax zset2 zset1 0</td>
<td>按照zset的key前后顺序，删除并返回zset2的分值最高的成员</td>
</tr>
<tr>
<td>bzpopmin key [key ..] timeout</td>
<td>删除并返回 有序集合 key 中分值最低的成员，在参数中的所有有序集合均为空的情况下，阻塞连接</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<h2 id="toc_6">Redis 中的 hash 散列表</h2>

<p>Redis散列存储有 ziplist 和 散列表(hashtable) 2种，有时我们需要从ziplist编码转换为散列表编码。值得注意的是，即使后期满足条件，也不会从散列表编码转换为ziplist编码。</p>

<p>当需要存储的key-value结构同时满足下面两个条件时，采用ziplist作为底层存储：</p>

<ul>
<li>key-value结构的所有键值对的字符串长度都小于hash-max- ziplist-value（默认值64），该值可以通过配置文件配置</li>
<li>散列对象保存的键值对的个数（一个键值对记为1个）小于hash-max-ziplist-entries（默认值512），该值也可以通过配置文件配置。</li>
</ul>

<table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
<th>示例</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>hset key field value</td>
<td>设置 key 指定的哈希集中指定字段的值</td>
<td></td>
<td>如果 key 指定的哈希集不存在，会创建一个新的哈希集并与 key 关联。如果字段在哈希集中存在，它将被重写。</td>
</tr>
<tr>
<td>hmset key field value [field value]</td>
<td>设置 key 指定的哈希集中指定字段的值</td>
<td></td>
<td>设置 key 指定的哈希集中指定字段的值</td>
</tr>
<tr>
<td>hsetnx key field value</td>
<td>只在 key 指定的哈希集中不存在指定的字段时，设置字段的值</td>
<td></td>
<td>如果 key 指定的哈希集不存在，会创建一个新的哈希集并与 key 关联。如果字段已存在，该操作无效果。</td>
</tr>
<tr>
<td>hexists key field</td>
<td>查看某个field是否存在，可以用于标识某个操作之前是否已经执行过</td>
<td>xxx</td>
<td>查看field是否存在，存在返回1，key不存在或者field不存在返回0。</td>
</tr>
<tr>
<td>hget key field</td>
<td>获取单个field对应的value值</td>
<td></td>
<td>该字段所关联的值。当字段不存在或者 key 不存在时返回nil。</td>
</tr>
<tr>
<td>hmget key field [field...]</td>
<td>获取多个field对应的value值</td>
<td></td>
<td>当字段不存在或者 key 不存在时返回nil</td>
</tr>
<tr>
<td>hkeys key</td>
<td>获取某个key下的所有field信息</td>
<td></td>
<td>当 key 指定的哈希集不存在时返回空列表</td>
</tr>
<tr>
<td>hvals key</td>
<td>获取某个key下的所有value信息</td>
<td></td>
<td>哈希集中的值的列表，当 key 指定的哈希集不存在时返回空列表</td>
</tr>
<tr>
<td>hgetall key</td>
<td>获取某个key下的所有key-field信息</td>
<td></td>
<td>哈希集中字段和值的列表。当 key 指定的哈希集不存在时返回空列表。</td>
</tr>
<tr>
<td>hlen key</td>
<td>获取散列表中field的个数，主要用于数据统计。</td>
<td></td>
<td>哈希集中字段的数量，当 key 指定的哈希集不存在时返回 0</td>
</tr>
<tr>
<td>hscan key cursor [match pattern] [COUNT count]</td>
<td>遍历散列表中所有的field-value对</td>
<td></td>
<td>cursor指向当前的位置，0代表新一轮的迭代，返回0代表本轮迭代结束；count是需要返回的field 个数，默认值是10，当底层编码为ziplist时，该值无效，Redis会将ziplist中所有field-value返回，当编码为散列表时，返回的元素个数不一定，可能大于，也可能小于或等于此值；pattern是需要匹配的模式，这一步是读取完数据之后，发送数据之前执行的</td>
</tr>
<tr>
<td>hdel key field [field ...]</td>
<td>将key对应的散列表中的field删除，key为空时返回0，key 不为空时返回成功删除的field个数</td>
<td></td>
<td>直接调用ziplist或者散列表的接口将数据删除。散列表中field全部被删除时，key也会被删除。</td>
</tr>
<tr>
<td>hincrby key field increment</td>
<td>将field对应的value增加increment</td>
<td></td>
<td>如果key不存在则直接新建key，field不存在则直接新建field，设置其值为0，命令返回增加后的新值</td>
</tr>
<tr>
<td>hincrbyfloat key field increment</td>
<td>将field对应的value增加increment</td>
<td></td>
<td>如果key不存在则直接新建key，field不存在则直接新建field，设置其值为0，命令返回增加后的新值</td>
</tr>
<tr>
<td>hstrlen key field</td>
<td>返回hash指定field的value的字符串长度</td>
<td></td>
<td>如果hash或field不存在，返回0</td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[四、Redis  通用命令]]></title>
    <link href="http://www.throne4j.com/15936158582613.html"/>
    <updated>2020-07-01T23:04:18+08:00</updated>
    <id>http://www.throne4j.com/15936158582613.html</id>
    <content type="html"><![CDATA[
<p>redis 是一个键值对数据库服务器，服务器中的每个数据库都有 redisDB 结构表示( 在<a href="15934396305281.html">redis命令处理生命周期</a> 文章中查找)， redisDb 结构的dict字典保存了数据库中的所有的键值对。</p>

<p>所有针对数据库的操作，比如本章节的键相关命令还是基本数据类型相关的命令，实际上都是通过对键空间字典进行操作来实现的。</p>

<p>在读写键空间的时候，redis会进行一些维护操作</p>

<ul>
<li>读写一个键之后，服务器会根据键是否存在来更新服务器的键空间命中 (hit) 次数或键空间未命中(miss)次数，这两个值可以在 info stats 命令的keyspace_hits和keyspace_misses 属性中查看</li>
<li>在读取一个键之后，服务器会更新键的 LRU （最后一次使用）时间，这个值可以用于计算键的空闲时间，以方便对象内存的释放与回收</li>
<li>如果服务器在读取一个键时发现该键已经过期，那么服务器会先删除这个过期键，然后才执行余下的其它操作</li>
<li>如果游客户端使用watch 命令见识了某个键，那么服务器在对被监视的键进行更新之后，会将这个件标记为 dirty ，从而让食物程序注意到这个件已经被修改过</li>
<li>服务器每次修改一个键之后，会对dirty键计数器的值 增 1，这个计数器会触发服务器的持久化以及复制操作</li>
<li>服务器开启了数据库通知功能，那么在对键进行修改之后，服务器将按照配置发送相应的数据库通知，用于Redis的发布订阅功能。</li>
</ul>

<h2 id="toc_0">1、Redis 键相关命令</h2>

<table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
<th>示例</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>del key [key ...]</td>
<td>同步方式删除键 key</td>
<td></td>
<td></td>
</tr>
<tr>
<td>exists key</td>
<td>查看key是否存在</td>
<td></td>
<td></td>
</tr>
<tr>
<td>expire key seconds</td>
<td>设置键的过期时间</td>
<td>expire mykey 10</td>
<td>mykey键值对 10秒后过期</td>
</tr>
<tr>
<td>pexpire key milliseconds</td>
<td>设置key的过期时间，时间单位是毫秒</td>
<td></td>
<td></td>
</tr>
<tr>
<td>expireat key timestamp</td>
<td>设置key的生存时间，接收的时间参数以秒为单位的unix时间戳</td>
<td></td>
<td></td>
</tr>
<tr>
<td>pexpireat key milliseconds-timestamp</td>
<td>设置key的生存时间，接收的时间参数为毫秒为单位时间戳</td>
<td></td>
<td></td>
</tr>
<tr>
<td>keys parttern</td>
<td>查看所有键</td>
<td>keys *</td>
<td>Redis存在大量键时，禁止使用此命令</td>
</tr>
<tr>
<td>hscan</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>migrate host post key destination-db timeout [COPY] [REPLACE]</td>
<td>将 key 原子性地从当前实例传送到目标实例的指定数据库上，一旦传送成功， key 保证会出现在目标实例上，而当前实例上的 key 会被删除。</td>
<td></td>
<td>这个命令是一个原子操作，它在执行的时候会阻塞进行迁移的两个实例，直到以下任意结果发生：迁移成功，迁移失败，等到超时。</td>
</tr>
<tr>
<td>dump key</td>
<td>序列化key并返回序列化后的数据</td>
<td></td>
<td></td>
</tr>
<tr>
<td>restore key ttl serialized-value [replace]</td>
<td>反序列化serialized-value，并与key关联</td>
<td></td>
<td></td>
</tr>
<tr>
<td>move key dbIndex</td>
<td>将key移动到另一个数据库</td>
<td>move mykey 3</td>
<td>移动mykey到3号数据库</td>
</tr>
<tr>
<td>OBJECT  help/refcount/encoding/idletime/freq key</td>
<td>查看数据库的值对象编码</td>
<td>object e</td>
<td>help ：帮助命令，object命令使用手册。refcount ：获得指定键关联的值的引用数，即redisObject对象refcount属性。encoding ：获得指定键关联的值的内部存储使用的编码，即redisObject对象encoding属性的字符串表达。idletime ：返回键的空闲时间，即自上次读写键以来经过的近似秒数。freq ：返回键的对数访问频率计数器。当maxmemory-policy设置为LFU策略时，此子命令可用。</td>
</tr>
<tr>
<td>persist key</td>
<td>删除key的过期时间，使key长期有效</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ttl [key]</td>
<td>查看键所剩的过期时间(时间单位：秒)</td>
<td>ttl mykey</td>
<td>查看设置过期时间的键所剩过期时间还有几秒</td>
</tr>
<tr>
<td>pttl [key]</td>
<td>查看键所剩的过期时间(时间单位：毫秒)</td>
<td>pttl mykey</td>
<td>查看设置过期时间的键所剩过期时间还有几毫秒</td>
</tr>
<tr>
<td>randomkey</td>
<td>从当前数据库随机返回一个key</td>
<td></td>
<td></td>
</tr>
<tr>
<td>rename key newkey</td>
<td>将key重命名为newkey，如果newkey已存在，则值将被覆盖</td>
<td></td>
<td></td>
</tr>
<tr>
<td>renamenx key newkey</td>
<td>重命名后的key不存在时才能执行成功</td>
<td></td>
<td></td>
</tr>
<tr>
<td>scan cursor [MATCH parttern] [COUNT count]</td>
<td></td>
<td></td>
<td>scan命令和hscan、sscan、zscan命令都用于增量迭代，每次只返回少量数据，不会有像keys命令堵塞服务器的隐患</td>
</tr>
<tr>
<td>sort key key [BY pattern] [LIMIT offset count] [GET pattern] [ASC/DESC] [ALPHA] destination</td>
<td>对列表、集合或有序集合中的元素进行排序，返回或保存List、Set、Zset类型的key中排序后的元素</td>
<td></td>
<td>·BY： 使用其他键的值作为权重进行排序，如果其他键不存在则跳过排序。·LIMIT： 限定排序返回的元素。·GET： 跟BY作用相反，将排序结果作为权重来排序匹配的其他键，可多次使用。·ASC/DESC： 正序/倒序排序。·ALPHA： 对字符串进行排序，默认使用数字排序。·STORE： 将排序后的结果保存到指定的键。</td>
</tr>
<tr>
<td>touch key [key]</td>
<td>修改指定key(s) 最后访问时间 若key不存在，不做操作</td>
<td></td>
<td></td>
</tr>
<tr>
<td>type [key]</td>
<td>查看键的数据结构类型</td>
<td>type mykey</td>
<td>键不存在返回 nil</td>
</tr>
<tr>
<td>unlink key [key ...]</td>
<td>根据删除的工作量决定使用同步方式还是异步方式删除键 key</td>
<td></td>
<td></td>
</tr>
<tr>
<td>wait numslaves timeout</td>
<td>阻塞当前客户端，直到所有以前的写命令都成功的传输和指定的slaves确认。如果指定以毫秒为单位，请求超时，即使指定的slaves还没有到达，命令任然返回。</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<h2 id="toc_1">2、Redis服务器相关命令</h2>

<table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
<th>示例</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>dbsize</td>
<td>查看当前数据库里面的 keys 总数</td>
<td>dbsize</td>
<td>Redis存在大量键时，禁止使用此命令</td>
</tr>
<tr>
<td>flushall</td>
<td>清除所有库的数据</td>
<td></td>
<td></td>
</tr>
<tr>
<td>flushdb dbIndex</td>
<td>清除指定index的库</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<table>
<thead>
<tr>
<th>命令</th>
<th>行为</th>
<th>示例</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>save</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>bgsave</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[三、redis命令处理生命周期]]></title>
    <link href="http://www.throne4j.com/15934396305281.html"/>
    <updated>2020-06-29T22:07:10+08:00</updated>
    <id>http://www.throne4j.com/15934396305281.html</id>
    <content type="html"><![CDATA[
<p>服务器处理客户端命令请求的整个流程，包括服务器启动监听，接收命令请求并解析，执行命令请求，返回命令回复等。</p>

<p>Redis服务器是典型的事件驱动程序，因此事件处理显得尤为重要，而Redis将事件分为两大类：文件事件与时间事件。文件事件即socket的读写事件，时间事件用于处理一些需要周期性执行的定时任务。</p>

<h2 id="toc_0">1、基本知识</h2>

<h3 id="toc_1">1.1、Redis 对象</h3>

<p>Redis 是一个 key-value 型数据库， key只能是字符串， vlaue可以是 字符串、列表、集合、有序集合、散列表， 这5中数据类型用结构体 robj表示，robj被称为 Redis 对象。<br/>
robj结构体如下所示：</p>

<pre><code class="language-c">typedef struct redisObject {     
    unsigned type:4;    // 对象类型
    unsigned encoding:4;    // 对象编码
    unsigned lru:LRU_BITS;  //缓存淘汰使用, 占24比特
    int refcount;   //存储当前对象的引用次数，用于实现对象的共享    
    void *ptr;  //指向实际存储的某一种数据结构
} robj;
</code></pre>

<ul>
<li>结构体robj的type字段表示对象类型，由 encoding 字段决定。</li>
</ul>

<pre><code class="language-c">#define OBJ_STRING 0
#define OBJ_LIST 1
#define OBJ_SET 2
#define OBJ_ZSET 3
#define OBJ_HASH 4
</code></pre>

<ul>
<li><p>结构体 robj 的ptr<br/>
ptr是void* 类型的指针，指向实际存储的某一种数据结构的地址。</p></li>
<li><p>结构体 robj 的 refcount <br/>
refcount 存储当前对象的引用次数，用于实现对象的共享。共享时 refcount加1；删除对象时，refcount减1；当refcount值为0时，释放对象空间。<br/>
只有当对象robj存储的是0～10000的整数时，对象robj才会被共享，且这些共享整数对象的引用计数初始化为INT_MAX，保证不会被释放。</p></li>
<li><p>结构体 robj 的 lru<br/>
用于实现缓存淘汰策略，可以在配置文件中使用maxmemory-policy配置已用内存达到最大内存限制时的缓存淘汰策略。lru根据用户配置的缓存淘汰策略存储不同数据，常用的策略就是LRU与LFU。</p>
<ul>
<li>LRU的核心思想是，如果数据最近被访问过，那么将来被访问的几率也更高，此时lru字段存储的是对象访问时间；</li>
<li>LFU的核心思想是，如果数据过去被访问多次，那么将来被访问的频率也更高，此时lru字段存储的是上次访问时间与访问次数，lru的低8比特存储的是对象的访问次数，高16比特存储的是对象的上次访问时间。</li>
</ul></li>
<li><p>结构体 robj 的 encoding <br/>
结构体 robj 的 encoding 表示当前对象的底层存储采用的数据结构，即对象的编码。</p>
<table>
<thead>
<tr>
<th>编码常量</th>
<th>编码所对应的底层数据结构</th>
<th>可存储对象类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>OBJ_ENCODING_INT</td>
<td>long类型的整数</td>
<td>字符串</td>
</tr>
<tr>
<td>OBJ_ENCODING_EMBSTR</td>
<td>embstr编码的简单动态字符串</td>
<td>字符串</td>
</tr>
<tr>
<td>OBJ_ENCODING_RAW</td>
<td>简单动态字符串</td>
<td>字符串</td>
</tr>
<tr>
<td>OBJ_ENCODING_Quicklist</td>
<td>快速列表</td>
<td>列表</td>
</tr>
<tr>
<td>OBJ_ENCODING_HT</td>
<td>字典</td>
<td>集合、散列表、有序集合</td>
</tr>
<tr>
<td>OBJ_ENCODING_ZIPLIST</td>
<td>压缩列表</td>
<td>散列表、有序集合</td>
</tr>
<tr>
<td>OBJ_ENCODING_INTSET</td>
<td>整数集合</td>
<td>集合</td>
</tr>
<tr>
<td>OBJ_ENCODING_SKIPLIST</td>
<td>跳跃表和字典</td>
<td>有序集合</td>
</tr>
<tr>
<td>OBJ_ENCODING_STREAM</td>
<td>stream</td>
<td>stream</td>
</tr>
<tr>
<td>OBJ_ENCODING_LINKEDLIST</td>
<td>双端链表(不再使用)</td>
<td>不再使用</td>
</tr>
<tr>
<td>OBJ_ENCODING_ZIPMAP</td>
<td>未使用</td>
<td>未使用</td>
</tr>
</tbody>
</table></li>
</ul>

<h4 id="toc_2">对象内存回收</h4>

<p>由于C语言不具备自动回收内存的功能，所以Redis在自己的对象系统中构建了一个引用计数技术实现的内存回收机制。程序可以通过跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收。</p>

<p>redisObject 结构中的引用计数器refcount会随着对象的使用状态而不断变化：</p>

<ul>
<li>在创建一个新对象是，引用计数的值会被初始化为 1</li>
<li>当对象被一个新程序使用的时候，它的引用计数值会被增加 1</li>
<li>当对象不再被一个新程序使用的时候，它的引用计数值会被减少 1</li>
<li>当对象的引用计数值变为0的时候，对象所占用的内存会被释放</li>
</ul>

<p>对象的整个生命周期可以划分为创建对象、操作对象、释放对象三个阶段。</p>

<p>为了节约内存空间，Redis 会共享 值为 0 ~ 9999 的字符串对象，但是为啥只是共享 0 ~ 9999的整数字符串呢？</p>

<p>当服务器考虑讲一个共享对象设置为键的值对象时，程序需要先检查给定的共享对象和键想创建的目标对象是否完全相同，只有在共享对象和目标对象完全相同的情况下，程序才会将共享对象用作键的值对象，而共享一个对象保存的值越复杂，验证共享对象和目标对象是否相同所需的复杂度就会越高，消耗cpu时间也会越多。</p>

<h4 id="toc_3">对象的空闲时长</h4>

<p>redisObject 对象结构的最后一个属性 lru记录了对象最后一次被命令程序访问的时间。<br/>
命令 object idletime 可以打印出给定键的空闲时间，这一空闲时长是通过将当前时间减去键的值对象 lru 时间计算得出的。</p>

<p>键的空闲时间有一项作用：如果服务器打开了maxmemory选项，并且服务器用于回收内存的算法为 volatile-lru或者 allkeys-lru，那么当服务器占用的内存数超过了maxmemory现象所设置的上限值，空闲时长较高的那部分键优先被服务器释放，从而回收内存。</p>

<h3 id="toc_4">1.2、服务端结构体redisServer</h3>

<p>结构体redisServer存储Redis服务器的所有信息，包括但不限于数据库、配置参数、命令表、监听端口与地址、客户端列表、若干统计信息、RDB与AOF持久化相关信息、主从复制相关信息、集群相关信息等。</p>

<p>一个redisDb就代表了一个数据库，而redisServer 中则保存了它所设计到的所有数据库的数组。</p>

<pre><code class="language-c">struct redisServer {     
    // 配置文件绝对路径
    char *configfile;     
    // 数据库的数目,默认16，可通过参数databases配置
    int dbnum;     
    // 数据库数组，数组的每个元素都是redisDb类型
    redisDb *db;     
    //命令字典，redis支持的所有命令都存储在这个字典中，value值为struct redisCommand对象
    dict *commands;     
    // redis的事件循环，类型为aeEventLoop
    aeEventLoop *el;
    // 服务器监听端口号，默认端口号 6379
    int port;     
    //绑定的所有IP地址，可以通过参数bind配置多个
    char *bindaddr[CONFIG_BINDADDR_MAX];     
    // 用户配置的IP地址数目
    int bindaddr_count;     
    //针对bindaddr字段的所有IP地址创建的socket文件描述符
    int ipfd[CONFIG_BINDADDR_MAX];     
    //创建的socket文件描述符数目
    int ipfd_count;    
    //当前连接到Redis服务器的所有客户端
    list *clients;     
    //最大空闲时间，可通过参数timeout配置
    int maxidletime; 
}
</code></pre>

<p>默认情况下，redis客户端的目标数据库为0号数据库，但客户端可以通过执行 select 命令来切换目标数据库。而客户端 client 结构中db属性则记录了它当前的目标数据库</p>

<h3 id="toc_5">1.3、客户端结构体 client</h3>

<p>Redis是典型的客户端服务器结构，客户端通过socket与服务端建立网络连接并发送命令请求，服务端处理命令请求并回复。Redis使用结构体client存储客户端连接的所有信息，包括但不限于客户端的名称、客户端连接的套接字描述符、客户端当前选择的数据库ID、客户端的输入缓冲区与输出缓冲区等。</p>

<pre><code class="language-c">typedef struct client {     
    uint64_t id;     
    int fd;     
    redisDb *db;     
    robj *name;      
    time_t lastinteraction                   
    sds querybuf;     
    int argc;     
    robj **argv;     
    struct redisCommand *cmd;          
    list *reply;     
    unsigned long long reply_bytes;     
    size_t sentlen;     
    char buf[PROTO_REPLY_CHUNK_BYTES];     
    int bufpos; 
} client;

// 用来管理数据库相关数据和实现相关操作
typedef struct redisDb {     
    int id;     // id为数据库序号，默认情况下Redis有16个数据库，id序号为0～15。
    long long avg_ttl;         //avg_ttl存储数据库对象的平均TTL，用于统计
    dict *dict;     //键空间散列表，存储数据库所有键值对。
    dict *expires;     //过期时间散列表，存放键的过期时间，注意dict和expires中的键都指向同一个键的sds。
    dict *blocking_keys;     // 处于阻塞状态的键和对应的client，比如blpop命令阻塞键和对应客户端，而解除客户端的阻塞状态有两种 1：进行push操作；2：阻塞超时
    dict *ready_keys;     //解除阻塞状态的键和对应的client
    list *defrag_later;         // 逐渐尝试逐个碎片整理的key列表
    dict *watched_keys;     //watch的键和对应的client，主要用于事务
} redisDb;
</code></pre>

<p>各字段含义如下:</p>

<ul>
<li>id为客户端唯一ID，通过全局变量server.next_client_id实现</li>
<li>fd为客户端socket的文件描述符</li>
<li>db为客户端使用select命令选择的数据库对象</li>
<li>name 客户端名称，可以使用命令 client setname 设置</li>
<li>lastinteraction 客户端上次与服务器交互的时间，以次实现客户端的超时处理。</li>
<li>querybuf：输入缓冲区，recv函数接收到的客户端命令请求会暂时缓存在此缓冲区</li>
<li>argc：输入缓冲区的命令请求时按照Redis协议格式编码字符串，需要解析出命令请求的所有参数，参数个数存储在argc字段，参数内容被解析为robj对象，存储在argv数组</li>
<li>cmd：待执行的客户端命令</li>
<li>reply：输出链表，存储待返回给客户端的命令回复数据。链表节点存储的值类型为 clientReplyBlock，定义为如下：</li>
</ul>

<pre><code class="language-c">typedef struct clientReplyBlock {     
    size_t size, used;     
    char buf[]; 
} clientReplyBlock;
</code></pre>

<ul>
<li>reply_bytes：表示输出链表中所有节点的存储空间的总和</li>
<li>sentlen：表示已返回给客户端的字节数</li>
<li>buf：输出缓冲区，存储待返回给客户端的命令回复数据，bufpos表示输出缓冲区中数据的最大字节位置，sentlen~bufpos区间的数据都是需要返回给客户端的。</li>
</ul>

<h3 id="toc_6">1.4、命令结构体 redisCommond</h3>

<p>Redis支持的所有命令初始都存储在全局变量redisCommandTable，类型为redisCommand，结构体redisCommand相对简单，主要定义了命令的名称、命令处理函数以及命令标志等</p>

<pre><code class="language-c">struct redisCommand {     
    //命令名称
    char *name;     
    //命令处理函数
    redisCommandProc *proc;    
    //命令参数数目,用于校验命令请求格式是否正确
    int arity;     
    //命令标志，例如标识命令时读命令还是写命令
    char *sflags;     
    //命令的二进制标志，服务器启动时解析sflags字段生成。
    int flags;            
    // calls :从服务器启动至今命令执行的次数，用于统计。
    // 从服务器启动至今命令总的执行时间，microseconds/calls即可计算出该命令的平均处理时间，用于统计
    long long microseconds, calls; 
};
</code></pre>

<h3 id="toc_7">1.5、事件处理</h3>

<p>Redis服务器是典型的事件驱动程序，而事件又分为 <strong><em>文件事件（socket的可读可写事件）</em></strong> 与 <strong><em>时间事件（定时任务）</em></strong> 两大类。无论是文件事件还是时间事件都封装在结构体aeEventLoop中：</p>

<pre><code class="language-c">typedef struct aeEventLoop {     
    //事件循环是否结束
    int stop;         
    //为文件事件数组，存储已经注册的文件事件
    aeFileEvent *events;     
    //存储被触发的文件事件
    aeFiredEvent *fired;     
    //多个时间事件形成链表，timeEventHead即为时间事件链表头节点
    aeTimeEvent *timeEventHead;
    // Redis底层可以使用4种 I/O 多路复用模型（kqueue、epoll等），apidata是对这4种模型的进一步封装。             
    void *apidata     
    //Redis服务器需要阻塞等待文件事件的发生，进程阻塞之前会调用beforesleep函数，
    //进程因为某种原因被唤醒之后会调用aftersleep函数
    aeBeforeSleepProc *beforesleep;     
    aeBeforeSleepProc *aftersleep; 
} aeEventLoop;
</code></pre>

<p>Redis有多个定时任务，因此理论上应该有多个时间事件，多个时间事件形成链表，timeEventHead即为时间事件链表头节点；</p>

<p>Redis服务器需要阻塞等待文件事件的发生，进程阻塞之前会调用beforesleep函数，进程因为某种原因被唤醒之后会调用aftersleep函数。</p>

<p>函数beforesleep会执行一些不是很费时的操作，如：集群相关操作、过期键删除操作（这里可称为快速过期键删除）、向客户端返回命令回复等。</p>

<p>事件驱动程序通常在server 启动过程的最后一步开启事件循环，之后只需等待事件发生处理文件事件和时间事件即可。</p>

<h4 id="toc_8">1.5.1、文件事件</h4>

<p>Redis客户端通过TCP socket与服务端交互，文件事件指的就是socket的可读可写事件。socket读写操作有阻塞与非阻塞之分。</p>

<p>采用阻塞模式时，一个进程只能处理一条网络连接的读写事件，为了同时处理多条网络连接，通常会采用多线程或者多进程，效率低下；非阻塞模式下，可以使用目前比较成熟的I/O多路复用模型，如select/epoll/kqueue等，视不同操作系统而定。</p>

<p>epoll是Linux内核为处理大量并发网络连接而提出的解决方案，能显著提升系统CPU利用率。</p>

<p>Redis并没有直接使用epoll提供的API，而是同时支持4种I/O多路复用模型，并将这些模型的API进一步统一封装。</p>

<p>Redis在编译阶段，会检查操作系统支持的I/O多路复用模型，并按照一定规则决定使用哪种模型。</p>

<h4 id="toc_9">1.5.2、时间事件</h4>

<p>通过文件事件一节可以知道，事件循环执行函数aeProcessEvents的主要逻辑：①查找最早会发生的时间事件，计算超时时间；②阻塞等待文件事件的产生；③处理文件事件；④处理时间事件。时间事件的执行函数为processTimeEvents。</p>

<p>Redis服务器内部有很多定时任务需要执行，定时任务被封装为时间事件aeTimeEvent对象，多个时间事件形成链表，存储在aeEventLoop结构体的timeEventHead字段，它指向链表首节点。</p>

<pre><code class="language-c">typedef struct aeTimeEvent {     
    //时间事件唯一ID，通过字段eventLoop-&gt;timeEventNextId实现
    long long id;     
    //时间事件触发的秒数与毫秒数
    long when_sec;     
    long when_ms;    
    //函数指针，指向时间事件处理函数 
    aeTimeProc *timeProc;
    //函数指针，删除时间事件节点之前会调用此函数     
    aeEventFinalizerProc *finalizerProc;     
    //指向对应的客户端对象
    void *clientData;     
    //指向下一个时间事件节点
    struct aeTimeEvent *next; 
} aeTimeEvent;
</code></pre>

<p>函数serverCron实现了Redis服务器所有定时任务的周期执行。serverCron函数的执行时间不能过长，否则会导致服务器不能及时响应客户端的命令请求。</p>

<h2 id="toc_10">2、server启动过程</h2>

<p>Redis服务器的启动过程，主要分为server初始化，监听端口以及等待命令3节。</p>

<p>服务器初始化主流程可以简要分为7个步骤：<br/>
①初始化配置，给配置参数赋初始值，包括用户可配置的参数，以及命令表的初始化；<br/>
②加载并解析配置文件；<br/>
③初始化服务端内部变量，比如客户端链表、数据库、全局变量和共享对象等；<br/>
④创建事件循环eventLoop，即分配结构体所需内存，并初始化结构体各字段；epoll就是在此时创建的；<br/>
⑤创建socket并启动监听，所有创建的socket都会设置为非阻塞模式，原因在于Redis 使用了IO多路复用模式，其要求socket读写必须是非阻塞的，用户可通过指令port配置socket绑定端口号，指令bind配置socket 绑定IP地址；；<br/>
⑥创建文件事件与时间事件；<br/>
⑦开启事件循环，等待文件时间和时间事件发生即可。</p>

<pre><code class="language-c">void aeMain(aeEventLoop *eventLoop) {     
    eventLoop-&gt;stop = 0;     //开始事件循环    
    while (!eventLoop-&gt;stop) {         
        if (eventLoop-&gt;beforesleep != NULL)             
            eventLoop-&gt;beforesleep(eventLoop);         //事件处理主函数  
        aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);     
    }
}
</code></pre>

<pre><code class="language-c">int aeProcessEvents(aeEventLoop *eventLoop, int flags) {
    shortest = aeSearchNearestTimer(eventLoop);     
    long long ms = shortest-&gt;when_sec - now_sec)*1000 + shortest-&gt;when_ms - now_ms;     
    …………    
    //阻塞等待文件事件发生
    numevents = aeApiPoll(eventLoop, tvp);     
    for (j = 0; j &lt; numevents; j++) {         
        aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];         
        //处理文件事件，即根据类型执行rfileProc或wfileProc     
    }     
    //处理时间事件    
    processed += processTimeEvents(eventLoop); 
}
</code></pre>

<p>TCP是基于字节流的可靠传输层协议，为了提升网络利用率，一般默认都会开启Nagle。当应用层调用write函数发送数据时，TCP并不一定会立刻将数据发送出去，根据Nagle算法，还必须满足一定条件才行。</p>

<p>Nagle是这样规定的：如果数据包长度大于一定门限时，则立即发送；如果数据包中含有FIN（表示断开TCP链接）字段，则立即发送；如果当前设置了TCP_NODELAY选项，则立即发送；如果以上所有条件都不满足，则默认需要等待200毫秒超时后才会发送。</p>

<p>TCP是可靠的传输层协议，但每次都需要经历“三次握手”与“四次挥手”，为了提升效率，可以设置SO_KEEPALIVE，即TCP长连接，这样TCP传输层会定时发送心跳包确认该连接的可靠性。</p>

<h2 id="toc_11">3、命令处理过程</h2>

<p>命令的处理过程，此过程分为3个阶段：解析命令请求、调用命令和返回结果给客户端。</p>

<h3 id="toc_12">3.1、命令解析</h3>

<p>TCP是一种基于字节流的传输层通信协议，因此接收到的TCP数据不一定是一个完整的数据包，其有可能是多个数据包的组合，也有可能是某一个数据包的部分，这种现象被称为半包与粘包。</p>

<p>为了区分一个完整的数据包，通常有如下3种方法：①数据包长度固定；②通过特定的分隔符区分，比如HTTP协议就是通过换行符区分的；③通过在数据包头部设置长度字段区分数据包长度，比如FastCGI协议。</p>

<pre><code class="language-text">SET redis-key value1
被翻译为如下结构
*3\r\n$3\r\nSET\r\n$9\r\nredis-key\r\n$6\r\nvalue1\r\n
</code></pre>

<p><strong>Redis 使用自定义格式区分不同的命令，客户端会对命令请求转换为如下的协议格式，其中换行符 <code>\r\n</code> 用于区分命令请求的若干参数，<code>“*3”</code>表示该命令请求有3个参数，<code>“$3”</code>表示第一个参数长度为3，顺序读取三个字符SET ， <code>“$9”</code>表示第二个参数的长度，读取为redis-key ， <code>“$6”</code> 表示第三个参数长度为，读取为value1</strong></p>

<p>Redis服务器接收到的命令请求首先存储在客户端对象的querybuf 输入缓冲区，然后解析命令请求各个参数，并存储在客户端对象的argv（参数对象数组）和argc（参数数目）字段。</p>

<p>客户端命令请求的入口函数为readQueryFromClient，会读取socket数据存储到客户端对象的输入缓冲区，并调用函数processInputBuffer解析命令请求。<br/>
<figure><img src="media/15934396305281/15936857634402.jpg" alt="processInputBuffer解析流程"/><figcaption>processInputBuffer解析流程</figcaption></figure></p>

<h3 id="toc_13">3.2、命令调用</h3>

<p>解析完命令请求之后，会调用函数 processCommand 处理该命令请求，而处理命令请求之前还有很多校验逻辑，比如1、客户端是否已经完成认证，2、命令请求参数是否合法，3、如果是quit命令直接返回并关闭客户端，4、执行函数 lookupCommand 查找命令后，如果命令不存在返回错误等，所有的校验规则通过后，才会调用命令处理函数执行命令。</p>

<p>命令执行完之后，如果有必要，还需要更新统计信息，记录慢查询日志，AOF 持久化该命令请求，传播命令请求给所有的从服务器等。</p>

<pre><code class="language-text">    int processCommand(client *c) {
        ...
            if (c-&gt;flags &amp; CLIENT_MULTI 
                &amp;&amp; c-&gt;cmd-&gt;proc != execCommand 
                &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand 
                &amp;&amp;  c-&gt;cmd-&gt;proc != multiCommand 
                &amp;&amp; c-&gt;cmd-&gt;proc != watchCommand) {
                //如果client有CLIENT_MULTI标志并且不是exec，discard，                                          multi和watch命令，则将该命令放入队列            
                queueMultiCommand(c);        //放入队列            
                addReply(c,shared.queued);         
            } else {                        
                //否则调用call命令            
                call(c,CMD_CALL_FULL);         
                ...
            } 
     ...
    }
    ```

### 3.3、返回结果
Redis服务器返回结果类型不同，协议格式不同，而客户端可以根据返回结果的第一个字符判断返回类型。

Redis的返回结果可以分为5类：
- 状态回复，第一个字符是`“+”`；例如，SET命令执行完毕会向客户端返回`“+OK\r\n”`。
- 错误回复，第一个字符是“-”。例如，当客户端请求命令不存在时，会向客户端返回`“-ERR unknown command&#39;testcmd&#39;”`。
- 整数回复，第一个字符是 “:”。例如，INCR命令执行完毕向客户端返回 `“:100\r\n”`。
- 批量回复，第一个字符是` &quot;$&quot;`。例如，GET命令查找键向客户端返回结果`&quot;$5\r\nhello\r\n&quot;`，其中`$5`表示返回字符串长度
- 多条批量回复，第一个字符是`“*”`。例如，LRANGE命令可能会返回多个值，格式为`“*3\r\n$6\r\nvalue1\r\n$6\r\nvalue2\r\n$6\r\nvalue3\r\n”`，与命令请求协议格式相同，`“*3”`表示返回值数目，`“$6”`表示当前返回值字符串长度。

## 总结
Redis服务器的所有数据库都保存在 redis Server.dib数组中,而数据库的数量则由 redisserver. danum属性保存。

客户端通过修改目标数据库指针,让它指向 redi sserver.db数组中的不同元素来切换不同的数据库。

数据库主要由dict和 expires两个字典构成,其中dict字典负责保存键值对, 而 expires字典则负责保存键的过期时间。

因为数据库由字典构成,所以对数据库的操作都是建立在字典操作之上的。

数据库的健总是一个字符串对象,而值则可以是任意一种 Redis对象类型,包括字符串对象、哈希表对象、集合对象、列表对象和有序集合对象,分别对应字符串键、哈希表键、集合键、列表键和有序集合键。

expires字典的键指向数据库中的某个键,而值则记录了数据库键的过期时间,过期时间是一个以毫秒为单位的UNIX时间戳。

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[二、Redis 底层基本数据结构]]></title>
    <link href="http://www.throne4j.com/15930711977940.html"/>
    <updated>2020-06-25T15:46:37+08:00</updated>
    <id>http://www.throne4j.com/15930711977940.html</id>
    <content type="html"><![CDATA[
<p>Redis  自己实现了底层的数据结构，简单动态字符串、跳跃表、压缩列表、字典、整数集合、quicklist、stream</p>

<table>
<thead>
<tr>
<th>底层数据结构</th>
<th>可存储对象类型</th>
</tr>
</thead>

<tbody>
<tr>
<td>简单动态字符串</td>
<td>字符串</td>
</tr>
<tr>
<td>quickList</td>
<td>列表</td>
</tr>
<tr>
<td>字典</td>
<td>集合、散列表、有序集合</td>
</tr>
<tr>
<td>压缩列表</td>
<td>列表、散列表、有序集合</td>
</tr>
<tr>
<td>整数集合</td>
<td>集合</td>
</tr>
<tr>
<td>跳跃表</td>
<td>有序集合</td>
</tr>
<tr>
<td>stream</td>
<td>stream</td>
</tr>
</tbody>
</table>

<h3 id="toc_0">简单动态字符串 SDS</h3>

<p>简单动态字符串（Simple Dynamic Strings，SDS）是Redis的基本数据结构之一，用于存储字符串和整型数据。SDS兼容C语言标准字符串处理函数，且在此基础上保证了二进制安全。</p>

<pre><code class="language-c">struct __attribute__ ((__packed__))sdshdr5 {     
    unsigned char flags; /* 低3位存储类型, 高5位存储长度 */
    char buf[];/*柔性数组，存放实际内容*/ 
};
struct __attribute__((__packed__))sdshdr8 {     
    uint8_t len; /* 已使用长度，用1字节存储 */    
     uint8_t alloc; /* 总长度，用1字节存储*/     
     unsigned char flags; /* 低3位存储类型, 高5位预留 */    
      char buf[];/*柔性数组，存放实际内容*/ 
};
 struct __attribute__((__packed__))sdshdr16 {    
    uint16_t len; /*已使用长度，用2字节存储*/     
    uint16_t alloc; /* 总长度，用2字节存储*/     
    unsigned char flags; /* 低3位存储类型, 高5位预留 */     
    char buf[];/*柔性数组，存放实际内容*/ 
}; 
struct __attribute__((__packed__))sdshdr32 {     
    uint32_t len; /*已使用长度，用4字节存储*/     
    uint32_t alloc; /* 总长度，用4字节存储*/    
    unsigned char flags;/* 低3位存储类型, 高5位预留 */     
    char buf[];/*柔性数组，存放实际内容*/ 
};
struct __attribute__((__packed__))sdshdr64 {     
    uint64_t len; /*已使用长度，用8字节存储*/     
    uint64_t alloc; /* 总长度，用8字节存储*/     
    unsigned char flags; /* 低3位存储类型, 高5位预留 */     
    char buf[];/*柔性数组，存放实际内容*/ 
};
</code></pre>

<p>(1) SDS如何兼容C语言字符串？如何保证二进制安全？SDS对象中的buf是一个柔性数组，上层调用时，SDS直接返回了buf。由于buf是直接指向内容的指针，故兼容C语言函数。而当真正读取内容时，SDS会通过len来限制读取长度，而非“\0”，保证了二进制安全。<br/>
(2) sdshdr5的特殊之处是什么？sdshdr5只负责存储小于32字节的字符串。一般情况下，小字符串的存储更普遍，故Redis进一步压缩了sdshdr5的数据结构，将sdshdr5的类型和长度放入了同一个属性中，用flags的低3位存储类型，高5位存储长度。创建空字符串时，sdshdr5会被sdshdr8替代。<br/>
(3) SDS是如何扩容的？SDS在涉及字符串修改处会调用sdsMakeroomFor函数进行检查，根据不同情况动态扩容，该操作对上层透明。</p>

<h3 id="toc_1">跳跃表 zskiplist</h3>

<p>通过将有序集合的部分节点分层，由最上层开始依次向后查找，如果本层的next节点大于要查找的值或next节点为NULL，则从本节点开始，降低一层继续向后查找，依次类推，如果找到则返回节点；否则返回NULL。采用该原理查找节点，在节点数量比较多时，可以跳过一些节点，查询效率大大提升，这就是跳跃表的基本思想。</p>

<p>跳跃表存储结构如下图所示：<br/>
<figure><img src="media/15930711977940/15932648695005.jpg" alt="跳跃表存储结构"/><figcaption>跳跃表存储结构</figcaption></figure></p>

<p>接下来看下跳跃表的数据结构 </p>

<pre><code class="language-c">// 定义了skiplist的节点结构
typedef struct zskiplistNode {    
    sds ele;    //用于存储字符串类型的数据
    double score;   //用于存储排序的分支
    struct zskiplistNode *backward;     //后退指针，只能执行当前节点最底层的前一个节点，头节点和第一个节点的backward指向NULL，从后向前遍历跳跃表时使用
    struct zskiplistLevel {
        struct zskiplistNode *forward;      //指向本层下一个节点，尾结点的forward指向null
        unsigned int span;      //forward 指向的节点与本节点之间的元素个数，span越大，跳过的节点个数越多。
    } level[];      // 柔性数组，每个节点的数组长度不一样，在生成跳跃表节点时，随机生成一个 1~64 的值，值越大出现的概率越低
} zskiplistNode;

// 定义了真正的skiplist结构
typedef struct zskiplist {     
    struct zskiplistNode *header, *tail;    // 头指针header和尾指针tail
    unsigned long length;   // 链表长度length，即链表包含的节点总数。创建的skiplist包含一个空的头指针，这个头指针不包含在length计数中
    int level;  //skiplist的总层数，即所有节点层数的最大值
} zskiplist;
</code></pre>

<p>所有节点是按照分值 score 从小到大的方式排序的，当有序集合的 score 相同时，节点会按照 ele 的字典序进行排序。</p>

<h3 id="toc_2">压缩列表 ziplist</h3>

<p>压缩列表ziplist本质上就是一个字节数组(一块连续的内存空间)，是Redis为了节约内存而设计的一种线性数据结构，可以包含多个元素，每个元素可以是一个字节数组或一个整数。ziplist 的存储顺序与插入顺序一致，而散列表的存储则不一致。</p>

<h4 id="toc_3">压缩列表 ziplist 存储结构</h4>

<p>压缩列表 结构示意图如下：<br/>
<figure><img src="media/15930711977940/15932748544287.jpg" alt="" style="width:856px;"/></figure></p>

<ul>
<li>zlbytes： 占4个字节，压缩列表的字节长度，因此压缩列表最多有232 -1个字节。</li>
<li>zltail： 占4个字节,压缩列表尾元素相对于压缩列表起始地址的偏移量。</li>
<li>zllen： 占2个字节,压缩列表的元素个数。zllen无法存储元素个数超过65535（216 -1）的压缩列表，必须遍历整个压缩列表才能获取到元素个数。</li>
<li>entryX： 压缩列表存储的元素，可以是字节数组或者整数，长度不限。</li>
<li>zlend： 占1个字节，压缩列表的结尾，恒为0xFF。</li>
</ul>

<p>查看一个压缩列表示例：</p>

<p><figure><img src="media/15930711977940/15932741442146.jpg" alt="" style="width:888px;"/></figure></p>

<p>了解了压缩列表的基本结构，我们可以很容易地获得压缩列表的字节长度、元素个数等，那么如何遍历压缩列表呢？对于任意一个元素，我们如何判断其存储的是什么类型呢？我们又如何获取字节数组的长度呢？</p>

<p><strong>压缩列表元素</strong>的结构示意图如下所示：<br/>
<figure><img src="media/15930711977940/15932749731815.jpg" alt="" style="width:900px;"/></figure></p>

<p>previous_entry_length 字段表示前一个元素的字节长度，占1个或者5个字节，</p>

<ul>
<li>当前一个元素的长度小于254字节时，用1个字节表示；</li>
<li>当前一个元素的长度大于或等于254字节时，用5个字节来表示。而此时previous_entry_length字段的第1个字节是固定的0xFE，后面4个字节才真正表示前一个元素的长度。<br/>
假设已知当前元素的首地址为p，那么p - previous_entry_length就是前一个元素的首地址，从而实现压缩列表从尾到头的遍历。</li>
</ul>

<p>encoding字段表示当前元素的编码，即content字段存储的数据类型（整数或者字节数组），数据内容存储在content字段。为了节约内存，encoding字段同样长度可变。</p>

<p>压缩列表元素的编码如下表所示：</p>

<table>
<thead>
<tr>
<th>encoding编码</th>
<th>encoding 长度</th>
<th>content类型</th>
</tr>
</thead>

<tbody>
<tr>
<td>00 bbbbbb (6 比特表示content长度)</td>
<td>1字节</td>
<td>最大长度为63的字节数组</td>
</tr>
<tr>
<td>01 bbbbbb xxxxxxxx (14比特表示content 长度)</td>
<td>2字节</td>
<td>最大长度为2<sup>14</sup> -1 的字节数组</td>
</tr>
<tr>
<td>10 aaaaaaaa bbbbbbbb cccccccc dddddddd (32比特表示 content长度)</td>
<td>5字节</td>
<td>最大长度为2<sup>32</sup> -1 的字节数组</td>
</tr>
<tr>
<td>11 00 0000</td>
<td>1字节</td>
<td>int 16整数</td>
</tr>
<tr>
<td>11 01 0000</td>
<td>1字节</td>
<td>int 32整数</td>
</tr>
<tr>
<td>11 10 0000</td>
<td>1字节</td>
<td>int 64整数</td>
</tr>
<tr>
<td>11 11 0000</td>
<td>1字节</td>
<td>24位整数</td>
</tr>
<tr>
<td>11 11 1110</td>
<td>1字节</td>
<td>8位 整数</td>
</tr>
<tr>
<td>11 11 xxxx</td>
<td>1字节</td>
<td>没有 content 字段 xxxx 表示 0~12的整数，数据直接存储在encoding字段的最后4位</td>
</tr>
</tbody>
</table>

<p>Redis 定义的 encoding 字段的各个编码类型：</p>

<pre><code class="language-c">#define ZIP_STR_06B (0 &lt;&lt; 6) 
#define ZIP_STR_14B (1 &lt;&lt; 6) 
#define ZIP_STR_32B (2 &lt;&lt; 6) 
#define ZIP_INT_16B (0xc0 | 0&lt;&lt;4) 
#define ZIP_INT_32B (0xc0 | 1&lt;&lt;4) 
#define ZIP_INT_64B (0xc0 | 2&lt;&lt;4) 
#define ZIP_INT_24B (0xc0 | 3&lt;&lt;4) 
#define ZIP_INT_8B 0xfe
</code></pre>

<p>由于previous_entry_length存储前一个元素的字节长度，长度占1个或5个字节，为了能存储前一个元素的字节长度，在更新压缩列表过程中可能会出现一种被称为“连锁更新”的现象，Redis 在删除和插入元素操作的末尾检查是需要更新后续元素的 previous_entry_length字段，不过其造成性能问题的几率很低</p>

<h4 id="toc_4">压缩列表 ziplist 的结构体</h4>

<p>我们发现对于压缩列表的任意元素，获取前一个元素的长度、判断存储的数据类型、获取数据内容都需要经过复杂的解码运算。解码后的结果应该被缓存起来，为此定义了结构体zlentry，用于表示解码后的压缩列表元素。</p>

<pre><code class="language-c">typedef struct zlentry {
    unsigned int prevrawlensize;    //previous_entry_length 字段的长度
    unsigned int prevrawlen;    //previous_entry_length 字段存储的内容
    unsigned int lensize;   //encoding 字段的长度
    unsigned int len;   //encoding 元素数据内容的长度
    unsigned char encoding;     //encoding中 数据类型
    unsigned int headersize;    // 表示当前元素的首部长度，即previous_entry_lengh字段长度与encoding字段长度之和
    unsigned char *p;   //当前元素首地址
} zlentry;
</code></pre>

<h3 id="toc_5">字典 Dict</h3>

<p>字典又称为散列表，是用来存储键值 (key-value) 对的一种数据结构，Redis 是K-V 型数据库，任何的增删改查操作实际上都是对字典中的数据进行增删改查操作。</p>

<p>Redis 字典实现依赖的数据结构主要包含了三部分：字典、Hash表、Hash表节点。字典中嵌入了两个 Hash 表，Hash 表中的table字段存放 Hash 表节点，Hash 表节点对应存储的是键值对。</p>

<ul>
<li>Hash表的数据结构如下：</li>
</ul>

<pre><code class="language-c">typedef struct dictht {     
    dictEntry **table;                /* 指针数组，用于存储键值对*/     
    unsigned long size;                /* table数组的总大小*/     
    unsigned long sizemask;        /* 掩码 = size - 1 ，用来计算键的索引值*/     
    unsigned long used;                /* table数组已存元素个数，包含next单链表的数据*/ 
} dictht;
</code></pre>

<ul>
<li>Hash 表节点的数据结构如下：</li>
</ul>

<pre><code class="language-c">typedef struct dictEntry {     
    void *key;                        /*存储键*/     
    union {         
        void *val;                        /*redisDb.dict 中的val*/         
        uint64_t u64;         
        int64_t s64;                /*redisDb.expires 中存储过期时间*/         
        double d;     
    } v;
    struct dictEntry *next;        /*当Hash冲突时，指向冲突的元素，形成单链表*/ 
} dictEntry;
</code></pre>

<ul>
<li>最外层的 字典 Dict 数据结构 如下：</li>
</ul>

<pre><code class="language-c">typedef struct dict {     
    dictType *type;           /*该字典对应的一组特定操作抽象函数*/     
    void *privdata;           /*该字典依赖的数据，配合type字段指向的函数一起使用*/     
    dictht ht[2];               /*  Hash 表的数组，键值对存储在这里，一般情况下只会使用ht[0]，只有当盖子点扩容、缩容需要进行rehash ，才会使用到ht[1]*/     
    long rehashidx;            /*rehash标识。默认值为-1，代表没进行rehash操作；不为-1时，代表正进行rehash操作，存储的值表示Hash表ht[0]的rehash操作进行到了哪个索引值*/     
    unsigned long iterators; /* 当前运行的迭代器数*/ 
} dict;
</code></pre>

<p>Redis字典这个数据结构，除了主数据库的K-V数据存储外，还有很多其他地方会用到。例如，Redis的哨兵模式，就用字典存储管理所有的Master节点及Slave节点；再如，数据库中键值对的值为Hash类型时，存储这个Hash类型的值也是用的字典。在不同的应用中，字典中的键值对形态都可能不同，而dictType结构体，则是为了实现各种形态的字典而抽象出来的一组操作函数。</p>

<p>Redis 字典结构的完整版<br/>
<figure><img src="media/15930711977940/15933377033789.jpg" alt=""/></figure></p>

<p><strong><em>在Hash 表扩容或者收缩的时候，程序需要将现有的哈希表中的所有键值对rehash 到新的 Hash表里面，此rehash 过程不是一次性完成的，而是渐进式的完成。</em></strong></p>

<h3 id="toc_6">整数集合</h3>

<p>整数集合 intset 的底层实现为数组， 是一个有序的、无重复数据的、存储整形数据的结构。</p>

<p>在两种情况下，set 集合 底层编码会发生转换：</p>

<ul>
<li>当元素个数超过一定数量(默认值512)之后，即使元素类型仍然是整型，也会将编码转换为 hashtable。由配置项 set-max-intset-entries 512 决定。</li>
<li>当增加非整型变量是，例如集合中增加元素 &#39;a&#39; ，集合编码从 intset 转换为 hashtable。</li>
</ul>

<p>整数集合在Redis 中可以保存 int16_t、int32_t、int64_t类型的整型数据，并且可以保证集合中<strong>不会出现重复数据</strong>。每个整数集合使用一个 intset 类型的数据结构表示。<br/>
intset 数据结构如下：<br/>
<figure><img src="media/15930711977940/15934343810923.jpg" alt=""/></figure></p>

<pre><code class="language-c">typedef struct intset {     
    uint32_t encoding;//编码类型    
    uint32_t length;//元素个数    
    int8_t contents[];//柔性数组,根据encoding字段决定几个字节表示一个元素
} intset
</code></pre>

<ul>
<li>encoding<br/>
编码类型，决定每个元素占用几个字节
<ul>
<li>INTSET_ENC_INT16：当元素值都位于INT16_MIN和INT16_MAX之间时使用。该编码方式为每个元素占用2个字节。</li>
<li>INTSET_ENC_INT32：当元素值位于INT16_MAX到INT32_MAX或者INT32_MIN到INT16_MIN之间时使用。该编码方式为每个元素占用4个字节。</li>
<li>INTSET_ENC_INT64：当元素值位于INT32_MAX到INT64_MAX或者INT64_MIN到INT32_MIN之间时使用。该编码方式为每个元素占用8个字节。</li>
</ul></li>
</ul>

<p>当 存放新元素到 整数集合中的时候，如果新元素的类型比整数集合现有所有元素的类型都要长时，整数集合需要先进性升级，然后才能将新元素添加到整数集合里面。</p>

<p>整数集合的升级操作提升了它的灵活性又尽可能的节约了内存空间。</p>

<h3 id="toc_7">quicklist</h3>

<h4 id="toc_8">quicklist 存储数据结构</h4>

<p>quicklist是Redis底层最重要的数据结构之一，它是Redis对外提供的6种基本数据结构中List的底层实现。</p>

<ul>
<li><p>list<br/>
链表是这样一种数据结构，其中的各对象按线性顺序排列。<br/>
链表与数组的不同点在于，数组的顺序由下标决定，链表的顺序由对象中的指针决定。<br/>
List是链型数据存储常用的数据结构，可以是单向链表、双向链表，可以是排序链表、无序链表，可以是循环链表、非循环链表。<br/>
链表具有可快速插入、删除的优点。<br/>
由于List查找复杂度为O(n)，n为元素个数，所以不适用于快速查找的场合。<br/>
双向非循环链表结构图：<br/>
<figure><img src="media/15930711977940/15937659545835.jpg" alt=""/></figure></p></li>
<li><p>quicklist<br/>
quicklist是Redis 3.2中新引入的数据结构，能够在时间效率和空间效率间实现较好的折中。<br/>
<strong>quicklist是一个由 ziplist 充当节点的双向链表</strong>。quicklist是一个双向链表，链表中的每个节点是一个 ziplist 结构。<br/>
quicklist可以看成是用双向链表将若干小型的ziplist连接到一起组成的一种数据结构。<br/>
当ziplist节点个数过多，quicklist退化为双向链表，一个极端的情况就是每个ziplist节点只包含一个entry，即只有一个元素。当ziplist元素个数过少时，quicklist可退化为ziplist，一种极端的情况就是quicklist中只有一个ziplist节点。</p></li>
</ul>

<p><figure><img src="media/15930711977940/15934465912385.jpg" alt=""/></figure></p>

<p>quicklist核心结构如下：</p>

<pre><code class="language-c">typedef struct quicklist {     
    quicklistNode *head;     // 头节点
    quicklistNode *tail;     // 尾节点
    unsigned long count;        //quicklist中元素总数 
    unsigned long len;          // quicklistNode节点个数   
    //指明每个quickListNade 中ziplist长度
    //当fill为正数时，表明每个ziplist最多含有的数据项数。
    //当fill为负数时，fill == -1 ：ziplist节点最大为 4KB；
    //fill == -2 ：ziplist节点最大为8KB； 
    //fill == -3 ：ziplist节点最大为16KB；
    //fill == -4 ：ziplist节点最大为32KB；
    //fill == -5 ：ziplist节点最大为64KB
    int fill : 16;        
     //Redis允许对中间的quicklistNode节点进行压缩，
     //通过修改参数list-compress-depth进行配置，即设置compress参数
     //该项的具体含义是两端各有compress个节点不压缩 ,  
     //通过修改参数list-compress-depth进行配置，0=off          
    unsigned int compress : 16; 
} quicklist;

typedef struct quicklistNode {     
    struct quicklistNode *prev;     // 指向该节点的前节点
    struct quicklistNode *next;     // 指向该节点的后节点
    unsigned char *zl;      //指向该节点对应的 ziplist 结构
    unsigned int sz;        //代表整个 ziplist 结构的大小
    unsigned int count : 16;        // ziplist 中元素个数
    unsigned int encoding : 2;      //代表采用的编码，1：原生结构；2：使用 LZF 进行压缩    
    unsigned int container : 2;     //为quicklistNode节点 zl 指向的容器类型，1: none；2: 使用 ziplist 存储数据    
    unsigned int recompress : 1;    // 这个节点之前是否是压缩节点，若是，则在使用压缩节点前新进行解压缩，使用后需要重新压缩；1的时候代表是压缩节点。
    unsigned int attempted_compress : 1;        // 测试时使用，   
    unsigned int extra : 10;     //预留字段 
} quicklistNode;

/* 当对 ziplist 利用 LZF 算法进行压缩时，quicklistNode 节点指向的结构为 quicklistLZF*/
typedef struct quicklistLZF {     
    unsigned int sz;    // compressed 所占用的 字节大小     
    char compressed[]; 
} quicklistLZF;

/* 当使用quicklistNode中ziplist中的一个节点时，Redis提供了quicklistEntry结构以便于使用 */
typedef struct quicklistEntry {     
    const quicklist *quicklist;     // 指向当前元素所在的quicklist
    quicklistNode *node;     // 指向当前元素所在的quicklistNode结构
    unsigned char *zi;     // 指向当前元素所在的ziplist
    unsigned char *value;    // 指向该节点的字符串内容
    long long longval;     // longval为该节点的整型值
    unsigned int sz;     // sz代表该节点的大小，与value配合使用
    int offset;     // 表明该节点相对于整个ziplist的偏移量，即该节点是ziplist第多少个entry
} quicklistEntry;

// quicklistIter是quicklist中用于遍历的迭代器
typedef struct quicklistIter {     
    const quicklist *quicklist;     //指向当前元素所处的quicklist
    quicklistNode *current;     // 指向元素所在quicklistNode
    unsigned char *zi;     // 指向元素所在的ziplist
    long offset;    // 表明节点在所在的ziplist中的偏移量     
    int direction;  //direction表明迭代器的方向
} quicklistIter;
</code></pre>

<h4 id="toc_9">数据压缩</h4>

<p>quicklist每个节点的实际数据存储结构为ziplist，这种结构的主要优势在于节省存储空间。</p>

<p>为了进一步降低ziplist所占用的空间，Redis 允许对ziplist进一步压缩，Redis采用的压缩算法是LZF，压缩过后的数据可以分成多个片段，每个片段有2部分：一部分是解释字段，另一部分是存放具体的数据字段。解释字段可以占用1～3个字节，数据字段可能不存在。</p>

<p>LZF压缩后的数据结构图如下所示：<br/>
<figure><img src="media/15930711977940/15935992099183.jpg" alt="LZF压缩后的数据结构"/><figcaption>LZF压缩后的数据结构</figcaption></figure></p>

<p>LZF压缩的数据格式有3种，即解释字段有3种：</p>

<ul>
<li><p>字面型，解释字段占用1个字节，数据字段长度由解释字段后5位决定。<br/>
<figure><img src="media/15930711977940/15937674478317.jpg" alt=""/></figure></p></li>
<li><p>简短重复型，解释字段占用2个字节，没有数据字段，数据内容与前面数据内容重复，重复长度小于8，图中L 是长度字段，数据长度为长度字段的字面值加2，o是偏移量字段，位置偏移量是偏移字段组成的字面值加1。<br/>
<figure><img src="media/15930711977940/15937678687562.jpg" alt=""/></figure></p></li>
<li><p>批量重复型，解释字段占3个字节，没有数据字段，数据内容与前面内容重复。图中L是长度字段，数据长度为长度字段的字面值加9，o是偏移量字段，位置偏移量是偏移字段组成的字面值加1。<br/>
<figure><img src="media/15930711977940/15937679218472.jpg" alt=""/></figure></p></li>
</ul>

<h4 id="toc_10">压缩</h4>

<p>LZF数据压缩的基本思想是：数据与前面重复的，记录重复位置以及重复长度，否则直接记录原始数据内容。</p>

<p>压缩算法的流程如下：遍历输入字符串，对当前字符及其后面2个字符进行散列运算，如果在Hash表中找到曾经出现的记录，则计算重复字节的长度以及位置，反之直接输出数据。</p>

<h4 id="toc_11">解压缩</h4>

<p>根据LZF压缩后的数据格式，我们可以较为容易地实现LZF的解压缩。值得注意的是，可能存在重复数据与当前位置重叠的情况，此时需要按位逐个进行复制。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一、Redis快速入门]]></title>
    <link href="http://www.throne4j.com/15929223279523.html"/>
    <updated>2020-06-23T22:25:27+08:00</updated>
    <id>http://www.throne4j.com/15929223279523.html</id>
    <content type="html"><![CDATA[
<p>此 Redis服务 采用 5.0+版本</p>

<h2 id="toc_0">redis简介</h2>

<p>redis是一个使用ANSI C语言编写的开源的基于内存的key-value高性能非关系型缓存数据库，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询，stream。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。</p>

<h3 id="toc_1">Redis5.0版本新特性</h3>

<ul>
<li>新增Streams数据类型，可以把 Streams 当做消息队列</li>
<li>新的模块 API 、定时器、集群集资点</li>
<li>RDB 中持久化存储 LFU 和 LRU 的信息</li>
<li>将集群管理功能完全用C语言集成到 redis-cli 中</li>
<li> 有序集合新增命令 zpopmin/zpopmax</li>
<li> 改进HyperLogLogs实现</li>
<li> 新增 client unblock 和 client id</li>
<li> 新增 lolwut 命令</li>
<li> Redis主从复制中的从 不在成为Slaves，改称 Replicas</li>
<li>引入动态哈希，一平衡 CPU 的利用率和相应性能，可以通过配置文件进行配置</li>
<li>Redis 核心代码新型了部分重构和优化</li>
</ul>

<h2 id="toc_2">Redis 可执行文件介绍</h2>

<table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>redis-server</td>
<td>启动redis</td>
</tr>
<tr>
<td>redis-cli</td>
<td>redis命令行客户端</td>
</tr>
<tr>
<td>redis-benchmark</td>
<td>基准测试工具</td>
</tr>
<tr>
<td>redis-check-aof</td>
<td>AOF持久化文件检测和修复工具</td>
</tr>
<tr>
<td>redis-check-rdb</td>
<td>RDB持久化文件检测和修复工具</td>
</tr>
<tr>
<td>redis-sentinel</td>
<td>启动哨兵</td>
</tr>
<tr>
<td>redis-trib</td>
<td>cluster集群构建工具</td>
</tr>
</tbody>
</table>

<h2 id="toc_3">为什么使用 Redis</h2>

<ul>
<li>读写速度快<br/>
数据存放在内存中，官方给出的读写性能可达到 10w/s
<ul>
<li>数据存放在内存中是速度快的主要原因</li>
<li>C语言实现，与操作系统的距离近</li>
<li>Redis 数据结构是专门设计的，增删改查等操作相对简单</li>
<li>使用了单线程架构
<ul>
<li>避免多线程可能产生的线程切换和竞争产生的资源消耗；</li>
<li>采用多路复用IO模型（select、poll、epoll）可以高效的处理大量并发连接；<br/>
Redis 命令的执行过程： 发送指令 --&gt; 执行指令 --&gt; 返回结果；<br/>
执行指令： 单线程执行，所有的指令进入队列，按顺序执行，使用I/O多路复用技术解决一个线程处理多个连接的问题。</li>
</ul></li>
</ul></li>
<li>键值对的value不仅可以是字符串，还可以是复杂的数据类型，如链表、集合、散列表等<br/></li>
<li>丰富的功能  发布订阅、主从复制、持久化、脚本、事务等功能</li>
<li>支持数据持久化，可以采用RDB、AOF、RDB&amp;AOF三种方案。计算机重启后可以在磁盘中进行数据恢复。 <br/>
发生断电或机器故障，数据可能会丢失，持久化到磁盘</li>
<li> 支持主从结构，可以利用从库进行数据备份<br/>
实现了多个相同数据的Redis副本，提高了系统的健壮性</li>
<li>高可用和分布式<br/>
哨兵机制实现高可用，保证redis节点故障发现和自动转移</li>
<li>有多种语言的客户端</li>
</ul>

<h2 id="toc_4">Redis与其他数据库之间的比较</h2>

<table>
<thead>
<tr>
<th>名称</th>
<th>类型</th>
<th>存储数据类型</th>
<th>查询类型</th>
<th>附加功能</th>
</tr>
</thead>

<tbody>
<tr>
<td>redis</td>
<td>使用内存存储的非关系型数据库</td>
<td>字符串、列表、散列表、集合、有序集合</td>
<td>每种数据类型都有自己专属命令，另外还有批量操作和不完全的事务支持</td>
<td>发布订阅、主从复制、持久化、脚本(存储过程)</td>
</tr>
<tr>
<td>memcached</td>
<td>使用内存存储的键值缓存</td>
<td>键值之间的映射</td>
<td>创建、读取、更新、删除以及其他几个命令</td>
<td>为提升性能而设计的多线程服务器</td>
</tr>
<tr>
<td>MySql</td>
<td>关系型数据库</td>
<td>每个数据库可以包含多个表，每个表可以包含多行，可以处理多表视图，支持空间和第三方支持</td>
<td>insert、select、update、delete、函数、存储过程</td>
<td>支持ACID性质、主从复制、多主复制</td>
</tr>
<tr>
<td>MongoDB</td>
<td>使用硬盘存储的非关系的文档存储</td>
<td>每个数据库可以包含多个表，每个表可以包含无schema的BSON文档</td>
<td>创建、读取、更新、删除、条件查询命令</td>
<td>支持map-reduce操作、主从复制、分片、空间索引</td>
</tr>
</tbody>
</table>

<h2 id="toc_5">Redis的使用场景</h2>

<p>redis的应用场景可以肆意的发挥想象力，以下是Redis 较为适用的一些场景</p>

<ul>
<li>缓存<br/>
例如session缓存、全页缓存、合理使用缓存加快数据访问速度，降低后端数据源压力</li>
<li>排行榜<br/>
按照热度、发布时间排行，主要用到列表和有序集合</li>
<li>计数器  网站的浏览数等</li>
<li>社交网络</li>
<li>消息队列  发布订阅</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[]]></title>
    <link href="http://www.throne4j.com/15929200774650.html"/>
    <updated>2020-06-23T21:47:57+08:00</updated>
    <id>http://www.throne4j.com/15929200774650.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[布隆过滤器原理]]></title>
    <link href="http://www.throne4j.com/15928436000448.html"/>
    <updated>2020-06-23T00:33:20+08:00</updated>
    <id>http://www.throne4j.com/15928436000448.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[java 语法树]]></title>
    <link href="http://www.throne4j.com/15925048146279.html"/>
    <updated>2020-06-19T02:26:54+08:00</updated>
    <id>http://www.throne4j.com/15925048146279.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005]]></title>
    <link href="http://www.throne4j.com/15925030861213.html"/>
    <updated>2020-06-19T01:58:06+08:00</updated>
    <id>http://www.throne4j.com/15925030861213.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM 类加载机制]]></title>
    <link href="http://www.throne4j.com/15922073766854.html"/>
    <updated>2020-06-15T15:49:36+08:00</updated>
    <id>http://www.throne4j.com/15922073766854.html</id>
    <content type="html"><![CDATA[
<p>JVM 类加载机制分为五个部分<br/>
<figure><img src="media/15922073766854/15922110200798.jpg" alt=""/></figure></p>

<h2 id="toc_0">加载</h2>

<p>在内存中生成一个代表这个类的java.lang.Class对象，作为方法去这个类的各种数据的入口。<br/>
此阶段完成三件事。</p>

<ul>
<li>通过一个类的全限定名来获取定义此类的二进制字节流(可以来自zip、war等压缩包，网络，动态生成，数据库等)。</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构</li>
<li>在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。</li>
</ul>

<p>加载阶段既可以使用Java虚拟机里内置的引导类加载器来完成，也可以由用户自定义的类加载器去完成。</p>

<p>对于数组类而言，情况就有所不同，数组类本身不通过类加载器创建，它是由Java虚拟机直接在 内存中动态构造出来的。但是数组的元素类型还是需要通过类加载器来完成加载。</p>

<ul>
<li>如果数组的组件类型是引用类型，那就递归采用本节中定义的加载过程去加载这个组件类型，数组C将被标 识在加载该组件类型的类加载器的类名称空间上(一个类型必须与类加 载器一起确定唯一性)</li>
<li>如果数组的组件类型不是引用类型(例如int[]数组的组件类型为int)，Java虚拟机将会把数组C标记为与引导类加载器关联。</li>
<li>数组类的可访问性与它的组件类型的可访问性一致，如果组件类型不是引用类型，它的数组类的可访问性将默认为public，可被所有的类和接口访问到。</li>
</ul>

<h2 id="toc_1">验证</h2>

<p>确保Class文件的字节流中包含的信息是否符合当前虚拟机要求.</p>

<ul>
<li>class文件格式验证</li>
<li><p>元数据验证</p>
<ul>
<li>这个类是否有父类(除了java.lang.Object之外，所有的类都应当有父类)。</li>
<li>这个类的父类是否继承了不允许被继承的类(被final修饰的类)。</li>
<li>如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法。</li>
<li>类中的字段、方法是否与父类产生矛盾(例如覆盖了父类的final字段，或者出现不符合规则的方 法重载，例如方法参数都一致，但返回值类型却不同等)。</li>
</ul></li>
<li><p>字节码验证<br/>
主要目的是通过数据流分析和控制流分析，确定 程序语义是合法的、符合逻辑的</p></li>
<li><p>符号引用验证</p>
<ul>
<li>符号引用中通过字符串描述的全限定名是否能找到对应的类。</li>
<li>在指定类中是否存在符合方法的字段描述符及简单名称所描述的方法和字段。</li>
<li>符号引用中的类、字段、方法的可访问性(private、protected、public、<package>)是否可被当 前类访问。<br/>
阶段的校验行为发生在虚拟机将符号引用转化为直接引用[3]的时候，这个转化动作将在 连接的第三阶段——解析阶段中发生,此阶段的目的是保证解析能够正常执行。</li>
</ul></li>
</ul>

<h2 id="toc_2">准备</h2>

<p>准备阶段是正式为类中定义的<strong>变量(即静态变量，被static修饰的变量)分配内存并设置类变量初始值</strong>的阶段。</p>

<p><strong><em>注意</em></strong> ： 关于准备阶段，还有两个容易产生混淆的概念笔者需要着重强调，首先是这时候进行内存分配的 仅包括类变量，而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次是这里所说的初始值“通常情况”下是数据类型的零值，</p>

<h2 id="toc_3">解析</h2>

<p>虚拟机将常量池中的符号引用替换为直接引用的过程</p>

<ul>
<li><p>符号引用<br/>
符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可（class文件中的CONSTANT_CLASS_INFO、CONSTANT_FIELD_INFO、CONSTANT_METHOD_INFO等类型的常量），符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。<br/>
各种虚拟机实现的内存布局可以各不相同，但是他们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在java虚拟机规范的Class文件格式中</p></li>
<li><p>直接引用：可以是执行目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那么引用的目标必定已经存在于内存中。</p></li>
</ul>

<h2 id="toc_4">初始化</h2>

<p>类加载阶段 的最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都有jvm主导，到了初始化阶段，才开始真正执行类中定义的java程序代码。</p>

<p>初始化阶段是执行类构造器<client>方法的过程。<client>方法是由编译器自动收集类中的类变 量的赋值操作和静态语句块中的语句合并而成的。<strong>虚拟机会保证子<client>方法执行之前，父类 的<client>方法已经执行完毕</strong></p>

<h3 id="toc_5">有且只有以下<strong>六种对类型进行主动引用的情况需要立即对类进行初始化</strong>：</h3>

<ul>
<li><p>遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果类型没有进行过初始化，则需要先出法器初始化阶段。</p>
<ul>
<li>使用new关键字实例化对象的时候</li>
<li>读取或设置一个类型的静态字段(被final修饰、已在编译器把结果放入常量池的静态字段除外)的时候</li>
<li><strong>调用一个类型的静态方法的时候</strong></li>
</ul></li>
<li><p>使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发器初始化</p></li>
<li><p>当初始化类的时候，如果发现其父类没有进行过初始化，则需要先触发其父类的初始化</p></li>
<li><p>当虚拟机启动时，用户需要制定一个要执行的主类(包含main()方法的哪个类)，虚拟机会先初始化这个主类</p></li>
<li><p>当使用 jdk7 新加入的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic、REF_p utStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，需要先触发其初始化</p></li>
<li><p>当一个接口中定义了jdk8新加入的默认方法(被default关键字修饰的接口方法)时，如果有这个接口的实现类发生了初始化，那该接口在其之前被初始化。</p></li>
</ul>

<hr/>

<h3 id="toc_6">以下几种 对类型的被动引用情况不会执行类初始化：</h3>

<ul>
<li>通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化</li>
<li>通过对象数组，不会触发该类的初始化</li>
<li>常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类</li>
<li>通过类名获取Class对象，不会触发类的初始化</li>
<li>通过Class.forName加载指定类是，如果指定参数 initialize 为 false 时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化</li>
<li>通过ClassLoader 默认的 loadClass 方法，也不会触发初始化动作。</li>
</ul>

]]></content>
  </entry>
  
</feed>
